{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b314c438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取otto-recommender-system\n",
      "正在爬取tabular-playground-series-nov-2022\n",
      "正在爬取scrabble-player-rating\n",
      "正在爬取nfl-big-data-bowl-2023\n",
      "正在爬取kaggle-survey-2022\n",
      "正在爬取g2net-detecting-continuous-gravitational-waves\n",
      "正在爬取lux-ai-2022-beta\n",
      "正在爬取tabular-playground-series-oct-2022\n",
      "正在爬取novozymes-enzyme-stability-prediction\n",
      "正在爬取tabular-playground-series-sep-2022\n",
      "正在爬取feedback-prize-english-language-learning\n",
      "正在爬取open-problems-multimodal\n",
      "正在爬取ai-village-ctf\n",
      "正在爬取big-data-derby-2022\n",
      "正在爬取tabular-playground-series-aug-2022\n",
      "正在爬取dfl-bundesliga-data-shootout\n",
      "正在爬取rsna-2022-cervical-spine-fracture-detection\n",
      "正在爬取google-universal-image-embedding\n",
      "正在爬取mayo-clinic-strip-ai\n",
      "正在爬取tabular-playground-series-jul-2022\n",
      "正在爬取hubmap-organ-segmentation\n",
      "正在爬取tabular-playground-series-jun-2022\n",
      "正在爬取amex-default-prediction\n",
      "正在爬取feedback-prize-effectiveness\n",
      "正在爬取AI4Code\n",
      "正在爬取smartphone-decimeter-2022\n",
      "正在爬取tabular-playground-series-may-2022\n",
      "正在爬取uw-madison-gi-tract-image-segmentation\n",
      "正在爬取foursquare-location-matching\n",
      "正在爬取kore-2022\n",
      "正在爬取jpx-tokyo-stock-exchange-prediction\n",
      "正在爬取image-matching-challenge-2022\n",
      "正在爬取tabular-playground-series-apr-2022\n",
      "正在爬取us-patent-phrase-to-phrase-matching\n",
      "正在爬取iwildcam2022-fgvc9\n",
      "正在爬取kore-2022-beta\n",
      "正在爬取hotel-id-to-combat-human-trafficking-2022-fgvc9\n",
      "正在爬取sorghum-id-fgvc-9\n",
      "正在爬取geolifeclef-2022-lifeclef-2022-fgvc9\n",
      "正在爬取phase-ii-widsdatathon2022\n",
      "正在爬取tabular-playground-series-mar-2022\n",
      "正在爬取spaceship-titanic\n",
      "正在爬取mens-march-mania-2022\n",
      "正在爬取womens-march-mania-2022\n",
      "正在爬取birdclef-2022\n",
      "正在爬取herbarium-2022-fgvc9\n",
      "正在爬取h-and-m-personalized-fashion-recommendations\n",
      "正在爬取nbme-score-clinical-patient-notes\n",
      "正在爬取happy-whale-and-dolphin\n",
      "正在爬取tabular-playground-series-feb-2022\n",
      "正在爬取ubiquant-market-prediction\n",
      "正在爬取tabular-playground-series-jan-2022\n",
      "正在爬取feedback-prize-2021\n",
      "正在爬取tabular-playground-series-dec-2021\n",
      "正在爬取tensorflow-great-barrier-reef\n",
      "https://www.kaggle.com/competitions/santa-2021\n",
      "https://www.kaggle.com/competitions/jigsaw-toxic-severity-rating\n",
      "正在爬取g-research-crypto-forecasting\n",
      "正在爬取tabular-playground-series-nov-2021\n",
      "正在爬取sartorius-cell-instance-segmentation\n",
      "正在爬取kaggle-survey-2021\n",
      "正在爬取store-sales-time-series-forecasting\n",
      "正在爬取tabular-playground-series-oct-2021\n",
      "正在爬取nfl-big-data-bowl-2022\n",
      "正在爬取petfinder-pawpularity-score\n",
      "正在爬取ventilator-pressure-prediction\n",
      "正在爬取wikipedia-image-caption\n",
      "正在爬取tabular-playground-series-sep-2021\n",
      "正在爬取lux-ai-2021\n",
      "正在爬取chaii-hindi-and-tamil-question-answering\n",
      "正在爬取landmark-retrieval-2021\n",
      "正在爬取landmark-recognition-2021\n",
      "正在爬取nfl-health-and-safety-helmet-assignment\n",
      "正在爬取learnplatform-covid19-impact-on-digital-learning\n",
      "正在爬取tabular-playground-series-aug-2021\n",
      "正在爬取rsna-miccai-brain-tumor-radiogenomic-classification\n",
      "正在爬取tabular-playground-series-jul-2021\n",
      "正在爬取g2net-gravitational-wave-detection\n",
      "正在爬取optiver-realized-volatility-prediction\n",
      "正在爬取mlb-player-digital-engagement-forecasting\n",
      "正在爬取tabular-playground-series-jun-2021\n",
      "正在爬取siim-covid19-detection\n",
      "正在爬取google-smartphone-decimeter-challenge\n",
      "正在爬取seti-breakthrough-listen\n",
      "正在爬取commonlitreadabilityprize\n",
      "正在爬取tabular-playground-series-may-2021\n",
      "正在爬取birdclef-2021\n",
      "正在爬取tabular-playground-series-apr-2021\n",
      "正在爬取coleridgeinitiative-show-us-the-data\n",
      "正在爬取plant-pathology-2021-fgvc8\n",
      "正在爬取hotel-id-2021-fgvc8\n",
      "正在爬取iwildcam2021-fgvc8\n",
      "正在爬取herbarium-2021-fgvc8\n",
      "正在爬取shopee-product-matching\n",
      "正在爬取bms-molecular-translation\n",
      "正在爬取tabular-playground-series-mar-2021\n",
      "正在爬取ncaam-march-mania-2021-spread\n",
      "正在爬取ncaaw-march-mania-2021-spread\n",
      "正在爬取ncaaw-march-mania-2021\n",
      "正在爬取ncaam-march-mania-2021\n",
      "正在爬取hashcode-2021-oqr-extension\n",
      "正在爬取tabular-playground-series-feb-2021\n",
      "正在爬取indoor-location-navigation\n",
      "正在爬取hpa-single-cell-image-classification\n",
      "正在爬取hungry-geese\n",
      "正在爬取tabular-playground-series-jan-2021\n",
      "正在爬取vinbigdata-chest-xray-abnormalities-detection\n",
      "正在爬取ranzcr-clip-catheter-line-classification\n",
      "正在爬取acea-water-prediction\n",
      "正在爬取santa-2020\n",
      "正在爬取jane-street-market-prediction\n",
      "正在爬取cassava-leaf-disease-classification\n",
      "正在爬取kaggle-survey-2020\n",
      "正在爬取rfcx-species-audio-detection\n",
      "正在爬取hubmap-kidney-segmentation\n",
      "正在爬取nfl-impact-detection\n",
      "正在爬取rock-paper-scissors\n",
      "正在爬取nfl-big-data-bowl-2021\n",
      "正在爬取cdp-unlocking-climate-solutions\n",
      "正在爬取predict-volcanic-eruptions-ingv-oe\n",
      "正在爬取riiid-test-answer-prediction\n",
      "正在爬取google-football\n",
      "正在爬取halite-iv-playground-edition\n",
      "正在爬取stanford-covid-vaccine\n",
      "正在爬取rsna-str-pulmonary-embolism-detection\n",
      "正在爬取hashcode-drone-delivery\n",
      "正在爬取lish-moa\n",
      "正在爬取conways-reverse-game-of-life-2020\n",
      "正在爬取gan-getting-started\n",
      "正在爬取lyft-motion-prediction-autonomous-vehicles\n",
      "正在爬取contradictory-my-dear-watson\n",
      "正在爬取landmark-recognition-2020\n",
      "正在爬取osic-pulmonary-fibrosis-progression\n",
      "正在爬取landmark-retrieval-2020\n",
      "正在爬取tpu-getting-started\n",
      "正在爬取birdsong-recognition\n",
      "正在爬取halite\n",
      "正在爬取siim-isic-melanoma-classification\n",
      "正在爬取trec-covid-information-retrieval\n",
      "正在爬取open-images-instance-segmentation-rvc-2020\n",
      "正在爬取open-images-object-detection-rvc-2020\n",
      "正在爬取covid19-global-forecasting-week-5\n",
      "正在爬取global-wheat-detection\n",
      "正在爬取alaska2-image-steganalysis\n",
      "正在爬取hashcode-photo-slideshow\n",
      "正在爬取trends-assessment-prediction\n",
      "正在爬取prostate-cancer-grade-assessment\n",
      "正在爬取covid19-global-forecasting-week-4\n",
      "正在爬取covid19-global-forecasting-week-3\n",
      "正在爬取imet-2020-fgvc7\n",
      "正在爬取covid19-global-forecasting-week-2\n",
      "正在爬取tweet-sentiment-extraction\n",
      "正在爬取jigsaw-multilingual-toxic-comment-classification\n",
      "正在爬取imaterialist-fashion-2020-fgvc7\n",
      "正在爬取covid19-global-forecasting-week-1\n",
      "正在爬取covid19-local-us-ca-forecasting-week-1\n",
      "正在爬取plant-pathology-2020-fgvc7\n",
      "正在爬取iwildcam-2020-fgvc7\n",
      "正在爬取herbarium-2020-fgvc7\n",
      "正在爬取m5-forecasting-accuracy\n",
      "正在爬取m5-forecasting-uncertainty\n",
      "正在爬取liverpool-ion-switching\n",
      "正在爬取march-madness-analytics-2020\n",
      "正在爬取google-cloud-ncaa-march-madness-2020-division-1-mens-tournament\n",
      "正在爬取google-cloud-ncaa-march-madness-2020-division-1-womens-tournament\n",
      "正在爬取abstraction-and-reasoning-challenge\n",
      "正在爬取ds4g-environmental-insights-explorer\n",
      "正在爬取flower-classification-with-tpus\n",
      "正在爬取connectx\n",
      "正在爬取cat-in-the-dat-ii\n",
      "正在爬取santa-2019-revenge-of-the-accountants\n",
      "https://www.kaggle.com/competitions/nlp-getting-started\n",
      "正在爬取bengaliai-cv19\n",
      "正在爬取deepfake-detection-challenge\n",
      "正在爬取santa-workshop-tour-2019\n",
      "正在爬取nfl-playing-surface-analytics\n",
      "正在爬取google-quest-challenge\n",
      "正在爬取kaggle-survey-2019\n",
      "正在爬取tensorflow2-question-answering\n",
      "正在爬取data-science-bowl-2019\n",
      "正在爬取pku-autonomous-driving\n",
      "正在爬取ashrae-energy-prediction\n",
      "正在爬取nfl-big-data-bowl-2020\n",
      "正在爬取Kannada-MNIST\n",
      "正在爬取rsna-intracranial-hemorrhage-detection\n",
      "正在爬取bigquery-geotab-intersection-congestion\n",
      "正在爬取3d-object-detection-for-autonomous-vehicles\n",
      "正在爬取cat-in-the-dat\n",
      "正在爬取understanding_cloud_organization\n",
      "正在爬取ciphertext-challenge-iii\n",
      "正在爬取severstal-steel-defect-detection\n",
      "正在爬取kuzushiji-recognition\n",
      "正在爬取ieee-fraud-detection\n",
      "正在爬取open-images-2019-instance-segmentation\n",
      "正在爬取generative-dog-images\n",
      "正在爬取aptos2019-blindness-detection\n",
      "正在爬取recursion-cellular-image-classification\n",
      "正在爬取youtube8m-2019\n",
      "正在爬取siim-acr-pneumothorax-segmentation\n",
      "正在爬取open-images-2019-object-detection\n",
      "正在爬取open-images-2019-visual-relationship\n",
      "正在爬取champs-scalar-coupling\n",
      "正在爬取instant-gratification\n",
      "正在爬取recognizing-faces-in-the-wild\n",
      "正在爬取data-science-for-good-city-of-los-angeles\n",
      "正在爬取imaterialist-fashion-2019-FGVC6\n",
      "正在爬取landmark-recognition-2019\n",
      "正在爬取landmark-retrieval-2019\n",
      "正在爬取freesound-audio-tagging-2019\n",
      "正在爬取inaturalist-2019-fgvc6\n",
      "正在爬取jigsaw-unintended-bias-in-toxicity-classification\n",
      "正在爬取imet-2019-fgvc6\n",
      "正在爬取ciphertext-challenge-ii\n",
      "正在爬取iwildcam-2019-fgvc6\n",
      "正在爬取career-con-2019\n",
      "正在爬取aerial-cactus-identification\n",
      "正在爬取data-science-for-good-careervillage\n",
      "正在爬取mens-machine-learning-competition-2019\n",
      "正在爬取womens-machine-learning-competition-2019\n",
      "正在爬取santander-customer-transaction-prediction\n",
      "正在爬取dont-overfit-ii\n",
      "正在爬取tmdb-box-office-prediction\n",
      "正在爬取gendered-pronoun-resolution\n",
      "正在爬取LANL-Earthquake-Prediction\n",
      "正在爬取petfinder-adoption-prediction\n",
      "正在爬取vsb-power-line-fault-detection\n",
      "正在爬取reducing-commercial-aviation-fatalities\n",
      "正在爬取20-newsgroups-ciphertext-challenge\n",
      "正在爬取microsoft-malware-prediction\n",
      "正在爬取NFL-Punt-Analytics-Competition\n",
      "正在爬取humpback-whale-identification\n",
      "正在爬取elo-merchant-category-recommendation\n",
      "正在爬取dont-call-me-turkey\n",
      "正在爬取traveling-santa-2018-prime-paths\n",
      "正在爬取histopathologic-cancer-detection\n",
      "正在爬取quora-insincere-questions-classification\n",
      "正在爬取pubg-finish-placement-prediction\n",
      "正在爬取human-protein-atlas-image-classification\n",
      "正在爬取PLAsTiCC-2018\n",
      "正在爬取quickdraw-doodle-recognition\n",
      "正在爬取two-sigma-financial-news\n",
      "正在爬取ga-customer-revenue-prediction\n",
      "正在爬取inclusive-images-challenge\n",
      "正在爬取rsna-pneumonia-detection-challenge\n",
      "正在爬取airbus-ship-detection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取new-york-city-taxi-fare-prediction\n",
      "正在爬取tgs-salt-identification-challenge\n",
      "正在爬取costa-rican-household-poverty-prediction\n",
      "正在爬取google-ai-open-images-visual-relationship-track\n",
      "正在爬取google-ai-open-images-object-detection-track\n",
      "正在爬取demand-forecasting-kernels-only\n",
      "正在爬取flavours-of-physics-kernels-only\n",
      "正在爬取whats-cooking-kernels-only\n",
      "正在爬取movie-review-sentiment-analysis-kernels-only\n",
      "正在爬取forest-cover-type-kernels-only\n",
      "正在爬取santander-value-prediction-challenge\n",
      "正在爬取youtube8m-2018\n",
      "正在爬取home-credit-default-risk\n",
      "正在爬取trackml-particle-identification\n",
      "正在爬取avito-demand-prediction\n",
      "正在爬取cvpr-2018-autonomous-driving\n",
      "正在爬取imaterialist-challenge-fashion-2018\n",
      "正在爬取freesound-audio-tagging\n",
      "正在爬取imaterialist-challenge-furniture-2018\n",
      "正在爬取talkingdata-adtracking-fraud-detection\n",
      "正在爬取donorschoose-application-screening\n",
      "正在爬取inaturalist-2018\n",
      "正在爬取womens-machine-learning-competition-2018\n",
      "正在爬取mens-machine-learning-competition-2018\n",
      "正在爬取competitive-data-science-predict-future-sales\n",
      "正在爬取landmark-retrieval-challenge\n",
      "正在爬取landmark-recognition-challenge\n",
      "正在爬取data-science-bowl-2018\n",
      "正在爬取whale-categorization-playground\n",
      "正在爬取imagenet-object-localization-challenge\n",
      "正在爬取sp-society-camera-model-identification\n",
      "正在爬取jigsaw-toxic-comment-classification-challenge\n",
      "正在爬取nomad2018-predict-transparent-conductors\n",
      "正在爬取santa-gift-matching\n",
      "正在爬取recruit-restaurant-visitor-forecasting\n",
      "正在爬取plant-seedlings-classification\n",
      "正在爬取mercari-price-suggestion-challenge\n",
      "正在爬取tensorflow-speech-recognition-challenge\n",
      "正在爬取spooky-author-identification\n",
      "正在爬取statoil-iceberg-classifier-challenge\n",
      "正在爬取favorita-grocery-sales-forecasting\n",
      "正在爬取porto-seguro-safe-driver-prediction\n",
      "正在爬取dog-breed-identification\n",
      "正在爬取kkbox-music-recommendation-challenge\n",
      "正在爬取kkbox-churn-prediction-challenge\n",
      "正在爬取cdiscount-image-classification-challenge\n",
      "正在爬取text-normalization-challenge-russian-language\n",
      "正在爬取text-normalization-challenge-english-language\n",
      "正在爬取carvana-image-masking-challenge\n",
      "正在爬取nyc-taxi-trip-duration\n",
      "正在爬取web-traffic-time-series-forecasting\n",
      "正在爬取nips-2017-defense-against-adversarial-attack\n",
      "正在爬取nips-2017-targeted-adversarial-attack\n",
      "正在爬取nips-2017-non-targeted-adversarial-attack\n",
      "正在爬取msk-redefining-cancer-treatment\n",
      "正在爬取passenger-screening-algorithm-challenge\n",
      "正在爬取imaterialist-challenge-FGVC2017\n",
      "正在爬取inaturalist-challenge-at-fgvc-2017\n",
      "正在爬取mercedes-benz-greener-manufacturing\n",
      "正在爬取zillow-prize-1\n",
      "正在爬取instacart-market-basket-analysis\n",
      "正在爬取invasive-species-monitoring\n",
      "正在爬取sberbank-russian-housing-market\n",
      "正在爬取planet-understanding-the-amazon-from-space\n",
      "正在爬取noaa-fisheries-steller-sea-lion-population-count\n",
      "正在爬取quora-question-pairs\n",
      "正在爬取intel-mobileodt-cervical-cancer-screening\n",
      "正在爬取youtube8m\n",
      "正在爬取two-sigma-connect-rental-listing-inquiries\n",
      "正在爬取march-machine-learning-mania-2017\n",
      "正在爬取data-science-bowl-2017\n",
      "正在爬取santas-uncertain-bags\n",
      "正在爬取dstl-satellite-imagery-feature-detection\n",
      "正在爬取two-sigma-financial-modeling\n",
      "正在爬取the-nature-conservancy-fisheries-monitoring\n",
      "正在爬取ghouls-goblins-and-ghosts-boo\n",
      "正在爬取transfer-learning-on-stack-exchange-tags\n",
      "正在爬取santander-product-recommendation\n",
      "正在爬取allstate-claims-severity\n",
      "正在爬取outbrain-click-prediction\n",
      "正在爬取dogs-vs-cats-redux-kernels-edition\n",
      "正在爬取melbourne-university-seizure-prediction\n",
      "正在爬取house-prices-advanced-regression-techniques\n",
      "正在爬取leaf-classification\n",
      "正在爬取bosch-production-line-performance\n",
      "正在爬取predicting-red-hat-business-value\n",
      "正在爬取talkingdata-mobile-user-demographics\n",
      "正在爬取grupo-bimbo-inventory-demand\n",
      "正在爬取integer-sequence-learning\n",
      "正在爬取ultrasound-nerve-segmentation\n",
      "正在爬取facebook-v-predicting-check-ins\n",
      "正在爬取avito-duplicate-ads-detection\n",
      "正在爬取painter-by-numbers\n",
      "正在爬取draper-satellite-image-chronology\n",
      "正在爬取expedia-hotel-recommendations\n",
      "正在爬取kobe-bryant-shot-selection\n",
      "正在爬取state-farm-distracted-driver-detection\n",
      "正在爬取shelter-animal-outcomes\n",
      "正在爬取santander-customer-satisfaction\n",
      "正在爬取march-machine-learning-mania-2016\n",
      "正在爬取bnp-paribas-cardif-claims-management\n",
      "正在爬取home-depot-product-search-relevance\n",
      "正在爬取yelp-restaurant-photo-classification\n",
      "正在爬取second-annual-data-science-bowl\n",
      "正在爬取cervical-cancer-screening\n",
      "正在爬取santas-stolen-sleigh\n",
      "正在爬取airbnb-recruiting-new-user-bookings\n",
      "正在爬取telstra-recruiting-network\n",
      "正在爬取prudential-life-insurance-assessment\n",
      "正在爬取homesite-quote-conversion\n",
      "正在爬取the-winton-stock-market-challenge\n",
      "正在爬取walmart-recruiting-trip-type-classification\n",
      "正在爬取the-allen-ai-science-challenge\n",
      "正在爬取rossmann-store-sales\n",
      "正在爬取how-much-did-it-rain-ii\n",
      "正在爬取whats-cooking\n",
      "正在爬取noaa-right-whale-recognition\n",
      "正在爬取deloitte-western-australia-rental-prices\n",
      "正在爬取springleaf-marketing-response\n",
      "正在爬取dato-native\n",
      "正在爬取flavours-of-physics\n",
      "正在爬取coupon-purchase-prediction\n",
      "正在爬取introducing-kaggle-scripts\n",
      "正在爬取liberty-mutual-group-property-inspection-prediction\n",
      "正在爬取machinery-tube-pricing\n",
      "正在爬取grasp-and-lift-eeg-detection\n",
      "正在爬取sf-crime\n",
      "正在爬取avito-context-ad-clicks\n",
      "正在爬取denoising-dirty-documents\n",
      "正在爬取icdm-2015-drawbridge-cross-device-connections\n",
      "正在爬取crowdflower-search-relevance\n",
      "正在爬取facebook-recruiting-iv-human-or-bot\n",
      "正在爬取pkdd-15-taxi-trip-time-prediction-ii\n",
      "正在爬取predict-west-nile-virus\n",
      "正在爬取pkdd-15-predict-taxi-service-trajectory-i\n",
      "正在爬取15-071x-the-analytics-edge-competition-spring-2015\n",
      "正在爬取pycon-2015-tutorial-predict-closed-questions-on-stack-overflow\n",
      "正在爬取15-071x-the-analytics-edge-spring-20152\n",
      "正在爬取walmart-recruiting-sales-in-stormy-weather\n",
      "正在爬取restaurant-revenue-prediction\n",
      "正在爬取otto-group-product-classification-challenge\n",
      "正在爬取diabetic-retinopathy-detection\n",
      "正在爬取malware-classification\n",
      "正在爬取march-machine-learning-mania-2015\n",
      "正在爬取how-much-did-it-rain\n",
      "正在爬取datasciencebowl\n",
      "正在爬取axa-driver-telematics-analysis\n",
      "正在爬取word2vec-nlp-tutorial\n",
      "正在爬取poker-rule-induction\n",
      "正在爬取helping-santas-helpers\n",
      "正在爬取inria-bci-challenge\n",
      "正在爬取avazu-ctr-prediction\n",
      "正在爬取finding-elo\n",
      "正在爬取tradeshift-text-classification\n",
      "正在爬取afsis-soil-properties\n",
      "正在爬取seizure-prediction\n",
      "正在爬取street-view-getting-started-with-julia\n",
      "正在爬取liberty-mutual-fire-peril\n",
      "正在爬取criteo-display-ad-challenge\n",
      "正在爬取avito-prohibited-content\n",
      "正在爬取mlsp-2014-mri\n",
      "正在爬取wise-2014\n",
      "正在爬取random-acts-of-pizza\n",
      "正在爬取bike-sharing-demand\n",
      "正在爬取seizure-detection\n",
      "正在爬取forest-cover-type-prediction\n",
      "正在爬取kdd-cup-2014-predicting-excitement-at-donors-choose\n",
      "正在爬取higgs-boson\n",
      "正在爬取billion-word-imputation\n",
      "正在爬取learning-social-circles\n",
      "正在爬取decoding-the-human-brain\n",
      "正在爬取the-analytics-edge-mit-15-071x\n",
      "正在爬取acquire-valued-shoppers-challenge\n",
      "正在爬取risky-business\n",
      "正在爬取random-number-grand-challenge\n",
      "正在爬取sentiment-analysis-on-movie-reviews\n",
      "正在爬取walmart-recruiting-store-sales-forecasting\n",
      "正在爬取allstate-purchase-prediction-challenge\n",
      "正在爬取connectomics\n",
      "正在爬取pakdd-cup-2014\n",
      "正在爬取lshtc\n",
      "正在爬取flight2-final\n",
      "正在爬取loan-default-prediction\n",
      "正在爬取march-machine-learning-mania-2014\n",
      "正在爬取galaxy-zoo-the-galaxy-challenge\n",
      "正在爬取genentech-flu-forecasting\n",
      "正在爬取packing-santas-sleigh\n",
      "正在爬取boston-data-festival-hackathon\n",
      "正在爬取deloitte-churn-prediction\n",
      "正在爬取cifar-10\n",
      "正在爬取multilabel-bird-species-classification-nips2013\n",
      "正在爬取conway-s-reverse-game-of-life\n",
      "正在爬取yandex-personalized-web-search-challenge\n",
      "正在爬取see-click-predict-fix\n",
      "正在爬取the-seeclickfix-311-challenge\n",
      "正在爬取crowdflower-weather-twitter\n",
      "正在爬取flight2-main\n",
      "正在爬取dogs-vs-cats\n",
      "正在爬取expedia-personalized-sort\n",
      "正在爬取facebook-recruiting-iii-keyword-extraction\n",
      "正在爬取stumbleupon\n",
      "正在爬取battlefin-s-big-data-combine-forecasting-challenge\n",
      "正在爬取flight2-milestone\n",
      "正在爬取mastercard-data-cleansing-competition-finals\n",
      "正在爬取accelerometer-biometric-competition\n",
      "正在爬取ams-2014-solar-energy-prediction-contest\n",
      "正在爬取belkin-energy-disaggregation-competition\n",
      "正在爬取multi-modal-gesture-recognition\n",
      "正在爬取mlsp-2013-birds\n",
      "正在爬取amazon-employee-access-challenge\n",
      "正在爬取hack-reduce-dunnhumby-hackathon\n",
      "正在爬取the-icml-2013-whale-challenge-right-whale-redux\n",
      "正在爬取the-icml-2013-bird-challenge\n",
      "正在爬取facial-keypoints-detection\n",
      "正在爬取yelp-recsys-2013\n",
      "正在爬取kdd-cup-2013-author-disambiguation\n",
      "正在爬取kdd-cup-2013-author-paper-identification-challenge\n",
      "正在爬取predict-who-is-more-influential-in-a-social-network\n",
      "正在爬取challenges-in-representation-learning-the-black-box-learning-challenge\n",
      "正在爬取challenges-in-representation-learning-multi-modal-learning\n",
      "正在爬取challenges-in-representation-learning-facial-expression-recognition-challenge\n",
      "正在爬取cause-effect-pairs\n",
      "正在爬取yelp-recruiting\n",
      "正在爬取icdar2013-stroke-recovery-from-offline-data\n",
      "正在爬取data-science-london-scikit-learn\n",
      "正在爬取icdar2013-gender-prediction-from-handwriting\n",
      "正在爬取just-the-basics-the-after-party\n",
      "正在爬取just-the-basics-strata-2013\n",
      "正在爬取job-salary-prediction\n",
      "正在爬取whale-detection-challenge\n",
      "正在爬取predicting-parkinson-s-disease-progression-with-smartphone-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取bluebook-for-bulldozers\n",
      "正在爬取event-recommendation-engine-challenge\n",
      "正在爬取leapfrogging-leaderboards\n",
      "正在爬取traveling-santa-problem\n",
      "正在爬取visualize-the-state-of-education-in-colorado\n",
      "正在爬取RxVolumePrediction\n",
      "正在爬取flight\n",
      "正在爬取hospital\n",
      "正在爬取facebook-ii\n",
      "正在爬取DarkWorlds\n",
      "https://www.kaggle.com/competitions/titanic\n",
      "正在爬取detecting-insults-in-social-commentary\n",
      "正在爬取cir-prospect\n",
      "正在爬取customer-retention\n",
      "正在爬取GEF2012-wind-forecasting\n",
      "正在爬取global-energy-forecasting-competition-2012-load-forecasting\n",
      "正在爬取us-census-challenge\n",
      "正在爬取predict-closed-questions-on-stack-overflow\n",
      "正在爬取harvard-business-review-vision-statement-prospect\n",
      "正在爬取acm-sf-chapter-hackathon-small\n",
      "正在爬取acm-sf-chapter-hackathon-big\n",
      "正在爬取MerckActivity\n",
      "正在爬取job-recommendation\n",
      "正在爬取digit-recognizer\n",
      "正在爬取MusicHackathon\n",
      "正在爬取Raising-Money-to-Fund-an-Organizational-Mission\n",
      "正在爬取pf2012-diabetes\n",
      "正在爬取cprod1\n",
      "正在爬取asap-sas\n",
      "正在爬取predict-wordpress-likes\n",
      "正在爬取emc-data-science\n",
      "正在爬取pf2012-at\n",
      "正在爬取pf2012\n",
      "正在爬取FacebookRecruiting\n",
      "正在爬取twitter-psychopathy-prediction\n",
      "正在爬取twitter-personality-prediction\n",
      "正在爬取GestureChallenge2\n",
      "正在爬取online-sales\n",
      "正在爬取dsg-hackathon\n",
      "正在爬取msdchallenge\n",
      "正在爬取emvic\n",
      "正在爬取bioresponse\n",
      "正在爬取awic2012\n",
      "正在爬取kddcup2012-track2\n",
      "正在爬取kddcup2012-track1\n",
      "正在爬取asap-aes\n",
      "正在爬取benchmark-bond-trade-price-challenge\n",
      "正在爬取getting-started\n",
      "正在爬取GestureChallenge\n",
      "正在爬取WhatDoYouKnow\n",
      "正在爬取AlgorithmicTradingChallenge\n",
      "正在爬取PhotoQualityPrediction\n",
      "正在爬取DontGetKicked\n",
      "正在爬取SemiSupervisedFeatureLearning\n",
      "正在爬取GiveMeSomeCredit\n",
      "正在爬取dunnhumbychallenge\n",
      "正在爬取ClaimPredictionChallenge\n",
      "正在爬取wikichallenge\n",
      "正在爬取mdm\n",
      "正在爬取hhp\n",
      "正在爬取overfitting\n",
      "正在爬取WIC2011\n",
      "正在爬取ChessRatings2\n",
      "正在爬取stayalert\n",
      "正在爬取unimelb\n",
      "正在爬取RTA\n",
      "正在爬取socialNetwork\n",
      "正在爬取R\n",
      "正在爬取tourism2\n",
      "正在爬取tourism1\n",
      "正在爬取chess\n",
      "正在爬取informs2010\n",
      "正在爬取worldcupconf\n",
      "正在爬取worldcup2010\n",
      "正在爬取hivprogression\n",
      "正在爬取Eurovision2010\n",
      "[{'title': 'OTTO – Multi-Objective Recommender System', 'url': 'https://www.kaggle.com/competitions/otto-recommender-system', 'briefDescription': 'Build a recommender system based on real-world e-commerce sessions', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/38760/logos/header.png?t=2022-10-25-15-59-56', 'tag': 'retail and shopping, recommender systems, weightedrecall@{k}', 'description': \"## Goal of the CompetitionThe goal of this competition is to predict e-commerce clicks, cart additions, and orders. You'll build a multi-objective recommender system based on previous events in a user session.  Your work will help improve the shopping experience for everyone involved. Customers will receive more tailored recommendations while online retailers may increase their sales.## ContextOnline shoppers have their pick of millions of products from large retailers. While such variety may be impressive, having so many options to explore can be overwhelming, resulting in shoppers leaving with empty carts. This neither benefits shoppers seeking to make a purchase nor retailers that missed out on sales. This is one reason online retailers rely on recommender systems to guide shoppers to products that best match their interests and motivations. Using data science to enhance retailers' ability to predict which products each customer actually wants to see, add to their cart, and order at any given moment of their visit in real-time could improve your customer experience the next time you shop online with your favorite retailer.  Current recommender systems consist of various models with different approaches, ranging from simple matrix factorization to a transformer-type deep neural network. However, no single model exists that can simultaneously optimize multiple objectives. In this competition, you’ll build a single entry to predict click-through, add-to-cart, and conversion rates based on previous same-session events.  With more than 10 million products from over 19,000 brands, [OTTO](https://otto.de) is the largest German online shop. OTTO is a member of the Hamburg-based, multi-national Otto Group, which also subsidizes Crate & Barrel (USA) and 3 Suisses (France).  Your work will help online retailers select more relevant items from a vast range to recommend to their customers based on their real-time behavior. Improving recommendations will ensure navigating through seemingly endless options is more effortless and engaging for shoppers.\"}, {'title': 'Tabular Playground Series - Nov 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-nov-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33111/logos/header.png?t=2021-12-30-01-31-14', 'tag': 'tabular, ensembling, logloss', 'description': \"You may have heard that blending predictions from model predictions can give better results than using the output of a single model. There are many different strategies that can be employed for this, and they are great to learn if you're looking for an effectively free boost in model scores. The November Tabular Playground is the chance to practice this skill!## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.### Getting Started For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.**Good luck and have fun!***Photo by RhondaK Native Florida Folk Artist on Unsplash*\"}, {'title': 'Scrabble Player Rating', 'url': 'https://www.kaggle.com/competitions/scrabble-player-rating', 'briefDescription': \"Predict players' ratings based on Woogles.io gameplay\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/39222/logos/header.png?t=2022-09-26-02-12-59', 'tag': 'tabular, rmse', 'description': 'Are you a Kaggle Scrabble Grandmaster? In the second edition of this Competition featuring data from Woogles.io, participants are challenged to predict the ratings of players based on Scrabble gameplay. The evaluation algorithm is RMSE.Find inspiration from the [first Competition based on Woogles.io data](https://www.kaggle.com/competitions/scrabble-point-value) where participants were challenged to predict the point value of the 20th turn from Scrabble games.## How to participate1. Log in or create a Kaggle account2. Accept the competition\\'s rules3. Download the data (click on the \"Data\" tab) or create a notebook directly on Kaggle (click on the \"Code\" tab)4. Train a model on `train.csv`, `games.csv`, and `turns.csv` predicting the missing (non-bot) player rating in `test.csv`5. Generate a `submission.csv` file in the same format as the `sample_submission.csv`6. Upload your `submission.csv` file on \"My Submissions\"**You get TWO SUBMISSIONS per day. They must be submitted before the end of the competition deadline.** You can hand select up to two submissions from the \"My Submissions\" tab, otherwise the submission with the best public score (on 30% of the test data) will be taken and scored on the private leaderboard (on 70% of the test data).## AcknowledgementsThank you to woogles.io for providing their platform for playing Scrabble online. Woogles is an entirely volunteer-run 501(c)(3) non-profit. If you enjoy the site, please feel free to contribute by clicking \"Want to help?\" at https://woogles.io/.'}, {'title': 'NFL Big Data Bowl 2023', 'url': 'https://www.kaggle.com/competitions/nfl-big-data-bowl-2023', 'briefDescription': 'Help evaluate linemen on pass plays', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/15696/logos/header.png?t=2019-10-04-16-16-53', 'tag': None, 'description': \"##Goal of the CompetitionThe National Football League (NFL) is back with another Big Data Bowl, where contestants use [Next Gen Stats](https://nextgenstats.nfl.com/) player tracking data to generate actionable, creative, and novel stats. Previous iterations have considered running backs, defensive backs, and special teams, and have generated [metrics](https://www.nfl.com/news/next-gen-stats-intro-to-expected-rushing-yards) that have been used on television and by NFL teams. In this year’s competition, you’ll have more subtle performances to consider—and potentially more players to measure.##2023 Theme: Linemen on Pass PlaysQuarterbacks may get the glory, but some of the most important work takes place a few feet in front of them. The offensive line protects the passer, providing precious seconds to find receivers downfield. At the same time, the opposing team’s defensive line attempts to find a disruptive path. If a defender sneaks through, it can mean a sack, a blocked pass, or even a turnover. Some of the game’s most important plays happen on the line and this competition examines the data behind the hardest workers in football.In this competition, you’ll have access to the NFL’s Next Gen Stats data, including player tracking, play, game, and player information, as well as Pro Football Focus (PFF) scouting data for 2021 passing plays (Weeks 1-8 of the NFL season). You’ll create new metrics and stats for America's most popular sports league. Notebook submissions will be scored based on five components: innovation, accuracy, relevance, clarity, and data visualization.Winners will be invited to present their results to the NFL, where one competition team will receive an additional prize. The most useful new metrics or analysis could be also used by NFL teams to evaluate their offensive and defensive lines.\"}, {'title': '2022 Kaggle Machine Learning & Data Science Survey', 'url': 'https://www.kaggle.com/competitions/kaggle-survey-2022', 'briefDescription': 'The most comprehensive dataset available on the state of ML and data science', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/39462/logos/header.png?t=2022-09-30-14-50-31', 'tag': 'data analytics, online communities, survey analysis', 'description': \"**Welcome to Kaggle's annual Machine Learning and Data Science Survey competition!  [You can read our executive summary here](https://www.kaggle.com/kaggle-survey-2022).**This year, as in [2017][1], [2018](https://www.kaggle.com/kaggle/kaggle-survey-2018/), [2019](https://www.kaggle.com/c/kaggle-survey-2019/), [2020](https://www.kaggle.com/c/kaggle-survey-2020/), and [2021](https://www.kaggle.com/c/kaggle-survey-2021/), we set out to conduct an industry-wide survey that presents a truly comprehensive view of the state of data science and machine learning. The survey was live from 09/16/2022 to 10/16/2022, and after cleaning the data we finished with 23,997 responses!There's a lot to explore here. The results include raw numbers about who is working with data, what’s happening with machine learning in different industries, and the best ways for new data scientists to break into the field. We've published all of the data rather than only the aggregated survey results, which makes it an unusual example of a survey dataset, as it allows analysts to investigate the data on their own.**This year Kaggle is once again launching an annual Data Science Survey Challenge, where we will be awarding a prize pool of $30,000 to notebook authors who tell a rich story about a subset of the data science and machine learning community.**In our sixth year running this survey, we were once again awed by the global, diverse, and dynamic nature of the data science and machine learning industry. This [survey data EDA][4] provides an overview of the industry on an aggregate scale, but it also leaves us **wanting to know more about the many specific communities comprised within the survey, and how they have changed from year over year**. For that reason, we’re inviting the Kaggle community to dive deep into the survey datasets and help us tell the diverse stories of data scientists from around the world.  **The challenge objective:** tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration. A “story” could be defined any number of ways, and that’s deliberate. The challenge is to deeply explore (through data) the impact, priorities, or concerns of a specific group of data science and machine learning practitioners. That group can be defined in the macro (for example: anyone who does most of their coding in Python) or the micro (for example: female data science students studying machine learning in masters programs). This is an opportunity to be creative and tell the story of a community you identify with or are passionate about! **Submissions will be evaluated on the following:** - Composition - Is there a clear narrative thread to the story that’s articulated and supported by data? The subject should be well defined, well researched, and well supported through the use of data and visualizations.  - Originality - Does the reader learn something new through this submission? Or is the reader challenged to think about something in a new way? A great entry will be informative, thought provoking, and fresh all at the same time.   - Documentation - Are your code, and notebook, and additional data sources well documented so a reader can understand what you did? Are your sources clearly cited? A high quality analysis should be concise and clear at each step so the rationale is easy to follow and the process is reproducible To be valid, a submission must be contained in one notebook, made public on or before the submission deadline. Participants are free to use any datasets in addition to the Kaggle Data Science survey, but those datasets must also be publicly available on Kaggle by the deadline for a submission to be valid. You can make your submission by filling out [the submission form](https://www.kaggle.com/page/2022-kaggle-survey-competition-submission-form).   [1]: https://www.kaggle.com/kaggle/kaggle-survey-2017  [3]: https://www.kaggle.com/page/2022-kaggle-survey-competition-submission-form  [4]: https://www.kaggle.com/paultimothymooney/kaggle-survey-2022-all-results\"}, {'title': 'G2Net Detecting Continuous Gravitational Waves', 'url': 'https://www.kaggle.com/competitions/g2net-detecting-continuous-gravitational-waves', 'briefDescription': 'Help us detect long-lasting gravitational-wave signals!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/37077/logos/header.png?t=2022-08-02-11-22-30', 'tag': 'astronomy, signal processing, auc', 'description': '### Goal of the CompetitionThe goal of this competition is to find [continuous gravitational-wave signals](https://www.ligo.org/science/GW-Continuous.php). You will develop a model sensitive enough to detect weak yet long-lasting signals emitted by rapidly-spinning neutron stars within noisy data.Your work will help scientists detect something new: a second class of gravitational waves! The first gravitational wave discoveries earned a Nobel Prize. Further study of these waves may enable scientists to learn about the structure of the most extreme stars in our universe.### ContextWhen scientists detected the first class of gravitational waves in 2015, they expected the discoveries to continue. There are four classes, yet at present only signals from merging black holes and neutron stars have been detected. Among those remaining are *continuous* gravitational-wave signals. These are weak yet long-lasting signals emitted by rapidly-spinning neutron stars. Imagine the mass of our Sun but condensed into a ball the size of a city and spinning over 1,000 times a second. The extreme compactness of these stars, composed of the densest material in the universe, could allow continuous waves to be emitted and then detected on Earth. There are potentially many continuous signals from neutron stars in our own galaxy and the current challenge for scientists is to make the first detection, and hopefully data science can help with this mission.This image, taken from a [2021 paper](https://arxiv.org/abs/2111.13106) by the LIGO-Virgo-KAGRA collaboration, shows the maximum amplitude of a continuous wave any of these neutron stars could emit without being found by the search analyses. Circled stars show results constraining the physical properties of specific neutron stars.  Traditional approaches to detecting these weak and hard-to-find continuous signals are based on matched-filtering variants. Scientists create a bank of possible signal waveform templates and ask how correlated each waveform is with the measured noisy data. High correlation is consistent with the presence of a signal similar to that waveform. Due to the long duration of these signals, banks could easily contain hundreds of quintillions of templates; yet, with so many possible waveforms, scientists don’t have the computational power to use the approach without making approximations that weaken the sensitivity to the signals.G2Net is a network of Gravitational Wave, Geophysics and Machine Learning. Via an Action from COST (European Cooperation in Science and Technology), a funding agency for research and innovation networks, G2Net aims to create a broad network of scientists. From four different areas of expertise, namely GW physics, Geophysics, Computing Science and Robotics, these scientists have agreed on a common goal of tackling challenges in data analysis and noise characterization for GW detectors.By helping G2Net in this challenge you\\'ll enable scientists to improve their sensitivity, leading to new discoveries in the field. As a result, scientists could learn more about the structure of the most extreme stars in our universe.### Resources Resources for the generation of background noise and continuous gravitational-wave signals can be found in [this pinned discussion](https://www.kaggle.com/competitions/g2net-detecting-continuous-gravitational-waves/discussion/347052). A brief [notebook](https://www.kaggle.com/code/rodrigotenorio/generating-continuous-gravitational-wave-signals) summarizing the very basics of generating data using [PyFstat](https://github.com/PyFstat/PyFstat) is also provided.### AcknowledgmentsWe acknowledge support from the LIGO-Virgo-Kagra Collaboration of which the hosts are members. Specifically we acknowledge the use of the Gravitational Wave Open Science Centre ([GWOSC](https://www.gw-openscience.org)) and the software resources [lalsuite](https://git.ligo.org/lscsoft/lalsuite) and [PyFstat](https://github.com/PyFstat/PyFstat).This challenge can be cited using the BibTeX entry attached below, should any of the resultshere generated be useful for any specific research results:```@techreport{G2NetCWKaggleChallenge,    author = \"Tenorio, Rodrigo and Williams, Michael J. and Messenger, Chris\",    title = \"Learning to detect continuous gravitational waves\",    number = \"LIGO-P2200295\",    url = {https://dcc.ligo.org/P2200295},    year = \"2022\"}```\\xa0 \\xa0'}, {'title': 'Lux AI 2022 - Beta', 'url': 'https://www.kaggle.com/competitions/lux-ai-2022-beta', 'briefDescription': 'Terraform mars and help test season 2 of the Lux AI Challenge!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/40898/logos/header.png?t=2022-10-27-20-38-10', 'tag': 'simulations, custom metric', 'description': '*Please note - this is a preview/beta launch of an upcoming competition. This competition is intended to help with rule balancing and establishing a fair and fun competition, soon to be launched. As such, this competition does not have cash prizes, points, or medals - but we hope to gain your feedback to help make the upcoming competition as fun as possible!*## IntroductionAs the sun set on the world an array of lights dotted the once dark horizon. With the help of a [brigade of toads](https://www.kaggle.com/competitions/lux-ai-2021/discussion/294993), Lux had made it past the terrors in the night to see the dawn of a new age. Seeking new challenges, plans were made to send a forward force with one mission: terraform Mars!**Welcome to the Lux AI Challenge Season 2!**The Lux AI Challenge is a competition where competitors design agents to tackle a multi-variable optimization, resource gathering, and allocation problem in a 1v1 scenario against other competitors. In addition to optimization, successful agents must be capable of analyzing their opponents and developing appropriate policies to get the upper hand.All code can be found at our [Github](https://github.com/Lux-AI-Challenge/Lux-Design-2022), make sure to give it a star while you are there! Make sure to join our community [discord](https://discord.gg/aWJt3UAcgn) to chat, strategize, and learn with other competitors! We will be posting announcements on the Kaggle Forums and on the discord.'}, {'title': 'Tabular Playground Series - Oct 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-oct-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33110/logos/header.png?t=2021-12-30-01-30-37', 'tag': 'tabular, video games, logistic regression, meancolumnwiselogloss', 'description': \"This may be one of the most challenging Tabular Playground competitions to date! It just so happens that one of Kaggle's software engineers is an avid Rocket League player and he's assembled a dataset of Rocket League gameplay for this month's TPS.This month's challenge is to predict the probability of each team scoring within the next 10 seconds of the game given a snapshot from a Rocket League match. Sounds awesome, right?Well, it's not *that* simple. The training data is fairly large; trying to read and model it in a single go might pose some challenges. The purpose of this month's competition is for you to explore ways you can take a big dataset and make it manageable within the time and resources you have. For most people, typical brute force approaches aren't going to work well.  - Can you scale down the dataset?  - Can you use, e.g., online learning methods that allow you to train from the data one row at a time? (FTLR is a great place to start if you're not familiar with online learning! e.g., [this notebook](https://www.kaggle.com/code/cttsai/instagrat-ftlr-starter))  - Can you figure out a nice set of features to reduce the dataset down to? In addition to that challenge, while your predictions must be made pointwise, the training data is made up of timeseries—maybe you can use that temporal information to improve your model?  This competition also has plenty of opportunity for data visualizations. Let's see some pretty graphs!So, share your ideas about tackling this beast of a dataset and have a great time!### AcknowledgmentsThis competition includes Rocket League data and images from the [Rocket League Community Tournament Assets](https://epicgames.ent.box.com/s/z14m4isqko9ifumy12e1o4sdy72wyzyz/folder/154490878719).\"}, {'title': 'Novozymes Enzyme Stability Prediction', 'url': 'https://www.kaggle.com/competitions/novozymes-enzyme-stability-prediction', 'briefDescription': 'Help identify the thermostable mutations in enzymes', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/37190/logos/header.png?t=2022-08-30-15-34-26', 'tag': 'chemistry, spearmanr', 'description': \"###Goal of the CompetitionEnzymes are proteins that act as catalysts in the chemical reactions of living organisms. The goal of this competition is to predict the thermostability of enzyme variants. The experimentally measured thermostability (melting temperature) data includes natural sequences, as well as engineered sequences with single or multiple mutations upon the natural sequences.Understanding and accurately predict protein stability is a fundamental problem in biotechnology. Its applications include enzyme engineering for addressing the world’s challenges in sustainability, carbon neutrality and more. Improvements to enzyme stability could lower costs and increase the speed scientists can iterate on concepts.###ContextNovozymes finds enzymes in nature and optimizes them for use in industry. In industry, enzymes replace chemicals and accelerate production processes. They help our customers make more from less, while saving energy and generating less waste. Enzymes are widely used in laundry and dishwashing detergents where they remove stains and enable low-temperature washing and concentrated detergents. Other enzymes improve the quality of bread, beer and wine, or increase the nutritional value of animal feed. Enzymes are also used in the production of biofuels where they turn starch or cellulose from biomass into sugars which can be fermented to ethanol. These are just a few examples as we sell enzymes to more than 40 different industries. Like enzymes, microorganisms have natural properties that can be put to use in a variety of processes. Novozymes supplies a range of microorganisms for use in agriculture, animal health and nutrition, industrial cleaning and wastewater treatment.  However, many enzymes are only marginally stable, which limits their performance under harsh application conditions. Instability also decreases the amount of protein that can be produced by the cell. Therefore, the development of efficient computational approaches to predict protein stability carries enormous technical and scientific interest.\\u202f  Computational protein stability prediction based on physics principles have made remarkable progress thanks to advanced physics-based methods such as FoldX, Rosetta, and others. Recently, many machine learning methods were proposed to predict the stability impact of mutations on protein based on the pattern of variation in natural sequences and their three dimensional structures. More and more protein structures are being solved thanks to the recent breakthrough of AlphaFold2. However, accurate prediction of protein thermal stability remains a great challenge. In this competition, Novozymes invites you to develop a model to predict/rank the thermostability of enzyme variants based on experimental melting temperature data, which is obtained from Novozymes’s high throughput screening lab. You’ll have access to data from previous scientific publications. The available thermostability data spans from natural sequences to engineered sequences with single or multiple mutations upon the natural sequences. If successful, you'll help tackle the fundamental problem of improving protein stability, making the approach to design novel and useful proteins, like enzymes and therapeutics, more rapidly and at lower cost. Novozymes is the world’s leading biotech powerhouse. Our growing world is faced with pressing needs, emphasizing the necessity for solutions that can ensure the health of the planet and its population. At Novozymes, we believe biotech is at the core of connecting those societal needs with the challenges and opportunities our customers face. Novozymes is the global market leader in biological solutions, producing a wide range of enzymes, microorganisms, technical and digital solutions which help our customers, amongst other things, add new features to their products and produce more from less. Together, we find biological answers for better lives in a growing world. Let’s Rethink Tomorrow. This is Novozymes’ purpose statement. Novozymes strives to have great impact by balancing good business for our customers and our company, while spearheading environmental and social change. In 2021, Novozymes enabled savings of 60 million tons of CO2 in global transport. \"}, {'title': 'Tabular Playground Series - Sep 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-sep-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33109/logos/header.png?t=2021-12-30-01-30-05', 'tag': 'tabular, smape', 'description': \"The competing Kaggle merchandise stores we saw in [January's Tabular Playground](https://www.kaggle.com/competitions/tabular-playground-series-jan-2022) are at it again. This time, they're selling books!The task for this month's competitions is a bit more complicated. Not only are there *six* countries and *four* books to forecast, but you're being asked to forecast sales during the tumultuous year 2021. Can you use your data science skills to predict book sales when conditions are far from the ordinary? ## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.### Getting Started For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.**Good luck and have fun!***Photo above by Aron Visuals on Unsplash*  \"}, {'title': 'Feedback Prize - English Language Learning', 'url': 'https://www.kaggle.com/competitions/feedback-prize-english-language-learning', 'briefDescription': 'Evaluating language knowledge of ELL students from grades 8-12', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/38321/logos/header.png?t=2022-08-23-05-06-07', 'tag': 'education, nlp, primary and secondary schools, custom metric', 'description': \"### Goal of the CompetitionThe goal of this competition is to assess the language proficiency of 8th-12th grade English Language Learners (ELLs). Utilizing a dataset of essays written by ELLs will help to develop proficiency models that better supports all students.Your work will help ELLs receive more accurate feedback on their language development and expedite the grading cycle for teachers. These outcomes could enable ELLs to receive more appropriate learning tasks that will help them improve their English language proficiency.### ContextWriting is a foundational skill. Sadly, it's one few students are able to hone, often because writing tasks are infrequently assigned in school. A rapidly growing student population, students learning English as a second language, known as English Language Learners (ELLs), are especially affected by the lack of practice. While automated feedback tools make it easier for teachers to assign more writing tasks, they are not designed with ELLs in mind. Existing tools are unable to provide feedback based on the language proficiency of the student, resulting in a final evaluation that may be skewed against the learner. Data science may be able to improve automated feedback tools to better support the unique needs of these learners.Competition host Vanderbilt University is a private research university in Nashville, Tennessee. It offers 70 undergraduate majors and a full range of graduate and professional degrees across 10 schools and colleges, all on a beautiful campus—an accredited arboretum—complete with athletic facilities and state-of-the-art laboratories. Vanderbilt is optimized to inspire and nurture cross-disciplinary research that fosters discoveries that have global impact. Vanderbilt and co-host, The Learning Agency Lab, an independent nonprofit based in Arizona, are focused on developing science of learning-based tools and programs for social good.Vanderbilt and [The Learning Agency Lab](https://www.the-learning-agency-lab.com) have partnered together to offer data scientists the opportunity to support ELLs using data science skills in machine learning, natural language processing, and educational data analytics. You can improve automated feedback tools for ELLs by sensitizing them to language proficiency. The resulting tools could serve teachers by alleviating the grading burden and support ELLs by ensuring their work is evaluated within the context of their current language level.### Acknowledgments Vanderbilt University and the Learning Agency Lab would like to thank the Bill & Melinda Gates Foundation, Schmidt Futures, and Chan Zuckerberg Initiative for their support in making this work possible.  \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0\\xa0\\xa0\\xa0> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/feedback-prize-english-language-learning/overview/code-requirements) for details.**\"}, {'title': 'Open Problems - Multimodal Single-Cell Integration', 'url': 'https://www.kaggle.com/competitions/open-problems-multimodal', 'briefDescription': 'Predict how DNA, RNA & protein measurements co-vary in single cells', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/38128/logos/header.png?t=2022-08-08-22-48-50', 'tag': 'tabular, genetics, biotechnology, meanpearson', 'description': \"### Goal of the CompetitionThe goal of this competition is to predict how DNA, RNA, and protein measurements co-vary in single cells as bone marrow stem cells develop into more mature blood cells. You will develop a  model trained on a subset of 300,000-cell time course dataset of CD34+ hematopoietic stem and progenitor cells (HSPC) from four human donors at five time points generated for this competition by Cellarity, a cell-centric drug creation company.In the test set, taken from an unseen later time point in the dataset, competitors will be provided with one modality and be tasked with predicting a paired modality measured in the same cell. The added challenge of this competition is that the test data will be from a later time point than any time point in the training data.Your work will help accelerate innovation in methods of mapping genetic information across layers of cellular state. If we can predict one modality from another, we may expand our understanding of the rules governing these complex regulatory processes.### ContextIn the past decade, the advent of single-cell genomics has enabled the measurement of DNA, RNA, and proteins in single cells. These technologies allow the study of biology at an unprecedented scale and resolution. Among the outcomes have been detailed maps of early human embryonic development, the discovery of new disease-associated cell types, and cell-targeted therapeutic interventions. Moreover, with recent advances in experimental techniques it is now possible to measure multiple genomic modalities in the same cell.While multimodal single-cell data is increasingly available, data analysis methods are still scarce. Due to the small volume of a single cell, measurements are sparse and noisy. Differences in molecular sampling depths between cells (sequencing depth) and technical effects from handling cells in batches (batch effects) can often overwhelm biological differences. When analyzing multimodal data, one must account for different feature spaces, as well as shared and unique variation between modalities and between batches. Furthermore, current pipelines for single-cell data analysis treat cells as static snapshots, even when there is an underlying dynamical biological process. Accounting for temporal dynamics alongside state changes over time is an open challenge in single-cell data science.Generally, genetic information flows from DNA to RNA to proteins. DNA must be accessible (ATAC data) to produce RNA (GEX data), and RNA in turn is used as a template to produce protein (ADT data). These processes are regulated by feedback: for example, a protein may bind DNA to prevent the production of more RNA. This genetic regulation is the foundation for dynamic cellular processes that allow organisms to develop and adapt to changing environments. In single-cell data science, dynamic processes have been modeled by so-called pseudotime algorithms that capture the progression of the biological process. Yet, generalizing these algorithms to account for both pseudotime and real time is still an open problem.Competition host Open Problems in Single-Cell Analysis is an open-source, community-driven effort to standardize benchmarking of single-cell methods. The core efforts of Open Problems include the formalization of existing challenges into measurable tasks, a collection of high-quality datasets, centralized benchmarking of community-contributed methods, and community-focused events that bring together diverse method developers to improve single-cell algorithms. They're excited to be partnering with Cellarity, Chan Zuckerbeg Biohub, the Chan Zuckerberg Initiative, Helmholtz Munich, and Yale to see what progress can be made in predicting changes in genetic dynamics over time through interdisciplinary collaboration.There are approximately 37 trillion cells in the human body, all with different behaviors and functions. Understanding how a single genome gives rise to a diversity of cellular states is the key to gaining mechanistic insight into how tissues function or malfunction in health and disease. You can help solve this fundamental challenge for single-cell biology. Being able to solve the prediction problems over time may yield new insights into how gene regulation influences differentiation as blood and immune cells mature.*Competition header image by Pawel Czerwinski on Unsplash*  \"}, {'title': 'AI Village Capture the Flag @ DEFCON', 'url': 'https://www.kaggle.com/competitions/ai-village-ctf', 'briefDescription': 'Hack AI! Collect flags by evading, poisoning, stealing, and fooling AI/ML', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/37381/logos/header.png?t=2022-06-24-21-27-01', 'tag': 'games, puzzles, adversarial learning, custom metric', 'description': \"Help Henry Hacker get to Homecoming during [DEFCON30](https://defcon.org/html/defcon-30/dc-30-index.html) -- Brought to you by the [AI Village](https://aivillage.org/)! In this series of challenges, you'll be interacting with various machine learning security challenges. The competition will be live from August 11th to September 12th @ 12:00. If you're in Vegas, stop by the village to chat about the competition. There's also the Kaggle Discussion Board and [Discord](https://discord.gg/c4hAzeRNGC).# ProcessThis capture-the-flag (CTF) follows a different flow than most Kaggle competitions. Competitors will be interacting with API endpoints or code/objects stored in the `input` directory during each of the challenges. Upon successful completion of a challenge, that challenge will return a flag (unique-to-you strings with a length of 128 characters). To update the scoreboard, competitors will submit a `.csv` containing all of their flags -- see [the kaggle documentation](https://www.kaggle.com/docs/competitions#submitting-by-uploading-a-file) or contact the competition organizers for help. Cumulative scores will be weighted based on the difficulty of the challenge. All competitors start at `0` and work their way towards a perfect score of `1.0`. There are 22 challenges, ensure your `submission.csv` has exactly those 22 challenge rows.NOTE: The template notebook is just a convenience function and method for submitting flags to the scoreboard. Don't feel constrained to that single operating environment. Interact with the challenges from your local host or any other machine that can access the internet. Afterwards, you can transport your flags into the notebook to update the scoreboard. The template is available [here](https://www.kaggle.com/lucasjt/getting-started).NOTE: If you want to interact with online challenges through Kaggle (using the template notebook, for instance), you may need to verify your Kaggle account using a phone number.Here is a handy link to Kaggle's [competition documentation](https://www.kaggle.com/docs/competitions), which includes, among other things, instructions on [submitting predictions](https://www.kaggle.com/docs/competitions#making-a-submission).Paranoid? If you don't have a kaggle account and don't want to make one, let us know and we can give you instructions for playing the challenges from your own machine. You won't be able to contribute to the scoreboard, but you'll know when you get the right flag.Please do not try and hack any infrastructure or share flags. Any teams found sharing flags will be disqualified.# ChallengesCTF's are inherently puzzles that are intended to challenge you and help you learn new things. Sometimes they may be a little ambiguous or misleading. That's part of the challenge!**Math Challenges**: Four challenges to explore the concept of dimensionality.**Hotdog and Hotterdog**: Dogs, wieners, and classifiers. What more could you want?**bad2good**: Can you poison a dataset to change how something is classified?**baseball**: Can you impersonate someone else by throwing the correct distribution of pitches?**crop**: Two challenges to test your ability to manipulate an image cropping model.**deepfake**: There's a nasty deepfake getting detected out there, can you help it?**honorstudent**: Can you change an image of an F to look like an A? Why would someone want to do such a thing?**salt**: This model has some pretty advanced defenses. Can you evade it anyway?**theft**: Can you steal this model to get a sneaky owl past it?**token**: Sentiment Analysis. Who needs?**waf**: A web-app-firewall blocks malicious requests. Can you discover and by-pass the 0-day?**inference**: I think something's backwards here. Can you, like, back something out?**forensics**: Nice artifact you got there, shame if there was a flag in it.**leakage**: Get a password out of a model, is that even possible?**murderbot**: Save the humans, escape the bots!**secret_sloth**: That sloth has a message. Why? I don't know, but it does.**wifi**: Can you pull your wifi password out of the embedding?Are you in? Of course you are. Come check it out by making a copy of this notebook: https://www.kaggle.com/lucasjt/getting-started# HelpFor help, contact us on [Discord](https://discord.gg/c4hAzeRNGC), use the Kaggle discussion board, or if you're attending DEFCON 30 in-person, come find us at the AI Village.\"}, {'title': 'Big Data Derby 2022', 'url': 'https://www.kaggle.com/competitions/big-data-derby-2022', 'briefDescription': 'Analyze horse racing data to improve the health of the horse and strategy of competition', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/37644/logos/header.png?t=2022-08-05-15-26-16', 'tag': 'data analytics, tabular, sports', 'description': \"##Goal of the CompetitionThe goal of this competition is to analyze horse racing tactics, drafting strategies, and path efficiency. You will develop a model using never-before-released coordinate data along with basic race information.Your work will help racing horse owners, trainers, and veterinarians better understand how equine performance and welfare fit together. With better data analysis, equine welfare could significantly improve.##ContextInjury prevention is a critical component in modern athletics. Sports that involve animals, such as horse racing, are no different than human sport. Typically, efficiency in movement correlates to both improvements in performance and injury prevention. A wealth of data is now collected, including measures for heart rate, EKG, longitudinal movement, dorsal/ventral movement, medial/lateral deviation, total power and total landing vibration. Your data science skills and analysis are needed to decipher what makes the most positive impact.In this competition, you will create a model to interpret one aspect of this new data. You’ll be among the first to access X/Y coordinate mapping of horses during races. Using the data, you might analyze jockey decision making, compare race surfaces, or measure the relative importance of drafting. With considerable data, contestants can flex their creativity problem solving skills. The New York Racing Association (NYRA) and the New York Thoroughbred Horsemen's Association (NYTHA) conduct world class thoroughbred racing at Aqueduct Racetrack, Belmont Park and Saratoga Race Course.With your help, NYRA and NYTHA will better understand their vast data set, which could lead to new ways of racing and training in a highly traditional industry. With improved use of horse tracking data, you could help improve equine welfare, performance and rider decision making.\"}, {'title': 'Tabular Playground Series - Aug 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-aug-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33108/logos/header.png?t=2021-12-30-01-29-08', 'tag': 'tabular, auc', 'description': \"The August 2022 edition of the Tabular Playground Series is an opportunity to help the fictional company *Keep It Dry* improve its main product *Super Soaker*. The product is used in factories to absorb spills and leaks.The company has just completed a large testing study for different product prototypes. Can you use this data to build a model that predicts product failures?## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.### Getting Started For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.**Good luck and have fun!***Photo above by freestocks on Unsplash*\"}, {'title': 'DFL - Bundesliga Data Shootout', 'url': 'https://www.kaggle.com/competitions/dfl-bundesliga-data-shootout', 'briefDescription': 'Identify plays based upon video footage ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/37244/logos/header.png?t=2022-06-30-22-25-12', 'tag': 'sports, football, video data, custom metric', 'description': \"### Goal of the CompetitionGoal! In this competition, you'll detect football (soccer) passes—including throw-ins and crosses—and challenges in original Bundesliga matches. You'll develop a computer vision model that can automatically classify these events in long video recordings.Your work will help scale the data collection process. Automatic event annotation could enable event data from currently unexplored competitions, like youth or semi-professional leagues or even training sessions.### ContextWhat does it take to go pro in football (soccer)? From a young age, hopeful talents devote time, money, and training to the sport. Yet, while the next superstar is guaranteed to start off in youth or semi-professional leagues, these leagues often have the fewest resources to invest. This includes resources for the collection of event data which helps generate insights into the performance of the teams and players.Currently, event data is mostly collected manually by human operators, who gather data in several steps and through numerous personnel involved. This manual process has room for innovation as in its current shape and form it involves a lot of resources and multiple iterations/quality checks. As a result, event data collection is usually reserved for professional competitions only.Based in Frankfurt, the [Deutsche Fußball Liga (DFL)](https://www.dfl.de/en/) manages Germany's professional football (soccer) leagues: [Bundesliga and Bundesliga 2](https://www.bundesliga.com/en/bundesliga). DFL partners with the operator of one of the largest sports databases in the world, [Sportec Solutions.](https://www.sportec-solutions.de/en/index.html) They're responsible for the leagues' sports data and sports technology activities. In addition, Sportec Solutions provides services to global sports entities and media companies.  Automatic event detection could provide event data faster and with greater depth. Having access to a broader range of competitions, match conditions and data scouts would be able to ensure no talented player is overlooked.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/dfl-bundesliga-data-shootout/overview/code-requirements) for details.**\"}, {'title': 'RSNA 2022 Cervical Spine Fracture Detection', 'url': 'https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection', 'briefDescription': 'Identify cervical fractures from scans', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/36363/logos/header.png?t=2022-07-22-15-19-11', 'tag': 'image, computer vision, binary classification, weightedmeancolumnwiselogloss', 'description': \"### Goal of the CompetitionOver 1.5 million spine fractures occur annually in the United States alone resulting in over 17,730 spinal cord injuries annually. The most common site of spine fracture is the cervical spine. There has been a rise in the incidence of spinal fractures in the elderly and in this population, fractures can be more difficult to detect on imaging due to superimposed degenerative disease and osteoporosis. Imaging diagnosis of adult spine fractures is now almost exclusively performed with computed tomography (CT) instead of radiographs (x-rays). Quickly detecting and determining the location of any vertebral fractures is essential to prevent neurologic deterioration and paralysis after trauma.### ContextRSNA has teamed with the [American Society of Neuroradiology (ASNR)](https://www.asnr.org/) and the [American Society of Spine Radiology (ASSR)](https://www.theassr.org/) to conduct an AI challenge competition exploring whether artificial intelligence can be used to aid in the detection and localization of cervical spine fractures.  To create the ground truth dataset, the challenge planning task force collected imaging data sourced from twelve sites on six continents, including approximately 3,000 CT studies. Spine radiology specialists from the ASNR and ASSR provided expert image level annotations these studies to indicate the presence, vertebral level and location of any cervical spine fractures.  In this challenge competition, you will try to develop machine learning models that match the radiologists' performance in detecting and localizing fractures to the seven vertebrae that comprise the cervical spine. Winners will be recognized at an event during the RSNA 2022 annual meeting.  For more information on the challenge, contact RSNA Informatics staff at [informatics@rsna.org](mailto:informatics@rsna.org).[A full set of acknowledgments can be found on this page](https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/overview/acknowledgements).> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/rsna-2022-cervical-spine-fracture-detection/overview/code-requirements) for details.**\"}, {'title': 'Google Universal Image Embedding', 'url': 'https://www.kaggle.com/competitions/google-universal-image-embedding', 'briefDescription': 'Create image representations that work across many visual domains', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/36414/logos/header.png?t=2022-07-06-20-40-23', 'tag': 'image, multiclass classification, custom metric', 'description': \"Welcome to the Universal Image Embedding competition! After hosting challenges in the domain of landmarks for the past four years, this year we introduce the first competition in image representations that should work across many object types.Image representations are a critical building block of computer vision applications. Traditionally, research on image embedding learning has been conducted with a focus on per-domain models. Generally, papers propose generic embedding learning techniques which are applied to different domains separately, rather than developing generic embedding models which could be applied to all domains combined.In this competition, the developed models are expected to retrieve relevant database images to a given query image (ie, the model should retrieve database images containing the same object as the query). The images in our dataset comprise a variety of object types, such as apparel, artwork, landmarks, furniture, packaged goods, among others.This year's competition is structured in a representation learning format: you will create a model that extracts a feature embedding for the images and submit the model via Kaggle Notebooks. Kaggle will run your model on a held-out test set, perform a k-nearest-neighbors lookup, and score the resulting embedding quality. Both Tensorflow and PyTorch models are supported.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/google-universal-image-embedding/overview/code-requirements) for details.**Cover image credits: [Chris Schrier, CC-BY](https://www.flickr.com/photos/schrierc/5502246181); [Petri Krohn, GNU Free Documentation License](https://commons.wikimedia.org/wiki/File:MOMA_chairs_2.jpg); [Drazen Nesic, CC0](https://pixnio.com/media/cartoon-textile-texture-funny-giraffe); [Marco Verch Professional Photographer, CCBY](https://www.flickr.com/photos/30478819@N08/44289962475); [Grendelkhan, CCBY](https://commons.wikimedia.org/wiki/File:Waymo_self-driving_car_side_view.gk.jpg); [Bobby Mikul, CC0](https://www.publicdomainpictures.net/en/view-image.php?image=16166&picture=empire-state-building); [Vincent Van Gogh, CC0](https://www.rawpixel.com/image/537438/the-starry-night-van-gogh); [pxhere.com, CC0](https://pxhere.com/en/photo/479766); [Smart Home Perfected, CC-BY](https://www.flickr.com/photos/smarthomeperfected/51048330253). \"}, {'title': 'Mayo Clinic - STRIP AI', 'url': 'https://www.kaggle.com/competitions/mayo-clinic-strip-ai', 'briefDescription': 'Image Classification of Stroke Blood Clot Origin', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/37333/logos/header.png?t=2022-06-29-00-47-20', 'tag': 'classification, image, computer vision, medicine, weightedmulticlassloss', 'description': \"### Goal of the CompetitionThe goal of this competition is to classify the blood clot origins in ischemic stroke. Using whole slide digital pathology images, you'll build a model that differentiates between the two major acute ischemic stroke (AIS) etiology subtypes: cardiac and large artery atherosclerosis.Your work will enable healthcare providers to better identify the origins of blood clots in deadly strokes, making it easier for physicians to prescribe the best post-stroke therapeutic management and reducing the likelihood of a second stroke.### ContextStroke remains the second-leading cause of death worldwide. Each year in the United States, over 700,000 individuals experience an ischemic stroke caused by a blood clot blocking an artery to the brain. A second stroke (23% of total events are recurrent) worsens the chances of the patient’s survival. However, subsequent strokes may be mitigated if physicians can determine stroke etiology, which influences the therapeutic management following stroke events. During the last decade, mechanical thrombectomy has become the standard of care treatment for acute ischemic stroke from large vessel occlusion. As a result, retrieved clots became amenable to analysis. Healthcare professionals are currently attempting to apply deep learning-based methods to predict ischemic stroke etiology and clot origin. However, unique data formats, image file sizes, as well as the number of available pathology slides create challenges you could lend a hand in solving.The Mayo Clinic is a nonprofit American academic medical center focused on integrated health care, education, and research. Stroke Thromboembolism Registry of Imaging and Pathology (STRIP) is a uniquely large multicenter project led by Mayo Clinic Neurovascular Lab with the aim of histopathologic characterization of thromboemboli of various etiologies and examining clot composition and its relation to mechanical thrombectomy revascularization.To decrease the chances of subsequent strokes, the Mayo Clinic Neurovascular Research Laboratory encourages data scientists to improve artificial intelligence-based etiology classification so that physicians are better equipped to prescribe the correct treatment. New computational and artificial intelligence approaches could help save the lives of stroke survivors and help us better understand the world's second-leading cause of death.\"}, {'title': 'Tabular Playground Series - Jul 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-jul-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33107/logos/header.png?t=2021-12-30-01-27-41', 'tag': 'tabular, clustering, adjustedrandindex', 'description': \"Welcome to Kaggle's first ever unsupervised clustering challenge!In this challenge, you are given a dataset where each row belongs to a particular cluster. Your job is to predict the cluster each row belongs to. You are not given any training data, and you are not told how many clusters are found in the ground truth labels. ## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.### Getting Started For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.**Good luck and have fun!***Photo above by Laura Rivera on Unsplash*    \"}, {'title': 'HuBMAP + HPA - Hacking the Human Body', 'url': 'https://www.kaggle.com/competitions/hubmap-organ-segmentation', 'briefDescription': 'Segment multi-organ functional tissue units', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/34547/logos/header.png?t=2022-02-15-22-37-27', 'tag': 'image, biology, computer vision, dice', 'description': \"When you think of “life hacks,” normally you’d imagine productivity techniques. But how about the kind that helps you understand your body at a molecular level? It may be possible! Researchers must first determine the function and relationships among the 37 trillion cells that make up the human body. A better understanding of our cellular composition could help people live healthier, longer lives.A previous [Kaggle competition](https://www.kaggle.com/c/hubmap-kidney-segmentation) aimed to annotate cell population neighborhoods that perform an organ’s main physiologic function, also called functional tissue units (FTUs). Manually annotating FTUs (e.g., glomeruli in kidney or alveoli in the lung) is a time-consuming process. In the average kidney, there are over 1 million glomeruli FTUs. While there are existing cell and FTU segmentation methods, we want to push the boundaries by building algorithms that generalize across different organs and are robust across different dataset differences. The [Human BioMolecular Atlas Program](https://hubmapconsortium.org/) (HuBMAP) is working to create a [Human Reference Atlas](https://www.nature.com/articles/s41556-021-00788-6) at the cellular level. Sponsored by the National Institutes of Health (NIH), HuBMAP and Indiana University’s Cyberinfrastructure for Network Science Center (CNS) have partnered with institutions across the globe for this endeavor. A major partner is the [Human Protein Atlas](https://www.proteinatlas.org/) (HPA), a Swedish research program aiming to map the protein expression in human cells, tissues, and organs, funded by the Knut and Alice Wallenberg Foundation.In this competition, you’ll identify and segment functional tissue units (FTUs) across five human organs. You'll build your model using a dataset of tissue section images, with the best submissions segmenting FTUs as accurately as possible.If successful, you'll help accelerate the world’s understanding of the relationships between cell and tissue organization. With a better idea of the relationship of cells, researchers will have more insight into the function of cells that impact human health. Further, the Human Reference Atlas constructed by HuBMAP will be freely available for use by researchers and pharmaceutical companies alike, potentially improving and prolonging human life.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/hubmap-organ-segmentation/overview/code-requirements) for details.**\"}, {'title': 'Tabular Playground Series - Jun 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-jun-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33106/logos/header.png?t=2021-12-30-01-27-03', 'tag': 'tabular, rmse', 'description': \"The June edition of the 2022 Tabular Playground series is all about data imputation. The dataset has similarities to the [May 2022 Tabular Playground](https://www.kaggle.com/competitions/tabular-playground-series-may-2022/overview), except that there are no targets. Rather, there are missing data values in the dataset, and your task is to predict what these values should be.## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.### Getting Started For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn. We've also provided a [notebook](https://www.kaggle.com/inversion/get-started-with-mean-imputation) to get people started*Good luck and have fun!*### AcknowledgmentsPhoto by Mika Baumeister on Unsplash.\"}, {'title': 'American Express - Default Prediction', 'url': 'https://www.kaggle.com/competitions/amex-default-prediction', 'briefDescription': 'Predict if a customer will default in the future', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/35332/logos/header.png?t=2022-03-23-01-05-50', 'tag': 'tabular, finance, binary classification, custom metric', 'description': \"Whether out at a restaurant or buying tickets to a concert, modern life counts on the convenience of a credit card to make daily purchases. It saves us from carrying large amounts of cash and also can advance a full purchase that can be paid over time. How do card issuers know we’ll pay back what we charge? That’s a complex problem with many existing solutions—and even more potential improvements, to be explored in this competition.Credit default prediction is central to managing risk in a consumer lending business. Credit default prediction allows lenders to optimize lending decisions, which leads to a better customer experience and sound business economics. Current models exist to help manage risk. But it's possible to create better models that can outperform those currently in use.American Express is a globally integrated payments company. The largest payment card issuer in the world, they provide customers with access to products, insights, and experiences that enrich lives and build business success. In this competition, you’ll apply your machine learning skills to predict credit default. Specifically, you will leverage an industrial scale data set to build a machine learning model that challenges the current model in production. Training, validation, and testing datasets include time-series behavioral data and anonymized customer profile information. You're free to explore any technique to create the most powerful model, from creating features to using the data in a more organic way within a model.If successful, you'll help create a better customer experience for cardholders by making it easier to be approved for a credit card. Top solutions could challenge the credit default prediction model used by the world's largest payment card issuer—earning you cash prizes, the opportunity to interview with American Express, and potentially a rewarding new career.\"}, {'title': 'Feedback Prize - Predicting Effective Arguments', 'url': 'https://www.kaggle.com/competitions/feedback-prize-effectiveness', 'briefDescription': 'Rate the effectiveness of argumentative writing elements from students grade 6-12\\n\\n', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/35308/logos/header.png?t=2022-05-12-15-29-47', 'tag': 'nlp, text, primary and secondary schools, multiclassloss', 'description': '###Goal of the CompetitionThe goal of this competition is to classify argumentative elements in student writing as \"effective,\" \"adequate,\" or \"ineffective.\" You will create a model trained on data that is representative of the 6th-12th grade population in the United States in order to minimize bias. Models derived from this competition will help pave the way for students to receive enhanced feedback on their argumentative writing. With automated guidance, students can complete more assignments and ultimately become more confident, proficient writers.    This competition will comprise two tracks. The first track will be a traditional track in which accuracy of classification will be the only metric used for success. Success on this track will be updated on the Kaggle leaderboard. Prize money for the accuracy-only, “Leaderboard Prize” track will be $25,000.    The second track will measure computational efficiency in which efficiency is determined using a combination of accuracy and the speed at which models are able to generate these predictions. We are hosting this track because highly accurate models are often computationally heavy. Such models have a stronger carbon footprint and frequently prove difficult to utilize in real-world educational contexts, since most educational organizations have limited computational capabilities. Weekly updates on models based on computational efficiency will be posted in the discussion forum. Prize money for the computational, “Efficiency Prize” track will be $30,000.You can find more details about the [Efficiency Prize Evaluation](https://www.kaggle.com/competitions/feedback-prize-effectiveness/overview/efficiency-prize-evaluation) via the side tab.###ContextWriting is crucial for success. In particular, argumentative writing fosters critical thinking and civic engagement skills, and can be strengthened by practice. However, only 13 percent of eighth-grade teachers ask their students to write persuasively each week. Additionally, resource constraints disproportionately impact Black and Hispanic students, so they are more likely to write at the “below basic” level as compared to their white peers. An automated feedback tool is one way to make it easier for teachers to grade writing tasks assigned to their students that will also improve their writing skills.    There are numerous automated writing feedback tools currently available, but they all have limitations, especially with argumentative writing. Existing tools often fail to evaluate the quality of argumentative elements, such as organization, evidence, and idea development. Most importantly, many of these writing tools are inaccessible to educators due to their cost, which most impacts already underserved schools.    [Georgia State University (GSU)](https://www.gsu.edu) is an undergraduate and graduate urban public research institution in Atlanta. U.S. News & World Report ranked GSU as one of the most innovative universities in the nation. GSU awards more bachelor’s degrees to African-Americans than any other non-profit college or university in the country. GSU and The Learning Agency Lab, an independent nonprofit based in Arizona, are focused on developing science of learning-based tools and programs for social good.    To best prepare all students, GSU and [The Learning Agency Lab](https://www.the-learning-agency-lab.com) have joined forces to encourage data scientists to improve automated writing assessments. This public effort could also encourage higher quality and more accessible automated writing tools. If successful, students will receive more feedback on the argumentative elements of their writing and will apply the skill across many disciplines.###Acknowledgements    Georgia State University and the Learning Agency Lab would like to thank the Bill & Melinda Gates Foundation, Schmidt Futures, and Chan Zuckerberg Initiative for their support in making this work possible.  \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0\\xa0\\xa0\\xa0> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/feedback-prize-effectiveness/overview/code-requirements) for details.**'}, {'title': 'Google AI4Code – Understand Code in Python Notebooks', 'url': 'https://www.kaggle.com/competitions/AI4Code', 'briefDescription': 'Predict the relationship between code and comments', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/35887/logos/header.png?t=2022-05-09-22-33-02', 'tag': 'computer science, nlp, text, custom metric', 'description': \"The goal of this competition is to understand the relationship between code and comments in Python notebooks. You are challenged to reconstruct the order of markdown cells in a given notebook based on the order of the code cells, demonstrating comprehension of which natural language references which code.### ContextResearch teams across Google and Alphabet are exploring new ways that machine learning can assist software developers, and want to rally more members of the developer community to help explore this area too. Python notebooks provide a unique learning opportunity, because unlike a lot of standard source code, notebooks often follow narrative format, with comment cells implemented in markdown that explain a programmer's intentions for corresponding code cells. An understanding of the relationships between code and markdown could lend to fresh improvements across many aspects of AI-assisted development, such as the construction of better data filtering and preprocessing pipelines for model training, or automatic assessments of a notebook's readability.We have assembled a dataset of approximately 160,000 public Python notebooks from Kaggle and have teamed up with [X, the moonshot factory](https://x.company/) to design a competition that challenges participants to use this dataset of published notebooks to build creative techniques aimed at better understanding the relationship between comment cells and code cells. ![Image of Notebook Cells](https://storage.googleapis.com/kaggle-media/Images/notebook_cell_examples.png)After the submission deadline, Kaggle and X will evaluate the performance of submitted techniques on new, previously unseen notebooks. We're excited to see how the insights learned from this competition affect the future of notebook authorship.\"}, {'title': 'Google Smartphone Decimeter Challenge 2022', 'url': 'https://www.kaggle.com/competitions/smartphone-decimeter-2022', 'briefDescription': 'Improve high precision GNSS positioning and navigation accuracy on smartphones', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/35779/logos/header.png?t=2022-04-29-21-07-48', 'tag': 'tabular, geospatial analysis, research, mobile and wireless, signal processing, custom metric', 'description': \"### Goal of the CompetitionThe goal of this competition is to compute smartphones location down to the decimeter or even centimeter resolution which could enable services that require lane-level accuracy such as HOV lane ETA estimation. You'll develop a model based on raw location measurements from Android smartphones collected in opensky and light urban roads using datasets collected by the host.Your work will help produce more accurate positions, bridging the connection between the geospatial information of finer human behavior and mobile internet with improved granularity. As a result, new navigation methods could be built upon the more precise data. ### ContextHave you ever missed the lane change before a highway exit? Do you want to know the estimated time of arrival (ETA) of a carpool lane rather than other lanes? These and other useful features require precise smartphone positioning services. Machine learning models can improve the accuracy of Global Navigation Satellite System (GNSS) data. With more refined data, billions of Android phone users could have a more fine-tuned positioning experience.GNSS chipsets provide raw measurements, which can be used to compute the smartphone’s position. Current mobile phones only offer 3-5 meters of positioning accuracy. For advanced use cases, the results are not fine enough nor reliable. Urban obstructions create the largest barriers to GPS accuracy. The data in this challenge includes only traces collected on opensky and light urban roads. These highways and main streets are the most widely used roads and will test the limits of smartphone positioning.The Android GPS team in Google hosted the [Smartphone Decimeter Challenge in 2021](https://kaggle.com/competitions/google-smartphone-decimeter-challenge/overview). Works by the three winners were presented at the ION GNSS+ 2021 Conference. This year, co-sponsored by the Institute of Navigation, this competition continues to seek advanced research in smartphone GNSS positioning accuracy and help people better navigate the world around them. In order to build upon last year’s progress, the data also includes traces from the 2021 competition.Future competitions could include traces collected in harsher environments, such as deep urban areas with obstacles to satellite signals. Your efforts in this competition could impact how this more difficult data is interpreted. With decimeter level position accuracy, mobile users could gain better lane-level navigation, AR walk/drive, precise agriculture via phones, and greater specificity in the location of road safety issues. It will also enable a more personalized fine tuned navigation experience.*Photos by Jared Murray, Thaddaeus Lim and Tobias Rademacher on Unsplash.*\"}, {'title': 'Tabular Playground Series - May 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-may-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33105/logos/header.png?t=2021-12-30-01-26-16', 'tag': 'tabular, auc', 'description': \"The May edition of the 2022 Tabular Playground series binary classification problem that includes a number of different feature interactions. This competition is an opportunity to explore various methods for identifying and exploiting these feature interactions.## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.### Getting Started For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.We've also built a [starter notebook](https://www.kaggle.com/code/paultimothymooney/getting-started-with-tensorflow-decision-forests) for you that uses TensorFlow Decision Forests, a TensorFlow library that matches the power of XGBoost with a friendly, straightforward user interface. *Good luck and have fun!*### AcknowledgmentsPhoto by Clarisse Croset on Unsplash.\"}, {'title': 'UW-Madison GI Tract Image Segmentation ', 'url': 'https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation', 'briefDescription': 'Track healthy organs in medical scans to improve cancer treatment', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/27923/logos/header.png?t=2021-06-02-20-30-25', 'tag': 'image, medicine, dice3dhausdorff', 'description': \"In 2019, an estimated 5 million people were diagnosed with a cancer of the gastro-intestinal tract worldwide. Of these patients, about half are eligible for radiation therapy, usually delivered over 10-15 minutes a day for 1-6 weeks. Radiation oncologists try to deliver high doses of radiation using X-ray beams pointed to tumors while avoiding the stomach and intestines. With newer technology such as integrated magnetic resonance imaging and linear accelerator systems, also known as MR-Linacs, oncologists are able to visualize the daily position of the tumor and intestines, which can vary day to day. In these scans, radiation oncologists must manually outline the position of the stomach and intestines in order to adjust the direction of the x-ray beams to increase the dose delivery to the tumor and avoid the stomach and intestines.  This is a time-consuming and labor intensive process that can prolong treatments from 15 minutes a day to an hour a day, which can be difficult for patients to tolerate—unless deep learning could help automate the segmentation process.  A method to segment the stomach and intestines would make treatments much faster and would allow more patients to get more effective treatment.  The UW-Madison Carbone Cancer Center is a pioneer in MR-Linac based radiotherapy, and has treated patients with MRI guided radiotherapy based on their daily anatomy since 2015. UW-Madison has generously agreed to support this project which provides anonymized MRIs of patients treated at the UW-Madison Carbone Cancer Center. The University of Wisconsin-Madison is a public land-grant research university in Madison, Wisconsin. The Wisconsin Idea is the university's pledge to the state, the nation, and the world that their endeavors will benefit all citizens.  In this competition, you’ll create a model to automatically segment the stomach and intestines on MRI scans. The MRI scans are from actual cancer patients who had 1-5 MRI scans on separate days during their radiation treatment.  You'll base your algorithm on a dataset of these scans to come up with creative deep learning solutions that will help cancer patients get better care.![Description Image](https://lh5.googleusercontent.com/zbBUgbj1jyZxyu3r1vr5zKKr8yK1hSdwAM3HpD_n6j2W-5-wKP3ZRusi_3yskSgnC-tMRKqOEtLycbLkTWCJAUe4Cylv_VsW81DYI4ray02uZLeSnlzAuZRIU7L2Q0KURYSMqFI)*In this figure, the tumor (pink thick line) is close to the stomach (red thick line).  High doses of radiation are directed to the tumor while avoiding the stomach.  The dose levels are represented by the rainbow of outlines, with higher doses represented by red and lower doses represented by green.*  Cancer takes enough of a toll. If successful, you'll enable radiation oncologists to safely deliver higher doses of radiation to tumors while avoiding the stomach and intestines. This will make cancer patients' daily treatments faster and allow them to get more effective treatment with less side effects and better long-term cancer control.## Acknowledgments:Sangjune Laurence Lee MSE MD FRCPC DABRPoonam Yadav  Ph.D., DABRYin Li PhDJason J. Meudt BS, RTTJessica StrangDustin HebelAlyx Alfson MS CMD, R.T.(T)Stephanie J. Olson RTT (BS), CMD (MS)Tera R. Kruser MS, RTT, CMDJennifer B Smilowitz, Ph.D., DABR, FAAPMKailee BorchertBrianne LoritzJohn Bayouth PhDMichael Bassetti MD PhD**Work funded by the University of Wisconsin Carbone Cancer Center Pancreas Pilot Research Grant.**> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/uw-madison-gi-tract-image-segmentation/overview/code-requirements) for details.**\"}, {'title': 'Foursquare - Location Matching', 'url': 'https://www.kaggle.com/competitions/foursquare-location-matching', 'briefDescription': 'Match point of interest data across datasets', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/35476/logos/header.png?t=2022-03-22-18-37-04', 'tag': 'business, tabular, geography, custom metric', 'description': \"When you look for nearby restaurants or plan an errand in an unknown area, you expect relevant, accurate information. To maintain quality data worldwide is a challenge, and one with implications beyond navigation. Businesses make decisions on new sites for market expansion, analyze the competitive landscape, and show relevant ads informed by location data. For these, and many other uses, reliable data is critical.Large-scale datasets on commercial points-of-interest (POI) can be rich with real-world information. To maintain the highest level of accuracy, the data must be matched and de-duplicated with timely updates from multiple sources. De-duplication involves many challenges, as the raw data can contain noise, unstructured information, and incomplete or inaccurate attributes. A combination of machine-learning algorithms and rigorous human validation methods are optimal to de-dupe datasets.With 12+ years of experience perfecting such methods, Foursquare is the #1 independent provider of global POI data. The leading independent location technology and data cloud platform, Foursquare is dedicated to building meaningful bridges between digital spaces and physical places. Trusted by leading enterprises like Apple, Microsoft, Samsung, and Uber, Foursquare’s tech stack harnesses the power of places and movement to improve customer experiences and drive better business outcomes.In this competition, you’ll match POIs together. Using a dataset of over one-and-a-half million Places entries heavily altered to include noise, duplications, extraneous, or incorrect information, you'll produce an algorithm that predicts which Place entries represent the same point-of-interest. Each Place entry includes attributes like the name, street address, and coordinates. Successful submissions will identify matches with the greatest accuracy.By efficiently and successfully matching POIs, you'll make it easier to identify where new stores or businesses would benefit people the most. > **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/foursquare-location-matching/overview/code-requirements) for details.**\"}, {'title': 'Kore 2022', 'url': 'https://www.kaggle.com/competitions/kore-2022', 'briefDescription': 'Use a fleet of spaceships to mine minerals before your opponents', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/35272/logos/header.png?t=2022-03-15-23-55-50', 'tag': 'custom metric', 'description': \"In this turn-based simulation game you control a small armada of spaceships. As you mine the rare mineral “kore” from the depths of space, you teleport it back to your homeworld. But it turns out you aren’t the only civilization with this goal. In each game two players will compete to collect the most kore from the board. Whoever has the largest kore cache by the end of 400 turns—or eliminates all of their opponents from the board before that—will be the winner!Your algorithms determine the movements of your fleets to collect kore, but it's up to you to figure out how to make effective and efficient moves. You control your ships, build new ships, create shipyards, eliminate opponents, and mine the kore on the game board.May your fleet live long and prosper!\"}, {'title': 'JPX Tokyo Stock Exchange Prediction', 'url': 'https://www.kaggle.com/competitions/jpx-tokyo-stock-exchange-prediction', 'briefDescription': 'Explore the Tokyo market with your data science skills', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/34349/logos/header.png?t=2022-03-09-00-33-57', 'tag': 'tabular, finance, custom metric', 'description': \"Success in any financial market requires one to identify solid investments. When a stock or derivative is undervalued, it makes sense to buy. If it's overvalued, perhaps it's time to sell. While these finance decisions were historically made manually by professionals, technology has ushered in new opportunities for retail investors. Data scientists, specifically, may be interested to explore quantitative trading, where decisions are executed programmatically based on predictions from trained models.There are plenty of existing quantitative trading efforts used to analyze financial markets and formulate investment strategies. To create and execute such a strategy requires both historical and real-time data, which is difficult to obtain especially for retail investors. This competition will provide financial data for the Japanese market, allowing retail investors to analyze the market to the fullest extent.Japan Exchange Group, Inc. (JPX) is a holding company operating one of the largest stock exchanges in the world, Tokyo Stock Exchange (TSE), and derivatives exchanges Osaka Exchange (OSE) and Tokyo Commodity Exchange (TOCOM). JPX is hosting this competition and is supported by AI technology company AlpacaJapan Co.,Ltd.This competition will compare your models against real future returns after the training phase is complete. The competition will involve building portfolios from the stocks eligible for predictions (around 2,000 stocks). Specifically, each participant ranks the stocks from highest to lowest expected returns and is evaluated on the difference in returns between the top and bottom 200 stocks. You'll have access to financial data from the Japanese market, such as stock information and historical stock prices to train and test your model.All winning models will be made public so that other participants can learn from the outstanding models. Excellent models also may increase the interest in the market among retail investors, including those who want to practice quantitative trading. At the same time, you'll gain your own insights into programmatic investment methods and portfolio analysis―and you may even discover you have an affinity for the Japanese market.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/jpx-tokyo-stock-exchange-prediction/overview/code-requirements) for details.**\"}, {'title': 'Image Matching Challenge 2022', 'url': 'https://www.kaggle.com/competitions/image-matching-challenge-2022', 'briefDescription': 'Register two images from different viewpoints', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/34970/logos/header.png?t=2022-03-30-01-06-45', 'tag': 'image, computer vision, custom metric', 'description': \"For most of us, our best camera is part of the phone in our pocket. We may take a snap of a landmark, like the Trevi Fountain in Rome, and share it with friends. By itself, that photo is two-dimensional and only includes the perspective of our shooting location. Of course, a lot of people have taken photos of that fountain. Together, we may be able to create a more complete, three-dimensional view. What if machine learning could help better capture the richness of the world using the vast amounts of unstructured image collections freely available on the internet?The process to reconstruct 3D objects and buildings from images is called Structure-from-Motion (SfM). Typically, these images are captured by skilled operators under controlled conditions, ensuring homogeneous, high-quality data. It is much more difficult to build 3D models from assorted images, given a wide variety of viewpoints, lighting and weather conditions, occlusions from people and vehicles, and even user-applied filters. The first part of the problem is to identify which parts of two images capture the same physical points of a scene, such as the corners of a window. This is typically achieved with local features (key locations in an image that can be reliably identified across different views). Local features contain short description vectors that capture the appearance around the point of interest. By comparing these descriptors, likely correspondences can be established between the pixel coordinates of image locations across two or more images. This “image registration” makes it possible to recover the 3D location of the point by triangulation.Google employs Structure-from-Motion techniques across many Google Maps services, such as the 3D models created from StreetView and aerial imagery. In order to accelerate research into this topic, and better leverage the volume of data already publicly available, Google presents this competition in collaboration with the University of British Columbia and Czech Technical University.In this code competition, you’ll create a machine learning algorithm that registers two images from different viewpoints. With access to a dataset of thousands of images to train and test your model, top-scoring notebooks will do so with the most accuracy.If successful, you'll help solve this well-known problem in computer vision, making it possible to map the world with unstructured image collections. Your solutions will have applications in photography and cultural heritage preservation, along with Google Maps. Winners will also be invited to give a presentation as part of the Image Matching: Local Features and Beyond workshop at the Conference on Computer Vision and Pattern Recognition (CVPR) in June.### Resources* [Image Matching Challenge 2021](https://www.cs.ubc.ca/research/image-matching-challenge/current/): Last year's competition (outside Kaggle).### OrganizationEduard Trulls (Google), Yuhe Jin & Kwang Moo Yi (University of British Columbia, Vancouver, Canada), Dmytro Mishkin & Jiri Matas (Czech Technical University, Prague, Czech Republic)### AcknowledgmentsThe organizers would like to thank the [Machine Learning Lab](https://apps.ucu.edu.ua/en/mllab/) at the [Faculty of Applied Sciences, Ukrainian Catholic University](https://apps.ucu.edu.ua/en/) (Lviv, Ukraine) for their help with dataset creation.Banner photo by Taneli Lahtinen on Unsplash.  Trevi Fountain photos, left to right, then top to bottom: [sarah|rose](https://www.flickr.com/photos/sarah_rose/3786822852/), [kmaschke](https://www.flickr.com/photos/14174853@N04/4165248133/), [jamingray](https://www.flickr.com/photos/jamingray/5179486993/), [deglispiriti](https://www.flickr.com/photos/73853155@N00/284462939/), [Lucas Uyezu](https://www.flickr.com/photos/luyezu/4292626471/), [justinknabb](https://www.flickr.com/photos/justinknabb/5040046824/), [Bogdan Migulski](https://www.flickr.com/photos/migulski/3701027825/), [S outH CheN](https://www.flickr.com/photos/7553102@N04/2799379452/), [Melirius](https://www.flickr.com/photos/melirius/11225456523/), [2bethere](https://www.flickr.com/photos/2bethere/5160423697/), [Steve AM](https://www.flickr.com/photos/scuba04/2401033603/), [L'amande](https://www.flickr.com/photos/l_amande/6333421472/).> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/image-matching-challenge-2022/overview/code-requirements) for details.**\"}, {'title': 'Tabular Playground Series - Apr 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-apr-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33104/logos/header.png?t=2021-12-30-01-25-24', 'tag': 'tabular, auc', 'description': \"Welcome to the April edition of the 2022 Tabular Playground Series! This month's challenge is a *time series classification* problem.You've been provided with thousands of sixty-second sequences of biological sensor data recorded from several hundred participants who could have been in either of two possible activity states. Can you determine what state a participant was in from the sensor data?## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.\"}, {'title': 'U.S. Patent Phrase to Phrase Matching ', 'url': 'https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching', 'briefDescription': 'Help Identify Similar Phrases in U.S. Patents', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33657/logos/header.png?t=2022-02-23-06-26-59', 'tag': 'nlp, text, pearsoncorrelationcoefficient', 'description': 'Can you extract meaning from a large, text-based dataset derived from inventions? Here\\'s your chance to do so.The U.S. Patent and Trademark Office (USPTO) offers one of the largest repositories of scientific, technical, and commercial information in the world through its [Open Data Portal](https://developer.uspto.gov/about-open-data). Patents are a form of [intellectual property](https://www.uspto.gov/patents/basics/general-information-patents) granted in exchange for the public disclosure of new and useful inventions. Because patents undergo an intensive [vetting process](https://www.uspto.gov/sites/default/files/documents/InventionCon2020_Understanding_the_Patent_Examination_Process.pdf) prior to grant, and because the history of U.S. innovation spans over two centuries and 11 million patents, the U.S. patent archives stand as a rare combination of data volume, quality, and diversity.> “The USPTO serves an American innovation machine that never sleeps by granting patents, registering trademarks, and promoting intellectual property around the globe. The USPTO shares over 200 years\\' worth of human ingenuity with the world, from lightbulbs to quantum computers. Combined with creativity from the data science community, USPTO datasets carry unbounded potential to empower AI and ML models that will benefit the progress of science and society at large.”>> — USPTO Chief Information Officer Jamie HolcombeIn this competition, you will train your models on a novel semantic similarity dataset to extract relevant information by matching key phrases in patent documents. Determining the semantic similarity between phrases is critically important during the patent search and examination process to determine if an invention has been described before. For example, if one invention claims \"television set\" and a prior publication describes \"TV set\", a model would ideally recognize these are the same and assist a patent attorney or examiner in retrieving relevant documents. This extends beyond paraphrase identification; if one invention claims a \"strong material\" and another uses \"steel\", that may also be a match. What counts as a \"strong material\" varies per domain (it may be steel in one domain and ripstop fabric in another, but you wouldn\\'t want your parachute made of steel). We have included the Cooperative Patent Classification as the technical domain context as an additional feature to help you disambiguate these situations.Can you build a model to match phrases in order to extract contextual information, thereby helping the patent community connect the dots between millions of patent documents?> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/us-patent-phrase-to-phrase-matching/overview/code-requirements) for details.**'}, {'title': 'iWildCam 2022 - FGVC9', 'url': 'https://www.kaggle.com/competitions/iwildcam2022-fgvc9', 'briefDescription': 'Count the number of animals in a sequence of images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33843/logos/header.png?t=2022-02-12-20-38-25', 'tag': 'image, animals, mae', 'description': \"## DescriptionCamera Traps enable the automatic collection of large quantities of image data. Ecologists all over the world use camera traps to monitor biodiversity and population density of animal species. In order to estimate the abundance (how many there are) and population density of species in camera trap data, ecologists need to know not just which species were seen, but also how many of each species were seen. However, because images are taken in motion-triggered bursts to increase the likelihood of capturing the animal(s) of interest, object detection alone is not sufficient as it could lead to over- or under-counting. For example, if you get 3 images taken at one frame per second, and in the first you see 3 gazelles, in the second you see 5 gazelles, and in the last you see 4 gazelles, how many total gazelles have you seen? This is more challenging than strictly detecting and categorizing species, as it requires reasoning and tracking of individuals across sparse temporal samples.This year our iWildCam competition will focus entirely on counting animals. We have prepared a challenge where the training data and test data are from different cameras spread across the globe. The set of species seen in each camera overlap, but are not identical. The challenge is to count individual animals across sequences in the test cameras. To explore multimodal solutions, we allow competitors to train on the following data:1. Our camera trap training set — data provided by the [Wildlife Conservation Society (WCS)](https://www.wcs.org/).1. iNaturalist 2017-2021 data.1. Multispectral imagery from [Landsat-8](https://www.usgs.gov/land-resources/nli/landsat/landsat-8) for each of the camera trap locations.Check the [Data section](https://www.kaggle.com/c/iwildcam2022-fgvc9/data) for a more comprehensive description of all these resources and for accessing the train set, test set and metadata. These are mirrored on the competition's [GitHub page](https://github.com/visipedia/iwildcam_comp) as well, where we also provide the multispectral data, a taxonomy file mapping our classes into the iNaturalist taxonomy, a subset of the iNaturalist data mapped into our class set, a camera trap detection model (the [MegaDetector](https://github.com/microsoft/CameraTraps/blob/main/megadetector.md)) along with the corresponding detections, and a class-agnostic instance segmentation model ([DeepMAC](https://google.github.io/deepmac/)) along with the segmentation masks for the MegaDetector's bounding boxes.## AcknowledgementsThis competition is part of the [FGVC9](https://sites.google.com/view/fgvc9) workshop at [CVPR 2022](https://cvpr2022.thecvf.com/) and is sponsored by [Wildlife Insights](https://www.wildlifeinsights.org/). Data is primarily provided by the [Wildlife Conservation Society (WCS)](https://www.wcs.org/) and [iNaturalist](https://www.inaturalist.org/), and is hosted on Azure by [Microsoft AI for Earth](https://www.microsoft.com/en-us/ai/ai-for-earth). Count annotations were generously provided by [Centaur Labs](https://www.centaurlabs.com/).*Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.*\"}, {'title': 'Kore 2022 - Beta', 'url': 'https://www.kaggle.com/competitions/kore-2022-beta', 'briefDescription': 'Collect the maximum amount of Kore against your opponents', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/35272/logos/header.png?t=2022-03-15-23-55-50', 'tag': 'custom metric', 'description': \"*Please note - this is a preview/beta launch of an upcoming competition. This competition is intended to help with rule balancing and establishing a fair and fun competition, soon to be launched. As such, this competition does not have cash prizes, points, or medals - but we hope to gain your feedback for when the featured competition goes live!*When you want to mine kore quickly: go alone. But when you want to mine the most kore: build a fleet.In this turn-based simulation game you control a small armada of spaceships. As you mine the rare mineral “kore” from the depths of space, you teleport it back to your homeworld. But it turns out you aren’t the only civilization with this goal. In each game four players will compete to collect the most kore from the board. Whoever has the largest kore cache by the end of 400 turns—or eliminates all of their opponents from the board before that—will be the winner!Your algorithms determine the movements of your fleets to collect kore, but it's up to you to figure out how to make effective and efficient moves. You control your ships, build new ships, create shipyards, eliminate opponents, and mine the kore on the game board.May your fleet live long and prosper!\"}, {'title': 'Hotel-ID to Combat Human Trafficking 2022 - FGVC9', 'url': 'https://www.kaggle.com/competitions/hotel-id-to-combat-human-trafficking-2022-fgvc9', 'briefDescription': 'Recognizing hotels to aid Human trafficking investigations', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/35150/logos/header.png?t=2022-03-10-00-02-44', 'tag': 'image, public safety, map@{k}', 'description': 'Hotel Recognition to Combat Human TraffickingVictims of human trafficking are often photographed in hotel rooms as in the below examples. Identifying these hotels is vital to these trafficking investigations but poses particular challenges due to low quality of images and uncommon camera angles.![Example investigative images.](https://cs.slu.edu/~astylianou/images/example_victim_images.png)Even without victims in the images, hotel identification in general is a challenging fine-grained visual recognition task with a huge number of classes and potentially high intraclass and low interclass variation. In order to support research into this challenging task and create image search tools for human trafficking investigators, we created the TraffickCam mobile application, which allows every day travelers to submit photos of their hotel room. Read more about TraffickCam on TechCrunch.Example images from one hotel in the TraffickCam dataset are shown below:![Example TraffickCam images.](https://cs.slu.edu/~astylianou/images/example_traffickcam_images.png)In this contest, competitors are tasked with identifying the hotel seen in test images from the TraffickCam dataset, which are based on a large gallery of training images with known hotel IDs.Our team currently supports an image search system used at the National Center for Missing and Exploited Children in human trafficking investigations. Novel and interesting approaches have the potential to be incorporated in this search system.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/hotel-id-2021-fgvc8/overview/code-requirements) for details.**'}, {'title': 'Sorghum -100 Cultivar Identification - FGVC 9', 'url': 'https://www.kaggle.com/competitions/sorghum-id-fgvc-9', 'briefDescription': 'Identify crop varietals', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/34375/logos/header.png?t=2022-03-12-00-53-27', 'tag': 'image, agriculture, categorizationaccuracy', 'description': '# OverviewThe Sorghum-100 dataset is a curated subset of the RGB imagery captured during the TERRA-REF experiments, labeled by cultivar. This data could be used to develop and assess a variety of plant phenotyping models which seek to answer questions relating to the presence or absence of desirable traits (e.g., \"does this plant exhibit signs of water stress?\\'\\'). In this contest, we focus on the question: \"What cultivar is shown in this image?\\'\\'![Field Scanner](https://terraref.org/sites/terraref.org/files/TERRA-REF-Scanner.jpg)Predicting the cultivar in an image is an especially good challenge problem for familiarizing the machine learning community with the TERRA-REF data. At first blush, the task of predicting the cultivar from an image of a plant may not seem to be the most biologically compelling question to answer -- in the context of plant breeding, the cultivar, or parental lines are typically known. A high accuracy machine learning predictor of the species captured by the sensor data, however, can be used to determine where errors in the planting process may have occurred. For example, seed may be mislabeled prior to planting, or planters may get jammed, depositing seeds non-uniformly in a field. Both types of errors are surprisingly common and can cause major problems when processing data from large-scale field experiments with hundreds of cultivars and complex field planting layouts.### Data DescriptionThe Sorghum-100 dataset consists of 48,106 images and 100 different sorghum cultivars grown in June of 2017 (the images come from the middle of the growing season when the plants were quite large but not yet lodging -- or falling over).Each image is taken using an RGB spectral camera taken from a vertical view of the sorghum plants in the [TERRA-REF](https://terraref.org/) field in Arizona. '}, {'title': 'GeoLifeCLEF 2022 - LifeCLEF 2022 x FGVC9', 'url': 'https://www.kaggle.com/competitions/geolifeclef-2022-lifeclef-2022-fgvc9', 'briefDescription': 'Location-based species presence prediction', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33317/logos/header.png?t=2022-03-08-13-06-08', 'tag': 'image, geospatial analysis, environment, meanbesterroratk', 'description': 'Description Task  The aim of this competition is to predict the localization of plant and animal species.  To do so, 1.6M geo-localized observations from France and the US of 17K species are provided (9K plant species and 8K animal species).  These observations are paired with aerial images and environmental features around them (as illustrated above).  The goal is, for each GPS position in the test set (for which we provide the associated aerial images and environmental features), to return a set of candidate species that should contain the true observed species.Motivation  Automatic prediction of the list of species most likely to be observed at a given location is useful for many scenarios related to biodiversity management and conservation.  First, this would allow to improve species identification tools - automatic, semi-automatic, or based on traditional field guides - by reducing the list of candidate species observable at a given site.  More generally, it could facilitate biodiversity inventories through the development of location-based recommendation services (e.g. on mobile phones), encourage the involvement of citizen scientist observers, and accelerate the annotation and validation of species observations to produce large, high-quality data sets.  Finally, this could be used for educational purposes through biodiversity discovery applications with features such as contextualized educational pathways.Context  This competition is held jointly as part of:  the LifeCLEF 2022 lab of the CLEF 2022 conference, and ofthe FGVC9 workshop organized in conjunction with CVPR 2022 conference.Being part of scientific research, the participants are encouraged to participate to both event.  In particular, only participants who submitted a working note paper to LifeCLEF (see below) will be part of the officially published ranking used for scientific communication.FGVC9 at CVPR 2022  This competition is part of the Fine-Grained Visual Categorization FGVC9 workshop at the Computer Vision and Pattern Recognition Conference CVPR 2022.  A panel will review the top submissions for the competition based on the description of the methods provided.  From this, a subset may be invited to present their results at the workshop.  Attending the workshop is not required to participate in the competition; however, only teams that are attending the workshop will be considered to present their work.CVPR 2022 will take place in New Orleans, USA, 19-24 June 2022.  PLEASE NOTE: CVPR frequently sells out early, we cannot guarantee CVPR registration after the competition\\'s end.  If you are interested in attending, please plan ahead.  You can see a list of all of the FGVC9 competitions here.LifeCLEF 2022  LifeCLEF lab is part of the Conference and Labs of the Evaluation Forum (CLEF).  CLEF consists of independent peer-reviewed workshops on a broad range of challenges in the fields of multilingual and multimodal information access evaluation, and a set of benchmarking activities carried in various labs designed to test different aspects of mono and cross-language Information retrieval systems.CLEF 2022 will be hosted by the Università di Bologna, Italy, 5-8 September 2022.  More details can be found on the CLEF 2022 website.  To participate to the LifeCLEF lab, participants must register using this form (and checking \"Task 3 - GeoLifeCLEF\" of \"LifeCLEF\" section).This registration is free of charge and will close on 22 April 2022, however free of charge late registration will still be possible at the end of the competition.  This will allow those participants to submit, at the end of the competition, a working note paper to LifeCLEF which will be peer-reviewed and published in CEUR-WS proceedings.  This paper should provide sufficient information to reproduce the final submitted runs.  Submitting a working note with the full description of the methods used in each run is mandatory.  Any run that could not be reproduced thanks to its description in the working notes might be removed from the official publication of the results.  Working notes are published within CEUR-WS proceedings, resulting in an assignment of an individual DOI (URN) and an indexing by many bibliography systems including DBLP.  According to the CEUR-WS policies, a light review of the working notes will be conducted by LifeCLEF organizing committee to ensure quality.  As an illustration, LifeCLEF 2021 working notes (task overviews and participant working notes) can be found within CLEF 2021 CEUR-WS proceedings. CreditsThis project has received funding from the French National Research Agency under the Investments for the Future Program, referred to as ANR-16-CONV-0004, and from the European Union’s Horizon 2020 research and innovation program under grant agreement No 863463 (Cos4Cloud project).'}, {'title': 'Excellence in Research Award (Phase II)', 'url': 'https://www.kaggle.com/competitions/phase-ii-widsdatathon2022', 'briefDescription': 'WiDS Datathon Further Examines the Impacts of Climate Change', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/34411/logos/header.png?t=2022-03-02-14-52-55', 'tag': 'data analytics, tabular, weather and climate', 'description': \"# WiDS Datathon 2022: Phase II Excellence in ResearchWe invite you to build a team, hone your data science skills, and join us for Phase II of the 5th Annual WiDS Datathon focused on social impact!This year’s WiDS Datathon, organized by the WiDS Worldwide team, [Stanford University](https://www.stanford.edu), [Harvard University IACS](https://iacs.seas.harvard.edu/home), and the [WiDS Datathon Committee](https://www.widsconference.org/committee-2022.html), will address the multi-faceted impacts of climate change. The WiDS Datathon Committee is partnering with experts from many disciplines at [Climate Change AI (CCAI)](https://www.climatechange.ai/), [Lawrence Berkeley National Laboratory (Berkeley Lab)](https://www.lbl.gov/), [US Environmental Protection Agency (EPA)](https://www.epa.gov/), and [MIT Critical Data](https://criticaldata.mit.edu/). [Phase I](https://www.kaggle.com/c/widsdatathon2022/) of this year's datathon focused on an important way to mitigate the effects of climate change - improving building energy efficiency through forecasting usage. In the [WiDS Datathon Excellence in Research Award (Phase II)](https://www.widsconference.org/excellence-award-2022.html), we will broaden our focus to examine the impacts of climate change across multiple domains. ### To qualify for Phase II, participants must:1. have participated in the [first phase](https://www.kaggle.com/c/widsdatathon2022) of the WiDS Datathon 2022 on Kaggle2. [REGISTER for the Excellence in Research Award (Phase II)](https://bit.ly/widsdatathon_phaseII_reg)# BackgroundClimate change is a globally relevant, urgent, and multi-faceted issue heavily impacting many industries and aspects of public life. Participants in Phase II will have the opportunity to examine the climate change from different perspectives. Participants will choose to explore one dataset among several, spanning sectors including healthcare, energy and environmental protection. Participants will also have opportunities to take deeper dives into their dataset and tackle a range of impactful real-world tasks. Teams will submit a research report at the end of Phase II.New this year, participants in Phase II can receive [mentorship](https://www.kaggle.com/c/phase-ii-widsdatathon2022/overview/timeline-and-mentorship-office-hours) from experts in the domain related to their choice of dataset and task. Domain expert mentorship in Phase II will allow participants to both strengthen their foundational data science skills as well as develop skills needed to conduct research in data science. Teams with outstanding paper submissions from Phase II will be invited to submit their work for publication.**The Excellence in Research Award (Phase II) is open from March 8 - June 30, 2022.** Submissions are due on [Submittable](https://datahubs.submittable.com/submit/219905/wids-datathon-2022-excellence-in-research-award-phase-ii). \\u200bAfter the June 30, 2022 research paper deadline, submissions will be reviewed for their potential for real-world impact, rigor in scientific methodology, and clarity of communication, by subject matter experts from the WiDS Datathon Committee, the National Science Foundation Big Data Innovation Hubs, and Datathon partners. # Phase II Datathon Partners and Research TracksPhase II participants will be able to choose [one of three research tracks](https://www.kaggle.com/c/phase-ii-widsdatathon2022/data) to explore:- **US Environmental Protection Agency (EPA):** weather, air pollutant, and census data- **MIT Critical Data:** CDC county level COVID data- **Climate Change AI:** Fine grained building energy usage data# Eligibility and TeamsTo be eligible for the award, all entrants must have participated in the [first phase](https://www.kaggle.com/c/widsdatathon2022) of the WiDS Datathon 2022 on Kaggle.We encourage Phase II individuals and author teams of up to 8 people to work together. You may collaborate with individuals in a “new” team for the second phase of the Datathon, as long as (1) each person participated in the first phase of the datathon on Kaggle and (2) your new team still includes 50% or more individuals identifying as women. Each team member must complete [Phase II registration](https://bit.ly/widsdatathon_phaseII_reg).Note that you do NOT need to merge teams within the Kaggle platform (it's actually disabled), but all team members must be listed as collaborators on your submitted research paper, and all team members must accept the competition rules before the submission deadline of June 30th.# Acknowledgements*The WiDS Datathon Excellence in Research Award 2022 is a collaboration led by the WiDS Worldwide team at Stanford University, the Institute for Applied Computational Sciences at Harvard University and the WiDS Datathon Committee. WiDS Datathon 2022 cash prizes are provided by Kaggle. The Excellence in Research Award is supported by the National Science Foundation under Grants 1916573, 1916481, and 1915774, as part of a network of Big Data Innovation Hubs. Special thanks to our datathon partners Climate Change AI, US Environmental Protection Agency (EPA), and MIT Critical Data.*![](https://i.ibb.co/2WqHdXy/Phase-II-partner-logo-bar-v2.png)\"}, {'title': 'Tabular Playground Series - Mar 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-mar-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33103/logos/header.png?t=2021-12-30-01-24-57', 'tag': 'tabular, time series analysis, cities and urban areas, mae', 'description': \"For the March edition of the 2022 Tabular Playground Series you're challenged to forecast twelve-hours of traffic flow in a U.S. metropolis. The time series in this dataset are labelled with both location coordinates and a direction of travel -- a combination of features that will test your skill at *spatio-temporal forecasting* within a highly dynamic traffic network.Which model will prevail? The venerable linear regression? The deservedly-popular ensemble of decision trees? Or maybe a cutting-edge graph neural-network? We can't wait to see!## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.\"}, {'title': 'Spaceship Titanic', 'url': 'https://www.kaggle.com/competitions/spaceship-titanic', 'briefDescription': 'Predict which passengers are transported to an alternate dimension', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/34377/logos/header.png?t=2022-02-11-21-53-06', 'tag': 'beginner, tabular, binary classification, categorizationaccuracy', 'description': \"Recommended CompetitionWe highly recommend Titanic - Machine Learning from Disaster to get familiar with the basics of machine learning and Kaggle competitions.Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.The *Spaceship Titanic* was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.While rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary *Spaceship Titanic* collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!To help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.Help save them and change history!### AcknowledgmentsPhotos by Joel Filipe, Richard Gatley and ActionVance on Unsplash.\"}, {'title': 'March Machine Learning Mania 2022 - Men’s', 'url': 'https://www.kaggle.com/competitions/mens-march-mania-2022', 'briefDescription': \"Predict the 2022 College Men's Basketball Tournament\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26080/logos/header.png?t=2021-02-24-01-37-37', 'tag': 'sports, basketball, logloss', 'description': \"Another year, another chance to predict the upsets, call the probabilities, and put your bracketology skills to the leaderboard test. In our *eighth* annual March Machine Learning Mania competition, Kagglers will once again join the millions of fans who attempt to predict the outcomes of this year's US men's college basketball tournament. But unlike most fans, you will pick the winners and losers using a combination of rich historical data and computing power, while the ground truth unfolds on television.You're provided data of historical NCAA games and are encouraged to use other sources of publicly available data to gain a winning edge.In stage one of this two-stage competition, participants will build and test their models against previous tournaments. In the second stage, participants will predict the outcome of the 2022 tournament. You don’t need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2022 results.And don't forget to take a look at our [companion competition](https://www.kaggle.com/c/34542) that looks to predict the outcome of the US women's college basketball tournament!###AcknowledgmentsBanner image by Ben Hershey on Unsplash\"}, {'title': \"March Machine Learning Mania 2022 - Women's\", 'url': 'https://www.kaggle.com/competitions/womens-march-mania-2022', 'briefDescription': \"Predict the 2022 College Women's Basketball Tournament\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26080/logos/header.png?t=2021-02-24-01-37-37', 'tag': 'sports, basketball, logloss', 'description': \"Another year, another chance to predict the upsets, call the probabilities, and put your bracketology skills to the leaderboard test. In our *eighth* annual March Machine Learning Mania competition, Kagglers will once again join the millions of fans who attempt to predict the outcomes of this year's US women's college basketball tournament. But unlike most fans, you will pick the winners and losers using a combination of rich historical data and computing power, while the ground truth unfolds on television.You're provided data of historical NCAA games and are encouraged to use other sources of publicly available data to gain a winning edge.In stage one of this two-stage competition, participants will build and test their models against previous tournaments. In the second stage, participants will predict the outcome of the 2022 tournament. You don’t need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2022 results.And don't forget to take a look at our [companion competition](https://www.kaggle.com/c/34538) that looks to predict the outcome of the US men's college basketball tournament!###AcknowledgmentsBanner image by Ben Hershey on Unsplash\"}, {'title': 'BirdCLEF 2022', 'url': 'https://www.kaggle.com/competitions/birdclef-2022', 'briefDescription': 'Identify bird calls in soundscapes', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33246/logos/header.png?t=2022-02-08-17-06-27', 'tag': 'environment, audio, weightedcategorizationaccuracy', 'description': \"As the “extinction capital of the world,” Hawai'i has lost 68% of its bird species, the consequences of which can harm entire food chains. Researchers use population monitoring to understand how native birds react to changes in the environment and conservation efforts. But many of the remaining birds across the islands are isolated in difficult-to-access, high-elevation habitats. With physical monitoring difficult, scientists have turned to sound recordings. Known as bioacoustic monitoring, this approach could provide a passive, low labor, and cost-effective strategy for studying endangered bird populations.Current methods for processing large bioacoustic datasets involve manual annotation of each recording. This requires specialized training and prohibitively large amounts of time. Thankfully, recent advances in machine learning have made it possible to automatically identify bird songs for common species with ample training data. However, it remains challenging to develop such tools for rare and endangered species, such as those in Hawai'i. The Cornell Lab of Ornithology's K. Lisa Yang Center for Conservation Bioacoustics (KLY-CCB) develops and applies innovative conservation technologies across multiple ecological scales to inspire and inform the conservation of wildlife and habitats. KLY-CCB does this by collecting and interpreting sounds in nature and they've joined forces with Google Bioacoustics Group, LifeCLEF, Listening Observatory for Hawaiian Ecosystems (LOHE) Bioacoustics Lab at the University of Hawai'i at Hilo, and Xeno-Canto for this competition.In this competition, you’ll use your machine learning skills to identify bird species by sound. Specifically, you'll develop a model that can process continuous audio data and then acoustically recognize the species. The best entries will be able to train reliable classifiers with limited training data.If successful, you'll help advance the science of bioacoustics and support ongoing research to protect endangered Hawaiian birds. Thanks to your innovations, it will be easier for researchers and conservation practitioners to accurately survey population trends. They'll be able to regularly and more effectively evaluate threats and adjust their conservation actions.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/birdclef-2022/overview/code-requirements) for details.**\"}, {'title': 'Herbarium 2022 - FGVC9', 'url': 'https://www.kaggle.com/competitions/herbarium-2022-fgvc9', 'briefDescription': 'Identify plant species of the Americas from herbarium specimens', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33679/logos/header.png?t=2022-02-14-16-38-02', 'tag': 'image, plants, macrofscore', 'description': \"[![My-Post.jpg](https://i.postimg.cc/15qZZfvt/My-Post.jpg)](https://postimg.cc/Xp4Pf7SS)*The Herbarium 2022: Flora of North America* is a part of a project of the [New York Botanical Garden](https://www.nybg.org/) funded by the [National Science Foundation](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2054684&HistoricalAwards=false) to build tools to identify novel plant species around the world. The dataset strives to represent all known vascular plant taxa in North America, using images gathered from 60 different botanical institutions around the world. In botany, a **‘flora’ is a complete account of the plants found in a geographic region**. The dichotomous keys and detailed descriptions of diagnostic morphological features contained within a flora are used by botanists to determine which names to apply to plant specimens. **This year's competition dataset aims to encapsulate the flora of North America so that we can test the capability of artificial intelligence to replicate this traditional tool** —a crucial first step to harnessing AI’s potential botanical applications.    *The Herbarium 2022: Flora of North America* dataset comprises **1.05 M images** of **15,501 vascular plants**, which constitute more than **90% of the taxa** documented in North America. Our dataset is constrained to include only **vascular land plants** (lycophytes, ferns, gymnosperms, and flowering plants). Our dataset has a long-tail distribution. **The number of images per taxon** is as few as seven and as many as 100 images. Although more images are available, we capped the maximum number in an attempt to ensure sufficient but manageable training data size for competition participants. # AboutThis is an FGVC competition hosted as part of the [FGVC9](https://sites.google.com/view/fgvc9) workshop at [CVPR 2022](http://cvpr2022.thecvf.com/) and sponsored by [NYBG](https://www.nybg.org/).Details of this competition are mirrored on the [github](https://github.com/visipedia/herbarium_comp) page. Please post in the forum or open an issue if you have any questions or problems with the dataset.# AcknowledgementsThe images are provided by the [New York Botanical Garden](https://www.nybg.org/) and 59 other institutions around the world. ![herb22banner](https://i.postimg.cc/g0DJMF52/output.png)\"}, {'title': 'H&M Personalized Fashion Recommendations', 'url': 'https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations', 'briefDescription': 'Provide product recommendations based on previous purchases', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/31254/logos/header.png?t=2021-10-26-22-52-52', 'tag': 'retail and shopping, recommender systems, map@{k}', 'description': '[H&M Group](https://www.hmgroup.com/) is a family of brands and businesses with 53 online markets and approximately 4,850 stores. Our online store offers shoppers an extensive selection of products to browse through. But with too many choices, customers might not quickly find what interests them or what they are looking for, and ultimately, they might not make a purchase. To enhance the shopping experience, product recommendations are key. More importantly, helping customers make the right choices also has a positive implications for sustainability, as it reduces returns, and thereby minimizes emissions from transportation. In this competition, H&M Group invites you to develop product recommendations based on data from previous transactions, as well as from customer and product meta data. The available meta data spans from simple data, such as garment type and customer age, to text data from product descriptions, to image data from garment images. There are no preconceptions on what information that may be useful – that is for you to find out. If you want to investigate a categorical data type algorithm, or dive into NLP and image processing deep learning, that is up to you.'}, {'title': 'NBME - Score Clinical Patient Notes', 'url': 'https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes', 'briefDescription': 'Identify Key Phrases in Patient Notes from Medical Licensing Exams', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33607/logos/header.png?t=2022-01-24-18-05-41', 'tag': 'education, nlp, text, medicine, custom metric', 'description': 'When you visit a doctor, how they interpret your symptoms can determine whether your diagnosis is accurate. By the time they’re licensed, physicians have had a lot of practice writing patient notes that document the history of the patient’s complaint, physical exam findings, possible diagnoses, and follow-up care. Learning and assessing the skill of writing patient notes requires feedback from other doctors, a time-intensive process that could be improved with the addition of machine learning.Until recently, the Step 2 Clinical Skills examination was one component of the United States Medical Licensing Examination® (USMLE®). The exam required test-takers to interact with Standardized Patients (people trained to portray specific clinical cases) and write a patient note. Trained physician raters later scored patient notes with rubrics that outlined each case’s important concepts (referred to as features). The more such features found in a patient note, the higher the score (among other factors that contribute to the final score for the exam).However, having physicians score patient note exams requires significant time, along with human and financial resources. Approaches using natural language processing have been created to address this problem, but patient notes can still be challenging to score computationally because features may be expressed in many ways. For example, the feature \"loss of interest in activities\" can be expressed as \"no longer plays tennis.\" Other challenges include the need to map concepts by combining multiple text segments, or cases of ambiguous negation such as “no cold intolerance, hair loss, palpitations, or tremor” corresponding to the key essential “lack of other thyroid symptoms.”In this competition, you’ll identify specific clinical concepts in patient notes. Specifically, you\\'ll develop an automated method to map clinical concepts from an exam rubric (e.g., “diminished appetite”) to various ways in which these concepts are expressed in clinical patient notes written by medical students (e.g., “eating less,” “clothes fit looser”). Great solutions will be both accurate and reliable.If successful, you\\'ll help tackle the biggest practical barriers in patient note scoring, making the approach more transparent, interpretable, and easing the development and administration of such assessments. As a result, medical practitioners will be able to explore the full potential of patient notes to reveal information relevant to clinical skills assessment.This competition is sponsored by the [National Board of Medical Examiners](https://www.nbme.org/)® (NBME®). Through research and innovation, NBME supports medical school and residency program educators in addressing issues around the evolution of teaching, learning, technology, and the need for meaningful feedback. NBME offers high-quality assessments and educational services for students, professionals, educators, regulators, and institutions dedicated to the evolving needs of medical education and health care. To serve these communities, NBME collaborates with a diverse and comprehensive array of practicing health professionals, medical educators, state medical board members, test developers, academic researchers, scoring experts and public representatives.*NBME gratefully acknowledges the valuable input of Dr Le An Ha from the University of Wolverhampton’s Research Group in Computational Linguistics.*> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/nbme-score-clinical-patient-notes/overview/code-requirements) for details.**'}, {'title': 'Happywhale - Whale and Dolphin Identification', 'url': 'https://www.kaggle.com/competitions/happy-whale-and-dolphin', 'briefDescription': 'Identify whales and dolphins by unique characteristics', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22962/logos/header.png?t=2021-03-17-22-44-09', 'tag': 'image, animals, map@{k}', 'description': \"We use fingerprints and facial recognition to identify people, but can we use similar approaches with animals? In fact, researchers manually track marine life by the shape and markings on their tails, dorsal fins, heads and other body parts. Identification by natural markings via photographs—known as photo-ID—is a powerful tool for marine mammal science. It allows individual animals to be tracked over time and enables assessments of population status and trends. With your help to automate whale and dolphin photo-ID, researchers can reduce image identification times by over 99%. More efficient identification could enable a scale of study previously unaffordable or impossible.Currently, most research institutions rely on time-intensive—and sometimes inaccurate—manual matching by the human eye. Thousands of hours go into manual matching, which involves staring at photos to compare one individual to another, finding matches, and identifying new individuals. While researchers enjoy looking at a whale photo or two, manual matching limits the scope and reach.Algorithms developed in this competition will be implemented in Happywhale, a research collaboration and citizen science web platform. Its mission is to increase global understanding and caring for marine environments through high quality conservation science and education. Happywhale aims to make it easy and rewarding for the public to participate in science by building innovative tools to engage anyone interested in marine mammals. The platform also serves the research community with powerful collaborative tools.In this competition, you’ll develop a model to match individual whales and dolphins by unique—but often subtle—characteristics of their natural markings. You'll pay particular attention to dorsal fins and lateral body views in image sets from a multi-species dataset built by 28 research institutions. The best submissions will suggest photo-ID solutions that are fast and accurate.If successful, you'll have a hand in building advanced technology to better understand and manage the impact on the world’s changing oceans. Previous automation attempts resulted in a global database of over 50,000 whales and an agreement with cruise ships to operate at a maximum speed of 11 mph in the most whale-rich region. Your ideas to automate the identification of marine life will help overcome increasing human impacts on oceans, providing a critical tool for conservation science. If there's a whale, there's a way!\"}, {'title': 'Tabular Playground Series - Feb 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-feb-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33102/logos/header.png?t=2021-12-30-01-24-25', 'tag': 'tabular, categorizationaccuracy', 'description': \"For the February 2022 Tabular Playground Series competition, your task is to classify 10 different bacteria species using data from a genomic analysis technique that has some data compression and data loss. In this technique, 10-mer snippets of DNA are sampled and analyzed to give the *histogram* of base count. In other words, the DNA segment \\\\\\\\(\\\\text{ATATGGCCTT}\\\\\\\\) becomes  \\\\\\\\(\\\\text{A}\\\\_2\\\\text{T}\\\\_4\\\\text{G}\\\\_2\\\\text{C}\\\\_2\\\\\\\\). Can you use this lossy information to accurately predict bacteria species?## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.### Getting Started For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn. *Good luck and have fun!*## AcknowledgementsThe idea for this competition came from the following [paper](https://www.frontiersin.org/articles/10.3389/fmicb.2020.00257/full):```@ARTICLE{10.3389/fmicb.2020.00257,AUTHOR={Wood, Ryan L. and Jensen, Tanner and Wadsworth, Cindi and Clement, Mark and Nagpal, Prashant and Pitt, William G.},   TITLE={Analysis of Identification Method for Bacterial Species and Antibiotic Resistance Genes Using Optical Data From DNA Oligomers},      JOURNAL={Frontiers in Microbiology},      VOLUME={11},      YEAR={2020},      URL={https://www.frontiersin.org/article/10.3389/fmicb.2020.00257},       DOI={10.3389/fmicb.2020.00257},      ISSN={1664-302X}}```\"}, {'title': 'Ubiquant Market Prediction', 'url': 'https://www.kaggle.com/competitions/ubiquant-market-prediction', 'briefDescription': 'Make predictions against future market data', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/32053/logos/header.png?t=2021-11-05-23-54-43', 'tag': 'tabular, finance, meanpearson', 'description': \"Regardless of your investment strategy, fluctuations are expected in the financial market. Despite this variance, professional investors try to estimate their overall returns. Risks and returns differ based on investment types and other factors, which impact stability and volatility. To attempt to predict returns, there are many computer-based algorithms and models for financial market trading. Yet, with new techniques and approaches, data science could improve quantitative researchers' ability to forecast an investment's return.Ubiquant Investment (Beijing) Co., Ltd is a leading domestic quantitative hedge fund based in China. Established in 2012, they rely on international talents in math and computer science along with cutting-edge technology to drive quantitative financial market investment. Overall, Ubiquant is committed to creating long-term stable returns for investors.In this competition, you’ll build a model that forecasts an investment's return rate. Train and test your algorithm on historical prices. Top entries will solve this real-world data science problem with as much accuracy as possible.If successful, you could improve the ability of quantitative researchers to forecast returns. This will enable investors at any scale to make better decisions. You may even discover you have a knack for financial datasets, opening up a world of new opportunities in many industries.See more information about Ubiquant below:[](https://www.youtube.com/watch?v=PCzi76d-W6o)> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/ubiquant-market-prediction/overview/code-requirements) for details.**\"}, {'title': 'Tabular Playground Series - Jan 2022', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-jan-2022', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/33101/logos/header.png?t=2021-12-30-01-23-41', 'tag': 'tabular, time series analysis, smape', 'description': \"We've heard your feedback from the 2021 Tabular Playground Series, and now Kaggle needs your help going forward in 2022!There are two (fictitious) independent store chains selling Kaggle merchandise that want to become **the** official outlet for all things Kaggle. We've decided to see if the Kaggle community could help us figure out which of the store chains would have the best sales going forward. So, we've collected some data and are asking you to build forecasting models to help us decide. Help us figure out whether KaggleMart or KaggleRama should become the official Kaggle outlet!![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F59561%2Fcc6d9a21f0c3ed71b00113b33efb2b66%2Fkaggle_sweater.png?generation=1640900016906235&alt=media)## About the Tabular Playground SeriesKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model. These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you; thus, we encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.\"}, {'title': 'Feedback Prize - Evaluating Student Writing', 'url': 'https://www.kaggle.com/competitions/feedback-prize-2021', 'briefDescription': 'Analyze argumentative writing elements from students grade 6-12 ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/31779/logos/header.png?t=2021-11-12-22-52-17', 'tag': 'nlp, text, primary and secondary schools, custom metric', 'description': \"Writing is a critical skill for success. However, less than a third of high school seniors are proficient writers, according to the National Assessment of Educational Progress. Unfortunately, low-income, Black, and Hispanic students fare even worse, with less than 15 percent demonstrating writing proficiency. One way to help students improve their writing is via automated feedback tools, which evaluate student writing and provide personalized feedback.There are currently numerous  automated writing feedback tools, but they all have limitations. Many often fail to identify writing structures, such as thesis statements and support for claims, in essays or do not do so thoroughly. Additionally, the majority of the available tools are proprietary, with algorithms and feature claims that cannot be independently backed up. More importantly, many of these writing tools are inaccessible to educators because of their cost. This problem is compounded for  under-serviced schools which serve a disproportionate number of students of color and from low-income backgrounds. In short, the field of automated writing feedback is ripe for innovation that could help democratize education.Georgia State University (GSU) is an undergraduate and graduate urban public research institution in Atlanta. U.S. News & World Report ranked GSU as one of the most innovative universities in the nation. GSU awards more bachelor’s degrees to African-Americans than any other non-profit college or university in the country. GSU and [The Learning Agency Lab](https://the-learning-agency-lab.com/), an independent nonprofit based in Arizona, are focused on developing science of learning-based tools and programs for social good.In this competition, you’ll identify elements in student writing. More specifically, you will automatically segment texts and classify argumentative and rhetorical elements in essays written by 6th-12th grade students. You'll have access to the largest dataset of student writing ever released in order to test your skills in natural language processing, a fast-growing area of data science.![Description Image](https://storage.googleapis.com/kaggle-media/competitions/The%20Learning%20Agency/Kaggle%20Description%20Image.png)If successful, you'll make it easier for students to receive feedback on their writing and increase opportunities to improve writing outcomes. Virtual writing tutors  and automated writing systems can leverage these algorithms while teachers may use them to reduce grading time. The open-sourced algorithms you come up with will allow any educational organization to better help young writers develop.###Acknowledgements    Georgia State University and the Learning Agency Lab would like to thank the Bill & Melinda Gates Foundation, Schmidt Futures and Chan Zuckerberg Initiative for their support in making this work possible.  \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0\\xa0\\xa0\\xa0> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/feedback-prize-2021/overview/code-requirements) for details.**\"}, {'title': 'Tabular Playground Series - Dec 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-dec-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/28012/logos/header.png?t=2021-06-30-01-16-12', 'tag': 'tabular, categorizationaccuracy', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic, but based on a real dataset and generated using a [CTGAN](https://github.com/sdv-dev/CTGAN). This dataset is based off of the original [Forest Cover Type Prediction](https://www.kaggle.com/c/forest-cover-type-prediction/overview) competition.Good luck and have fun!For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'TensorFlow - Help Protect the Great Barrier Reef ', 'url': 'https://www.kaggle.com/competitions/tensorflow-great-barrier-reef', 'briefDescription': 'Detect crown-of-thorns starfish in underwater image data', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/31703/logos/header.png?t=2021-10-29-00-30-04', 'tag': 'earth and nature, image, custom metric', 'description': '## Goal of the CompetitionThe goal of this competition is to accurately identify starfish in real-time by building an object detection model trained on underwater videos of coral reefs.Your work will help researchers identify species that are threatening Australia\\'s Great Barrier Reef and take well-informed action to protect the reef for future generations.## ContextAustralia\\'s stunningly beautiful Great Barrier Reef is the world’s largest coral reef and home to 1,500 species of fish, 400 species of corals, 130 species of sharks, rays, and a massive variety of other sea life. Unfortunately, the reef is under threat, in part because of the overpopulation of one particular starfish – the coral-eating crown-of-thorns starfish (or COTS for short). Scientists, tourism operators and reef managers established a large-scale intervention program to control COTS outbreaks to ecologically sustainable levels.[](https://www.youtube.com/watch?v=UT2noVDFoaA) To know where the COTS are, a traditional reef survey method, called \"Manta Tow\", is performed by a snorkel diver. While towed by a boat, they visually assess the reef, stopping to record variables observed every 200m. While generally effective, this method faces clear limitations, including operational scalability, data resolution, reliability, and traceability. The Great Barrier Reef Foundation established an [innovation program](https://www.barrierreef.org/what-we-do/reef-trust-partnership/crown-of-thorns-starfish-control) to develop new survey and intervention methods to provide a step change in COTS Control. Underwater cameras will collect thousands of reef images and AI technology could drastically improve the efficiency and scale at which reef managers detect and control COTS outbreaks.To scale up video-based surveying systems, Australia’s national science agency, CSIRO has teamed up with Google to develop innovative machine learning technology that can analyse large image datasets accurately, efficiently, and in near real-time.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/tensorflow-great-barrier-reef/overview/code-requirements) for details.**## CitationPlease cite [this short paper](https://arxiv.org/abs/2111.14311) if you are using this dataset for research purposes.```@misc{liu2021csiro,      title={The CSIRO Crown-of-Thorn Starfish Detection Dataset},       author={Jiajun Liu and Brano Kusy and Ross Marchant and Brendan Do and Torsten Merz and Joey Crosswell and Andy Steven and Nic Heaney and Karl von Richter and Lachlan Tychsen-Smith and David Ahmedt-Aristizabal and Mohammad Ali Armin and Geoffrey Carlin and Russ Babcock and Peyman Moghadam and Daniel Smith and Tim Davis and Kemal El Moujahid and Martin Wicke and Megha Malpani},      year={2021},      eprint={2111.14311},      archivePrefix={arXiv},      primaryClass={cs.CV}}```'}, {'title': 'G-Research Crypto Forecasting ', 'url': 'https://www.kaggle.com/competitions/g-research-crypto-forecasting', 'briefDescription': 'Use your ML expertise to predict real crypto market data', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/30894/logos/header.png?t=2021-09-14-17-32-48', 'tag': 'tabular, finance, time series analysis, custom metric', 'description': \"Over $40 billion worth of cryptocurrencies are traded every day. They are among the most popular assets for speculation and investment, yet have proven wildly volatile. Fast-fluctuating prices have made millionaires of a lucky few, and delivered crushing losses to others. Could some of these price movements have been predicted in advance?In this competition, you'll use your machine learning expertise to forecast short term returns in 14 popular cryptocurrencies. We have amassed a dataset of millions of rows of high-frequency market data dating back to 2018 which you can use to build your model.   Once the submission deadline has passed, your final score will be calculated over the following 3 months using live crypto data as it is collected.The simultaneous activity of thousands of traders ensures that most signals will be transitory, persistent alpha will be exceptionally difficult to find, and the danger of overfitting will be considerable. In addition, since 2018, interest in the cryptomarket has exploded, so the volatility and correlation structure in our data are likely to be highly non-stationary. The successful contestant will pay careful attention to these considerations, and in the process gain valuable insight into the art and science of financial forecasting.[G-Research] (https://www.gresearch.co.uk/) is Europe’s leading quantitative finance research firm. We have long explored the extent of market prediction possibilities, making use of machine learning, big data, and some of the most advanced technology available. Specializing in data science and AI education for workforces, [Cambridge Spark] (https://www.cambridgespark.com/) is partnering with G-Research for this competition. Watch our introduction to the competition below:[](https://www.youtube.com/watch?v=GW84uCnYr30)> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/g-research-crypto-forecasting/overview/code-requirements) for details.**\"}, {'title': 'Tabular Playground Series - Nov 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-nov-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/28011/logos/header.png?t=2021-06-30-01-14-31', 'tag': 'tabular, auc', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic, but based on a real dataset and generated using a [CTGAN](https://github.com/sdv-dev/CTGAN). The original dataset deals with predicting identifying spam emails via various extracted features from the email. Although the features are anonymized, they have properties relating to real-world features.Good luck and have fun!For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'Sartorius - Cell Instance Segmentation', 'url': 'https://www.kaggle.com/competitions/sartorius-cell-instance-segmentation', 'briefDescription': 'Detect single neuronal cells in microscopy images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/30201/logos/header.png?t=2021-09-03-15-27-46', 'tag': 'image, biology, custom metric', 'description': \"Neurological disorders, including neurodegenerative diseases such as Alzheimer's and brain tumors, are a leading cause of death and disability across the globe. However, it is hard to quantify how well these deadly disorders respond to treatment. One accepted method is to review neuronal cells via light microscopy, which is both accessible and non-invasive. Unfortunately, segmenting individual neuronal cells in microscopic images can be challenging and time-intensive. Accurate instance segmentation of these cells—with the help of computer vision—could lead to new and effective drug discoveries to treat the millions of people with these disorders.Current solutions have limited accuracy for neuronal cells in particular. In internal studies to develop cell instance segmentation models, the neuroblastoma cell line SH-SY5Y consistently exhibits the lowest precision scores out of eight different cancer cell types tested. This could be because neuronal cells have a very unique, irregular and concave morphology associated with them, making them challenging to segment with commonly used mask heads.Sartorius is a partner of the life science research and the biopharmaceutical industry. They empower scientists and engineers to simplify and accelerate progress in life science and bioprocessing, enabling the development of new and better therapies and more affordable medicine. They're a magnet and dynamic platform for pioneers and leading experts in the field. They bring creative minds together for a common goal: technological breakthroughs that lead to better health for more people.In this competition, you’ll detect and delineate distinct objects of interest in biological images depicting neuronal cell types commonly used in the study of neurological disorders. More specifically, you'll use phase contrast microscopy images to train and test your model for instance segmentation of neuronal cells. Successful models will do this with a high level of accuracy.If successful, you'll help further research in neurobiology thanks to the collection of robust quantitative data. Researchers may be able to use this to more easily measure the effects of disease and treatment conditions on neuronal cells. As a result, new drugs could be discovered to treat the millions of people with these leading causes of death and disability.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/sartorius-cell-instance-segmentation/overview/code-requirements) for details.**\"}, {'title': '2021 Kaggle Machine Learning & Data Science Survey', 'url': 'https://www.kaggle.com/competitions/kaggle-survey-2021', 'briefDescription': 'The most comprehensive dataset available on the state of ML and data science', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/31480/logos/header.png?t=2021-10-05-16-58-19', 'tag': 'data analytics, online communities, survey analysis', 'description': \"**Welcome to Kaggle's annual Machine Learning and Data Science Survey competition!  [You can read our executive summary here](https://www.kaggle.com/kaggle-survey-2021).**This year, as in [2017][1], [2018](https://www.kaggle.com/kaggle/kaggle-survey-2018/), [2019](https://www.kaggle.com/c/kaggle-survey-2019/), and [2020](https://www.kaggle.com/c/kaggle-survey-2020/)  we set out to conduct an industry-wide survey that presents a truly comprehensive view of the state of data science and machine learning. The survey was live from 09/01/2021 to 10/04/2021, and after cleaning the data we finished with 25,973 responses!There's a lot to explore here. The results include raw numbers about who is working with data, what’s happening with machine learning in different industries, and the best ways for new data scientists to break into the field. We've published the data in as raw a format as possible without compromising anonymization, which makes it an unusual example of a survey dataset.**This year Kaggle is once again launching an annual Data Science Survey Challenge, where we will be awarding a prize pool of $30,000 to notebook authors who tell a rich story about a subset of the data science and machine learning community.**In our fifth year running this survey, we were once again awed by the global, diverse, and dynamic nature of the data science and machine learning industry. This [survey data EDA][4] provides an overview of the industry on an aggregate scale, but it also leaves us **wanting to know more about the many specific communities comprised within the survey**. For that reason, we’re inviting the Kaggle community to dive deep into the survey datasets and help us tell the diverse stories of data scientists from around the world.  **The challenge objective:** tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration. A “story” could be defined any number of ways, and that’s deliberate. The challenge is to deeply explore (through data) the impact, priorities, or concerns of a specific group of data science and machine learning practitioners. That group can be defined in the macro (for example: anyone who does most of their coding in Python) or the micro (for example: female data science students studying machine learning in masters programs). This is an opportunity to be creative and tell the story of a community you identify with or are passionate about! **Submissions will be evaluated on the following:** - Composition - Is there a clear narrative thread to the story that’s articulated and supported by data? The subject should be well defined, well researched, and well supported through the use of data and visualizations.  - Originality - Does the reader learn something new through this submission? Or is the reader challenged to think about something in a new way? A great entry will be informative, thought provoking, and fresh all at the same time.   - Documentation - Are your code, and notebook, and additional data sources well documented so a reader can understand what you did? Are your sources clearly cited? A high quality analysis should be concise and clear at each step so the rationale is easy to follow and the process is reproducible To be valid, a submission must be contained in one notebook, made public on or before the submission deadline. Participants are free to use any datasets in addition to the Kaggle Data Science survey, but those datasets must also be publicly available on Kaggle by the deadline for a submission to be valid. You can make your submission by filling out [the submission form](https://www.kaggle.com/page/2021-kaggle-survey-competition-submission-form).   [1]: https://www.kaggle.com/kaggle/kaggle-survey-2017  [2]: http://blog.kaggle.com/  [3]: https://www.kaggle.com/page/2021-kaggle-survey-competition-submission-form  [4]: https://www.kaggle.com/paultimothymooney/2021-kaggle-data-science-machine-learning-survey\"}, {'title': 'Store Sales - Time Series Forecasting', 'url': 'https://www.kaggle.com/competitions/store-sales-time-series-forecasting', 'briefDescription': 'Use machine learning to predict grocery sales', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/29781/logos/header.png?t=2021-09-22-19-59-35', 'tag': 'beginner, tabular, time series analysis, rmsle', 'description': \"Goal of the CompetitionIn this “getting started” competition, you’ll use time-series forecasting to forecast store sales on data from Corporación Favorita, a large Ecuadorian-based grocery retailer.Specifically, you'll build a model that more accurately predicts the unit sales for thousands of items sold at different Favorita stores. You'll practice your machine learning skills with an approachable training dataset of dates, store, and item information, promotions, and unit sales.Get StartedWe highly recommend the Time Series course, which walks you through how to make your first submission.  The lessons in this course are inspired by winning solutions from past Kaggle time series forecasting competitions.ContextForecasts aren’t just for meteorologists. Governments forecast economic growth. Scientists attempt to predict the future population. And businesses forecast product demand—a common task of professional data scientists. Forecasts are especially relevant to brick-and-mortar grocery stores, which must dance delicately with how much inventory to buy. Predict a little over, and grocers are stuck with overstocked, perishable goods. Guess a little under, and popular items quickly sell out, leading to lost revenue and upset customers. More accurate forecasting, thanks to machine learning, could help ensure retailers please customers by having just enough of the right products at the right time.Current subjective forecasting methods for retail have little data to back them up and are unlikely to be automated. The problem becomes even more complex as retailers add new locations with unique needs, new products, ever-transitioning seasonal tastes, and unpredictable product marketing. Potential ImpactIf successful, you'll have flexed some new skills in a real world example. For grocery stores, more accurate forecasting can decrease food waste related to overstocking and improve customer satisfaction. The results of this ongoing competition, over time, might even ensure your local store has exactly what you need the next time you shop.\"}, {'title': 'Tabular Playground Series - Oct 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-oct-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/28010/logos/header.png?t=2021-06-30-01-13-23', 'tag': 'tabular, binary classification, auc', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic, but based on a real dataset and generated using a [CTGAN](https://github.com/sdv-dev/CTGAN). The original dataset deals with predicting the biological response of molecules given various chemical properties. Although the features are anonymized, they have properties relating to real-world features.Good luck and have fun!For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'NFL Big Data Bowl 2022', 'url': 'https://www.kaggle.com/competitions/nfl-big-data-bowl-2022', 'briefDescription': 'Help evaluate special teams performance', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/15696/logos/header.png?t=2019-10-04-16-16-53', 'tag': None, 'description': \"Before National Football League (NFL) coaches celebrate a big W, they strategize ways to improve field position and score points. Both of these objectives receive significant contributions from special teams plays, which consist of punts, kickoffs, field goals and extra points. These play types take on important roles in a game’s final score—so much so that coaches say they're a third of the game. Yet special teams remain an understudied part of American football, with an opportunity for data science to offer better ways to understand its impact.The 2022 Big Data Bowl creates the opportunity for you (and the world!) to learn more about special teams play than ever before. We've provided the NFL's [Next Gen Stats](https://nextgenstats.nfl.com/) (NGS) tracking data from all 2018-2020 special teams plays. This data provides location information for each special teams player, wherever they are on the field, and includes their speed, acceleration, and direction. Additionally, and for the first time in Big Data Bowl history, participants can utilize scouting data from [PFF](https://www.pff.com/), which supplements the tracking data with football specific metrics that coaches find critical to team success. The NFL is America's most popular sports league. Founded in 1920, the organization behind American football has developed the model for the successful modern sports league. They're committed to advancing every aspect of the game, including the lesser researched special teams. In this competition, you’ll quantify what happens on special teams plays. You might create a new special teams metric, quantify team or individual strategies, rank players, or even something we haven’t considered.With your creativity and analytical skills, the development of these new methods could lead to additional stats for special teams plays. If successful, your effort [may even be adopted by the NFL](https://www.nfl.com/news/next-gen-stats-intro-to-expected-rushing-yards) for on air distribution, and you can watch future games knowing you had a hand in improving America's most popular sports league.\"}, {'title': 'PetFinder.my - Pawpularity Contest', 'url': 'https://www.kaggle.com/competitions/petfinder-pawpularity-score', 'briefDescription': 'Predict the popularity of shelter pet photos', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25383/logos/header.png?t=2021-08-31-18-49-29', 'tag': 'image, rmse', 'description': '\\xa0A picture is worth a thousand words. But did you know a picture can save a thousand lives? Millions of stray animals suffer on the streets or are euthanized in shelters every day around the world. You might expect pets with attractive photos to generate more interest and be adopted faster. But what makes a good picture? With the help of data science, you may be able to accurately determine a pet photo’s appeal and even suggest improvements to give these rescue animals a higher chance of loving homes.PetFinder.my is Malaysia’s leading animal welfare platform, featuring over 180,000 animals with 54,000 happily adopted. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.Currently, PetFinder.my uses a basic Cuteness Meter to rank pet photos. It analyzes picture composition and other factors compared to the performance of thousands of pet profiles. While this basic tool is helpful, it\\'s still in an experimental stage and the algorithm could be improved.In this competition, you’ll analyze raw images and metadata to predict the “Pawpularity” of pet photos. You\\'ll train and test your model on PetFinder.my\\'s thousands of pet profiles. Winning versions will offer accurate recommendations that will improve animal welfare.If successful, your solution will be adapted into AI tools that will guide shelters and rescuers around the world to improve the appeal of their pet profiles, automatically enhancing photo quality and recommending composition improvements. As a result, stray dogs and cats can find their \"furever\" homes much faster. With a little assistance from the Kaggle community, many precious lives could be saved and more happy families created.Top participants may be invited to collaborate on implementing their solutions and creatively improve global animal welfare with their AI skills.\\xa0> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/petfinder-pawpularity-score/overview/code-requirements) for details.**'}, {'title': 'Google Brain - Ventilator Pressure Prediction', 'url': 'https://www.kaggle.com/competitions/ventilator-pressure-prediction', 'briefDescription': \"Simulate a ventilator connected to a sedated patient's lung\\n\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/29594/logos/header.png?t=2021-07-29-12-44-09', 'tag': 'tabular, biology, medicine, mae', 'description': \"What do doctors do when a patient has trouble breathing? They use a ventilator to pump oxygen into a sedated patient's lungs via a tube in the windpipe. But mechanical ventilation is a clinician-intensive procedure, a limitation that was prominently on display during the early days of the COVID-19 pandemic. At the same time, developing new methods for controlling mechanical ventilators is prohibitively expensive, even before reaching clinical trials. High-quality simulators could reduce this barrier. Current simulators are trained as an ensemble, where each model simulates a single lung setting. However, lungs and their attributes form a continuous space, so a parametric approach must be explored that would consider the differences in patient lungs. Partnering with Princeton University, the team at Google Brain aims to grow the community around machine learning for mechanical ventilation control. They believe that neural networks and deep learning can better generalize across lungs with varying characteristics than the current industry standard of PID controllers.  In this competition, you’ll simulate a ventilator connected to a sedated patient's lung. The best submissions will take lung attributes compliance and resistance into account.If successful, you'll help overcome the cost barrier of developing new methods for controlling mechanical ventilators. This will pave the way for algorithms that adapt to patients and reduce the burden on clinicians during these novel times and beyond. As a result, ventilator treatments may become more widely available to help patients breathe.Photo by Nino Liverani on Unsplash\"}, {'title': 'Wikipedia - Image/Caption Matching', 'url': 'https://www.kaggle.com/competitions/wikipedia-image-caption', 'briefDescription': 'Retrieve captions based on images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/29705/logos/header.png?t=2021-08-09-04-38-12', 'tag': 'image, text, ndcg@{k}', 'description': \"A picture is worth a thousand words, yet sometimes a few will do. We all rely on online images for knowledge sharing, learning, and understanding. Even the largest websites are missing visual content and metadata to pair with their images. Captions and “[alt text](https://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Accessibility/Alternative_text_for_images)” increase accessibility and enable better search. The majority of images on Wikipedia articles, for example, don't have any written context connected to the image. Open models could help anyone improve accessibility and learning for all.Current solutions rely on simple methods based on translations or page interlinks, which have limited coverage. Even the most advanced computer vision image captioning isn't suitable for images with complex semantics.In this competition, you’ll build a model that automatically retrieves the text closest to an image. Specifically, you'll train your model to associate given images with article titles or complex captions, in multiple languages. The best models will account for the semantic granularity of Wikipedia images.If successful, you'll be contributing to the accessibility of the largest online encyclopedia. The millions of Wikipedia readers and editors will be able to more easily understand, search, and describe media at scale. As a result, you’ll contribute to an open model to improve learning for all.--This competition is organized by the [Research](https://research.wikimedia.org/) team at the [Wikimedia Foundation](https://wikimediafoundation.org/). This competition is based on the [WIT dataset](https://github.com/google-research-datasets/wit) published by Google Research as detailed in this [SIGIR paper](https://dl.acm.org/doi/abs/10.1145/3404835.3463257).\"}, {'title': 'Tabular Playground Series - Sep 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-sep-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/28009/logos/header.png?t=2021-06-30-01-12-34', 'tag': 'tabular, binary classification, auc', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic, but based on a real dataset and generated using a [CTGAN](https://github.com/sdv-dev/CTGAN). The original dataset deals with predicting whether a claim will be made on an insurance policy. Although the features are anonymized, they have properties relating to real-world features.Good luck and have fun!For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'Lux AI', 'url': 'https://www.kaggle.com/competitions/lux-ai-2021', 'briefDescription': 'Gather the most resources and survive the night!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/30067/logos/header.png?t=2021-07-20-15-37-18', 'tag': 'video games, simulations, custom metric', 'description': '## IntroductionThe night is dark and full of terrors. Two teams must fight off the darkness, collect resources, and advance through the ages. Daytime finds a desperate rush to gather the resources that can carry you through the impending night whilst growing your city. Plan and expand carefully -- any city that fails to produce enough light will be consumed by darkness. **Welcome to the Lux AI Challenge Season 1!**The Lux AI Challenge is a competition where competitors design agents to tackle a multi-variable optimization, resource gathering, and allocation problem in a 1v1 scenario against other competitors. In addition to optimization, successful agents must be capable of analyzing their opponents and developing appropriate policies to get the upper hand. All code can be found at our [Github](https://github.com/Lux-AI-Challenge/Lux-Design-2021), make sure to give it a star while you are there! Make sure to join our community [discord](https://discord.gg/aWJt3UAcgn) to chat, strategize, and learn with other competitors! We will be posting announcements on the Kaggle Forums and on the discord. ## SponsorsWe would like to thank our 3 sponsors, [QuantCo](https://quantco.com/), [J Ventures](http://thejiangmen.com), and [QAImera](https://qaimera.com) this year for allowing us to provide a prize pool and exciting opportunities to our competitors!  For more information on them, go to the [sponsors tab](https://www.kaggle.com/c/lux-ai-2021/overview/sponsors)'}, {'title': 'chaii - Hindi and Tamil Question Answering', 'url': 'https://www.kaggle.com/competitions/chaii-hindi-and-tamil-question-answering', 'briefDescription': 'Identify the answer to questions found in Indian language passages', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/30060/logos/header.png?t=2021-07-29-17-23-51', 'tag': 'text, languages, custom metric', 'description': \"With nearly 1.4 billion people, India is the second-most populated country in the world. Yet Indian languages, like Hindi and Tamil, are underrepresented on the web. Popular Natural Language Understanding (NLU) models perform worse with Indian languages compared to English, the effects of which lead to subpar experiences in downstream web applications for Indian users. With more attention from the Kaggle community and your novel machine learning solutions, we can help Indian users make the most of the web.Predicting answers to questions is a common NLU task, but not for Hindi and Tamil. Current progress on multilingual modeling requires a concentrated effort to generate high-quality datasets and modelling improvements. Additionally, for languages that are typically underrepresented in public datasets, it can be difficult to build trustworthy evaluations. We hope the dataset provided for this competition—and [additional datasets generated by participants](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/overview/sharing-datasets)—will enable future machine learning for Indian languages.In this competition, your goal is to predict answers to real questions about Wikipedia articles. You will use chaii-1, a new question answering dataset with question-answer pairs. The dataset covers Hindi and Tamil, collected without the use of translation. It provides a realistic information-seeking task with questions written by native-speaking expert data annotators. You will be provided with a [baseline model](https://www.kaggle.com/deeplearning10/chaii-1-starter-notebook) and [inference code](https://www.kaggle.com/deeplearning10/chaii-1-inference) to build upon.If successful, you'll improve upon the baseline performance of NLU models in Indian languages. The results could improve the web experience for many of the nearly 1.4 billion people of India. Additionally, you’ll contribute to multilingual NLP, which could be applied beyond the languages in this competition.### Acknowledgments**Google Research India** contributes fundamental advances in computer science and applies their research to big problems impacting India, Google, and communities around the world. The Natural Language Understanding group at Google Research India works specifically with ML to address the unique challenges in the Indian context (such as code mixing in Search, diversity of languages, dialects and accents in Assistant), learning from limited resources and advancing multilingual models. **chaii ([Challenge in AI for India](https://events.withgoogle.com/chaii2021))** is a [Google Research India](https://research.google/teams/india-research-lab/) initiative created with the purpose of sparking AI applications to address some of the pressing problems in India and to find unique ways to address them. Starting with a focus on NLU, chaii hopes to make progress towards multilingual modelling, as language diversity is significantly underserved on the web. Google Research India is  working on transformational approaches to healthcare, agriculture and education, and also improving apps and services such as search, assistant and payments, e.g., to deal with challenges arising out of the diversity of languages in India. We also acknowledge the support from the [AI4Bharat](https://indicnlp.ai4bharat.org/home/) Team at the Indian Institute of Technology Madras.\"}, {'title': 'Google Landmark Retrieval 2021', 'url': 'https://www.kaggle.com/competitions/landmark-retrieval-2021', 'briefDescription': 'Given an image, can you find all of the same landmarks in a dataset?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/29761/logos/header.png?t=2021-07-21-17-07-00', 'tag': 'image, computer vision, map@{k}', 'description': \"Welcome to the fourth Landmark Retrieval competition! This year, we introduce a lot more diversity in the challenge’s test images in order to measure global landmark retrieval performance in a fairer manner. And following last year’s success, we set this up as a code competition.Image retrieval is a central problem in computer vision, relevant to many applications. The problem is usually posed as follows: given a query image, can you find similar images in a large database? This is especially important for query images containing landmarks, which accounts for a large portion of what people like to photograph.In this competition, the developed models are expected to retrieve relevant database images to a given query image (i.e., the model should retrieve database images containing the same landmark as the query). This challenge is organized in conjunction with the [Landmark Recognition Challenge 2021](https://www.kaggle.com/c/landmark-recognition-2021/). Both challenges will be discussed at the [Instance-Level Recognition workshop](https://ilr-workshop.github.io/ICCVW2021/) in ICCV 21.In contrast to previous editions of this challenge ([2018](https://www.kaggle.com/c/landmark-retrieval-challenge), [2019](https://www.kaggle.com/c/landmark-retrieval-2019), and [2020](https://www.kaggle.com/c/landmark-retrieval-2020)), this year's competition is structured in a synchronous rerun format, where participants need to submit their Kaggle notebooks for scoring.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/landmark-retrieval-2021/overview/code-requirements) for details.**\"}, {'title': 'Google Landmark Recognition 2021', 'url': 'https://www.kaggle.com/competitions/landmark-recognition-2021', 'briefDescription': 'Label famous, and not-so-famous, landmarks in images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/29762/logos/header.png?t=2021-07-21-17-09-45', 'tag': 'image, computer vision, custom metric', 'description': \"Welcome to the fourth Landmark Recognition competition! This year, we introduce a lot more diversity in the challenge’s test images in order to measure global landmark recognition performance in a fairer manner. And following last year’s success, we set this up as a code competition.Have you ever gone through your vacation photos and asked yourself: What is the name of this temple I visited in China? Who created this monument I saw in France? Landmark recognition can help! This technology can predict landmark labels directly from image pixels, to help people better understand and organize their photo collections. This competition challenges Kagglers to build models that recognize the correct landmark (if any) in a dataset of challenging test images.Many Kagglers are familiar with image classification challenges like the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), which aims to recognize 1K general object categories. Landmark recognition is a little different from that: it contains a much larger number of classes (there are more than 81K classes in this challenge), and the number of training examples per class may not be very large. Landmark recognition is challenging in its own way.This year's competition is structured in a synchronous rerun format, where participants need to submit their Kaggle notebooks for scoring. This is similar to the [2020 version of the competition](https://www.kaggle.com/c/landmark-recognition-2020). In older editions ([2018](https://www.kaggle.com/c/landmark-recognition-challenge) and  [2019](https://www.kaggle.com/c/landmark-recognition-2019)), submissions had been handled by uploading prediction files to the system. This challenge is organized in conjunction with the [Landmark Retrieval Challenge 2021](https://www.kaggle.com/c/landmark-retrieval-2021). Both challenges will be discussed at the [Instance-Level Recognition workshop](https://ilr-workshop.github.io/ICCVW2021/) in ICCV 21.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/landmark-recognition-2021/overview/code-requirements) for details.**Cover image credits: Muhammad Mahdi Karim. The original is available on Wikimedia [here](https://commons.wikimedia.org/wiki/File:Mount_Kilimanjaro.jpg). License: [GNU Free Documentation License](https://commons.wikimedia.org/wiki/Commons:GNU_Free_Documentation_License,_version_1.2).\"}, {'title': 'NFL Health & Safety - Helmet Assignment', 'url': 'https://www.kaggle.com/competitions/nfl-health-and-safety-helmet-assignment', 'briefDescription': 'Segment and label helmets in video footage', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12125/logos/header.png?t=2018-11-30-18-08-32', 'tag': 'health, football, custom metric', 'description': \"The National Football League (NFL) and Amazon Web Services (AWS) are teaming up to develop the best sports injury surveillance and mitigation program. In previous competitions, Kaggle has helped detect helmet impacts. As a next step, the NFL wants to assign specific players to each helmet, which would help accurately identify each player's “exposures” throughout a football play.Currently, the NFL manually annotates a subset of plays each year to determine a sample of exposures for each player. To expand this program, the current player assignment requires a field map to determine player locations. The NFL is interested in matching this model's accuracy without the need for the mapping step. The league is calling on Kagglers to invent a better way to identify individual players.The National Football League is America's most popular sports league. Founded in 1920, the NFL developed the model for the successful modern sports league and is committed to advancing progress in the diagnosis, prevention, and treatment of sports-related injuries. Health and safety efforts include support for independent medical research and engineering advancements as well as a commitment to work to better protect players and make the game safer, including enhancements to medical protocols and improvements to how our game is taught and played. For more information about the NFL's health and safety efforts, please visit [www.NFL.com/PlayerHealthandSafety](http://www.NFL.com/PlayerHealthandSafety).In this competition, you’ll identify and assign football players’ helmets from video footage. In particular, you'll create algorithms capable of assigning detected helmet impacts to correct players via tracking information. Successful submissions should aim for 90% accuracy.If successful, you'll support the NFL in its efforts to efficiently improve player safety. If the league no longer has to manually label each exposure, it would dramatically increase the speed and scale at which they could answer complex research questions related to helmet impact. Automatic player detection would also allow the NFL to back-calculate historic exposure trends, allowing for deeper insights into how to mitigate them in the future.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/nfl-health-and-safety-helmet-assignment/overview/code-requirements) for details.**\"}, {'title': 'LearnPlatform COVID-19 Impact on Digital Learning', 'url': 'https://www.kaggle.com/competitions/learnplatform-covid19-impact-on-digital-learning', 'briefDescription': 'Use digital learning data to analyze the impact of COVID-19 on student learning', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26939/logos/header.png?t=2021-07-22-17-26-48', 'tag': 'education, data analytics, covid19', 'description': \"Nelson Mandela believed education was the most powerful weapon to change the world. But not every student has equal opportunities to learn. Effective policies and plans need to be enacted in order to make education more equitable—and perhaps your innovative data analysis will help reveal the solution.Current research shows educational outcomes are far from equitable. The imbalance was exacerbated by the COVID-19 pandemic. There's an urgent need to better understand and measure the scope and impact of the pandemic on these inequities.Education technology company LearnPlatform was founded in 2014 with a mission to expand equitable access to education technology for all students and teachers. LearnPlatform’s comprehensive edtech effectiveness system is used by districts and states to continuously improve the safety, equity, and effectiveness of their educational technology. LearnPlatform does so by generating an evidence basis for what’s working and enacting it to benefit students, teachers, and budgets. In this analytics competition, you’ll work to uncover trends in digital learning. Accomplish this with data analysis about how engagement with digital learning relates to factors like district demographics, broadband access, and state/national level policies and events. Then, submit a Kaggle Notebook to propose your best solution to these educational inequities.Your submissions will inform policies and practices that close the digital divide. With a better understanding of digital learning trends, you may help reverse the long-term learning loss among America’s most vulnerable, making education more equitable.### Problem StatementThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America’s most vulnerable learners continue to grow. ### Challenge**We challenge the Kaggle community to explore (1) the state of digital learning in 2020 and (2) how the engagement of digital learning relates to factors such as district demographics, broadband access, and state/national level policies and events.**We encourage you to guide the analysis with questions that are related to the themes that are described above (in bold font). Below are some examples of questions that relate to our problem statement:* What is the picture of digital connectivity and engagement in 2020?* What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?* How does student engagement with different types of education technology change over the course of the pandemic?* How does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?* Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?\"}, {'title': 'Tabular Playground Series - Aug 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-aug-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/28008/logos/header.png?t=2021-06-30-01-11-56', 'tag': 'tabular, regression, banking, rmse', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic, but based on a real dataset and generated using a [CTGAN](https://github.com/sdv-dev/CTGAN). The original dataset deals with calculating the loss associated with a loan defaults. Although the features are anonymized, they have properties relating to real-world features.Good luck and have fun!For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'RSNA-MICCAI Brain Tumor Radiogenomic Classification', 'url': 'https://www.kaggle.com/competitions/rsna-miccai-brain-tumor-radiogenomic-classification', 'briefDescription': 'Predict the status of a genetic biomarker important for brain cancer treatment', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/29653/logos/header.png?t=2021-07-07-17-26-56', 'tag': 'image, binary classification, healthcare, auc', 'description': \"A malignant tumor in the brain is a life-threatening condition. Known as glioblastoma, it's both the most common form of brain cancer in adults and the one with the worst prognosis, with median survival being less than a year. The presence of a specific genetic sequence in the tumor known as MGMT promoter methylation has been shown to be a favorable prognostic factor and a strong predictor of responsiveness to chemotherapy. Currently, genetic analysis of cancer requires surgery to extract a tissue sample. Then it can take several weeks to determine the genetic characterization of the tumor. Depending upon the results and type of initial therapy chosen, a subsequent surgery may be necessary. If an accurate method to predict the genetics of the cancer through imaging (i.e., radiogenomics) alone could be developed, this would potentially minimize the number of surgeries and refine the type of therapy required.The Radiological Society of North America (RSNA) has teamed up with the Medical Image Computing and Computer Assisted Intervention Society (the MICCAI Society) to improve diagnosis and treatment planning for patients with glioblastoma. In this competition you will predict the genetic subtype of glioblastoma using MRI (magnetic resonance imaging) scans to train and test your model to detect for the presence of MGMT promoter methylation.If successful, you'll help brain cancer patients receive less invasive diagnoses and treatments. The introduction of new and customized treatment strategies before surgery has the potential to improve the management, survival, and prospects of patients with brain cancer.###Acknowledgments**The Radiological Society of North America (RSNA®)** is a non-profit organization that represents 31 radiologic subspecialties from 145 countries around the world. RSNA promotes excellence in patient care and health care delivery through education, research and technological innovation.RSNA provides high-quality educational resources, publishes five top peer-reviewed journals, hosts the world’s largest radiology conference and is dedicated to building the future of the profession through the RSNA Research & Education (R&E) Foundation, which has funded $66 million in grants since its inception. RSNA also supports and facilitates artificial intelligence (AI) research in medical imaging by sponsoring an ongoing series of AI challenge competitions.**The Medical Image Computing and Computer Assisted Intervention Society (the MICCAI Society)** is dedicated to the promotion, preservation and facilitation of research, education and practice in the field of medical image computing and computer assisted medical interventions including biomedical imaging and medical robotics. The Society achieves this aim through the organization and operation of annual high quality international conferences, workshops, tutorials and publications that promote and foster the exchange and dissemination of advanced knowledge, expertise and experience in the field produced by leading institutions and outstanding scientists, physicians and educators around the world. [A full set of acknowledgments can be found on this page](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/overview/acknowledgments).![](https://storage.googleapis.com/kaggle-media/competitions/RSNA-2021/sponsors.png)\"}, {'title': 'Tabular Playground Series - Jul 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-jul-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/28007/logos/header.png?t=2021-06-30-01-10-51', 'tag': 'tabular, time series analysis, pollution, mcrmsle', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is based on a real dataset, but has synthetic-generated aspects to it. The original dataset deals with predicting air pollution in a city via various input sensor values (e.g., a time series).Good luck and have fun!For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'G2Net Gravitational Wave Detection', 'url': 'https://www.kaggle.com/competitions/g2net-gravitational-wave-detection', 'briefDescription': 'Find gravitational wave signals from binary black hole collisions', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/23249/logos/header.png?t=2021-05-26-16-18-03', 'tag': 'numpy, astronomy, signal processing, auc', 'description': \"It's been said that teamwork makes the dream work. This couldn't be truer for the breakthrough discovery of gravitational waves (GW), signals from colliding binary black holes in 2015. It required the collaboration of experts in physics, mathematics, information science, and computing. GW signals have led researchers to observe a new population of massive, stellar-origin black holes, to unlock the mysteries of neutron star mergers, and to measure the expansion of the Universe. These signals are unimaginably tiny ripples in the fabric of space-time and even though the global network of GW detectors are some of the most sensitive instruments on the planet, the signals are buried in detector noise. Analysis of GW data and the detection of these signals is a crucial mission for the growing global network of increasingly sensitive GW detectors. These challenges in data analysis and noise characterization could be solved with the help of data science.As with the multi-disciplined approach to the discovery of GWs, additional expertise will be needed to further GW research. In particular, social and natural sciences have taken an interest in machine learning, deep learning, classification problems, data mining, and visualization to develop new techniques and algorithms to efficiently handle complex and massive data sets. The increase in computing power and the development of innovative techniques for the rapid analysis of data will be vital to the exciting new field of GW Astronomy. Potential outcomes may include increased sensitivity to GW signals, application to control and feedback systems for next-generation detectors, noise removal, data conditioning tools, and signal characterization.G2Net is a network of Gravitational Wave, Geophysics and Machine Learning. Via an Action from COST (European Cooperation in Science and Technology), a funding agency for research and innovation networks, G2Net aims to create a broad network of scientists. From four different areas of expertise, namely GW physics, Geophysics, Computing Science and Robotics, these scientists have agreed on a common goal of tackling challenges in data analysis and noise characterization for GW detectors.In this competition, you’ll aim to detect GW signals from the mergers of binary black holes. Specifically, you'll build a model to analyze simulated GW time-series data from a network of Earth-based detectors. ![](https://storage.googleapis.com/kaggle-media/competitions/G2Net-gravitational-waves/800px-LIGO_measurement_of_gravitational_waves.svg.png)*The series of images above were taken from the 2015 [paper](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.116.061102) announcing the discovery of gravitational waves from a pair of merging black holes.*If successful, you'll play a part in solving a crucial mission in the exciting new field of GW science. With the development of new algorithms, scientists will have a better handle on the potential power of the data science community and their innovative approaches to data analysis. Moreover, it will enable closer interaction between computer science and physics, which could benefit both disciplines. Your participation can further this collaboration and the help advance this breakthrough discovery.### AcknowledgmentsWe acknowledge support from the LIGO-Virgo-Kagra Collaboration of which the hosts are members. Specifically we acknowledge the use of the software resource [lalsuite](https://git.ligo.org/lscsoft/lalsuite).\"}, {'title': 'Optiver Realized Volatility Prediction', 'url': 'https://www.kaggle.com/competitions/optiver-realized-volatility-prediction', 'briefDescription': 'Apply your data science skills to make financial markets better', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/27233/logos/header.png?t=2021-05-21-16-39-32', 'tag': 'tabular, finance, rootmeansquarepercentageerror', 'description': \"[Volatility](https://www.optiver.com/insights/guides/options-volatility/) is one of the most prominent terms you’ll hear on any trading floor – and for good reason. In financial markets, volatility captures the amount of fluctuation in prices. High volatility is associated to periods of market turbulence and to large price swings, while low volatility describes more calm and quiet markets. For trading firms like Optiver, accurately predicting volatility is essential for the trading of options, whose price is [directly related to the volatility](https://www.optiver.com/insights/guides/options-pricing/) of the underlying product.As a leading global electronic market maker, Optiver is dedicated to continuously improving financial markets, creating better access and prices for options, ETFs, cash equities, bonds and foreign currencies on numerous exchanges around the world. Optiver’s teams have spent countless hours building sophisticated models that predict volatility and continuously generate fairer options prices for end investors. However, an industry-leading pricing algorithm can never stop evolving, and there is no better place than Kaggle to help Optiver take its model to the next level.In the first three months of this competition, you’ll build models that predict short-term volatility for hundreds of stocks across different sectors. You will have hundreds of millions of rows of highly granular financial data at your fingertips, with which you'll design your model forecasting volatility over 10-minute periods. Your models will be evaluated against real market data collected in the three-month evaluation period after training.Through this competition, you'll gain invaluable insight into volatility and financial market structure. You'll also get a better understanding of the sort of data science problems Optiver has faced for decades. We look forward to seeing the creative approaches the Kaggle community will apply to this ever complex but exciting trading challenge. ## Getting startedIn order to make Kagglers better prepared for this competition, Optiver's data scientists have created a [**tutorial notebook**](https://www.kaggle.com/jiashenliu/introduction-to-financial-concepts-and-data) debriefing competition data and relevant financial concepts of this trading challenge. Also, Optiver's online course can tell you more about financial market and market making.[](https://www.youtube.com/watch?v=ZDF2LDsiLBs)For more information about exciting data science opportunities at Optiver, check out their data science landing page [here](https://hubs.li/H0R7Fjx0) or e-mail their recruiting team directly at datascience@optiver.com.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/optiver-realized-volatility-prediction/overview/code-requirements) for details.**\"}, {'title': 'MLB Player Digital Engagement Forecasting', 'url': 'https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting', 'briefDescription': 'Predict fan engagement with baseball player digital content', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/27783/logos/header.png?t=2021-06-09-18-46-55', 'tag': 'meancolumnwisemae', 'description': '> As of August 1st, we are in the evaluation phase of the competition, where the leaderboard will be refreshed periodically based on performance of participant submissions on the future-looking test set. No new submissions will be accepted at this time.A player hits a walk-off home run. A pitcher throws a no-hitter. A team gets red hot going into the Postseason. We know some of the catalysts that increase baseball fan interest. Now Major League Baseball (MLB) and Google Cloud want the Kaggle community’s help to identify the many other factors which pique supporter engagement and create deeper relationships betweens players and fans.The sport has a long history of being numbers-driven. Nearly every day from at least April through October, baseball fans watch, read, and search for information about players. Which individuals they seek can depend on player performance, team standings, popularity, among other, currently unknown factors—which could be better understood thanks to data science.Since at least the early 1990s, MLB has led the sports world in the use of data, showing fans, players, coaches, and media what’s possible when you combine data with human performance. MLB continues its leadership using technology to engage fans and provide new fans innovative ways to experience America’s Favorite Pastime. MLB has teamed up with Google Cloud to transform the fan experience through data. Google Cloud proudly supports this Kaggle contest to celebrate the launch of Vertex AI: Google Cloud’s new platform to unify your ML workflows.In this competition, you’ll predict how fans engage with MLB players’ digital content on a daily basis for a future date range. You’ll have access to player performance data, social media data, and team factors like market size. Successful models will provide new insights into what signals most strongly correlate with and influence engagement.Imagine if you could predict MLB All Stars all season long or when each of a team’s 25 players has his moment in the spotlight. These insights are possible when you dive deeper into the fandom of America’s pastime. Be part of the first method of its kind to try to understand digital engagement at the player level in this granular, day-to-day fashion. Simultaneously help MLB build innovation more easily using Google Cloud’s data analytics, Vertex AI and MLOps tools. You could play a part in shaping the future of MLB fan and player engagement.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/mlb-player-digital-engagement-forecasting/overview/code-requirements) for details.**'}, {'title': 'Tabular Playground Series - Jun 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-jun-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26480/logos/header.png?t=2021-04-09-00-57-05', 'tag': 'beginner, classification, tabular, multiclass classification, multiclassloss', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic, but based on a real dataset and generated using a [CTGAN](https://github.com/sdv-dev/CTGAN). The original dataset deals with predicting the category on an eCommerce product given various attributes about the listing. Although the features are anonymized, they have properties relating to real-world features.Good luck and have fun!For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'SIIM-FISABIO-RSNA COVID-19 Detection', 'url': 'https://www.kaggle.com/competitions/siim-covid19-detection', 'briefDescription': 'Identify and localize COVID-19 abnormalities on chest radiographs', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26680/logos/header.png?t=2021-04-23-22-04-05', 'tag': 'image, multilabel classification, custom metric', 'description': \"Five times more deadly than the flu, COVID-19 causes significant morbidity and mortality. Like other pneumonias, pulmonary infection with COVID-19 results in inflammation and fluid in the lungs. COVID-19 looks very similar to other viral and bacterial pneumonias on chest radiographs, which makes it difficult to diagnose. Your computer vision model to detect and localize COVID-19 would help doctors provide a quick and confident diagnosis. As a result, patients could get the right treatment before the most severe effects of the virus take hold.Currently, COVID-19 can be diagnosed via polymerase chain reaction to detect genetic material from the virus or chest radiograph. However, it can take a few hours and sometimes days before the molecular test results are back. By contrast, chest radiographs can be obtained in minutes. While guidelines exist to help radiologists differentiate COVID-19 from other types of infection, their assessments vary. In addition, non-radiologists could be supported with better localization of the disease, such as with a visual bounding box.As the leading healthcare organization in their field, the Society for Imaging Informatics in Medicine (SIIM)'s mission is to advance medical imaging informatics through education, research, and innovation. SIIM has partnered with the Foundation for the Promotion of Health and Biomedical Research of Valencia Region (FISABIO), Medical Imaging Databank of the Valencia Region (BIMCV) and the Radiological Society of North America (RSNA) for this competition.In this competition, you’ll identify and localize COVID-19 abnormalities on chest radiographs. In particular, you'll categorize the radiographs as negative for pneumonia or typical, indeterminate, or atypical for COVID-19. You and your model will work with imaging data and annotations from a group of radiologists.If successful, you'll help radiologists diagnose the millions of COVID-19 patients more confidently and quickly. This will also enable doctors to see the extent of the disease and help them make decisions regarding treatment. Depending upon severity, affected patients may need hospitalization, admission into an intensive care unit, or supportive therapies like mechanical ventilation. As a result of better diagnosis, more patients will quickly receive the best care for their condition, which could mitigate the most severe effects of the virus.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/siim-covid19-detection/overview/code-requirements) for details.**### Host Organizations**FISABIO, The Foundation for the Promotion of Health and Biomedical Research of Valencia Region**The Foundation for the Promotion of Health and Biomedical Research of Valencia Region, FISABIO, is a non-profit scientific and healthcare entity, whose primary purpose is to encourage, to promote and to develop scientific and technical health and biomedical research in Valencia Region. FISABIO integrates and manages the Health Research Map of the Centre for Public Health Research, Dr. Peset University Hospital Foundation, Alicante University General Hospital Foundation, Elche University General Hospital Foundation, and the Mediterranean Ophthalmological Foundation. The BIMCV facility is connected with a multi-level vendor neutral archive (VNA). The imaging population facility is storing data from the Valencia Region, which accounts for more than 5.1 million habitants.**Radiological Society of North America (RSNA)**The Radiological Society of North America (RSNA) is a non-profit organization that represents 31 radiologic subspecialties from 145 countries around the world. RSNA promotes excellence in patient care and health care delivery through education, research and technological innovation.RSNA provides high-quality educational resources, publishes five top peer-reviewed journals, hosts the world’s largest radiology conference and is dedicated to building the future of the profession through the RSNA Research & Education (R&E) Foundation, which has funded $66 million in grants since its inception. RSNA also supports and facilitates artificial intelligence (AI) research in medical imaging by sponsoring an ongoing series of AI challenge competitions.\"}, {'title': 'Google Smartphone Decimeter Challenge', 'url': 'https://www.kaggle.com/competitions/google-smartphone-decimeter-challenge', 'briefDescription': 'Improve high precision GNSS positioning and navigation accuracy on smartphones', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26933/logos/header.png?t=2021-04-01-16-13-07', 'tag': 'tabular, geospatial analysis, research, mobile and wireless, signal processing, custom metric', 'description': \"Have you ever hit a surprise pothole or other road obstruction? Do you wish your navigation app could provide more precise location or lane-level accuracy? These and other novel features are powered by smartphone positioning services. Machine learning and precision GNSS algorithms are expected to improve this accuracy and provide billions of Android phone users with a more fine-tuned positioning experience.Global Navigation Satellite System (GNSS) provides raw signals, which the GPS chipset uses to compute a position. Current mobile phones only offer 3-5 meters of positioning accuracy. While useful in many cases, it can create a “jumpy” experience. For many use cases the results are not fine nor stable enough to be reliable.This competition, hosted by the Android GPS team, is being presented at the ION GNSS+ 2021 Conference. They seek to advance research in smartphone GNSS positioning accuracy and help people better navigate the world around them. In this competition, you'll use data collected from the host team’s own Android phones to compute location down to decimeter or even centimeter resolution, if possible. You'll have access to precise ground truth, raw GPS measurements, and assistance data from nearby GPS stations, in order to train and test your submissions. If successful, you'll help produce more accurate positions, bridging the connection between the geospatial information of finer human behavior and mobile internet with much finer granularity. Mobile users could gain better lane-level coordinates, enhanced experience in location-based gaming, and greater specificity in the location of road safety issues. You may even notice it's easier to get you where you need to go.### AcknowledgmentsThe Android GPS team would like to show its appreciation to Verizon Hyper Precise Location Service and Swift Navigation Skylark Correction Service who provided assistance data for datasets in the challenge.\"}, {'title': 'SETI Breakthrough Listen - E.T. Signal Search', 'url': 'https://www.kaggle.com/competitions/seti-breakthrough-listen', 'briefDescription': 'Find extraterrestrial signals in data from deep space  ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/23652/logos/header.png?t=2021-02-24-19-15-30', 'tag': 'science and technology, astronomy, signal processing, auc', 'description': '####**“Are we alone in the Universe?”**     It’s one of the most profound—and perennial—human questions. As technology improves, we’re finding new and more powerful ways to seek answers. The Breakthrough Listen team at the University of California, Berkeley, employs the world’s most powerful telescopes to scan millions of stars for signs of technology. Now it wants the Kaggle community to help interpret the signals they pick up.The Listen team is part of the Search for ExtraTerrestrial Intelligence (SETI) and uses the largest steerable dish on the planet, the 100-meter diameter Green Bank Telescope. Like any SETI search, the motivation to communicate is also the major challenge. Humans have built enormous numbers of radio devices. It’s hard to search for a faint needle of alien transmission in the huge haystack of detections from modern technology. Current methods use two filters to search through the haystack. First, the Listen team intersperses scans of the target stars with scans of other regions of sky. Any signal that appears in both sets of scans probably isn’t coming from the direction of the target star. Second, the pipeline discards signals that don’t change their frequency, because this means that they are probably nearby the telescope. A source in motion should have a signal that suggests movement, similar to the change in pitch of a passing fire truck siren. These two filters are quite effective, but we know they can be improved. The pipeline undoubtedly misses interesting signals, particularly those with complex time or frequency structure, and those in regions of the spectrum with lots of interference.In this competition, use your data science skills to help identify anomalous signals in scans of Breakthrough Listen targets. Because there are no confirmed examples of alien signals to use to train machine learning algorithms, the team included some simulated signals (that they call “needles”) in the haystack of data from the telescope. They have identified some of the hidden needles so that you can train your model to find more. The data consist of two-dimensional arrays, so there may be approaches from computer vision that are promising, as well as digital signal processing, anomaly detection, and more. The algorithm that’s successful at identifying the most needles will win a cash prize, but also has the potential to help answer one of the biggest questions in science.![](https://storage.googleapis.com/kaggle-media/competitions/SETI-Berkeley/DSC_4014-Edit_2.jpg)### Acknowledgments The Breakthrough Listen science and engineering effort is headquartered at the University of California, Berkeley SETI Research Center. The Breakthrough Prize Foundation funds the Breakthrough Initiatives which manages Breakthrough Listen. The Green Bank Observatory is supported by the National Science Foundation, and is operated by Associated Universities, Inc. under a cooperative agreement.'}, {'title': 'CommonLit Readability Prize', 'url': 'https://www.kaggle.com/competitions/commonlitreadabilityprize', 'briefDescription': 'Rate the complexity of literary passages for grades 3-12 classroom use', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25914/logos/header.png?t=2021-04-01-15-58-06', 'tag': 'text, regression, rmse', 'description': \"Can machine learning identify the appropriate reading level of a passage of text, and help inspire learning? Reading is an essential skill for academic success.  When students have access to engaging passages offering the right level of challenge, they naturally develop reading skills.Currently, most educational texts are matched to readers using traditional readability methods or commercially available formulas. However, each has its issues. Tools like Flesch-Kincaid Grade Level are based on weak proxies of text decoding (i.e., characters or syllables per word) and syntactic complexity (i.e., number or words per sentence). As a result, they lack construct and theoretical validity. At the same time, commercially available formulas, such as Lexile, can be cost-prohibitive, lack suitable validation studies, and suffer from transparency issues when the formula's features aren't publicly available.CommonLit, Inc., is a nonprofit education technology organization serving over 20 million teachers and students with free digital reading and writing lessons for grades 3-12. Together with Georgia State University, an R1 public research university in Atlanta, they are challenging Kagglers to improve readability rating methods.In this competition, you’ll build algorithms to rate the complexity of reading passages for grade 3-12 classroom use. To accomplish this, you'll pair your machine learning skills with a dataset that includes readers from a wide variety of age groups and a large collection of texts taken from various domains. Winning models will be sure to incorporate text cohesion and semantics.If successful, you'll aid administrators, teachers, and students. Literacy curriculum developers and teachers who choose passages will be able to quickly and accurately evaluate works for their classrooms. Plus, these formulas will become more accessible for all. Perhaps most importantly, students will benefit from feedback on the complexity and readability of their work, making it far easier to improve essential reading skills. ### Acknowledgements    CommonLit would like to extend a special thanks to Professor Scott Crossley's research team at the Georgia State University Departments of Applied Linguistics and Learning Sciences for their partnership on this project.  The organizers would like to thank Schmidt Futures for their advice and support for making this work possible. \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/commonlitreadabilityprize/overview/code-requirements) for details.**\"}, {'title': 'Tabular Playground Series - May 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-may-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26479/logos/header.png?t=2021-04-09-00-55-58', 'tag': 'beginner, classification, tabular, multiclass classification, multiclassloss', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams, to inspire broad participation we are limiting winner's of swag to once per person for this series. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic, but based on a real dataset and generated using a [CTGAN](https://github.com/sdv-dev/CTGAN). The original dataset deals with predicting the category on an eCommerce product given various attributes about the listing. Although the features are anonymized, they have properties relating to real-world features.Good luck and have fun!For ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'BirdCLEF 2021 - Birdcall Identification', 'url': 'https://www.kaggle.com/competitions/birdclef-2021', 'briefDescription': 'Identify bird calls in soundscape recordings\\n', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25954/logos/header.png?t=2021-03-19-18-32-57', 'tag': 'environment, audio, meanfscorebeta', 'description': \"Birds of a feather flock together. Thankfully, this makes it easier to hear them! There are over 10,000 bird species around the world. Identifying the red-winged blackbirds or Bewick’s wrens in an area, for example, can provide important information about the habitat. As birds are high up in the food chain, they are excellent indicators of deteriorating environmental quality and pollution. Monitoring the status and trends of biodiversity in ecosystems is no small task. With proper sound detection and classification—aided by machine learning—researchers can improve their ability to track the status and trends of biodiversity in important ecosystems, enabling them to better support global conservation efforts.Recent advances in machine listening have improved acoustic data collection. However, it remains a challenge to generate analysis outputs with high precision and recall. The majority of data is unexamined due to a lack of effective tools for efficient and reliable extraction of the signals of interests (e.g., bird calls).The Cornell Lab of Ornithology is dedicated to advancing the understanding and protection of birds and the natural world. The Lab joins with people from all walks of life to make new scientific discoveries, share insights, and galvanize conservation action. For this competition, they're collaborating with Google Research, LifeCLEF, and Xeno-canto.In this competition, you’ll automate the acoustic identification of birds in soundscape recordings.  You'll examine an acoustic dataset to  build detectors and classifiers to extract the signals of interest (bird calls). Innovative solutions will be able to do so efficiently and reliably.The ornithology community is collecting many petabytes of acoustic data every year, but the majority of data remains unexamined. If successful, you'll help researchers properly detect and classify bird sounds, significantly improving their ability to monitor the status and trends of biodiversity in important ecosystems. Researchers will better be able to infer factors about an area’s quality of life based on a changing bird population, which allows them to identify how they can best support global conservation efforts.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/birdclef-2021/overview/code-requirements) for details.**The LifeCLEF Bird Recognition Challenge ([BirdCLEF](https://www.imageclef.org/BirdCLEF2021)) focuses on developing machine learning algorithms to identify avian vocalizations in continuous soundscape data to aid conservation efforts worldwide. Launched in 2014, it has become one of the largest bird sound recognition competitions in terms of dataset size and species diversity.\"}, {'title': 'Tabular Playground Series - Apr 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-apr-2021', 'briefDescription': \"Synthanic - You're going to need a bigger boat\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26478/logos/header.png?t=2021-03-29-17-07-03', 'tag': 'beginner, tabular, binary classification, categorizationaccuracy', 'description': 'Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we\\'ve launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we\\'re trying a new experiment in 2021. We\\'ll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there\\'s sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset.  These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you\\'re an established competitions master or grandmaster, these probably won\\'t be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we\\'ll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we\\'re limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic but based on a real dataset (in this case, the actual [Titanic data](https://www.kaggle.com/c/titanic/data)!) and generated using a CTGAN. The statistical properties of this dataset are very similar to the original Titanic dataset, but there\\'s no way to \"cheat\" by using public labels for predictions. How well does your model perform on truly private test labels?Good luck and have fun!### Getting StartedCheck out the original [Titanic competition](https://www.kaggle.com/c/titanic/overview) which walks you through how to build various models.For more ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.'}, {'title': 'Coleridge Initiative - Show US the Data ', 'url': 'https://www.kaggle.com/competitions/coleridgeinitiative-show-us-the-data', 'briefDescription': 'Discover how data is used for the public good', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25925/logos/header.png?t=2021-03-24-14-11-29', 'tag': 'text, research, custom metric', 'description': 'This competition challenges data scientists to show how publicly funded data are used to serve science and society. Evidence through data is critical if government is to address the many threats facing society, including;  pandemics, climate change,  Alzheimer’s disease, child hunger, increasing food production, maintaining biodiversity, and addressing many other challenges. Yet much of the information about data necessary to inform evidence and science is locked inside publications. Can natural language processing find the hidden-in-plain-sight data citations? Can machine learning find the link between the words used in research articles and the data referenced in the article? Now is the time for data scientists to help restore trust in data and evidence. In the United States, federal agencies are now mandated to show how their data are being used. The new [Foundations of Evidence-based Policymaking Act](https://www.cio.gov/policies-and-priorities/evidence-based-policymaking/) requires agencies to modernize their data management. New [Presidential Executive Orders](https://www.whitehouse.gov/briefing-room/presidential-actions/2021/01/27/memorandum-on-restoring-trust-in-government-through-scientific-integrity-and-evidence-based-policymaking/) are pushing government agencies to make evidence-based decisions based on the best available data and science. And the government is working to respond in an [open and transparent way](https://www.bea.gov/evidence).This competition will build just such an open and transparent approach. The results will show how public data are being used in science and help the government make wiser, more transparent public investments. It will help move researchers and governments from using ad-hoc methods to automated ways of finding out what datasets are being used to solve problems, what measures are being generated, and which researchers are the experts. Previous competitions have shown that it is possible to develop algorithms to automate the search and discovery of references to data. Now, we want the Kaggle community to develop the best approaches to identify critical datasets used in scientific publications.    In this competition, you\\'ll use natural language processing (NLP) to automate the discovery of how scientific data are referenced in publications. Utilizing the full text of scientific publications from numerous research areas gathered from [CHORUS](https://www.chorusaccess.org/) publisher members and other sources, you\\'ll identify data sets that the publications\\' authors used in their work.  If successful, you\\'ll help support evidence in government data. Automated NLP approaches will enable government agencies and researchers to quickly find the information they need. The approach will be used to develop data usage scorecards to better enable agencies to show how their data are used and bring down a critical barrier to the access and use of public data.    The Coleridge Initiative is a not-for-profit that has been established to use data for social good. One way in which the organization does this is by furthering science through publicly available research.    ### Resources [Coleridge Data Examples](https://coleridgeinitiative.org/data-products/)[Rich Search and Discovery for Research Datasets](https://study.sagepub.com/richcontext)[Democratizing Our Data](https://mitpress.mit.edu/books/democratizing-our-data)[NSF\"Rich Context\" Video](https://youtu.be/PIReIlsTI8U)### AcknowledgmentsUnited States Department of AgricultureUnited States Department of CommerceUnited States Geological SurveyNational Oceanic and Atmospheric AdministrationNational Science FoundationNational Institutes of HealthCHORUSWestatAlfred P. Sloan FoundationSchmidt FuturesOverdeck Family Foundation> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/overview/code-requirements) for details.**'}, {'title': 'Plant Pathology 2021 - FGVC8 ', 'url': 'https://www.kaggle.com/competitions/plant-pathology-2021-fgvc8', 'briefDescription': 'Identify the category of foliar diseases in apple trees', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25563/logos/header.png?t=2021-02-28-03-55-21', 'tag': 'image, plants, meanfscore', 'description': '## Problem Statement Apples are one of the most important temperate fruit crops in the world. Foliar (leaf) diseases pose a major threat to the overall productivity and quality of apple orchards. The current process for disease diagnosis in apple orchards is based on manual scouting by humans, which is time-consuming and expensive.     Although computer vision-based models have shown promise for plant disease identification, there are some limitations that need to be addressed. Large variations in visual symptoms of a single disease across different apple cultivars, or new varieties that originated under cultivation, are major challenges for computer vision-based disease identification. These variations arise from differences in natural and image capturing environments, for example, leaf color and leaf morphology, the age of infected tissues, non-uniform image background, and different light illumination during imaging etc. Plant Pathology 2020-FGVC7 challenge competition had a pilot dataset of 3,651 RGB images of foliar disease of apples. For Plant Pathology 2021-FGVC8, we have significantly increased the number of foliar disease images and added additional disease categories. This year’s dataset contains approximately 23,000 high-quality RGB images of apple foliar diseases, including a large expert-annotated disease dataset. This dataset reflects real field scenarios by representing non-homogeneous backgrounds of leaf images taken at different maturity stages and at different times of day under different focal camera settings.## Specific ObjectivesThe main objective of the competition is to develop machine learning-based models to accurately classify a given leaf image from the test dataset to a particular disease category, and to identify an individual disease from multiple disease symptoms on a single leaf image. ## ResourcesDetails and background information on the dataset and Kaggle competition ‘Plant Pathology 2020 Challenge’ were published as a peer-reviewed research article. If you use the dataset for your project, please cite the following[Thapa, Ranjita; Zhang, Kai; Snavely, Noah; Belongie, Serge; Khan, Awais. The Plant Pathology Challenge 2020 data set to classify foliar disease of apples. Applications in Plant Sciences, 8 (9), 2020.](https://bsapubs.onlinelibrary.wiley.com/doi/10.1002/aps3.11390)### AcknowledgementsWe acknowledge sponsorship from Cornell Initiative for Digital Agriculture (CIDA).> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/plant-pathology-2021-fgvc8/overview/code-requirements) for details.**'}, {'title': 'Hotel-ID to Combat Human Trafficking 2021 - FGVC8', 'url': 'https://www.kaggle.com/competitions/hotel-id-2021-fgvc8', 'briefDescription': 'Recognizing hotels to aid Human trafficking investigations', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25980/logos/header.png?t=2021-03-09-19-11-13', 'tag': 'image, public safety, map@{k}', 'description': 'Hotel Recognition to Combat Human TraffickingVictims of human trafficking are often photographed in hotel rooms as in the below examples. Identifying these hotels is vital to these trafficking investigations but poses particular challenges due to low quality of images and uncommon camera angles.![Example investigative images.](https://cs.slu.edu/~astylianou/images/example_victim_images.png)Even without victims in the images, hotel identification in general is a challenging fine-grained visual recognition task with a huge number of classes and potentially high intraclass and low interclass variation. In order to support research into this challenging task and create image search tools for human trafficking investigators, we created the TraffickCam mobile application, which allows every day travelers to submit photos of their hotel room. Read more about TraffickCam on TechCrunch.Example images from one hotel in the TraffickCam dataset are shown below:![Example TraffickCam images.](https://cs.slu.edu/~astylianou/images/example_traffickcam_images.png)In this contest, competitors are tasked with identifying the hotel seen in test images from the TraffickCam dataset, which are based on a large gallery of training images with known hotel IDs.Our team currently supports an image search system used at the National Center for Missing and Exploited Children in human trafficking investigations. Novel and interesting approaches have the potential to be incorporated in this search system.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/hotel-id-2021-fgvc8/overview/code-requirements) for details.**'}, {'title': 'iWildcam 2021 - FGVC8', 'url': 'https://www.kaggle.com/competitions/iwildcam2021-fgvc8', 'briefDescription': 'Count the number of animals of each species present in a sequence of images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/24911/logos/header.png?t=2021-03-02-03-13-50', 'tag': 'image, animals, mcrmse', 'description': \"##DescriptionCamera traps enable the automatic collection of large quantities of image data. Ecologists all over the world use camera traps to monitor biodiversity and population density of animal species. In order to estimate the abundance and density of species in camera trap data, ecologists need to know not just which species were seen, but also **how many** of each species were seen. However, because images are taken in motion-triggered bursts to increase the likelihood of capturing the animal(s) of interest, object detection alone is not sufficient as it could lead to over or undercounting. For example, if you get 3 images taken at one frame per second and in the first image you see 3 gazelles, in the second you see 5 gazelles, and in the last you see 4 gazelles, how many total gazelles have you seen? This is more challenging than strictly detecting and categorizing species as it requires reasoning and tracking of individuals across sparse temporal samples.![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F115173%2Ffc6541055bb381b99aac808449bebcab%2Ftrain_examples_smallest.gif?generation=1615337929634349&alt=media)We have prepared a challenge where the training data and test data are from different cameras spread across the globe. The set of species seen in each camera overlap but are not identical. The challenge is to categorize species and count the number of individuals across image bursts. To explore multimodal solutions, we allow competitors to train on the following data: (i) our camera trap training set (data provided by WCS), (ii) iNaturalist 2017-2019 data, and (iii) multispectral imagery (from [Landsat 8][9]) for each of the camera trap locations. On the competition [GitHub page][6] we provide the multispectral data, a taxonomy file mapping our classes into the iNat taxonomy, a subset of iNat data mapped into our class set, and a camera trap detection model (the MegaDetector) along with the corresponding detections.This is an FGVCx competition as part of the [FGVC8][4] workshop at [CVPR 2021][5] and is sponsored by [Microsoft AI for Earth][3] and [Wildlife Insights][8]. There is a GitHub page for the competition [here][6]. Please open an issue if you have questions or problems with the dataset.     You can find the iWildCam 2018 Competition [here](https://github.com/visipedia/iwildcam_comp/blob/master/2018/readme.md), the iWildCam 2019 Competition [here](https://github.com/visipedia/iwildcam_comp/blob/master/2019/readme.md), and the iWildCam 2020 Competition [here](https://github.com/visipedia/iwildcam_comp/blob/master/2020/readme.md).##AcknowledgementsWe would like to acknowledge [WCS](https://www.wcs.org/) for providing the camera trap data, [Centaur Labs](https://www.centaurlabs.com/) for generously providing count annotations on the test data, and [Microsoft AI4Earth](https://www.microsoft.com/en-us/ai/ai-for-earth) for hosting our external datasets on Azure. *Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.*   [1]: http://lila.science/datasets/wcscameratraps  [2]: https://github.com/visipedia/inat_comp  [3]: https://www.microsoft.com/en-us/ai/ai-for-earth  [4]: https://sites.google.com/view/fgvc8/home  [5]: http://cvpr2021.thecvf.com/  [6]: https://github.com/visipedia/iwildcam_comp  [7]: https://github.com/microsoft/CameraTraps/blob/master/megadetector.md  [8]: https://www.wildlifeinsights.org/  [9]: https://www.usgs.gov/land-resources/nli/landsat/landsat-8 \"}, {'title': 'Herbarium 2021 - Half-Earth Challenge - FGVC8', 'url': 'https://www.kaggle.com/competitions/herbarium-2021-fgvc8', 'briefDescription': 'Identify plant species of the Americas, Oceania and the Pacific from herbarium specimens', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25558/logos/header.png?t=2021-03-05-17-29-30', 'tag': 'image, plants, macrofscore', 'description': '*The Herbarium 2021: Half-Earth Challenge* is to identify vascular plant specimens provided by the [New York Botanical Garden](https://www.nybg.org/) (NY), [Bishop Museum](https://www.bishopmuseum.org/) (BPBM), [Naturalis Biodiversity Center](https://www.naturalis.nl/en) (NL), [Queensland Herbarium](https://www.qld.gov.au/environment/plants-animals/plants/herbarium) (BRI), and [Auckland War Memorial Museum](https://www.aucklandmuseum.com/) (AK).*The Herbarium 2021: Half-Earth Challenge* dataset includes more than **2.5M images** representing nearly **65,000 species** from the Americas and Oceania that have been aligned to a standardized plant list ([LCVP v1.0.2](https://www.nature.com/articles/s41597-020-00702-z)). This dataset has a long tail; there are a minimum of 3 images per species. However, some species can be represented by more than 100 images. This dataset only includes vascular land plants which include lycophytes, ferns, gymnosperms, and flowering plants. The extinct forms of lycophytes are the major component of coal deposits, ferns are indicators of ecosystem health, gymnosperms provide major habitats for animals, and flowering plants provide almost all of our crops, vegetables, and fruits.The teams with the most accurate models will be contacted with the intention of using them on the unnamed plant collections in the NYBG herbarium and then be assessed by the NYBG plant specialists for accuracy.[![Herbarium2021.png](https://i.postimg.cc/htpxH99f/Herbarium2021.png)](https://postimg.cc/BjPXFP70)# BackgroundThere are approximately 3,000 herbaria world-wide, and they are massive repositories of plant diversity data. These collections not only represent a vast amount of plant diversity, but since herbarium collections include specimens dating back hundreds of years, they provide snapshots of plant diversity through time. The integrity of the plant is maintained in herbaria as a pressed, dried specimen; a specimen collected nearly two hundred years ago by Darwin looks much the same as one collected a month ago by an NYBG botanist. All specimens not only maintain their morphological features but also include collection dates and locations, their reproductive state, and the name of the person who collected the specimen. This information, multiplied by millions of plant collections, provides the framework for understanding plant diversity on a massive scale and learning how it has changed over time. The models developed during this competition are an integral first step to speed the pace of species discovery and save the plants of the world.There are approximately 400,000 known vascular plant species with an estimated 80,000 still to be discovered. Herbaria contain an overwhelming amount of unnamed and new specimens, and with the threats of climate change, we need new tools to quicken the pace of species discovery. This is more pressing today as a United Nations report indicates that more than one million species are at risk of extinction, and amid this dire prediction is a recent estimate that suggests plants are disappearing more quickly than animals. This year, we have expanded our curated herbarium dataset to vascular plant diversity in the Americas and Oceania. The most accurate models will be used on the unidentified plant specimens in our herbarium and assessed by our taxonomists thereby producing a tool to quicken the pace of species discovery.# AboutThis is an FGVC competition hosted as part of the [FGVC8](https://sites.google.com/view/fgvc8) workshop at [CVPR 2021](http://cvpr2021.thecvf.com/) and sponsored by [NYBG](https://www.nybg.org/).Details of this competition are mirrored on the [github](https://github.com/visipedia/herbarium_comp) page. Please post in the forum or open an issue if you have any questions or problems with the dataset.# AcknowledgementsThe images are provided by the [New York Botanical Garden](https://www.nybg.org/), [Bishop Museum](https://www.bishopmuseum.org/), [Naturalis Biodiversity Center](https://www.naturalis.nl/en), [Queensland Herbarium](https://www.qld.gov.au/environment/plants-animals/plants/herbarium), and [Auckland War Memorial Museum](https://www.aucklandmuseum.com/).[![Logos.png](https://i.postimg.cc/fbSLBX54/Logos.png)](https://postimg.cc/xkYndXWg)'}, {'title': 'Shopee - Price Match Guarantee', 'url': 'https://www.kaggle.com/competitions/shopee-product-matching', 'briefDescription': 'Determine if two products are the same by their images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/24286/logos/header.png?t=2021-01-07-16-57-37', 'tag': 'image, text, retail and shopping, meanfscore', 'description': \"Do you scan online retailers in search of the best deals? You're joined by the many savvy shoppers who don't like paying extra for the same product depending on where they shop. Retail companies use a variety of methods to assure customers that their products are the cheapest. Among them is product matching, which allows a company to offer products at rates that are competitive to the same product sold by another retailer. To perform these matches automatically requires a thorough machine learning approach, which is where your data science skills could help.Two different images of similar wares may represent the same product or two completely different items. Retailers want to avoid misrepresentations and other issues that could come from conflating two dissimilar products. Currently, a combination of deep learning and traditional machine learning analyzes image and text information to compare similarity. But major differences in images, titles, and product descriptions prevent these methods from being entirely effective.Shopee is the leading e-commerce platform in Southeast Asia and Taiwan. Customers appreciate its easy, secure, and fast online shopping experience tailored to their region. The company also provides strong payment and logistical support along with a 'Lowest Price Guaranteed' feature on thousands of Shopee's listed products. In this competition, you’ll apply your machine learning skills to build a model that predicts which items are the same products. The applications go far beyond Shopee or other retailers. Your contributions to product matching could support more accurate product categorization and uncover marketplace spam. Customers will benefit from more accurate listings of the same or similar products as they shop. Perhaps most importantly, this will aid you and your fellow shoppers in your hunt for the very best deals.\"}, {'title': 'Bristol-Myers Squibb – Molecular Translation', 'url': 'https://www.kaggle.com/competitions/bms-molecular-translation', 'briefDescription': 'Can you translate chemical images to text?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22422/logos/header.png?t=2021-02-03-02-05-31', 'tag': 'image, chemistry, levenshteinmean', 'description': \"In a technology-forward world, sometimes the best and easiest tools are still pen and paper. Organic chemists frequently draw out molecular work with the Skeletal formula, a structural notation used for centuries. Recent publications are also annotated with machine-readable chemical descriptions (InChI), but there are decades of scanned documents that can't be automatically searched for specific chemical depictions. Automated recognition of optical chemical structures, with the help of machine learning, could speed up research and development efforts.Unfortunately, most public data sets are too small to support modern machine learning models. Existing tools produce 90% accuracy but only under optimal conditions. Historical sources often have some level of image corruption, which reduces performance to near zero. In these cases, time-consuming, manual work is required to reliably convert scanned chemical structure images into a machine-readable format.Bristol-Myers Squibb is a global biopharmaceutical company working to transform patients' lives through science. Their mission is to discover, develop, and deliver innovative medicines that help patients prevail over serious diseases.In this competition, you’ll interpret old chemical images. With access to a large set of synthetic image data generated by Bristol-Myers Squibb, you'll convert images back to the underlying chemical structure annotated as InChI text.Tools to curate chemistry literature would be a significant benefit to researchers. If successful, you'll help chemists expand access to collective chemical research. In turn, this would speed up research and development efforts in many key fields by avoiding repetition of previously published chemistries and identifying novel trends via mining large data sets.Photo by Terry Vlisidis on Unsplash\"}, {'title': 'Tabular Playground Series - Mar 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-mar-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25226/logos/header.png?t=2021-01-27-17-34-31', 'tag': 'tabular, logistic regression, auc', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset.  These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting the amount of an insurance claim. Although the features are anonymized, they have properties relating to real-world features.Good luck and have fun!### Getting StartedCheck out this [Starter Notebook](https://www.kaggle.com/inversion/get-started-mar-tabular-playground-competition) which walks you through how to make your very first submission!For more ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'March Machine Learning Mania 2021 - NCAAM - Spread', 'url': 'https://www.kaggle.com/competitions/ncaam-march-mania-2021-spread', 'briefDescription': \"Predict the margin of victory in the 2021 men's tournament\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26082/logos/header.png?t=2021-02-24-16-35-44', 'tag': 'sports, basketball, rmse', 'description': \"In addition to the predictive modeling competitions we typically host (NCAA Women's and Men’s), we are hosting two separate, experimental challenges that ask you to not only predict the the winner, but to predict the margin of victor. The mania of March can come down to final second buzzer beaters, upsets, and even a few blowouts. Can you predict big wins as easily as you can predict close calls?This competition (and the parallel competition for the women's tournament) allows you to explore how data science and machine learning can continue to examine the depths of college basketball. You're provided data of historical NCAA games and are encouraged to use other sources of publicly available data to gain a winning edge.In stage one of this two-stage competition, participants will build and test their models against previous tournaments. In the second stage, participants will predict the point spreads of the 2021 tournament. You don’t need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2021 results.*Note: From 2018-2020, Google Cloud, of which Kaggle is a part, served as official corporate sponsors of the NCAA basketball tournaments. This official sponsorship has concluded, but we at Kaggle are happy to bring back this tradition for it's 8th year!*AcknowledgmentsMarkus Spiske on Unsplash and The Noun Project\"}, {'title': 'March Machine Learning Mania 2021 - NCAAW - Spread', 'url': 'https://www.kaggle.com/competitions/ncaaw-march-mania-2021-spread', 'briefDescription': \"Predict the margin of victory in the 2021 women's tournament\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26082/logos/header.png?t=2021-02-24-16-35-44', 'tag': 'sports, basketball, rmse', 'description': \"In addition to the predictive modeling competitions we typically host (NCAA Women's and Men’s), we are hosting two separate, experimental challenges that ask you to not only predict the the winner, but to predict the margin of victor. The mania of March can come down to final second buzzer beaters, upsets, and even a few blowouts. Can you predict big wins as easily as you can predict close calls?This competition (and the parallel competition for the men's tournament) allows you to explore how data science and machine learning can continue to examine the depths of college basketball. You're provided data of historical NCAA games and are encouraged to use other sources of publicly available data to gain a winning edge.In stage one of this two-stage competition, participants will build and test their models against previous tournaments. In the second stage, participants will predict the point spreads of the 2021 tournament. You don’t need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2021 results.*Note: From 2018-2020, Google Cloud, of which Kaggle is a part, served as official corporate sponsors of the NCAA basketball tournaments. This official sponsorship has concluded, but we at Kaggle are happy to bring back this tradition for it's 8th year!*AcknowledgmentsMarkus Spiske on Unsplash and The Noun Project\"}, {'title': 'March Machine Learning Mania 2021 - NCAAW', 'url': 'https://www.kaggle.com/competitions/ncaaw-march-mania-2021', 'briefDescription': 'Predict the 2021 NCAAW Basketball Tournament', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26080/logos/header.png?t=2021-02-24-01-37-37', 'tag': 'sports, basketball, logloss', 'description': \"Back again after a pandemic-year hiatus, Kaggle's March Machine Learning Mania challenges data scientists to predict winners and losers of the women's 2021 NCAA basketball tournament. You're provided data  of historical NCAA games and are encouraged to use other sources of publicly available data to gain a winning edge.In stage one of this two-stage competition, participants will build and test their models against previous tournaments. In the second stage, participants will predict the outcome of the 2021 tournament. You don’t need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2021 results.*Note: From 2018-2020, Google Cloud, of which Kaggle is a part, served as official corporate sponsors of the NCAA basketball tournaments. This official sponsorship has concluded, but we at Kaggle are happy to bring back this tradition for its 8th year!*AcknowledgmentsBanner image by Ben Hershey on Unsplash\"}, {'title': 'March Machine Learning Mania 2021 - NCAAM', 'url': 'https://www.kaggle.com/competitions/ncaam-march-mania-2021', 'briefDescription': 'Predict the 2021 NCAAM Basketball Tournament', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/26080/logos/header.png?t=2021-02-24-01-37-37', 'tag': 'sports, basketball, logloss', 'description': \"Back again after a pandemic-year hiatus, Kaggle's March Machine Learning Mania challenges data scientists to predict winners and losers of the men's 2021 NCAA basketball tournament. You're provided data  of historical NCAA games and are encouraged to use other sources of publicly available data to gain a winning edge.In stage one of this two-stage competition, participants will build and test their models against previous tournaments. In the second stage, participants will predict the outcome of the 2021 tournament. You don’t need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2021 results.*Note: From 2018-2020, Google Cloud, of which Kaggle is a part, served as official corporate sponsors of the NCAA basketball tournaments. This official sponsorship has concluded, but we at Kaggle are happy to bring back this tradition for its 8th year!*AcknowledgmentsBanner image by Ben Hershey on Unsplash\"}, {'title': 'Hash Code 2021 - Traffic Signaling', 'url': 'https://www.kaggle.com/competitions/hashcode-2021-oqr-extension', 'briefDescription': 'Optimize city traffic in this extension of the 2021 Hash Code qualifier', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25951/logos/header.png?t=2021-02-18-20-26-18', 'tag': 'automobiles and vehicles, optimization, custom metric', 'description': 'This is an extended version of the [Hash Code](https://codingcompetitions.withgoogle.com/hashcode/) Online Qualifications 2021 problem. After Hash Code\\'s official Online Qualifications, which lasts only 4 hours, you can improve your submissions here on Kaggle, optimize them in more detail, and discuss your approaches with other teams. We created a new data set just for this Kaggle competition that was not used in Hash Code before. Please find the full problem statement as a PDF file under the data tab.*Note that this is not Hash Code\\'s official Online Qualifications and that there are no prizes for this competition. You can\\'t qualify for Hash Code\\'s Finals on Kaggle.***Problem statement** The world\\'s first traffic light dates back to 1868. It was installed in London to control traffic for... *horse-drawn vehicles*! Today, traffic lights can be found at street intersections in almost every city in the world, making it safer for vehicles to go through them.Traffic lights have at least two states- and use one color (usually red) to signal \"stop\"- and another (usually green) to signal that cars can proceed through. The very first traffic lights were manually controlled. Nowadays they are automatic, meaning that they have to be carefully designed and timed in order to optimize the overall travel time for all the participants in traffic.Given the description of a city plan and planned paths for all cars in that city, you will be optimizing the schedule of traffic lights to minimize the total amount of time spent in traffic, and help as many cars as possible reach their destination before a given deadline. Photo by Eliobed Suarez on Unsplash'}, {'title': 'Tabular Playground Series - Feb 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-feb-2021', 'briefDescription': 'Practice your ML skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25225/logos/header.png?t=2021-01-27-17-34-26', 'tag': 'tabular, regression, rmse', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. The dataset is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting the amount of an insurance claim. Although the features are anonymized, they have properties relating to real-world features.Good luck and have fun!### Getting StartedCheck out this [Starter Notebook](https://www.kaggle.com/inversion/get-started-feb-tabular-playground-competition) which walks you through how to make your very first submission!For more ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'Indoor Location & Navigation', 'url': 'https://www.kaggle.com/competitions/indoor-location-navigation', 'briefDescription': 'Identify the position of a smartphone in a shopping mall', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22559/logos/header.png?t=2020-09-30-17-40-59', 'tag': 'text mining, signal processing, custom metric', 'description': \"Your smartphone goes everywhere with you—whether driving to the grocery store or shopping for holiday gifts. With your permission, apps can use your location to provide contextual information. You might get driving directions, find a store, or receive alerts for nearby promotions. These handy features are enabled by GPS, which requires outdoor exposure for the best accuracy. Yet, there are many times when you’re inside large structures, such as a shopping mall or event center. Accurate indoor positioning, based on public sensors and user permission, allows for a great location-based experience even when you aren’t outside.Current positioning solutions have poor accuracy, particularly in multi-level buildings, or generalize poorly to small datasets. Additionally, GPS was built for a time before smartphones. Today’s use cases often require more granularity than is typically available indoors.In this competition, your task is to predict the indoor position of smartphones based on real-time sensor data, provided by indoor positioning technology company XYZ10 in partnership with Microsoft Research. You'll locate devices using “active” localization data, which is made available with the cooperation of the user. Unlike passive localization methods (e.g. radar, camera), the data provided for this competition requires explicit user permission. You'll work with a dataset of nearly 30,000 traces from over 200 buildings.If successful, you’ll contribute to research with broad-reaching possibilities, including industries like manufacturing, retail, and autonomous devices. With more accurate positioning, existing location-based apps could even be improved. Perhaps you’ll even see the benefits yourself the next time you hit the mall.### AcknowledgmentsXYZ10 is a rising indoor positioning technology company in China. Since 2017, XYZ10 has been accumulating a privacy-sensitive indoor location dataset of WiFi, geomagnetic, and Bluetooth signatures with ground truths from nearly 1,000 buildings.Microsoft Research is the research subsidiary of Microsoft. Its goal is to advance state-of-the-art computing and solve difficult world research-motivated competition problems through technological innovation in collaboration with academic, government, and industry researchers.\"}, {'title': 'Human Protein Atlas - Single Cell Classification', 'url': 'https://www.kaggle.com/competitions/hpa-single-cell-image-classification', 'briefDescription': 'Find individual human cell differences in microscope images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/23823/logos/header.png?t=2020-11-24-14-18-10', 'tag': 'image, multiclass classification, multilabel classification, custom metric', 'description': \"There are billions of humans on this earth, and each of us is made up of trillions of cells. Just like every individual is unique, even genetically identical twins, scientists observe differences between the genetically identical cells in our bodies.Differences in the location of proteins can give rise to such cellular heterogeneity. Proteins play essential roles in virtually all cellular processes. Often, many different proteins come together at a specific location to perform a task, and the exact outcome of this task depends on which proteins are present. As you can imagine, different subcellular distributions of one protein can give rise to great functional heterogeneity between cells. Finding such differences, and figuring out how and why they occur, is important for understanding how cells function, how diseases develop, and ultimately how to develop better treatments for those diseases.To see more, start with less. That may seem counterintuitive, but the study of a single cell enables the discovery of mechanisms too difficult to see with multi-cell research. The importance of studying single cells is reflected in the ongoing revolution in biology centered around technologies for single cell analysis. Microscopy offers an opportunity to study differences in protein localizations within a population of cells. Current machine learning models for classifying protein localization patterns in microscope images gives a summary of the entire population of cells. However, the single-cell revolution in biology demands models that can precisely classify patterns in each individual cell in the image.The Human Protein Atlas is an initiative based in Sweden that is aimed at mapping proteins in all human cells, tissues, and organs. The data in the [Human Protein Atlas database](https://www.proteinatlas.org/) is freely accessible to scientists all around the world that allows them to explore the cellular makeup of the human body. Solving the single-cell image classification challenge will help us characterize single-cell heterogeneity in our large collection of images by generating more accurate annotations of the subcellular localizations for thousands of human proteins in individual cells. Thanks to you, we will be able to more accurately model the spatial organization of the human cell and provide new open-access cellular data to the scientific community, which may accelerate our growing understanding of how human cells functions and how diseases develop.This is a weakly supervised multi-label classification problem and a code competition. Given images of cells from our microscopes and labels of protein location assigned together for all cells in the image, Kagglers will develop models capable of segmenting and classifying each individual cell with precise labels. If successful, you'll contribute to the revolution of single-cell biology! The scientific journal [Nature Methods] (https://www.nature.com/nmeth/) is interested in considering a paper discussing the outcome and approaches of the challenge. The Human Protein Atlas team, led by Professor Emma Lundberg, would like to invite top performing teams to join as co-authors in writing this paper. Please follow the discussion forum for more details on how you can help.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/hpa-single-cell-image-classification/overview/code-requirements) for details.**\"}, {'title': 'Hungry Geese', 'url': 'https://www.kaggle.com/competitions/hungry-geese', 'briefDescription': \"Don't. Stop. Eating.\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/25401/logos/header.png?t=2021-01-22-07-12-33', 'tag': 'custom metric', 'description': 'Whether it be in an arcade, on a phone, as an app, on a computer, or maybe stumbled upon in a [web search](https://www.google.com/search?q=play+snake), many of us have likely developed fond memories playing a version of Snake. It’s addicting to control a slithering serpent and watch it grow along the grid until you make one… wrong… move. Then you have to try again because surely you won’t make the same mistake twice!  With Hungry Geese, Kaggle has taken this classic in the video game industry and put a multi-player, simulation spin to it. You will create an AI agent to play against others and survive the longest. You must make sure your goose doesn’t starve or run into other geese; it’s a good thing that geese love peppers, donuts, and pizza—which show up across the board. Extensive research exists in building Snake models using reinforcement learning, Q-learning, neural networks, and more (maybe you’ll use... Python?). Take your grid-based reinforcement learning knowledge to the next level with this exciting new challenge!'}, {'title': 'Tabular Playground Series - Jan 2021', 'url': 'https://www.kaggle.com/competitions/tabular-playground-series-jan-2021', 'briefDescription': 'Practice your ML regression skills on this approachable dataset!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/24673/logos/header.png?t=2021-01-02-00-34-25', 'tag': 'tabular, regression, rmse', 'description': \"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions, and thus more beginner-friendly. In order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching a month-long tabular Playground competition on the 1st of every month, and continue the experiment as long as there's sufficient interest and participation.The goal of these competitions is to provide a fun, but less challenging, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.For each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals. Good luck and have fun!### Getting StartedCheck out this [Starter Notebook](https://www.kaggle.com/inversion/get-started-jan-tabular-playground-competition) which walks you through how to make your very first submission!For more ideas on how to improve your score, check out the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses on Kaggle Learn.\"}, {'title': 'VinBigData Chest X-ray Abnormalities Detection', 'url': 'https://www.kaggle.com/competitions/vinbigdata-chest-xray-abnormalities-detection', 'briefDescription': 'Automatically localize and classify thoracic abnormalities from chest radiographs', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/24800/logos/header.png?t=2020-12-17-19-26-15', 'tag': 'image, healthcare, custom metric', 'description': \"When you have a broken arm, radiologists help save the day—and the bone. These doctors diagnose and treat medical conditions using imaging techniques like CT and PET scans, MRIs, and, of course, X-rays. Yet, as it happens when working with such a wide variety of medical tools, radiologists face many daily challenges, perhaps the most difficult being the chest radiograph. The interpretation of chest X-rays can lead to medical misdiagnosis, even for the best practicing doctor. Computer-aided detection and diagnosis systems (CADe/CADx) would help reduce the pressure on doctors at metropolitan hospitals and improve diagnostic quality in rural areas.Existing methods of interpreting chest X-ray images classify them into a list of findings. There is currently no specification of their locations on the image which sometimes leads to inexplicable results. A solution for localizing findings on chest X-ray images is needed for providing doctors with more meaningful diagnostic assistance.Established in August 2018 and funded by the Vingroup JSC, the Vingroup Big Data Institute (VinBigData) aims to promote fundamental research and investigate novel and highly-applicable technologies. The Institute focuses on key fields of data science and artificial intelligence: computational biomedicine, natural language processing, computer vision, and medical image processing. The medical imaging team at VinBigData conducts research in collecting, processing, analyzing, and understanding medical data. They're working to build large-scale and high-precision medical imaging solutions based on the latest advancements in artificial intelligence to facilitate effective clinical workflows.In this competition, you’ll automatically localize and classify 14 types of thoracic abnormalities from chest radiographs. You'll work with a dataset consisting of 18,000 scans that have been annotated by experienced radiologists. You can train your model with 15,000 independently-labeled images and will be evaluated on a test set of 3,000 images. These annotations were collected via VinBigData's web-based platform, [VinLab](https://vindr.ai/vinlab). Details on building the dataset can be found in our recent paper [“VinDr-CXR: An open dataset of chest X-rays with radiologist's annotations”](https://arxiv.org/pdf/2012.15029.pdf).If successful, you'll help build what could be a valuable second opinion for radiologists. An automated system that could accurately identify and localize findings on chest radiographs would relieve the stress of busy doctors while also providing patients with a more accurate diagnosis.###Acknowledgments**Challenge Organizing Team*** Ha Q. Nguyen, PhD - Vingroup Big Data Institute * Hieu H. Pham, PhD - Vingroup Big Data Institute* Nhan T. Nguyen, MSc - Vingroup Big Data Institute* Dung B. Nguyen, BSc - Vingroup Big Data Institute* Minh Dao, PhD - Vingroup Big Data Institute* Van Vu, PhD - Vingroup Big Data Institute* Khanh Lam, MD, PhD - Hospital 108* Linh T. Le, MD, PhD - Hanoi Medical University Hospital**Data Contributors**The dataset used in this competition was created by assembling de-identified Chest X-ray studies provided by two hospitals in Vietnam: the Hospital 108 and the Hanoi Medical University Hospital. \"}, {'title': 'RANZCR CLiP - Catheter and Line Position Challenge', 'url': 'https://www.kaggle.com/competitions/ranzcr-clip-catheter-line-classification', 'briefDescription': 'Classify the presence and correct placement of tubes on chest x-rays to save lives', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/23870/logos/header.png?t=2020-12-01-04-28-05', 'tag': 'image, multilabel classification, mcauc', 'description': 'Serious complications can occur as a result of malpositioned lines and tubes in patients. Doctors and nurses frequently use checklists for placement of lifesaving equipment to ensure they follow protocol in managing patients. Yet, these steps can be time consuming and are still prone to human error, especially in stressful situations when hospitals are at capacity.     Hospital patients can have catheters and lines inserted during the course of their admission and serious complications can arise if they are positioned incorrectly. Nasogastric tube malpositioning into the airways has been reported in up to 3% of cases, with up to 40% of these cases demonstrating complications [1-3]. Airway tube malposition in adult patients intubated outside the operating room is seen in up to 25% of cases [4,5].  The likelihood of complication is directly related to both the experience level and specialty of the proceduralist.  Early recognition of malpositioned tubes is the key to preventing risky complications (even death), even more so now that millions of COVID-19 patients are in need of these tubes and lines.The gold standard for the confirmation of line and tube positions are chest radiographs. However, a physician or radiologist must manually check these chest x-rays to verify that the lines and tubes are in the optimal position. Not only does this leave room for human error, but delays are also common as radiologists can be busy reporting other scans. Deep learning algorithms may be able to automatically detect malpositioned catheters and lines. Once alerted, clinicians can reposition or remove them to avoid life-threatening complications.The Royal Australian and New Zealand College of Radiologists (RANZCR) is a not-for-profit professional organisation for clinical radiologists and radiation oncologists in Australia, New Zealand, and Singapore. The group is one of many medical organisations around the world (including the NHS) that recognizes malpositioned tubes and lines as preventable. RANZCR is helping design safety systems where such errors will be caught.In this competition, you’ll detect the presence and position of catheters and lines on chest x-rays. Use machine learning to train and test your model on 40,000 images to categorize a tube that is poorly placed.The dataset has been labelled with a set of definitions to ensure consistency with labelling. The **normal** category includes lines that were appropriately positioned and did not require repositioning. The **borderline** category includes lines that would ideally require some repositioning but would in most cases still function adequately in their current position.  The **abnormal** category included lines that required immediate repositioning.If successful, your efforts may help clinicians save lives. Earlier detection of malpositioned catheters and lines  is even more important as COVID-19 cases continue to surge. Many hospitals are at capacity and more patients are in need of these tubes and lines. Quick feedback on catheter and line placement could help clinicians better treat these patients. Beyond COVID-19, detection of line and tube position will ALWAYS be a requirement in many ill hospital patients.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/overview/code-requirements) for details.**1. Koopmann MC, Kudsk KA, Szotkowski MJ, Rees SM. A Team-Based Protocol and Electromagnetic Technology Eliminate Feeding Tube Placement Complications [Internet]. Vol. 253, Annals of Surgery. 2011. p. 297–302. Available from: http://dx.doi.org/10.1097/sla.0b013e318208f5502. Sorokin R, Gottlieb JE. Enhancing patient safety during feeding-tube insertion: a review of more than 2,000 insertions. JPEN J Parenter Enteral Nutr. 2006 Sep;30(5):440–5.3. Marderstein EL, Simmons RL, Ochoa JB. Patient safety: effect of institutional protocols on adverse events related to feeding tube placement in the critically ill. J Am Coll Surg. 2004 Jul;199(1):39–47; discussion 47–50.4. Jemmett ME. Unrecognized Misplacement of Endotracheal Tubes in a Mixed Urban to Rural Emergency Medical Services Setting [Internet]. Vol. 10, Academic Emergency Medicine. 2003. p. 961–5. Available from: http://dx.doi.org/10.1197/s1069-6563(03)00315-45. Lotano R, Gerber D, Aseron C, Santarelli R, Pratter M. Utility of postintubation chest radiographs in the intensive care unit. Crit Care. 2000 Jan 24;4(1):50–3.'}, {'title': 'Acea Smart Water Analytics ', 'url': 'https://www.kaggle.com/competitions/acea-water-prediction', 'briefDescription': 'Can you help preserve \"blue gold\" using data to predict water availability?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/24191/logos/header.png?t=2020-11-24-14-43-27', 'tag': 'data analytics, tabular, water bodies', 'description': '## WelcomeThe  [Acea Group](https://www.gruppo.acea.it/en)  is one of the leading Italian multiutility operators. Listed on the Italian Stock Exchange since 1999, the company manages and develops water and electricity networks and environmental services. Acea is the foremost Italian operator in the water services sector supplying 9 million inhabitants in Lazio, Tuscany, Umbria, Molise, Campania.       In this competition we will focus only on the water sector to help Acea Group preserve precious waterbodies. As it is easy to imagine, a water supply company struggles with the need to forecast the water level in a waterbody (water spring, lake, river, or aquifer) to handle daily consumption. During fall and winter waterbodies are refilled, but during spring and summer they start to drain. To help preserve the health of these waterbodies it is important to predict the most efficient water availability, in terms of level and water flow for each day of the year.## DataThe reality is that each waterbody has such unique characteristics that their attributes are not linked to each other. This analytics competition uses datasets that are completely independent from each other. However, it is critical to understand total availability in order to preserve water across the country.      Each dataset represents a different kind of waterbody. As each waterbody is different from the other, the related features are also different. So, if for instance we consider a water spring we notice that its features are different from those of a lake. These variances are expected based upon the unique behavior and characteristics of each waterbody. The Acea Group deals with four different type of waterbodies: water springs, lakes, rivers and aquifers.## ChallengeCan you build a story to predict the amount of water in each unique waterbody? The challenge is to determine how features influence the water availability of each presented waterbody. To be more straightforward, gaining a better understanding of volumes, they will be able to ensure water availability for each time interval of the year.      The time interval is defined as day/month depending on the available measures for each waterbody. Models should capture volumes for each waterbody(for instance, for a model working on a monthly interval a forecast over the month is expected).      The desired outcome is a notebook that can generate four mathematical models, one for each category of waterbody (acquifers, water springs, river, lake) that might be applicable to each single waterbody.    ![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F6195295%2Fcca952eecc1e49c54317daf97ca2cca7%2FAcea-Input.png?generation=1606932492951317&alt=media)See the [Submission Evaluation][1] criteria.   [1]: https://www.kaggle.com/c/acea-water-prediction/overview/evaluation'}, {'title': 'Santa 2020 - The Candy Cane Contest', 'url': 'https://www.kaggle.com/competitions/santa-2020', 'briefDescription': 'May your workdays be merry and bright', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/24539/logos/header.png?t=2020-12-07-16-26-26', 'tag': 'custom metric', 'description': \"It's the most wonderful time of the year With the elves eating candy They’ll feel super dandy and be of good cheer It's the most wonderful time of the yearIt's the hap-happiest season of allWhen spirits are lifted the toys will be gifted And games to enthrall!It's the hap-happiest season of allThe party for throwingHas snow cones a’glowingWith bragging rights out on display.So now you must plan it,To beat the armed banditswho keep all the candy away.It's the most wonderful time of the year!Morale has been low at the North Pole this year. But Santa really believes in “making spirits bright!” So he has planned a friendly competition among the elves to keep the Christmas cheer alive and make as many toys as possible! And the winning team gets a snow cone party! As one of the team leaders, you know that nothing keeps your fellow elves more productive and motivated than a steady supply of candy canes! But all seven levels of the Candy Cane Forest are closed for revegetation, so the only ones available are stuck in the break room vending machines. And even though you receive free snacks on the job, the vending machines are always broken and don’t always give you what you want.Due to social distancing, only two elves can be in the break room at once. You and another team leader will take turns trying to get candy canes out of the 100 possible vending machines in the room, but each machine is unpredictable in how likely it is to work. You do know, however, that the more often you try to use a machine, the less likely it will give you a candy cane. Plus, you only have time to try 2000 times on the vending machines until you need to get back to the workshop! If you can collect more candy canes than the other team leaders, you’ll surely be able to help your team win Santa's contest! Try your hand at this multi-armed candy cane challenge!Image Credit: Photos by Joanna Kosinska and Misty Ladd on Unsplash.\"}, {'title': 'Jane Street Market Prediction', 'url': 'https://www.kaggle.com/competitions/jane-street-market-prediction', 'briefDescription': 'Test your model against future real market data', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/23304/logos/header.png?t=2020-11-16-17-41-04', 'tag': 'tabular, finance, custom metric', 'description': '***“Buy low, sell high.” It sounds so easy….*** In reality, trading for profit has always been a difficult problem to solve, even more so in today’s fast-moving and complex financial markets. Electronic trading allows for thousands of transactions to occur within a fraction of a second, resulting in nearly unlimited opportunities to potentially find and take advantage of price differences in real time.    In a perfectly efficient market, buyers and sellers would have all the agency and information needed to make rational trading decisions. As a result, products would always remain at their “fair values” and never be undervalued or overpriced. However, financial markets are not perfectly efficient in the real world.    Developing trading strategies to identify and take advantage of inefficiencies is challenging. Even if a strategy is profitable now, it may not be in the future, and market volatility makes it impossible to predict the profitability of any given trade with certainty. As a result, it can be hard to distinguish good luck from having made a good trading decision.     In the first three months of this challenge, you will build your own quantitative trading model to maximize returns using market data from a major global stock exchange. Next, you’ll test the predictiveness of your models against future market returns and receive feedback on the leaderboard.    Your challenge will be to use the historical data, mathematical tools, and technological tools at your disposal to create a model that gets as close to certainty as possible. You will be presented with a number of potential trading opportunities, which your model must choose whether to accept or reject.    In general, if one is able to generate a highly predictive model which selects the right trades to execute, they would also be playing an important role in sending the market signals that push prices closer to “fair” values.  That is, a better model will mean the market will be more efficient going forward. However, developing good models will be challenging for many reasons, including a very low signal-to-noise ratio, potential redundancy, strong feature correlation, and difficulty of coming up with a proper mathematical formulation.    Jane Street has spent decades developing their own trading models and machine learning solutions to identify profitable opportunities and quickly decide whether to execute trades. These models help Jane Street trade thousands of financial products each day across 200 trading venues around the world.    Admittedly, this challenge far oversimplifies the depth of the quantitative problems Jane Streeters work on daily, and Jane Street is happy with the performance of its existing trading model for this particular question. However, there’s nothing like a good puzzle, and this challenge will hopefully serve as a fun introduction to a type of data science problem that a Jane Streeter might tackle on a daily basis. Jane Street looks forward to seeing the new and creative approaches the Kaggle community will take to solve this trading challenge. > **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/jane-street-market-prediction/overview/code-requirements) for details.**'}, {'title': 'Cassava Leaf Disease Classification', 'url': 'https://www.kaggle.com/competitions/cassava-leaf-disease-classification', 'briefDescription': 'Identify the type of disease present on a Cassava Leaf image', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13836/logos/header.png?t=2020-10-01-17-22-54', 'tag': 'image, multiclass classification, plants, categorizationaccuracy', 'description': 'As the second-largest provider of carbohydrates in Africa, cassava is a key food security crop grown by smallholder farmers because it can withstand harsh conditions. At least 80% of household farms in Sub-Saharan Africa grow this starchy root, but viral diseases are major sources of poor yields. With the help of data science, it may be possible to identify common diseases so they can be treated.Existing methods of disease detection require farmers to solicit the help of government-funded agricultural experts to visually inspect and diagnose the plants. This suffers from being labor-intensive, low-supply and costly. As an added challenge, effective solutions for farmers must perform well under significant constraints, since African farmers may only have access to mobile-quality cameras with low-bandwidth.In this competition, we introduce a dataset of 21,367 labeled images collected during a regular survey in Uganda. Most images were crowdsourced from farmers taking photos of their gardens, and annotated by experts at the National Crops Resources Research Institute (NaCRRI) in collaboration with the AI lab at Makerere University, Kampala. This is in a format that most realistically represents what farmers would need to diagnose in real life.Your task is to classify each cassava image into four disease categories or a fifth category indicating a healthy leaf. With your help, farmers may be able to quickly identify diseased plants, potentially saving their crops before they inflict irreparable damage.Recommended TutorialWe highly recommend Jesse Mostipak’s Getting Started Tutorial that walks you through making your very first submission step by step.## AcknowledgementsThe **Makerere Artificial Intelligence (AI) Lab** is an AI and Data Science research group based at Makerere University in Uganda. The lab specializes in the application of artificial intelligence and data science - including for example, methods from machine learning, computer vision and predictive analytics to problems in the developing world. Their mission is: “To advance Artificial Intelligence research to solve real-world challenges.\"We thank the different experts and collaborators from **National Crops Resources Research Institute (NaCRRI)** for assisting in preparing this dataset.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/cassava-leaf-disease-classification/overview/code-requirements) for details.**'}, {'title': '2020 Kaggle Machine Learning & Data Science Survey', 'url': 'https://www.kaggle.com/competitions/kaggle-survey-2020', 'briefDescription': 'The most comprehensive dataset available on the state of ML and data science ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/23724/logos/header.png?t=2020-10-31-23-22-58', 'tag': 'data analytics, online communities, survey analysis', 'description': \"**Welcome to Kaggle's annual Machine Learning and Data Science Survey competition!  [You can read our executive summary here](https://www.kaggle.com/kaggle-survey-2020).**This year, as in [2017][1], [2018](https://www.kaggle.com/kaggle/kaggle-survey-2018/), and [2019](https://www.kaggle.com/c/kaggle-survey-2019/) we set out to conduct an industry-wide survey that presents a truly comprehensive view of the state of data science and machine learning. The survey was live for 3.5 weeks in October, and after cleaning the data we finished with 20,036 responses!There's a lot to explore here. The results include raw numbers about who is working with data, what’s happening with machine learning in different industries, and the best ways for new data scientists to break into the field. We've published the data in as raw a format as possible without compromising anonymization, which makes it an unusual example of a survey dataset.**This year Kaggle is once again launching an annual Data Science Survey Challenge, where we will be awarding a prize pool of $30,000 to notebook authors who tell a rich story about a subset of the data science and machine learning community.**In our fourth year running this survey, we were once again awed by the global, diverse, and dynamic nature of the data science and machine learning industry. This [survey data EDA][4] provides an overview of the industry on an aggregate scale, but it also leaves us **wanting to know more about the many specific communities comprised within the survey**. For that reason, we’re inviting the Kaggle community to dive deep into the survey datasets and help us tell the diverse stories of data scientists from around the world.  **The challenge objective:** tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration. A “story” could be defined any number of ways, and that’s deliberate. The challenge is to deeply explore (through data) the impact, priorities, or concerns of a specific group of data science and machine learning practitioners. That group can be defined in the macro (for example: anyone who does most of their coding in Python) or the micro (for example: female data science students studying machine learning in masters programs). This is an opportunity to be creative and tell the story of a community you identify with or are passionate about! **Submissions will be evaluated on the following:** - Composition - Is there a clear narrative thread to the story that’s articulated and supported by data? The subject should be well defined, well researched, and well supported through the use of data and visualizations.  - Originality - Does the reader learn something new through this submission? Or is the reader challenged to think about something in a new way? A great entry will be informative, thought provoking, and fresh all at the same time.   - Documentation - Are your code, and notebook, and additional data sources well documented so a reader can understand what you did? Are your sources clearly cited? A high quality analysis should be concise and clear at each step so the rationale is easy to follow and the process is reproducible To be valid, a submission must be contained in one notebook, made public on or before the submission deadline. Participants are free to use any datasets in addition to the Kaggle Data Science survey, but those datasets must also be publicly available on Kaggle by the deadline for a submission to be valid. ---# How to Participate To make a submission, complete the [submission form][3]. Only one submission will be judged per participant, so if you make multiple submissions we will review the last (most recent) entry. No submission is necessary for the Notebook Award. To be eligible, a notebook must be public and use the 2020 Data Science Survey as a data source. Submission deadline: 11:59PM UTC, January 6th, 2021.---__________________________________________________  [1]: https://www.kaggle.com/kaggle/kaggle-survey-2017  [2]: http://blog.kaggle.com/  [3]: https://www.kaggle.com/page/2020-kaggle-survey-competition-submission-form  [4]: https://www.kaggle.com/paultimothymooney/2020-kaggle-data-science-machine-learning-survey\"}, {'title': 'Rainforest Connection Species Audio Detection', 'url': 'https://www.kaggle.com/competitions/rfcx-species-audio-detection', 'briefDescription': 'Automate the detection of bird and frog species in a tropical soundscape', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/21669/logos/header.png?t=2020-10-28-04-28-01', 'tag': 'tensorflow, animals, audio, weightedlabelrankingaverageprecision', 'description': \"Who doesn't enjoy the morning chirp of a bird or a frog’s evening croak? Animals bring more than sweet songs and natural ambience to the world. The presence of rainforest species is a good indicator of the impact of climate change and habitat loss. As it's easier to hear these species than see them, it’s important to use acoustic technologies that can work on a global scale. Real-time information, such as provided through machine learning techniques, could enable early-stage detection of human impacts on the environment. This result could drive more effective conservation management decisions.Traditional methods of assessing the diversity and abundance of species are costly and limited in space and time. And while automatic acoustic identification via deep learning has been successful, models require a large number of training samples per species. This limits applicability to rarer species, which are central to conservation efforts. Thus, methods to automate high-accuracy species detection in noisy soundscapes with limited training data are the solution.Rainforest Connection (RFCx) created the world’s first scalable, real-time monitoring system for protecting and studying remote ecosystems. Unlike visual-based tracking systems like drones or satellites, RFCx relies on acoustic sensors that monitor the ecosystem soundscape at selected locations year round. RFCx technology has advanced to support a comprehensive biodiversity monitoring program that allows local partners to measure progress of wildlife restoration and recovery through principles of adaptive management. The RFCx monitoring platform also has the capacity to create convolutional neural network (CNN) models for analysis.In this competition, you’ll automate the detection of bird and frog species in tropical soundscape recordings. You'll create your models with limited, acoustically complex training data. Rich in more than bird and frog noises, expect to hear an insect or two, which your model will need to filter out.If successful, you'll have a hand in a rapidly expanding field of science: the development of automated eco-acoustic monitoring systems. The resulting real-time information could enable earlier detection of human environmental impacts, making environmental conservation more swift and effective.\"}, {'title': 'HuBMAP - Hacking the Kidney', 'url': 'https://www.kaggle.com/competitions/hubmap-kidney-segmentation', 'briefDescription': 'Identify glomeruli in human kidney tissue images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22990/logos/header.png?t=2020-11-05-21-54-19', 'tag': 'health, image, biology, dice', 'description': 'Our best estimates show there are over 7 billion people on the planet and 300 billion stars in the Milky Way galaxy. By comparison, the adult human body contains 37 *trillion* cells. To determine the function and relationship among these cells is a monumental undertaking. Many areas of human health would be impacted if we better understand cellular activity. A problem with this much data is a great match for the Kaggle community.Just as the Human Genome Project mapped the entirety of human DNA, the [Human BioMolecular Atlas Program](https://hubmapconsortium.org/) (HuBMAP) is a major endeavor. Sponsored by the National Institutes of Health (NIH), HuBMAP is working to catalyze the development of a framework for mapping the human body at a level of glomeruli functional tissue units for the first time in history. Hoping to become one of the world’s largest collaborative biological projects, HuBMAP aims to be an open map of the human body at the cellular level. This competition, “Hacking the Kidney,\" starts by mapping the human kidney at single cell resolution.Your challenge is to detect functional tissue units (FTUs) across different tissue preparation pipelines. An FTU is defined as a “three-dimensional block of cells centered around a capillary, such that each cell in this block is within diffusion distance from any other cell in the same block” ([de Bono, 2013](https://www.ncbi.nlm.nih.gov/pubmed/24103658)). The goal of this competition is the implementation of a successful and robust glomeruli FTU detector.You will also have the opportunity to present your findings to a panel of judges for additional consideration. Successful submissions will construct the tools, resources, and cell atlases needed to determine how the relationships between cells can affect the health of an individual.Advancements in HuBMAP will accelerate the world’s understanding of the relationships between cell and tissue organization and function and human health. These datasets and insights can be used by researchers in cell and tissue anatomy, pharmaceutical companies to develop therapies, or even parents to show their children the magnitude of  the human body.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/hubmap-kidney-segmentation/overview/code-requirements) for details.**'}, {'title': 'NFL 1st and Future - Impact Detection', 'url': 'https://www.kaggle.com/competitions/nfl-impact-detection', 'briefDescription': 'Detect helmet impacts in videos of NFL plays', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12125/logos/header.png?t=2018-11-30-18-08-32', 'tag': 'sports, computer vision, football, video data, custom metric', 'description': \"The National Football League (NFL) has teamed up with Amazon Web Services (AWS) to develop the “Digital Athlete,” a virtual representation of a composite NFL player that the NFL can use to model game scenarios to try to better predict and prevent player injury. The NFL is actively addressing the need for a computer vision system to detect on-field helmet impacts as part of the “Digital Athlete” platform, and the league is calling on Kagglers to help.In this competition, you’ll develop a computer vision model that automatically detects helmet impacts that occur on the field. Kick off with a dataset of more than one thousand definitive head impacts from thousands of game images, labeled video from the sidelines and end zones, and player tracking data. This information is sourced from the NFL’s Next Gen Stats (NGS) system, which documents the position, speed, acceleration, and orientation for every player on the field during NFL games.This competition is part of the NFL’s annual 1st and Future competition, which is designed to spur innovation in athlete safety and performance. For the first time this year, 1st and Future will be broadcast in primetime during Super Bowl LV week on NFL Network, and winning Kagglers may have the opportunity to present their computer vision systems as part of this exciting event. If successful, you could support the NFL’s research programs in a big way: improving athletes' safety. Backed by this research, the NFL may implement rule changes and helmet design improvements to try to better protect the athletes who play the game millions watch each week.The National Football League is America's most popular sports league. Founded in 1920, the NFL developed the model for the successful modern sports league and is committed to advancing progress in the diagnosis, prevention, and treatment of sports-related injuries. Health and safety efforts include support for independent medical research and engineering advancements as well as a commitment to work to better protect players and make the game safer, including enhancements to medical protocols and improvements to how our game is taught and played. For more information about the NFL's health and safety efforts, please visit NFL.com/PlayerHealthandSafety. > **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/nfl-impact-detection/overview/code-requirements) for details.**\"}, {'title': 'Rock, Paper, Scissors', 'url': 'https://www.kaggle.com/competitions/rock-paper-scissors', 'briefDescription': 'Shoot!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22838/logos/header.png?t=2020-11-02-21-55-44', 'tag': 'custom metric', 'description': 'Rock, Paper, Scissors (sometimes called roshambo) has been a staple to settle playground disagreements or determine who gets to ride in the front seat on a road trip. The game is simple, with a balance of power. There are three options to choose from, each winning or losing to the other two. In a series of truly random games, each player would win, lose, and draw roughly one-third of games. But people are not truly random, which provides a fun opportunity for AI.Studies have shown that a Rock, Paper, Scissors AI can consistently beat human opponents. With previous games as input, it studies patterns to understand a player’s tendencies. But what happens when we expand the simple “Best-of-3” game to be “Best-of-1000”? How well can artificial intelligence perform?In this simulation competition, you will create an AI to play against others in many rounds of this classic game. Can you find patterns to make yours win more often than it loses? It’s possible to greatly outperform a random player when the matches involve non-random agents. A strong AI can consistently beat predictable AI.This problem is fundamental to the fields of machine learning, artificial intelligence, and data compression. There are even potential applications in human psychology and hierarchical temporal memory. Warm up your hands and get ready to Rock, Paper, Scissors in this challenge.Image acknowledgements:Photos from The Noun Project: [Rock](https://thenounproject.com/term/rock/899808/), [Paper](https://thenounproject.com/term/paper/661463/), [Scissors](https://thenounproject.com/term/scissors/3582625/)'}, {'title': 'NFL Big Data Bowl 2021', 'url': 'https://www.kaggle.com/competitions/nfl-big-data-bowl-2021', 'briefDescription': 'Help evaluate defensive performance on passing plays', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/15696/logos/header.png?t=2019-10-04-16-16-53', 'tag': 'data analytics, tabular, football', 'description': 'When a quarterback takes a snap and drops back to pass, what happens next may seem like chaos. As offensive players move in various patterns, the defense works together to prevent successful pass completions and then to quickly tackle receivers that do catch the ball. In this year’s Kaggle competition, your goal is to use data science to better understand the schemes and players that make for a successful defense against passing plays.In American football, there are a plethora of defensive strategies and outcomes. The National Football League (NFL) has used previous Kaggle competitions to focus on offensive plays, but as the old proverb goes, “defense wins championships.” Though metrics for analyzing quarterbacks, running backs, and wide receivers are consistently a part of public discourse, techniques for analyzing the defensive part of the game trail and lag behind. Identifying player, team, or strategic advantages on the defensive side of the ball would be a significant breakthrough for the game.This competition uses NFL’s Next Gen Stats data, which includes the position and speed of every player on the field during each play. You’ll employ player tracking data for all drop-back pass plays from the 2018 regular season.  The goal of submissions is to identify unique and impactful approaches to measure defensive performance on these plays. There are several different directions for participants to ‘tackle’ (ha)—which may require levels of football savvy, data aptitude, and creativity. As examples:- What are coverage schemes (man, zone, etc) that the defense employs? What coverage options tend to be better performing?- Which players are the best at closely tracking receivers as they try to get open?- Which players are the best at closing on receivers when the ball is in the air?- Which players are the best at defending pass plays when the ball arrives?- Is there any way to use player tracking data to predict whether or not certain penalties – for example, defensive pass interference – will be called?- Who are the NFL’s best players against the pass?- How does a defense react to certain types of offensive plays?- Is there anything about a player – for example, their height, weight, experience, speed, or position – that can be used to predict their performance on defense?What does data tell us about defending the pass play? You are about to find out.Note: Are you a university participant? Students have the option to participate in a college-only Competition, where you’ll work on the identical themes above. Students can opt-in for either the Open or College Competitions, but not both. '}, {'title': 'CDP - Unlocking Climate Solutions', 'url': 'https://www.kaggle.com/competitions/cdp-unlocking-climate-solutions', 'briefDescription': 'City-Business Collaboration for a Sustainable Future', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22420/logos/header.png?t=2020-09-08-21-21-20', 'tag': 'environment, survey analysis, pollution', 'description': '[CDP](https://www.cdp.net/en) is a\\u202fglobal\\u202fnon-profit that drives companies and governments to reduce their greenhouse gas emissions, safeguard water resources, and protect forests.  Each year, CDP takes the information supplied in its annual reporting process and [scores companies and cities](https://www.cdp.net/en/scores) based on their journey through disclosure and towards environmental leadership. CDP houses the world’s largest, most comprehensive dataset on environmental action. As the data grows to include thousands more companies and cities each year, there is increasing potential for the data to be utilized in impactful ways. Because of this potential, CDP is excited to launch an analytics challenge for the Kaggle community. Data scientists will scour environmental information provided to CDP by disclosing companies and cities, searching for solutions to our most pressing problems related to climate change, water security, deforestation, and social inequity. - *How do you help cities adapt to a rapidly changing climate amidst a global pandemic, but do it in a way that is socially equitable?* - *What are the projects that can be invested in that will help pull cities out of a recession, mitigate climate issues, but not perpetuate racial/social inequities?*   - *What are the practical and actionable points where city and corporate ambition join, i.e. where do cities have problems that corporations affected by those problems could solve, and vice versa?* - *How can we measure the intersection between environmental risks and social equity, as a contributor to resiliency?*## PROBLEM STATEMENTDevelop a methodology for calculating key performance indicators (KPIs) that relate to the environmental and social issues that are discussed in the CDP survey data.   Leverage external data sources and thoroughly discuss the intersection between environmental issues and social issues.  Mine information to create automated insight generation demonstrating whether city and corporate ambitions take these factors into account.## HOW TO PARTICIPATETo make a submission, complete the [submission form](https://www.kaggle.com/page/cdp-kpis-submission-form). Only one submission will be judged per participant, so if you make multiple submissions we will only review the most recent entry.  A [starter notebook]( https://www.kaggle.com/callumr22/cdp-starter-notebook) demonstrates how to load and work with the data.**To be valid, a submission must be contained in one or more notebook, and made public on or before the submission deadline. Participants are free to use any datasets in addition to the [official Kaggle dataset](https://www.kaggle.com/c/cdp-unlocking-climate-solutions), but those datasets must be public and hosted on Kaggle for the submission to be valid.**'}, {'title': 'INGV - Volcanic Eruption Prediction', 'url': 'https://www.kaggle.com/competitions/predict-volcanic-eruptions-ingv-oe', 'briefDescription': 'Discover hidden precursors in geophysical data to help emergency response', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19059/logos/header.png?t=2020-09-20-19-43-36', 'tag': 'physics, geology, signal processing, mae', 'description': \"What if scientists could anticipate volcanic eruptions as they predict the weather? While determining rain or shine days in advance is more difficult, weather reports become more accurate on shorter time scales. A similar approach with volcanoes could make a big impact. Just one unforeseen eruption can result in tens of thousands of lives lost. If scientists could reliably predict when a volcano will next erupt, evacuations could be more timely and the damage mitigated.Currently, scientists often identify “time to eruption” by surveying volcanic tremors from seismic signals. In some volcanoes, this intensifies as volcanoes awaken and prepare to erupt. Unfortunately, patterns of seismicity are difficult to interpret. In very active volcanoes, current approaches predict eruptions some minutes in advance, but they usually fail at longer-term predictions.Enter Italy's Istituto Nazionale di Geofisica e Vulcanologia (INGV), with its focus on geophysics and volcanology. The INGV's main objective is to contribute to the understanding of the Earth's system while mitigating the associated risks. Tasked with the 24-hour monitoring of seismicity and active volcano activity across the country, the INGV seeks to find the earliest detectable precursors that provide information about the timing of future volcanic eruptions.In this competition, using your data science skills, you’ll predict when a volcano's next eruption will occur. You'll analyze a large geophysical dataset collected by sensors deployed on active volcanoes. If successful, your algorithms will identify signatures in seismic waveforms that characterize the development of an eruption. With enough notice, areas around a volcano can be safely evacuated prior to their destruction. Seismic activity is a good indicator of an impending eruption, but earlier precursors must be identified to improve longer-term predictability. The impact of your participation could be felt worldwide with tens of thousands of lives saved by more predictable volcanic ruptures and earlier evacuations.\"}, {'title': 'Riiid Answer Correctness Prediction', 'url': 'https://www.kaggle.com/competitions/riiid-test-answer-prediction', 'briefDescription': 'Track knowledge states of 1M+ students in the wild', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/21651/logos/header.png?t=2020-09-09-03-03-31', 'tag': 'education, tabular, auc', 'description': 'Riiid AIEd Challenge 2020[Challenge Website](https://www.ednetchallenge.ai/)>Thank you for all those who attended the [AAAI-2021](https://aaai.org/Conferences/AAAI-21/) workshop on AI Education! Prize-winning teams presented their models at the AAAI-2021 Workshop on AI Education - [Imagining Post-COVID Education with AI](https://sites.google.com/view/tipce-2021/home?authuser=1) - on February 9, 2021. You can find the model write-ups on the workshop website.Think back to your favorite teacher. They motivated and inspired you to learn. And they knew your strengths and weaknesses. The lessons they taught were based on your ability. For example, teachers would make sure you understood algebra before advancing to calculus. Yet, many students don’t have access to personalized learning. In a world full of information, data scientists like you can help. Machine learning can offer a path to success for young people around the world, and you are invited to be part of this mission.In 2018, 260 million children weren\\'t attending school. At the same time, more than half of these young students didn\\'t meet minimum reading and math standards. Education was already in a tough place when COVID-19 forced most countries to temporarily close schools. This further delayed learning opportunities and intellectual development. The equity gaps in every country could grow  wider. We need to re-think the current education system in terms of attendance, engagement, and individualized attention.Riiid Labs, an AI solutions provider delivering creative disruption to the education market, empowers global education players to rethink traditional ways of learning leveraging AI. With a strong belief in equal opportunity in education, Riiid launched an AI tutor based on deep-learning algorithms in 2017 that attracted more than one million South Korean students. This year, the company released EdNet, the world’s largest open database for AI education containing more than 100 million student interactions.In this competition, your challenge is to create algorithms for \"Knowledge Tracing,\" the modeling of student knowledge over time. The goal is to accurately predict how students will perform on future interactions. You will pair your machine learning skills using Riiid’s EdNet data. Your innovative algorithms will help tackle global challenges in education. If successful, it’s possible that any student with an Internet connection can enjoy the benefits of a personalized learning experience, regardless of where they live. With your participation, we can build a better and more equitable model for education in a post-COVID-19 world.AcknowledgementsAcademic Advisors[Paul Kim](https://gse-it.stanford.edu/about/team/paul-kim), Stanford Graduate School of Education[Neil Heffernan](https://www.neilheffernan.net/), WPI & ASSISTmentsPartners![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F5180416%2F1316be20b53c09a1569e3bb4af77762a%2FScreen%20Shot%202020-10-12%20at%2011.24.59%20AM.png?generation=1602469542965510&alt=media)'}, {'title': 'Google Research Football with Manchester City F.C.', 'url': 'https://www.kaggle.com/competitions/google-football', 'briefDescription': \"Train agents to master the world's most popular sport\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/21723/logos/header.png?t=2020-07-23-19-26-16', 'tag': 'reinforcement learning, simulations, custom metric', 'description': 'Manchester City F.C. and Google Research are proud to present AI football competition using the [Google Research Football Environment](https://github.com/google-research/football).### A word from Manchester City F.C.Brian Prestidge, Director of Data Insights & Decision Technology at City Football Group, the owners of Manchester City F.C., sets out the challenge. “Football is a tough environment to perform in and an even tougher environment to learn in. Learning is all about harnessing failure, but failure in football is seldom accepted. Working with Google Research’s physics based football environment provides us with a new place to learn through simulation and offers us the capabilities to test tactical concepts and refine principles so that they are strong enough for a coach to stake their career on.”“We are therefore very pleased to be working with Google’s research team in creating this competition and are looking forward to the opportunity to support some of the most creative and successful competitors through funding and exclusive prizes. We hope to establish ongoing collaboration with the winners beyond this competition, and that it will provide us all with the platform to explore and establish fundamental principles of football tactics, thus improving our ability to perform and be successful on the pitch.”Greg Swimer, Chief Technology Officer at City Football Group added \"Technologies such as Machine Learning and Artificial Intelligence have huge future potential to enhance the understanding and enjoyment of football for players, coaches and fans.  We are delighted to be collaborating with Google\\'s research team to help broaden the knowledge, talent, and innovation working in this exciting and transformational area\". ### The Google Research football environment competitionThe world gets a kick out of football (soccer in the United States). As the most popular sport on the planet, millions of fans enjoy watching Sergio Agüero, Raheem Sterling, and Kevin de Bruyne on the field. Football video games are less lively, but still immensely popular, and we wonder if AI agents would be able to play those properly.Researchers want to explore AI agents\\' ability to play in complex settings like football. The sport requires a balance of short-term control, learned concepts such as passing, and high-level strategy, which can be difficult to teach agents. A current environment exists to train and test agents, but other solutions may offer better results.The teams at Google Research aspire to make discoveries that impact everyone. Essential to their approach is sharing research and tools to fuel progress in the field. Together with Manchester City F.C., Google Research has put forth this competition to get help in reaching their *goal*.![GRF](https://1.bp.blogspot.com/-tSPIa1HlNrg/XPqRavoz7lI/AAAAAAAAEMU/oGB2mmwSl_4TFVKN1NNCQD-qlDNZQr2VQCLcBGAs/s640/Screenshot%2B2019-06-05%2Bat%2B1.38.14%2BPM.png)In this competition, you’ll create AI agents that can play football. Teams compete in “steps,” where agents react to a game state. Each agent in an 11 vs 11 game controls a single active player and takes actions to improve their team’s situation. As with a typical football game, you want your team to score more than the other side. You can optionally see your efforts rendered in a physics-based 3D football simulation.If controlling 11 football players with code sounds difficult, don\\'t be discouraged! You only need to control one player at a time (the one with the ball on offense, or the one closest to the ball on defense) and your code gets to pick from 1 of 19 possible actions. We have prepared a [getting started](https://www.kaggle.com/c/google-football/overview/getting-started) example to show you how simple a basic strategy can be. Before implementing your own strategy, however, you might want to learn more about [the Google Research football environment](https://github.com/google-research/football/), especially [observations provided to you by the environment and available actions](https://github.com/google-research/football/blob/master/gfootball/doc/observation.md). You can also [play the game yourself](https://github.com/google-research/football/#playing-the-game) on your computer locally to get better understanding of the environment\\'s dynamics and explore different scenarios.If successful, you\\'ll help researchers explore the ability of AI agents to play in complex settings. This could offer new insights into the strategies of the world\\'s most-watched sport. Additionally, this research could pave the way for a new generation of AI agents that can be trained to learn complex skills.'}, {'title': 'Halite by Two Sigma - Playground Edition', 'url': 'https://www.kaggle.com/competitions/halite-iv-playground-edition', 'briefDescription': 'Collect the most halite during your match in space', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22806/logos/header.png?t=2020-09-23-20-52-54', 'tag': 'custom metric', 'description': '*Note: This simulation is a playground competition extending the fourth season of [Halite](http://www.kaggle.com/c/halite) for participation. We have modified the rules to serve as a two-player game instead of four-player game. No points or medals will be awarded for this competition.*Ahoy there! There\\'s halite to be had and ships to be deployed! Are you ready to navigate the skies and secure your territory?Halite by [Two Sigma](https://www.twosigma.com/) (\"Halite\") is a resource management game where you build and control a small armada of ships. Your algorithms determine their movements to collect halite, a luminous energy source. The most halite at the end of the match wins, but it\\'s up to you to figure out how to make effective and efficient moves. You control your fleet, build new ships, create shipyards, and mine the regenerating halite on the game board.Created by Two Sigma in 2016, more than 15,000 people around the world have participated in a Halite challenge. Players apply advanced algorithms in a dynamic, open source game setting. The strategic depth and immersive, interactive nature of Halite games make each challenge a unique learning environment.Halite IV builds on the core game design of Halite III with a number of key changes that shift the focus of the game towards tighter competition on a smaller board. New game features include regenerating halite, shipyard creation, no more ship movement costs, and stealing halite from other players!So dust off your halite meters and fasten your seatbelts. The fourth season of Halite is about to begin!  '}, {'title': 'OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction', 'url': 'https://www.kaggle.com/competitions/stanford-covid-vaccine', 'briefDescription': 'Urgent need to bring the COVID-19 vaccine to mass production', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22111/logos/header.png?t=2020-09-10-20-12-59', 'tag': 'biology, covid19, public health, biotechnology, custom metric', 'description': 'Winning the fight against the COVID-19 pandemic will require an effective vaccine that can be equitably and widely distributed. Building upon decades of research has allowed scientists to accelerate the search for a vaccine against COVID-19, but every day that goes by without a vaccine has enormous costs for the world nonetheless. We need new, fresh ideas from all corners of the world. Could online gaming and crowdsourcing help solve a worldwide pandemic? Pairing scientific and crowdsourced intelligence could help computational biochemists make measurable progress. mRNA vaccines have taken the lead as the fastest vaccine candidates for COVID-19,  but currently, they face key potential limitations. One of the biggest challenges right now is how to design super stable messenger RNA molecules (mRNA). Conventional vaccines (like your seasonal flu shots) are packaged in disposable syringes and shipped under refrigeration around the world, but that is not currently possible for mRNA vaccines. Researchers have observed that RNA molecules have the tendency to spontaneously degrade. This is a serious limitation--a single cut can render the mRNA vaccine useless. Currently, little is known on the details of where in the backbone of a given RNA is most prone to being affected. Without this knowledge, current mRNA vaccines against COVID-19 must be prepared and shipped under intense refrigeration, and are unlikely to reach more than a tiny fraction of human beings on the planet unless they can be stabilized.  The Eterna community, led by Professor Rhiju Das, a computational biochemist at Stanford’s School of Medicine, brings together scientists and gamers to solve puzzles and invent medicine. Eterna is an online video game platform that challenges players to solve scientific problems such as mRNA design through puzzles. The solutions are synthesized and experimentally tested at Stanford by researchers to gain new insights about RNA molecules. The Eterna community has previously unlocked new scientific principles, made new diagnostics against deadly diseases, and engaged the world’s most potent intellectual resources for the betterment of the public. The Eterna community has advanced biotechnology through its contribution in over 20 publications, including advances in RNA biotechnology.In this competition, we are looking to leverage the data science expertise of the Kaggle community to develop models and design rules for RNA degradation. Your model will predict likely degradation rates at each base of an RNA molecule, trained on a subset of an Eterna dataset comprising over 3000 RNA molecules (which span a panoply of sequences and structures) and their degradation rates at each position. We will then score your models on a  second generation of RNA sequences that have just been devised by Eterna players for COVID-19 mRNA vaccines. These final test sequences are currently being synthesized and experimentally characterized at Stanford University in parallel to your modeling efforts -- Nature will score your models! Improving the stability of mRNA vaccines was a problem that was being explored before the pandemic but was expected to take many years to solve.  Now, we must solve this deep scientific challenge in months, if not weeks, to accelerate mRNA vaccine research and deliver a refrigerator-stable vaccine against SARS-CoV-2, the virus behind COVID-19. The problem we are trying to solve has eluded academic labs, industry R&D groups, and supercomputers, and so we are turning to you. To help, you can join the team of video game players, scientists, and developers at Eterna to unlock the key in our fight against this devastating pandemic.    \\xa0\\xa0\\xa0\\xa0 \\xa0\\xa0\\xa0\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0'}, {'title': 'RSNA STR Pulmonary Embolism Detection', 'url': 'https://www.kaggle.com/competitions/rsna-str-pulmonary-embolism-detection', 'briefDescription': 'Classify Pulmonary Embolism cases in chest CT scans', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22307/logos/header.png?t=2020-09-02-17-44-41', 'tag': 'health, image, weightedmeancolumnwiselogloss', 'description': \"If every breath is strained and painful, it could be a serious and potentially life-threatening condition. A pulmonary embolism (PE) is caused by an artery blockage in the lung. It is time consuming to confirm a PE and prone to overdiagnosis. Machine learning could help to more accurately identify PE cases, which would make management and treatment more effective for patients.Currently, CT pulmonary angiography (CTPA), is the most common type of medical imaging to evaluate patients with suspected PE. These CT scans consist of hundreds of images that require detailed review to identify clots within the pulmonary arteries. As the use of imaging continues to grow, constraints of radiologists’ time may contribute to delayed diagnosis.The Radiological Society of North America (RSNA®) has teamed up with the Society of Thoracic Radiology (STR) to help improve the use of machine learning in the diagnosis of PE.In this competition, you’ll detect and classify PE cases. In particular, you'll use chest CTPA images (grouped together as studies) and your data science skills to enable more accurate identification of PE. If successful, you'll help reduce human delays and errors in detection and treatment.With 60,000-100,000 PE deaths annually in the United States, it is among the most fatal cardiovascular diseases. Timely and accurate diagnosis will help these patients receive better care and may also improve outcomes.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection/overview/code-requirements) for details.**###AcknowledgmentsThe Radiological Society of North America (RSNA®) is an international society of radiologists, medical physicists, and other medical professionals with more than 53,400 members worldwide.  RSNA hosts the world’s premier radiology forum and publishes two top peer-reviewed journals: Radiology, the highest-impact scientific journal in the field, and RadioGraphics, the only journal dedicated to continuing education in radiology. The Society of Thoracic Radiology (STR) was founded in 1982.  The STR is dedicated to advancing cardiothoracic imaging in clinical application, education, and research in radiology and allied disciplines.  Continuing professional development opportunities provided by the STR include educational and scientific meetings, mentorship programs, grant support and award opportunities, our society journal, Journal of Thoracic Imaging, and global collaboration activities.[A full set of acknowledgments can be found on this page](https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection/overview/acknowledgments).\"}, {'title': 'Hash Code Archive - Drone Delivery', 'url': 'https://www.kaggle.com/competitions/hashcode-drone-delivery', 'briefDescription': 'Can you help coordinate the drone delivery supply chain?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22040/logos/header.png?t=2020-08-19-16-25-21', 'tag': 'internet, optimization, custom metric', 'description': \"This is a synthetic code challenge to sharpen your programming skills. This problem was first released during the 2016 qualification round of Google's annual coding competition, [Hash Code](https://codingcompetitions.withgoogle.com/hashcode/). We’ve re-released it as a Playground Code Competition to help you sharpen your skills. Along with the [Photo Slideshow Optimization competition](https://www.kaggle.com/c/hashcode-photo-slideshow), open for late submissions, you can use it as practice in advance of Hash Code 2021.The Internet has profoundly changed the way we buy things, but the online shopping of today is likely not the end of that change; the expectations for purchase delivery has gone from a week, to two days, to one day, to same day. What about in just a few hours? With drones, this may be possible, and they’ll bring a whole new fleet of problems to solve with data science.Drones are\\xad autonomous, electric vehicles often used to deliver online purchases. Current experiments use flying drones, so they’re never stuck in traffic. As drone technology improves every year, there remains a major issue: how would we manage and coordinate all those drones?In this competition, you are given a hypothetical fleet of drones, a list of customer orders, and availability of the individual products in warehouses. Can you schedule the drone operations so that the orders are completed as soon as possible?When flying delivery drones become the norm, scheduling is one of the many problems to be solved. Get a head start—and improve your data science skills at the same time.This is a Code Competition. Refer to Code Requirements for details.Photo by Ian Usher on Unsplash\"}, {'title': 'Mechanisms of Action (MoA) Prediction', 'url': 'https://www.kaggle.com/competitions/lish-moa', 'briefDescription': 'Can you improve the algorithm that classifies drugs based on their biological activity?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19988/logos/header.png?t=2020-06-16-17-24-17', 'tag': 'tabular, biology, drugs and medications, genetics, meancolumnwiselogloss', 'description': 'The [Connectivity Map](https://clue.io), a project within the Broad Institute of MIT and Harvard,  the [Laboratory for Innovation Science at Harvard (LISH)](http://lish.harvard.edu), and the [NIH Common Funds Library of Integrated Network-Based Cellular Signatures (LINCS)](http://lincsproject.org), present this challenge with the goal of advancing drug development through improvements to MoA prediction algorithms.**What is the Mechanism of Action (MoA) of a drug? And why is it important?**   In the past, scientists derived drugs from natural products or were inspired by traditional remedies. Very common drugs, such as paracetamol, known in the US as acetaminophen, were put into clinical use decades before the biological mechanisms driving their pharmacological activities were understood. Today, with the advent of more powerful technologies, drug discovery has changed from the serendipitous approaches of the past to a more targeted model based on an understanding of the underlying biological mechanism of a disease. In this new framework, scientists seek to identify a protein target associated with a disease and develop a molecule that can modulate that protein target. As a shorthand to describe the biological activity of a given molecule, scientists assign a label referred to as mechanism-of-action or MoA for short.**How do we determine the MoAs of a new drug?**   One approach is to treat a sample of human cells with the drug and then analyze the cellular responses with algorithms that search for similarity to known patterns in large genomic databases, such as libraries of gene expression or cell viability patterns of drugs with known MoAs.In this competition, you will have access to a unique dataset that combines gene expression and cell viability data. The data is based on a new technology that measures simultaneously (within the same samples) human cells’ responses to drugs in a pool of 100 different cell types (thus solving the problem of identifying ex-ante, which cell types are better suited for a given drug). In addition, you will have access to MoA annotations for more than 5,000 drugs in this dataset.As is customary, the dataset has been split into testing and training subsets. Hence, your task is to use the training dataset to develop an algorithm that automatically labels each case in the test set as one or more MoA classes. Note that since drugs can have multiple MoA annotations, the task is formally a multi-label classification problem.    **How to evaluate the accuracy of a solution?**    Based on the MoA annotations, the accuracy of solutions will be evaluated on the average value of the [logarithmic  loss function](https://www.kaggle.com/c/lish-moa/overview/evaluation) applied to each drug-MoA annotation pair.If successful, you’ll help to develop an algorithm to predict a compound’s MoA given its cellular signature, thus helping scientists advance the drug discovery process.    > **This is a Code Competition. Refer to [Code Requirements](/c/lish-moa/overview/code-requirements) for details.**![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4688294%2Fa7c39a710116cc60ab0e0707020df4f5%2FUnknown-31?generation=1601643378654178&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4688294%2F7b66ae0c294d9ca67272209d4756e0e9%2Flogo_largetext_preview-4.png?generation=1601643409931253&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4688294%2F18004b33573a510867eac50ae6c68ec2%2FUnknown-32?generation=1601643476632984&alt=media)'}, {'title': \"Conway's Reverse Game of Life 2020\", 'url': 'https://www.kaggle.com/competitions/conways-reverse-game-of-life-2020', 'briefDescription': 'Reverse the arrow of time in the Game of Life', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/22122/logos/header.png?t=2020-08-31-19-59-27', 'tag': 'simulations, board games, custom metric', 'description': 'This is a relaunch of a previous competition, [Conway\\'s Reverse Game of Life](https://www.kaggle.com/c/conway-s-reverse-game-of-life/overview), with the following changes:1. The grid size is larger (25 vs. 25) and the grid wraps around from top to bottom and left to right2. Submissions are solved forward by the appropriate number of steps, so that _any_ correct starting solution will achieve a maximum score. This [article](http://jakevdp.github.io/blog/2013/08/07/conways-game-of-life/) contains the stepping function that is used for this competition.**Obligatory Disclaimer:** A lot has changed since the original competition was launched 6 years ago. With the change from \"exact starting point\" to  \"_any_ correct starting point\", it is possible to get a perfect score. We just don\\'t know how difficult that will be. Use it as a fun learning experience, _**and don\\'t spoil it for others by posting perfect solutions!**_~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~The Game of Life is a cellular automaton created by mathematician John Conway in 1970. The game consists of a board of cells that are either on or off. One creates an initial configuration of these on/off states and observes how it evolves. There are four simple rules to determine the next state of the game board, given the current state:- **Overpopulation:** if a living cell is surrounded by more than three living cells, it dies.- **Stasis:** if a living cell is surrounded by two or three living cells, it survives.- **Underpopulation:** if a living cell is surrounded by fewer than two living cells, it dies.- **Reproduction:** if a dead cell is surrounded by exactly three cells, it becomes a live cell.These simple rules result in many interesting behaviors and have been the focus of a large body of mathematics. As [Wikipedia](http://en.wikipedia.org/wiki/Conway\\'s_Game_of_Life) states```Ever since its publication, Conway\\'s Game of Life has attracted much interest, because of the surprising ways in which the patterns can evolve. Life provides an example of emergence and self-organization. It is interesting for computer scientists, physicists, biologists, biochemists, economists, mathematicians, philosophers, generative scientists and others to observe the way that complex patterns can emerge from the implementation of very simple rules. The game can also serve as a didactic analogy, used to convey the somewhat counter-intuitive notion that \"design\" and \"organization\" can spontaneously emerge in the absence of a designer. For example, philosopher and cognitive scientist Daniel Dennett has used the analogue of Conway\\'s Life \"universe\" extensively to illustrate the possible evolution of complex philosophical constructs, such as consciousness and free will, from the relatively simple set of deterministic physical laws governing our own universe.```The emergence of order from simple rules begs an interesting question—_what happens if we set time backwards?_This competition is an experiment to see if machine learning (or optimization, or any method) can predict the game of life in reverse. Is the chaotic start of Life predictable from its orderly ends? We have created many games, evolved them, and provided only the end boards. You are asked to predict the starting board that resulted in each end board.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/conways-reverse-game-of-life-2020/overview/code-requirements) for details.**'}, {'title': 'I’m Something of a Painter Myself', 'url': 'https://www.kaggle.com/competitions/gan-getting-started', 'briefDescription': 'Use GANs to create art - will you be the next Monet?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/21755/logos/header.png?t=2020-08-26-18-44-58', 'tag': 'image, gan, custom metric', 'description': \">*“Every artist dips his brush in his own soul, and paints his own nature into his pictures.”*-Henry Ward Beecher We recognize the works of artists through their unique style, such as color choices or brush strokes. The “je ne sais quoi” of artists like Claude Monet can now be imitated with algorithms thanks to generative adversarial networks (GANs). In this getting started competition, you will bring that style to your photos or recreate the style from scratch! Computer vision has advanced tremendously in recent years and GANs are now capable of mimicking objects in a very convincing way.  But creating museum-worthy masterpieces is thought of to be, well, more art than science. So can (data) science, in the form of GANs, trick classifiers into believing you’ve created a true Monet? That’s the challenge you’ll take on!## The Challenge: A GAN consists of at least two neural networks: a generator model and a discriminator model. The generator is a neural network that creates the images. For our competition, you should generate images in the style of Monet. This generator is trained using a discriminator. The two models will work against each other, with the generator trying to trick the discriminator, and the discriminator trying to accurately classify the real vs. generated images. Your task is to build a GAN that generates 7,000 to 10,000 Monet-style images. ## Getting Started: Details on the dataset can be found [here](https://www.kaggle.com/c/gan-getting-started/data) and an overview of the evaluation process can be found [here](https://www.kaggle.com/c/gan-getting-started/overview/evaluation). To learn how to submit and answers to other FAQs, review the [Frequently Asked Questions](https://www.kaggle.com/c/gan-getting-started/overview/frequently-asked-questions). Recommended TutorialWe highly recommend Amy Jang's notebook  that goes over the basics of loading data from TFRecords, using TPUs, and building a CycleGAN.Although the competition dataset only includes Monet images, check out this [dataset](https://github.com/junyanz/CycleGAN) for Cezanne, Ukiyo-e, and Van Gogh paintings to run your GAN on.\"}, {'title': 'Lyft Motion Prediction for Autonomous Vehicles', 'url': 'https://www.kaggle.com/competitions/lyft-motion-prediction-autonomous-vehicles', 'briefDescription': 'Build motion prediction models for self-driving vehicles ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19990/logos/header.png?t=2020-08-17-20-10-07', 'tag': 'tabular, image, automobiles and vehicles, transportation, custom metric', 'description': \"Autonomous vehicles (AVs) are expected to dramatically redefine the future of transportation. However, there are still significant engineering challenges to be solved before one can fully realize the benefits of self-driving cars. One such challenge is building models that reliably predict the movement of traffic agents around the AV, such as cars, cyclists, and pedestrians.  The ridesharing company Lyft started [Level 5](https://level5.lyft.com/) to take on the self-driving challenge and build a full self-driving system ([they’re hiring!](https://www.lyft.com/careers?category=autonomous%2520vehicles)). Their [previous competition](http://kaggle.com/c/3d-object-detection-for-autonomous-vehicles/) tasked participants with identifying 3D objects, an important step prior to detecting their movement. Now, they’re challenging you to predict the motion of these traffic agents.  In this competition, you’ll apply your data science skills to build motion prediction models for self-driving vehicles. You'll have access to the largest [Prediction Dataset](https://self-driving.lyft.com/level5/prediction/) ever released to train and test your models. Your knowledge of machine learning will then be required to predict how cars, cyclists,and pedestrians move in the AV's environment.  Lyft’s mission is to improve people’s lives with the world’s best transportation. They believe in a future where self-driving cars make transportation safer, environment-friendly and more accessible for everyone. Their goal is to accelerate development across the industry by sharing data with researchers. As a result of your participation, you can have a hand in propelling the industry forward and helping people around the world benefit from self-driving cars sooner.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles/overview/code-requirements) for details.**\"}, {'title': 'Contradictory, My Dear Watson', 'url': 'https://www.kaggle.com/competitions/contradictory-my-dear-watson', 'briefDescription': 'Detecting contradiction and entailment in multilingual text using TPUs', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/21733/logos/header.png?t=2020-07-29-20-44-13', 'tag': 'nlp, text, multiclass classification, categorizationaccuracy', 'description': '> *\"...when you have eliminated the impossible,whatever remains, however improbable, must be the truth\"*-Sir Arthur Conan DoyleOur brains process the meaning of a sentence like this rather quickly. We\\'re able to surmise:- Some things to be true: \"You can find the right answer through the process of elimination.”- Others that may have truth: \"Ideas that are improbable are not impossible!\"- And some claims are clearly contradictory: \"Things that you have ruled out as impossible are where the truth lies.\"Natural language processing (NLP) has grown increasingly elaborate over the past few years. Machine learning models tackle question answering, text extraction, sentence generation, and many other complex tasks. But, can machines determine the relationships between sentences, or is that still left to humans? If NLP can be applied between sentences, this could have profound implications for fact-checking, identifying fake news, analyzing text, and much more. ## The Challenge:If you have two sentences, there are three ways they could be related: one could entail the other, one could contradict the other, or they could be unrelated. Natural Language Inferencing (NLI) is a popular NLP problem that involves determining how pairs of sentences (consisting of a premise and a hypothesis) are related. Your task is to create an NLI model that assigns labels of 0, 1, or 2 (corresponding to entailment, neutral, and contradiction) to pairs of premises and hypotheses. To make things more interesting, the train and test set include text in fifteen different languages! You can find more details on the dataset by reviewing the [Data page](https://www.kaggle.com/c/contradictory-my-dear-watson/data).Today, the most common approaches to NLI problems include using embeddings and transformers like BERT. In this competition, we’re providing [a starter notebook](https://www.kaggle.com/anasofiauzsoy/tutorial-notebook) to try your hand at this problem using the power of Tensor Processing Units (TPUs). TPUs are powerful hardware accelerators specialized in deep learning tasks, including Natural Language Processing. Kaggle provides all users TPU Quota at no cost, which you can use to explore this competition. Check out our [TPU documentation](https://www.kaggle.com/docs/tpu) and [Kaggle’s YouTube playlist](https://www.youtube.com/playlist?list=PLqFaTIg4myu-1c3ygYzakW8-hNzQG59-5) for more information and resources.Recommended TutorialWe highly recommend Ana Sofia Uzsoy’s Tutorial that walks you through creating your very first submission step by step with TPUs and BERT.This is a great opportunity to flex your NLP muscles and solve an exciting problem!*Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.*'}, {'title': 'Google Landmark Recognition 2020', 'url': 'https://www.kaggle.com/competitions/landmark-recognition-2020', 'briefDescription': 'Label famous (and not-so-famous) landmarks in images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19231/logos/header.png?t=2020-07-23-22-48-06', 'tag': 'image, computer vision, custom metric', 'description': \"Welcome to the third Landmark Recognition competition! This year, we have worked to set this up as a code competition and collected a new set of test images.Have you ever gone through your vacation photos and asked yourself: *What was the name of that temple I visited in China?* or *Who created this monument I saw in France?* Landmark recognition can help! This technology can predict landmark labels directly from image pixels, to help people better understand and organize their photo collections. This competition challenges Kagglers to build models that recognize the correct landmark (if any) in a dataset of challenging test images.Many Kagglers are familiar with image classification challenges like the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), which aims to recognize 1K general object categories. Landmark recognition is a little different from that: it contains a much larger number of classes (there are more than 81K classes in this challenge), and the number of training examples per class may not be very large. Landmark recognition is challenging in its own way.In the previous editions of this challenge ([2018](https://www.kaggle.com/c/landmark-recognition-challenge) and  [2019](https://www.kaggle.com/c/landmark-recognition-2019)), submissions were handled by uploading prediction files to the system. This year's competition is structured in a synchronous rerun format, where participants need to submit their Kaggle notebooks for scoring.This challenge is organized in conjunction with the [Landmark Retrieval Challenge 2020](https://www.kaggle.com/c/landmark-retrieval-2020), which was launched June 30, 2020. Both challenges are affiliated with the [Instance-Level Recognition workshop](https://ilr-workshop.github.io/ECCVW2020/) in ECCV’20.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/landmark-recognition-2020/overview/code-requirements) for details.**\"}, {'title': 'OSIC Pulmonary Fibrosis Progression', 'url': 'https://www.kaggle.com/competitions/osic-pulmonary-fibrosis-progression', 'briefDescription': 'Predict lung function decline', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/20604/logos/header.png?t=2020-05-06-19-02-45', 'tag': 'image, healthcare, laplaceloglikelihood', 'description': 'Imagine one day, your breathing became consistently labored and shallow. Months later you were finally diagnosed with pulmonary fibrosis, a disorder with no known cause and no known cure, created by scarring of the lungs. If that happened to you, you would want to know your prognosis. That’s where a troubling disease becomes frightening for the patient: outcomes can range from long-term stability to rapid deterioration, but doctors aren’t easily able to tell where an individual may fall on that spectrum. Your help, and data science, may be able to aid in this prediction, which would dramatically help both patients and clinicians.Current methods make fibrotic lung diseases difficult to treat, even with access to a chest CT scan. In addition, the wide range of varied prognoses create issues organizing clinical trials. Finally, patients suffer extreme anxiety—in addition to fibrosis-related symptoms—from the disease’s opaque path of progression.Open Source Imaging Consortium (OSIC) is a not-for-profit, co-operative effort between academia, industry and philanthropy. The group enables rapid advances in the fight against Idiopathic Pulmonary Fibrosis (IPF), fibrosing interstitial lung diseases (ILDs), and other respiratory diseases, including emphysematous conditions. Its mission is to bring together radiologists, clinicians and computational scientists from around the world to improve imaging-based treatments.In this competition, you’ll predict a patient’s severity of decline in lung function based on a CT scan of their lungs. You’ll determine lung function based on output from a spirometer, which measures the volume of air inhaled and exhaled. The challenge is to use machine learning techniques to make a prediction with the image, metadata, and baseline FVC as input.If successful, patients and their families would better understand their prognosis when they are first diagnosed with this incurable lung disease. Improved severity detection would also positively impact treatment trial design and accelerate the clinical development of novel treatments.This is a Code Competition. Refer to Code Requirements for details.'}, {'title': 'Google Landmark Retrieval 2020', 'url': 'https://www.kaggle.com/competitions/landmark-retrieval-2020', 'briefDescription': 'Given an image, can you find all of the same landmarks in a dataset?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19233/logos/header.png?t=2020-06-24-19-50-33', 'tag': 'image, computer vision, custom metric', 'description': \"Welcome to the third Landmark Retrieval competition! This year, we have worked to set this up as a code competition and we have completely refreshed the test and index image sets. Image retrieval is a fundamental problem in computer vision: given a query image, can you find similar images in a large database? This is especially important for query images containing landmarks, which accounts for a large portion of what people like to photograph.In this competition, the developed models are expected to retrieve relevant database images to a given query image (ie, the model should retrieve database images containing the same landmark as the query). This challenge is organized in conjunction with the [Landmark Recognition Challenge 2020](https://kaggle.com/c/landmark-recognition-2020). Both challenges will be discussed at the [Instance-Level Recognition workshop](https://ilr-workshop.github.io/ECCVW2020/) in ECCV’20.In the previous editions of this challenge ([2018](https://www.kaggle.com/c/landmark-retrieval-challenge) and  [2019](https://www.kaggle.com/c/landmark-retrieval-2019)), submissions were handled by uploading prediction files to the system. This year's competition is structured in a representation learning format: rather than creating a submission file with retrieved images, you will create a model that extracts a feature embedding for the images and submit the model via Kaggle Notebooks. Kaggle will run your model on a held-out test set, perform a k-nearest-neighbors lookup, and score the resulting embedding quality with mean average precision.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/landmark-retrieval-2020/overview/code-requirements) for details.**\"}, {'title': 'Petals to the Metal - Flower Classification on TPU', 'url': 'https://www.kaggle.com/competitions/tpu-getting-started', 'briefDescription': 'Getting Started with TPUs on Kaggle!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/21154/logos/header.png?t=2020-06-04-00-33-35', 'tag': 'image, multiclass classification, macrofscore', 'description': 'Learn how to use Tensor Processing Units (TPUs) on KaggleTPUs are powerful hardware accelerators specialized in deep learning tasks. They were developed (and first used) by Google to process large image databases, such as extracting all the text from Street View. This competition is designed for you to give TPUs a try.TPU quotas are available on Kaggle at no cost to users.Watch the video below to see how to get started!  You can follow along with this notebook.The ChallengeIt’s difficult to fathom just how vast and diverse our natural world is.There are over 5,000 species of mammals, 10,000 species of birds, 30,000 species of fish – and astonishingly, over 400,000 different types of flowers.In this competition, you’re challenged to build a machine learning model that identifies the type of flowers in a dataset of images (for simplicity, we’re sticking to just over 100 types).Recommended TutorialWe highly recommend Ryan Holbrook’s Tutorial that walks you through making your very first submission step by step.Have Questions?Kaggle Data Scientists will be actively monitoring the competition forum - your fellow data scientists and TPU users will be there too! If you have a question or need help troubleshooting, that’s the best place to find help.Learn MoreCheck out  Kaggle’s Youtube playlist for more videos introducing TPUs.Read the TPU documentation for more information and resources.Many thanks to Martin Görner, Google Developer Advocate and author of Tensorflow without a PhD for his tireless work on the dataset, the notebooks, and the original competition that this Getting Started competition draws from.'}, {'title': 'Cornell Birdcall Identification', 'url': 'https://www.kaggle.com/competitions/birdsong-recognition', 'briefDescription': 'Build tools for bird population monitoring', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19596/logos/header.png?t=2020-05-29-00-25-08', 'tag': 'audio, meanfscorebeta', 'description': 'Do you hear the birds chirping outside your window? Over 10,000 bird species occur in the world, and they can be found in nearly every environment, from untouched rainforests to suburbs and even cities. Birds play an essential role in nature. They are high up in the food chain and integrate changes occurring at lower levels. As such, birds are excellent indicators of deteriorating habitat quality and environmental pollution. However, it is often easier to hear birds than see them. With proper sound detection and classification, researchers could automatically intuit factors about an area’s quality of life based on a changing bird population.There are already many projects underway to extensively monitor birds by continuously recording natural soundscapes over long periods. However, as many living and nonliving things make noise, the analysis of these datasets is often done manually by domain experts. These analyses are painstakingly slow, and results are often incomplete. Data science may be able to assist, so researchers have turned to large crowdsourced databases of focal recordings of birds to train AI models. Unfortunately, there is a domain mismatch between the training data (short recording of individual birds) and the soundscape recordings (long recordings with often multiple species calling at the same time) used in monitoring applications. This is one of the reasons why the performance of the currently used AI models has been subpar. To unlock the full potential of these extensive and information-rich sound archives, researchers need good machine listeners to reliably extract as much information as possible to aid data-driven conservation.The [Cornell Lab of Ornithology’s Center for Conservation Bioacoustics](https://www.birds.cornell.edu/ccb/) (CCB)’s mission is to collect and interpret sounds in nature. The CCB develops innovative conservation technologies to inspire and inform the conservation of wildlife and habitats globally. By partnering with the data science community, the CCB hopes to further its mission and improve the accuracy of soundscape analyses.In this competition, you will identify a wide variety of bird vocalizations in soundscape recordings. Due to the complexity of the recordings, they contain weak labels. There might be anthropogenic sounds (e.g., airplane overflights) or other bird and non-bird (e.g., chipmunk) calls in the background, with a particular labeled bird species in the foreground. Bring your new ideas to build effective detectors and classifiers for analyzing complex soundscape recordings!If successful, your work will help researchers better understand changes in habitat quality, levels of pollution, and the effectiveness of restoration efforts. Reliable machine listeners would also allow conservationists to deploy more recording units worldwide and would enable data-driven conservation at a scale not yet possible. The eventual conservation outcomes could greatly improve the quality of life for many living organisms—birds and human beings included.'}, {'title': 'Halite by Two Sigma', 'url': 'https://www.kaggle.com/competitions/halite', 'briefDescription': 'Collect the most halite during your match in space', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18011/logos/header.png?t=2019-12-20-19-33-21', 'tag': 'video games, simulations, custom metric', 'description': 'Ahoy there! There\\'s halite to be had and ships to be deployed! Are you ready to navigate the skies and secure your territory?Halite by [Two Sigma](https://www.twosigma.com/) (\"Halite\") is a resource management game where you build and control a small armada of ships. Your algorithms determine their movements to collect halite, a luminous energy source. The most halite at the end of the match wins, but it\\'s up to you to figure out how to make effective and efficient moves. You control your fleet, build new ships, create shipyards, and mine the regenerating halite on the game board.Created by Two Sigma in 2016, more than 15,000 people around the world have participated in a Halite challenge. Players apply advanced algorithms in a dynamic, open source game setting. The strategic depth and immersive, interactive nature of Halite games make each challenge a unique learning environment.Halite IV builds on the core game design of Halite III with a number of key changes that shift the focus of the game towards tighter competition on a smaller board. New game features include regenerating halite, shipyard creation, no more ship movement costs, and stealing halite from other players!So dust off your halite meters and fasten your seatbelts. The fourth season of Halite is about to begin!  '}, {'title': 'SIIM-ISIC Melanoma Classification', 'url': 'https://www.kaggle.com/competitions/siim-isic-melanoma-classification', 'briefDescription': 'Identify melanoma in lesion images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/20270/logos/header.png?t=2020-05-06-18-21-24', 'tag': 'image, mcauc', 'description': \"Skin cancer is the most prevalent type of cancer. Melanoma, specifically, is responsible for 75% of skin cancer deaths, despite being the least common skin cancer. The American Cancer Society estimates over 100,000 new melanoma cases will be diagnosed in 2020. It's also expected that almost 7,000 people will die from the disease. As with other cancers, early and accurate detection—potentially aided by data science—can make treatment more effective.Currently, dermatologists evaluate every one of a patient's moles to identify outlier lesions or “ugly ducklings” that are most likely to be melanoma. Existing AI approaches have not adequately considered this clinical frame of reference. Dermatologists could enhance their diagnostic accuracy if detection algorithms take into account “contextual” images within the same patient to determine which images represent a melanoma. If successful, classifiers would be more accurate and could better support dermatological clinic work.As the leading healthcare organization for informatics in medical imaging, the [Society for Imaging Informatics in Medicine (SIIM)](https://siim.org/)'s mission is to advance medical imaging informatics through education, research, and innovation in a multi-disciplinary community. SIIM is joined by the [International Skin Imaging Collaboration (ISIC)](https://www.isic-archive.com/), an international effort to improve melanoma diagnosis. The ISIC Archive contains the largest publicly available collection of quality-controlled dermoscopic images of skin lesions.In this competition, you’ll identify melanoma in images of skin lesions. In particular, you’ll use images within the same patient and determine which are likely to represent a melanoma. Using patient-level contextual information may help the development of image analysis tools, which could better support clinical dermatologists.Melanoma is a deadly disease, but if caught early, most melanomas can be cured with minor surgery. Image analysis tools that automate the diagnosis of melanoma will improve dermatologists' diagnostic accuracy. Better detection of melanoma has the opportunity to positively impact millions of people.\"}, {'title': 'TREC-COVID Information Retrieval', 'url': 'https://www.kaggle.com/competitions/trec-covid-information-retrieval', 'briefDescription': 'Build a pandemic document retrieval system', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/20829/logos/header.png?t=2020-05-19-03-00-05', 'tag': 'nlp, text, covid19, text mining, ndcg@{k}', 'description': '>  **LAUNCHED**This competition was launched and opened for submissions on May 27th 2020. Submissions will close in 1 week at 11:00 AM UTC on June 3rd 2020. The public leaderboard is based on the TREC-COVID Round 2 dataset. The private leaderboard will be based on the Round 3 dataset, which will be evaluated after the competition closes. Review the [Data page](https://www.kaggle.com/c/trec-covid-information-retrieval/data) for more details.Researchers, clinicians, and policy makers involved with the response to COVID-19 are constantly searching for reliable information on the virus and its impact. This presents a unique opportunity for the information retrieval (IR) and text processing communities to contribute to the response to this pandemic, as well as to study methods for quickly standing up information systems for similar future events. The results of the TREC-COVID Challenge will identify answers for some of today\\'s questions while building infrastructure to improve tomorrow\\'s search systems.Kaggle first teamed up with the Allen Institute for AI in the launch of the [COVID-19 Open Research Dataset (CORD-19)](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge). TREC-COVID builds on the CORD-19 Challenge by using the same document set, a collection of biomedical literature articles that has been updated on a weekly rolling basis. This is the **3rd Round of the TREC-COVID Challenge**. Prior runs were hosted directly on the [TREC-COVID Site](https://ir.nist.gov/covidSubmit/data.html). For this round, you have the option to submit on Kaggle or directly to the TREC-COVID platform. The organizers have added 5 additional COVID-related topics to the 35 topics from the first two rounds, for a total of 40 topics. You will create a retrieval system that returns ranked lists of documents from CORD-19 for (a) each of these additional Round 3 topics (\"runs\") and as well as (b) residual rankings on the completed Round 1 & 2 topics, i.e., for any documents not judged in the CORD-19 dataset (not previously included as a ranked document).  The eligible population of documents for Round 3 is anything included in the CORD-19 release up to Round 3\\'s launch date, last updated on May 19th 2020.Following the close of Round 3, NIST will gather the collective set of participants\\' runs, to include those participants submitting directly through TREC-COVID. The organizers will then assess some reasonable subset of these submissions for relevance by human annotators with biomedical expertise. The results of the human annotation, known as relevance judgments, will then be used to score the submitted runs. It is important to understand that not all documents will be assessed, and thus the private leaderboard score will be based on partial document assessment.With your help, the final document and topic sets together with the cumulative relevance judgments will comprise a COVID test collection. The incremental nature of the collection will support research on search systems for dynamic environments.### AcknowledgmentsThe [Text REtrieval Conference (TREC)](http://trec.nist.gov/) was founded in 1992 to support research within the information retrieval community by providing the infrastructure necessary for large-scale evaluation of text retrieval methodologies.The TREC-COVID Challenge is being organized by the [Allen Institute for Artificial Intelligence (AI2)](https://allenai.org/), the [National Institute of Standards and Technology (NIST)](http://nist.gov/), the [National Library of Medicine (NLM)](https://www.nlm.nih.gov/), [Oregon Health and Science University (OHSU)](http://ohsu.edu/informatics/), and the [University of Texas Health Science Center at Houston (UTHealth)](https://sbmi.uth.edu/).See the [NIST press release](https://www.nist.gov/news-events/news/2020/04/nist-and-ostp-launch-effort-improve-search-engines-covid-19-research) for more information.'}, {'title': 'Open Images Instance Segmentation RVC 2020 edition', 'url': 'https://www.kaggle.com/competitions/open-images-instance-segmentation-rvc-2020', 'briefDescription': 'Outline segmentation masks of objects in images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/20009/logos/header.png?t=2020-05-04-14-48-29', 'tag': 'image, custom metric', 'description': '#IntroductionComputer vision has advanced considerably but is still challenged in matching the precision of human perception.[Open Images](https://storage.googleapis.com/openimages/web/factsfigures.html) is a collaborative release of ~9 million images annotated with image-level labels, object bounding boxes, object segmentation masks, visual relationships, and localized narratives. This uniquely large and diverse dataset is designed to spur state of the art advances in analyzing and understanding images.This year the Open Images  Instance Segmentation competition is a part of the larger [Robust Vision Challenge 2020](http://www.robustvision.net). This challenge encourages the participants to develop robust computer vision algorithms able to perform well across multiple datasets. Please refer to the [RVC 2020 page](http://www.robustvision.net) and the [Open Images Challenge page](https://storage.googleapis.com/openimages/web/challenge_overview.html) for more details.![http://www.robustvision.net](http://www.robustvision.net/images/banner_rvc2020_loop.gif)Participants are also welcome to submit to this playground competition beyond the context of RVC.#Instance Segmentation TrackIn this track of the Challenge, you are asked **to provide segmentation masks of objects**.This track’s training set represents 2.1M segmentation masks for object instances in 300 categories; with a validation set containing an additional 23k masks. The train set masks were produced by our state-of-the-art [interactive segmentation process](https://arxiv.org/pdf/1903.10830.pdf), where professional human annotators iteratively correct the output of a segmentation neural network. The validation and test set masks have been annotated manually with a strong focus on quality. *Example train set annotations. Left: [Wuxi science park, 1995](https://www.flickr.com/photos/garysoup/3777131020) by [Gary Stevens](https://www.flickr.com/people/garysoup/). Right: [Cat Cafe Shinjuku calico](https://www.flickr.com/photos/picsoflife/6776736950) by [Ari Helminen](https://www.flickr.com/people/picsoflife/). Both images used under CC BY 2.0 license.*The training data, format, and submission modalities are identical to the [2019 Open Images Challenge](https://www.kaggle.com/c/open-images-2019-instance-segmentation/overview/).'}, {'title': 'Open Images Object Detection RVC 2020 edition', 'url': 'https://www.kaggle.com/competitions/open-images-object-detection-rvc-2020', 'briefDescription': 'Detect objects in varied and complex images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19205/logos/header.png?t=2020-05-04-14-48-59', 'tag': 'image, custom metric', 'description': '#IntroductionComputer vision has advanced considerably but is still challenged in matching the precision of human perception.[Open Images](https://storage.googleapis.com/openimages/web/factsfigures.html) is a collaborative release of ~9 million images annotated with image-level labels, object bounding boxes, object segmentation masks, visual relationships, and localized narratives. This uniquely large and diverse dataset is designed to spur state of the art advances in analyzing and understanding images.This year the Open Images Object Detection competition is a part of the larger [Robust Vision Challenge 2020](http://www.robustvision.net). This challenge encourages the participants to develop robust computer vision algorithms able to perform well across multiple datasets. Please refer to the [RVC 2020 page](http://www.robustvision.net) and the [Open Images Challenge page](https://storage.googleapis.com/openimages/web/challenge_overview.html) for more details.![http://www.robustvision.net](http://www.robustvision.net/images/banner_rvc2020_loop.gif)Participants are also welcome to submit to this playground competition beyond the context of RVC.#Object Detection TrackIn this track, you are asked **to predict a tight bounding box around object instances**.The training set contains 12.2M bounding-boxes across 500 categories on 1.7M images. The boxes have been largely manually drawn by professional annotators to ensure accuracy and consistency. The images are very diverse and often contain complex scenes with several objects (7 per image on average).![guitar](https://storage.googleapis.com/kaggle-media/competitions/open-images/guitarist.png) ![house](https://storage.googleapis.com/kaggle-media/competitions/open-images/table.png)*Example annotations. Left: [Mark Paul Gosselaar plays the guitar](https://www.flickr.com/photos/rhysasplundh/5738556102) by [Rhys A](https://www.flickr.com/people/rhysasplundh/). Right: [the house](https://www.flickr.com/photos/krakluski/2950388100) by [anita kluska](https://www.flickr.com/photos/krakluski/). Both images used under CC BY 2.0 license.*The training data, format, and submission modalities are identical to the [2019 Open Images Challenge](https://www.kaggle.com/c/open-images-2019-object-detection).'}, {'title': 'COVID19 Global Forecasting (Week 5)', 'url': 'https://www.kaggle.com/competitions/covid19-global-forecasting-week-5', 'briefDescription': 'Forecast daily COVID-19 spread in regions around world', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/20475/logos/header.png?t=2020-04-30-15-50-51', 'tag': 'tabular, covid19, weightedpinballloss', 'description': \"*This is week 5 of Kaggle's COVID-19 forecasting series, following the [Week 4 competition](https://www.kaggle.com/c/covid19-global-forecasting-week-4). This competition has some changes from prior weeks - be sure to check the [Evaluation](https://www.kaggle.com/c/covid19-global-forecasting-week-5/overview/evaluation) and [Data](https://www.kaggle.com/c/covid19-global-forecasting-week-5/data) pages for more details. All of the prior discussion forums have been migrated to this competition for continuity.*### BackgroundThe White House Office of Science and Technology Policy (OSTP) pulled together a coalition research groups and companies (including Kaggle)  to prepare the [COVID-19 Open Research Dataset (CORD-19)](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) to attempt to address [key open scientific questions on COVID-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks). Those questions are drawn from [National Academies of Sciences, Engineering, and Medicine’s (NASEM)](https://www.nationalacademies.org/event/03-11-2020/standing-committee-on-emerging-infectious-diseases-and-21st-century-health-threats-virtual-meeting-1) and the [World Health Organization (WHO)](https://www.who.int/blueprint/priority-diseases/key-action/Global_Research_Forum_FINAL_VERSION_for_web_14_feb_2020.pdf?ua=1).### The ChallengeKaggle is launching a companion COVID-19 forecasting challenges to help answer a [subset of the NASEM/WHO questions](https://www.kaggle.com/c/covid19-global-forecasting-week-4/overview/open-scientific-questions). While the challenge involves developing quantile estimates intervals for confirmed cases and fatalities between May 12 and June 7 by region, the primary goal **isn't only to produce accurate forecasts**. It’s also to identify factors that appear to impact the transmission rate of COVID-19.You are encouraged to pull in, curate and share data sources that might be helpful. If you find variables that look like they impact the transmission rate, please share your finding in a notebook. As the data becomes available, we will update the leaderboard with live results based on [data made available](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series) from the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE).We have received support and guidance from health and policy organizations in launching these challenges. We're hopeful the Kaggle community can make valuable contributions to developing a better understanding of factors that impact the transmission of COVID-19. ### Companies and Organizations**There is also a call to action for companies and other organizations:** If you have datasets that might be useful, please upload them to [Kaggle’s dataset platform](https://www.kaggle.com/datasets) and reference them in [this forum thread](https://www.kaggle.com/c/covid19-global-forecasting-week-4/discussion/137078). That will make them accessible to those participating in this challenge and a resource to the wider scientific community.### AcknowledgementsJHU CSSE for making the data available to the public. The White House OSTP for pulling together the key open questions. The image comes from the Center for Disease Control.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/covid19-global-forecasting-week-4/overview) for details.**\"}, {'title': 'Global Wheat Detection ', 'url': 'https://www.kaggle.com/competitions/global-wheat-detection', 'briefDescription': 'Can you help identify wheat heads using image analysis?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19989/logos/header.png?t=2020-04-20-18-13-31', 'tag': 'image, plants, custom metric', 'description': 'Open up your pantry and you’re likely to find several wheat products. Indeed, your morning toast or cereal may rely upon this common grain. Its popularity as a food and crop makes wheat widely studied. To get large and accurate data about wheat fields worldwide, plant scientists use image detection of \"wheat heads\"—spikes atop the plant containing grain. These images are used to estimate the density and size of wheat heads in different varieties. Farmers can use the data to assess health and maturity when making management decisions in their fields.However, accurate wheat head detection in outdoor field images can be visually challenging. There is often overlap of dense wheat plants, and the wind can blur the photographs. Both make it difficult to identify single heads. Additionally, appearances vary due to maturity, color, genotype, and head orientation. Finally, because wheat is grown worldwide, different varieties, planting densities, patterns, and field conditions must be considered. Models developed for wheat phenotyping need to generalize between different growing environments. Current detection methods involve one- and two-stage detectors (Yolo-V3 and Faster-RCNN), but even when trained with a large dataset, a bias to the training region remains.The [Global Wheat Head Dataset](http://www.global-wheat.com/2020-challenge/) is led by nine research institutes from seven countries: the University of Tokyo, Institut national de recherche pour l’agriculture, l’alimentation et l’environnement, Arvalis, ETHZ, University of Saskatchewan, University of Queensland, Nanjing Agricultural University, and Rothamsted Research. These institutions are joined by many in their pursuit of accurate wheat head detection, including the Global Institute for Food Security, DigitAg, Kubota, and Hiphen.In this competition, you’ll detect wheat heads from outdoor images of wheat plants, including wheat datasets from around the globe. Using worldwide data, you will focus on a generalized solution to estimate the number and size of wheat heads. To better gauge the performance for unseen genotypes, environments, and observational conditions, the training dataset covers multiple regions. You will use more than 3,000 images from Europe (France, UK, Switzerland) and North America (Canada). The test data includes about 1,000 images from Australia, Japan, and China.Wheat is a staple across the globe, which is why this competition must account for different growing conditions. Models developed for wheat phenotyping need to be able to generalize between environments. If successful, researchers can accurately estimate the density and size of wheat heads in different varieties. With improved detection farmers can better assess their crops, ultimately bringing cereal, toast, and other favorite dishes to your table.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/global-wheat-classification#Code-Requirements) for details.**'}, {'title': 'ALASKA2 Image Steganalysis', 'url': 'https://www.kaggle.com/competitions/alaska2-image-steganalysis', 'briefDescription': 'Detect secret data hidden within digital images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19991/logos/header.png?t=2020-04-15-14-49-42', 'tag': 'custom metric', 'description': 'That file you downloaded may contain hidden messages that aren’t part of its regular contents. The same technology employed for digital watermarking is also misused by crime rings. Law enforcement must now use steganalysis to detect these messages as part of their investigations. Machine learning is an important tool in the discovery of this secret data.Current methods produce unreliable results, raising false alarms. One reason for inaccuracy is the many different devices and processing combinations. Yet, detection models are trained on a homogeneous dataset. To increase accuracy, researchers must put data hidden within digital images “into the wild” (hence the name ALASKA) to mimic real world conditions.In the competition, you’ll create an efficient and reliable method to detect secret data hidden within innocuous-seeming digital images. Rather than limiting the data source, these images have been acquired with as many as 50 different cameras (from smartphone to full-format high end) and processed in different fashions. Successful entries will include robust detection algorithms with minimal false positives.The IEEE WIFS (Workshop on Information Forensics and Security) is eager to make this happen again, as a follow up to the ALASKA#1 Challenge. WIFS is an annual event where researchers gather to discuss emerging challenges, exchange fresh ideas, and share state-of-the-art results and technical expertise in the areas of information security and forensics. WIFS has teamed up with Troyes University of Technology, CRIStAL Lab, Lille University, and CNRS to enable more accurate steganalysis. Law enforcement officers need better methods to combat criminals using hidden messages. The data science community and other researchers can help with better automated detection. More accurate methods could help catch criminals whose communications are hidden in plain sight. The challenge is organized by Rémi COGRANNE (UTT), Patrick BAS (CRIStAL / CNRS) and Quentin Giboulot (UTT) ; in addition to Kaggle, we have been greatly helped by the following sponsors:![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1951250%2F3a24a302d6a43d42087769d57048b566%2Flogo_UTT_CRIStAL.png?generation=1588208625932740&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1951250%2Fa5c6f8c179e51a4048b581191166425d%2FLogoCNRS_SPS.png?generation=1588208648755636&alt=media)'}, {'title': 'Hash Code Archive - Photo Slideshow Optimization', 'url': 'https://www.kaggle.com/competitions/hashcode-photo-slideshow', 'briefDescription': 'Optimizing a photo album from Hash Code 2019', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18685/logos/header.png?t=2020-04-24-16-15-10', 'tag': 'internet, optimization, custom metric', 'description': 'Note: Put your heads together to solve programming challenges. Google\\'s coding competition, [Hash Code](https://codingcompetitions.withgoogle.com/hashcode), has just finished for 2020. Use this online qualifier from 2019 to keep your skills sharp for future competitions!As the saying goes, \"a picture is worth a thousand words.\"  We agree – photos are an important part of contemporary digital and cultural life. How we experience photos largely depends on the story they’re arranged to tell. The same shots could be a monotonous series of snaps or form a narrative masterpiece.Approximately 2.5 billion people around the world carry a camera – in the form of a smartphone – in their pocket every day. We tend to make good use of it, too, taking more photos than ever (back in 2017, Google Photos announced it was backing up more than 1.2 billion photos and videos per day)! The rise of digital photography creates an interesting challenge: what should we do with all of these photos? In this competition, you will compose a slideshow out of a photo collection.Given a list of photos and the tags associated with each photo, you are challenged to arrange the photos into a slideshow that is as interesting as possible (the [evaluation](https://www.kaggle.com/c/hashcode-photo-slideshow/overview/evaluation) section explains what we mean by “interesting”)Will your slideshow tell a good story or be a major snoozefest?'}, {'title': 'TReNDS Neuroimaging', 'url': 'https://www.kaggle.com/competitions/trends-assessment-prediction', 'briefDescription': 'Multiscanner normative age and assessments prediction with brain function, structure, and connectivity', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/16245/logos/header.png?t=2019-10-28-01-13-44', 'tag': 'computer vision, neuroscience, wmae', 'description': 'Human brain research is among the most complex areas of study for scientists. We know that age and other factors can affect its function and structure, but more research is needed into what specifically occurs within the brain. With much of the research using MRI scans, data scientists are well positioned to support future insights. In particular, neuroimaging specialists look for measurable markers of behavior, health, or disorder to help identify relevant brain regions and their contribution to typical or symptomatic effects.In this competition, you will predict multiple assessments plus age from multimodal brain MRI features. You will be working from existing results from other data scientists, doing the important work of validating the utility of multimodal features in a normative population of unaffected subjects. Due to the complexity of the brain and differences between scanners, generalized approaches will be essential to effectively propel multimodal neuroimaging research forward.The Tri-Institutional Georgia State University/Georgia Institute of Technology/Emory University [Center for Translational Research in Neuroimaging and Data Science (TReNDS)](http://trendscenter.org/) leverages advanced brain imaging to promote research into brain health. The organization is focused on developing, applying and sharing advanced analytic approaches and neuroinformatics tools. Among its [software projects](http://trendscenter.org/software/) are the GIFT and FIT neuroimaging toolboxes, the COINS data management system, and the COINSTAC toolkit for federated learning, all aimed at supporting data scientists and other neuroimaging researchers.Making the leap from research to clinical application is particularly difficult in brain health. In order to translate to clinical settings, research findings have to be reproduced consistently and validated in out-of-sample instances. The problem is particularly well-suited for data science, but current approaches typically do not generalize well. With this large dataset and competition, your efforts could directly address an important area of brain research.**Acknowledgments**![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1095143%2Faa4d99443bbf16acc44c5b66bd362c2a%2FOfHBM.png?generation=1587603203346450&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1095143%2F08d4f3ea426afd2fc2a370a294eaffe4%2FIEEE.png?generation=1587603262596610&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1095143%2F47c74960e6540f11287e1e271438e029%2FTReNDS.png?generation=1587603283379241&alt=media)'}, {'title': 'Prostate cANcer graDe Assessment (PANDA) Challenge', 'url': 'https://www.kaggle.com/competitions/prostate-cancer-grade-assessment', 'briefDescription': 'Prostate cancer diagnosis using the Gleason grading system', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18647/logos/header.png?t=2020-04-10-17-14-59', 'tag': 'image, medicine, quadraticweightedkappa', 'description': \"With more than 1 million new diagnoses reported every year, prostate cancer (PCa) is the second most common cancer among males worldwide that results in more than 350,000 deaths annually. The key to decreasing mortality is developing more precise diagnostics. Diagnosis of PCa is based on the grading of prostate tissue biopsies. These tissue samples are examined by a pathologist and scored according to the Gleason grading system. In this challenge, you will develop models for detecting PCa on images of prostate tissue samples, and estimate severity of the disease using the most extensive multi-center dataset on Gleason grading yet available.The grading process consists of finding and classifying cancer tissue into so-called Gleason patterns (3, 4, or 5) based on the architectural growth patterns of the tumor (Fig. 1). After the biopsy is assigned a Gleason score, it is converted into an ISUP grade on a 1-5 scale. The Gleason grading system is the most important prognostic marker for PCa, and the ISUP grade has a crucial role when deciding how a patient should be treated. There is both a risk of missing cancers and a large risk of overgrading resulting in unnecessary treatment. However, the system suffers from significant inter-observer variability between pathologists, limiting its usefulness for individual patients. This variability in ratings could lead to unnecessary treatment, or worse, missing a severe diagnosis. Automated deep learning systems have shown some promise in accurately grading PCa. Recent research, including two studies independently conducted by the groups hosting this challenge, have shown that these systems can achieve pathologist-level performance. However, these systems/results were not tested with multi-center datasets at scale.    Your work here will improve on these efforts using the most extensive multi-center dataset on Gleason grading yet. The training set consists of around 11,000 whole-slide images of digitized H&E-stained biopsies originating from two centers. This is the largest public whole-slide image dataset available, roughly 8 times the size of the [CAMELYON17](https://camelyon17.grand-challenge.org/) challenge, one of the largest digital pathology datasets and best known challenges in the field. Furthermore, in contrast to previous challenges, we are making full diagnostic biopsy images available. Using a sizable multi-center test set, graded by expert uro-pathologists, we will evaluate challenge submissions on their applicability to improve this critical diagnostic function.   **Figure 1**: An illustration of the Gleason grading process for an example biopsy containing prostate cancer. The most common (blue outline, Gleason pattern 3) and second most common (red outline, Gleason pattern 4) cancer growth patterns present in the biopsy dictate the Gleason score (3+4 for this biopsy), which in turn is converted into an ISUP grade (2 for this biopsy) following guidelines of the International Society of Urological Pathology. Biopsies not containing cancer are represented by an ISUP grade of 0 in this challenge.**[Radboud University Medical Center](https://www.radboudumc.nl/en/research)** and **[Karolinska Institute](https://ki.se/en/meb)** have teamed up to organize this competition in collaboration with colleagues from Tampere University. The [Computational Pathology Group (CPG)](https://www.computationalpathologygroup.eu/) of the Radboud University Medical Center is a research group that develops computer algorithms to aid clinicians. Karolinska Institute’s Department of Medical Epidemiology and Biostatistics (MEB) includes an interdisciplinary research group to improve the diagnostics and treatment of prostate cancer. Together, they hope to further their existing research to make a significant impact on the healthcare of prostate cancer patients.Challenge organizer team: Wouter Bulten, Geert Litjens, Hans Pinckaers, Peter Ström, Martin Eklund, Lars Egevad, Henrik Grönberg, Kimmo Kartasalo, Pekka Ruusuvuori, Tomi Häkkinen, Sohier Dane, Maggie Demkin.   ###Sponsors   The PANDA workshop at MICCAI 2020 is sponsored by ContextVision, Ibex and Google.   ###Published resultsThe paper on the PANDA challenge has been published as Open Access in Nature Medicine. In the paper, we took a deep dive into the solutions, tested the methods to see if they generalize well to unseen data, and performed a comparison with pathologists. You can read the full paper and all results here:https://www.nature.com/articles/s41591-021-01620-2    Bulten, W., Kartasalo, K., Chen, PH.C. et al. Artificial intelligence for diagnosis and Gleason grading of prostate cancer: the PANDA challenge. Nat Med (2022). https://doi.org/10.1038/s41591-021-01620-2###Using the data outside of the competitionWith the paper's publication, the embargo on the data is now lifted (see [forum post](https://www.kaggle.com/competitions/prostate-cancer-grade-assessment/discussion/300840)). If you want, you can now use the dataset for further scientific work and publish your results on the dataset. If you do so, please take the license (CC BY-SA-NC 4.0) into account (non-commercial) and make sure you cite the PANDA paper. The test sets will not be made public at this time, to allow further late submissions to be used for benchmarking algorithms. We are looking forward to seeing new scientific projects coming out of this dataset! \"}, {'title': 'COVID19 Global Forecasting (Week 4)', 'url': 'https://www.kaggle.com/competitions/covid19-global-forecasting-week-4', 'briefDescription': 'Forecast daily COVID-19 spread in regions around world', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/20010/logos/header.png?t=2020-04-08-20-08-54', 'tag': 'tabular, covid19, mcrmsle', 'description': \"*This is week 4 of Kaggle's COVID-19 forecasting series, following the [Week 3 competition](https://www.kaggle.com/c/covid19-global-forecasting-week-3). This is the 4th competition we've launched in this series. All of the prior discussion forums have been migrated to this competition for continuity.*### BackgroundThe White House Office of Science and Technology Policy (OSTP) pulled together a coalition research groups and companies (including Kaggle)  to prepare the [COVID-19 Open Research Dataset (CORD-19)](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) to attempt to address [key open scientific questions on COVID-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks). Those questions are drawn from [National Academies of Sciences, Engineering, and Medicine’s (NASEM)](https://www.nationalacademies.org/event/03-11-2020/standing-committee-on-emerging-infectious-diseases-and-21st-century-health-threats-virtual-meeting-1) and the [World Health Organization (WHO)](https://www.who.int/blueprint/priority-diseases/key-action/Global_Research_Forum_FINAL_VERSION_for_web_14_feb_2020.pdf?ua=1).### The ChallengeKaggle is launching a companion COVID-19 forecasting challenges to help answer a [subset of the NASEM/WHO questions](https://www.kaggle.com/c/covid19-global-forecasting-week-4/overview/open-scientific-questions). While the challenge involves forecasting confirmed cases and fatalities between April 15 and May 14 by region, the primary goal **isn't only to produce accurate forecasts**. It’s also to identify factors that appear to impact the transmission rate of COVID-19.You are encouraged to pull in, curate and share data sources that might be helpful. If you find variables that look like they impact the transmission rate, please share your finding in a notebook. As the data becomes available, we will update the leaderboard with live results based on [data made available](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series) from the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE).We have received support and guidance from health and policy organizations in launching these challenges. We're hopeful the Kaggle community can make valuable contributions to developing a better understanding of factors that impact the transmission of COVID-19. ### Companies and Organizations**There is also a call to action for companies and other organizations:** If you have datasets that might be useful, please upload them to [Kaggle’s dataset platform](https://www.kaggle.com/datasets) and reference them in [this forum thread](https://www.kaggle.com/c/covid19-global-forecasting-week-4/discussion/137078). That will make them accessible to those participating in this challenge and a resource to the wider scientific community.### AcknowledgementsJHU CSSE for making the data available to the public. The White House OSTP for pulling together the key open questions. The image comes from the Center for Disease Control.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/covid19-global-forecasting-week-4/overview) for details.**\"}, {'title': 'COVID19 Global Forecasting (Week 3)', 'url': 'https://www.kaggle.com/competitions/covid19-global-forecasting-week-3', 'briefDescription': 'Forecast daily COVID-19 spread in regions around world', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19853/logos/header.png?t=2020-04-01-21-45-38', 'tag': 'tabular, covid19, mcrmsle', 'description': \"**[This week 3 forecasting task is now closed for submissions. Click here to visit the week 4 version, and make a submission there.](https://www.kaggle.com/c/covid19-global-forecasting-week-4)***This is week 3 of Kaggle's COVID19 forecasting series, following the [Week 2 competition](https://www.kaggle.com/c/covid19-global-forecasting-week-2). This is the 3rd of at least 4 competitions we plan to launch in this series. All of the prior discussion forums have been migrated to this competition for continuity.*### BackgroundThe White House Office of Science and Technology Policy (OSTP) pulled together a coalition research groups and companies (including Kaggle)  to prepare the [COVID-19 Open Research Dataset (CORD-19)](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) to attempt to address [key open scientific questions on COVID-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks). Those questions are drawn from [National Academies of Sciences, Engineering, and Medicine’s (NASEM)](https://www.nationalacademies.org/event/03-11-2020/standing-committee-on-emerging-infectious-diseases-and-21st-century-health-threats-virtual-meeting-1) and the [World Health Organization (WHO)](https://www.who.int/blueprint/priority-diseases/key-action/Global_Research_Forum_FINAL_VERSION_for_web_14_feb_2020.pdf?ua=1).### The ChallengeKaggle is launching a companion COVID-19 forecasting challenges to help answer a [subset of the NASEM/WHO questions](https://www.kaggle.com/c/covid19-global-forecasting-week-3/overview/open-scientific-questions). While the challenge involves forecasting confirmed cases and fatalities between April 1 and April 30 by region, the primary goal **isn't only to produce accurate forecasts**. It’s also to identify factors that appear to impact the transmission rate of COVID-19.You are encouraged to pull in, curate and share data sources that might be helpful. If you find variables that look like they impact the transmission rate, please share your finding in a notebook. As the data becomes available, we will update the leaderboard with live results based on [data made available](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series) from the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE).We have received support and guidance from health and policy organizations in launching these challenges. We're hopeful the Kaggle community can make valuable contributions to developing a better understanding of factors that impact the transmission of COVID-19. ### Companies and Organizations**There is also a call to action for companies and other organizations:** If you have datasets that might be useful, please upload them to [Kaggle’s dataset platform](https://www.kaggle.com/datasets) and reference them in [this forum thread](https://www.kaggle.com/c/covid19-global-forecasting-week-3/discussion/137078). That will make them accessible to those participating in this challenge and a resource to the wider scientific community.### AcknowledgementsJHU CSSE for making the data available to the public. The White House OSTP for pulling together the key open questions. The image comes from the Center for Disease Control.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/covid19-global-forecasting-week-3/overview) for details.**\"}, {'title': 'iMet Collection 2020 - FGVC7', 'url': 'https://www.kaggle.com/competitions/imet-2020-fgvc7', 'briefDescription': 'Recognize artwork attributes from The Metropolitan Museum of Art', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18626/logos/header.png?t=2020-03-13-01-40-56', 'tag': 'meanfscorebeta', 'description': 'The [Metropolitan Museum of Art](https://www.metmuseum.org/) in New York, also known as The Met, has a diverse collection of over 1.5M objects of which over 200K have been digitized with imagery. Can you help find the significant attributes to identify a specific work of art? Help advance this research in this notebook competition.   The online cataloguing information is generated by subject matter experts and includes a wide range of data. These include, but are not limited to: multiple object classifications, artist, title, period, date, medium, culture, size, provenance, geographic location, and other related museum objects within The Met’s collection. While the annotations describe the object from an art history perspective, they can also be indirect in describing finer-grained attributes for the museum-goer’s understanding. Adding fine-grained attributes to aid in the visual understanding of the museum objects will enable the ability to search for visually related objects.> This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/imet-2020-fgvc7/overview/code-requirements) for details.## AboutThis is an FGVCx competition hosted as part of the [FGVC7 workshop](https://sites.google.com/view/fgvc7/home) at [CVPR 2020](http://cvpr2020.thecvf.com/).'}, {'title': 'COVID19 Global Forecasting (Week 2)', 'url': 'https://www.kaggle.com/competitions/covid19-global-forecasting-week-2', 'briefDescription': 'Forecast daily COVID-19 spread in regions around world', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19702/logos/header.png?t=2020-03-26-06-02-18', 'tag': 'tabular, covid19, mcrmsle', 'description': \"**[This week 2 forecasting task is now closed for submissions. Click here to visit the week 3 version, and make a submission there.](https://www.kaggle.com/c/covid19-global-forecasting-week-3)***This is week 2 of Kaggle's COVID19 forecasting series, following the [Week 1 competition](https://www.kaggle.com/c/covid19-global-forecasting-week-1). This is the 2nd of at least 4 competitions we plan to launch in this series.*### BackgroundThe White House Office of Science and Technology Policy (OSTP) pulled together a coalition research groups and companies (including Kaggle)  to prepare the [COVID-19 Open Research Dataset (CORD-19)](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) to attempt to address [key open scientific questions on COVID-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks). Those questions are drawn from [National Academies of Sciences, Engineering, and Medicine’s (NASEM)](https://www.nationalacademies.org/event/03-11-2020/standing-committee-on-emerging-infectious-diseases-and-21st-century-health-threats-virtual-meeting-1) and the [World Health Organization (WHO)](https://www.who.int/blueprint/priority-diseases/key-action/Global_Research_Forum_FINAL_VERSION_for_web_14_feb_2020.pdf?ua=1).### The ChallengeKaggle is launching a companion COVID-19 forecasting challenges to help answer a [subset of the NASEM/WHO questions](https://www.kaggle.com/c/covid19-global-forecasting-week-2/overview/open-scientific-questions). While the challenge involves forecasting confirmed cases and fatalities between April 1 and April 30 by region, the primary goal **isn't only to produce accurate forecasts**. It’s also to identify factors that appear to impact the transmission rate of COVID-19.You are encouraged to pull in, curate and share data sources that might be helpful. If you find variables that look like they impact the transmission rate, please share your finding in a notebook. As the data becomes available, we will update the leaderboard with live results based on [data made available](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series) from the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE).We have received support and guidance from health and policy organizations in launching these challenges. We're hopeful the Kaggle community can make valuable contributions to developing a better understanding of factors that impact the transmission of COVID-19. ### Companies and Organizations**There is also a call to action for companies and other organizations:** If you have datasets that might be useful, please upload them to [Kaggle’s dataset platform](https://www.kaggle.com/datasets) and reference them in [this forum thread](https://www.kaggle.com/c/covid19-global-forecasting-week-2/discussion/137078). That will make them accessible to those participating in this challenge and a resource to the wider scientific community.### AcknowledgementsJHU CSSE for making the data available to the public. The White House OSTP for pulling together the key open questions. The image comes from the Center for Disease Control.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/covid19-global-forecasting-week-2/overview) for details.**\"}, {'title': 'Tweet Sentiment Extraction', 'url': 'https://www.kaggle.com/competitions/tweet-sentiment-extraction', 'briefDescription': 'Extract support phrases for sentiment labels', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/16295/logos/header.png?t=2019-12-12-19-46-30', 'tag': 'internet, text, custom metric', 'description': '*\"My ridiculous dog is amazing.\"* [sentiment: positive]With all of the tweets circulating every second it is hard to tell whether the sentiment behind a specific tweet will impact a company, or a person\\'s, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in language is important in these times where decisions and reactions are created and updated in seconds.  But, which words actually lead to the sentiment description? In this competition you will need to pick out the part of the tweet (word or phrase) that reflects the sentiment. Help build your skills in this important area with this broad dataset of tweets. Work on your technique to grab a top spot in this competition. What words in tweets support a positive, negative, or neutral sentiment? How can you help make that determination using machine learning tools?In this competition we\\'ve extracted support phrases from [Figure Eight\\'s Data for Everyone platform](https://www.figure-eight.com/data-for-everyone/). The dataset is titled Sentiment Analysis: Emotion in Text tweets with existing sentiment labels, used here under creative commons attribution 4.0. international licence. Your objective in this competition is to construct a model that can do the same - look at the labeled sentiment for a given tweet and figure out what word or phrase best supports it.Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.'}, {'title': 'Jigsaw Multilingual Toxic Comment Classification', 'url': 'https://www.kaggle.com/competitions/jigsaw-multilingual-toxic-comment-classification', 'briefDescription': 'Use TPUs to identify toxicity comments across multiple languages', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19018/logos/header.png?t=2020-02-20-19-20-37', 'tag': 'tpu, text, languages, auc', 'description': 'It only takes one toxic comment to sour an online discussion. The Conversation AI team, a research initiative founded by [Jigsaw](https://jigsaw.google.com/) and Google, builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything *rude, disrespectful or otherwise likely to make someone leave a discussion*. If these toxic contributions can be identified, we could have a safer, more collaborative internet.In the previous 2018 [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge), Kagglers built multi-headed models to recognize toxicity and several subtypes of toxicity. In 2019, in the [Unintended Bias in Toxicity Classification Challenge](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification), you worked to build toxicity models that operate fairly across a diverse range of conversations. This year, we\\'re taking advantage of [Kaggle\\'s new TPU support](https://www.kaggle.com/docs/tpu) and challenging you to build multilingual models with English-only training data.Jigsaw\\'s API, [Perspective](http://perspectiveapi.com/), serves toxicity models and others in a growing set of languages (see our [documentation](https://github.com/conversationai/perspectiveapi/blob/master/2-api/models.md#all-attribute-types) for the full list). Over the past year, the field has seen impressive multilingual capabilities from the latest model innovations, including few- and zero-shot learning. We\\'re excited to learn whether these results \"translate\" (pun intended!) to toxicity classification. Your training data will be the English data provided for our previous two competitions and your test data will be Wikipedia talk page comments in several different languages. As our computing resources and modeling capabilities grow, so does our potential to support healthy conversations across the globe. Develop strategies to build effective multilingual models and you\\'ll help Conversation AI and the entire industry realize that potential.*Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.*To get started with TPUs:Read the TPU documentation one-pagerThen jump right into the Getting Started Notebooks for this competitionQuick note: a TPU is a network-connected accelerator and requires a couple extra lines in your code. Flipping the TPU switch in your notebook will not, by itself, accelerate your code.'}, {'title': 'iMaterialist (Fashion) 2020 at FGVC7 ', 'url': 'https://www.kaggle.com/competitions/imaterialist-fashion-2020-fgvc7', 'briefDescription': 'Fine-grained segmentation task for fashion and apparel', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18237/logos/header.png?t=2020-02-27-05-48-35', 'tag': 'custom metric', 'description': '![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3258%2F7011d2728a1cce89e10e9000c5a123ce%2Finbox_2453540_c0eb9f705d7937c1cdf237922efa7c65_kaggle_banner_3.png?generation=1584977986424573&alt=media)Designers know what they are creating, but what, and how, do people really wear their products? What combinations of products are people using? In this competition, we challenge you to develop algorithms that will help with an important step towards automatic product detection – to accurately assign segmentations and attribute labels for fashion images. Visual analysis of clothing is a topic that has received increasing attention in recent years. Being able to recognize apparel products and associated attributes from pictures could enhance the shopping experience for consumers, and increase work efficiency for fashion professionals.We present a clothing dataset with the goal of introducing **a novel fine-grained segmentation task** by joining forces between the fashion and computer vision communities. The proposed task unifies both categorization and segmentation of rich and complete apparel attributes, an important step toward real-world applications. ![enter image description here][2]While early work in computer vision addressed related clothing recognition tasks, these are not designed with fashion insiders’ needs in mind, possibly due to the research gap in fashion design and computer vision. To address this, we first propose a fashion taxonomy built by fashion experts, informed by product description from the internet. To capture the complex structure of fashion objects and ambiguity in descriptions obtained from crawling the web, our standardized taxonomy contains 46 apparel objects (27 main apparel items and 19 apparel parts), and 294 related fine-grained attributes. Secondly, a total of 50K clothing images (with both segmentation masks and fine-grained attributes) in daily-life, celebrity events, and online shopping are labeled by both domain experts and crowd workers for fine-grained segmentation.Individuals/Teams with top submissions will be invited to present their work live at the [FGVC7 workshop](https://sites.google.com/view/fgvc7/home) at the [Conference on Computer Vision and Pattern Recognition (CVPR) 2020](http://cvpr2020.thecvf.com/).### AcknowledgmentsThe iMat-Fashion Challenge 2020 is sponsored by Google AI, CVDF, [Fashionpedia][6] and Hearst Magazine.![enter image description here][7]        ![enter image description here][8]        ![enter image description here][9]           ![enter image description here][10]        ![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2453540%2F17bd48f449cbe6bbe49bd32b624161fb%2Fhearst_magazine2.png?generation=1582850349873108&alt=media)  [1]: https://s3.amazonaws.com/ifashionist/Kaggle/Kaggle3.jpg  [2]: https://s3.amazonaws.com/ifashionist/Kaggle/dataset_example.jpg  [5]: https://github.com/visipedia/imat_comp  [6]: https://fashionpedia.github.io/home/index.html  [7]: https://s3.amazonaws.com/ifashionist/Kaggle/googleai.jpg  [8]: https://s3.amazonaws.com/ifashionist/Kaggle/cvdf-logo.png  [9]: https://s3.amazonaws.com/ifashionist/Kaggle/Fashionpedia_logo.jpg  [10]: https://ifashionist.s3.amazonaws.com/Kaggle/hearst_magazine_logo.jpg'}, {'title': 'COVID19 Global Forecasting (Week 1)', 'url': 'https://www.kaggle.com/competitions/covid19-global-forecasting-week-1', 'briefDescription': 'Forecast daily COVID-19 spread in regions around world', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19539/logos/header.png?t=2020-03-18-01-05-54', 'tag': 'tabular, covid19, mcrmsle', 'description': \"**[This week 1 forecasting task is now closed for submissions. Click here to visit the week 2 version, and make a submission there.](https://www.kaggle.com/c/covid19-global-forecasting-week-2)***This is one of the two complementary forecasting tasks to predict COVID-19 spread. This task is based on various regions across the world. To start on a single state-level subcomponent, please see the companion forecasting task for [California, USA](https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1/overview/description)*.### BackgroundThe White House Office of Science and Technology Policy (OSTP) pulled together a coalition research groups and companies (including Kaggle)  to prepare the [COVID-19 Open Research Dataset (CORD-19)](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) to attempt to address [key open scientific questions on COVID-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks). Those questions are drawn from [National Academies of Sciences, Engineering, and Medicine’s (NASEM)](https://www.nationalacademies.org/event/03-11-2020/standing-committee-on-emerging-infectious-diseases-and-21st-century-health-threats-virtual-meeting-1) and the [World Health Organization (WHO)](https://www.who.int/blueprint/priority-diseases/key-action/Global_Research_Forum_FINAL_VERSION_for_web_14_feb_2020.pdf?ua=1).### The ChallengeKaggle is launching two companion COVID-19 forecasting challenges to help answer a [subset of the NASEM/WHO questions](https://www.kaggle.com/c/covid19-global-forecasting-week-1/overview/open-scientific-questions). While the challenge involves forecasting confirmed cases and fatalities between March 25 and April 22 by region, the primary goal **isn't to produce accurate forecasts**. It’s to identify factors that appear to impact the transmission rate of COVID-19.You are encouraged to pull in, curate and share data sources that might be helpful. If you find variables that look like they impact the transmission rate, please share your finding in a notebook. As the data becomes available, we will update the leaderboard with live results based on [data made available](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series) from the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE).We have received support and guidance from health and policy organizations in launching these challenges. We're hopeful the Kaggle community can make valuable contributions to developing a better understanding of factors that impact the transmission of COVID-19. ### Companies and Organizations**There is also a call to action for companies and other organizations:** If you have datasets that might be useful, please upload them to [Kaggle’s dataset platform](https://www.kaggle.com/datasets) and reference them in [this forum thread](https://www.kaggle.com/c/covid19-global-forecasting-week-1/discussion/137078). That will make them accessible to those participating in this challenge and a resource to the wider scientific community.### AcknowledgementsJHU CSSE for making the data available to the public. The White House OSTP for pulling together the key open questions. The image comes from the Center for Disease Control.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/covid19-global-forecasting-week-1/overview) for details.**\"}, {'title': 'COVID19 Local US-CA Forecasting (Week 1)', 'url': 'https://www.kaggle.com/competitions/covid19-local-us-ca-forecasting-week-1', 'briefDescription': 'Forecast daily COVID-19 spread in California, USA', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/19548/logos/header.png?t=2020-03-18-01-06-45', 'tag': 'tabular, covid19, mcrmsle', 'description': \"*This is one of the two complementary forecasting tasks to predict COVID-19 spread. This one is based on a single state-level subcomponent in California, USA. Our intent in having this region-specific version is to offer a more manageable starting point for the global forecasting task. To start on the global version, please see [the companion forecasting task](https://www.kaggle.com/c/covid19-global-forecasting-week-1).*### BackgroundThe White House Office of Science and Technology Policy (OSTP) pulled together a coalition research groups and companies (including Kaggle)  to prepare the [COVID-19 Open Research Dataset (CORD-19)](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) to attempt to address [key open scientific questions on COVID-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks). Those questions are drawn from [National Academies of Sciences, Engineering, and Medicine’s (NASEM)](https://www.nationalacademies.org/event/03-11-2020/standing-committee-on-emerging-infectious-diseases-and-21st-century-health-threats-virtual-meeting-1) and the [World Health Organization (WHO)](https://www.who.int/blueprint/priority-diseases/key-action/Global_Research_Forum_FINAL_VERSION_for_web_14_feb_2020.pdf?ua=1).### The ChallengeKaggle is launching two companion COVID-19 forecasting challenges to help answer a [subset of the NASEM/WHO questions](https://www.kaggle.com/c/covid19-global-forecasting-week-1/overview/open-scientific-questions). While the challenge involves forecasting confirmed cases and fatalities between March 25 and April 22 in California, the primary goal **isn't to produce accurate forecasts**. It’s to identify factors that appear to impact the transmission rate of COVID-19.You are encouraged to pull in, curate and share data sources that might be helpful. If you find variables that look like they impact the transmission rate, please share your finding in a notebook. As the data becomes available, we will update the leaderboard with live results based on [data made available](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series) from the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE).We have received support and guidance from health and policy organizations in launching these challenges. We're hopeful the Kaggle community can make valuable contributions to developing a better understanding of factors that impact the transmission of COVID-19. ### Companies and Organizations**There is also a call to action for companies and other organizations:** If you have datasets that might be useful, please upload them to [Kaggle’s dataset platform](https://www.kaggle.com/datasets) and reference them in [this forum thread](https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1/discussion/137079). That will make them accessible to those participating in this challenge and a resource to the wider scientific community.### AcknowledgementsJHU CSSE for making the data available to the public. The White House OSTP for pulling together the key open questions. The image comes from the Center for Disease Control.> **This is a Code Competition. Refer to [Code Requirements](https://www.kaggle.com/c/covid19-global-forecasting-week-1/overview) for details.**\"}, {'title': 'Plant Pathology 2020 - FGVC7', 'url': 'https://www.kaggle.com/competitions/plant-pathology-2020-fgvc7', 'briefDescription': 'Identify the category of foliar diseases in apple trees', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18648/logos/header.png?t=2020-02-20-17-30-35', 'tag': 'image, agriculture, mcauc', 'description': \"## Problem StatementMisdiagnosis of the many diseases impacting agricultural crops can lead to misuse of chemicals leading to the emergence of resistant pathogen strains, increased input costs, and more outbreaks with significant economic loss and environmental impacts. Current disease diagnosis based on human scouting is time-consuming and expensive, and although computer-vision based models have the promise to increase efficiency, the great variance in symptoms due to age of infected tissues, genetic variations, and light conditions within trees decreases the accuracy of detection. ## Specific ObjectivesObjectives of ‘Plant Pathology Challenge’ are to train a model using images of training dataset to 1) Accurately classify a given image from testing dataset into different diseased category or a healthy leaf; 2) Accurately distinguish between many diseases, sometimes more than one on a single leaf; 3) Deal with rare classes and novel symptoms; 4) Address depth perception—angle, light, shade, physiological age of the leaf; and 5) Incorporate expert knowledge in identification, annotation, quantification, and guiding computer vision to search for relevant features during learning. ## ResourcesDetails and background information on the dataset and Kaggle competition ‘Plant Pathology 2020 Challenge’ were published. If you use the dataset for your project, please cite the following peer-reviewed research article[Thapa, Ranjita; Zhang, Kai; Snavely, Noah; Belongie, Serge; Khan, Awais. The Plant Pathology Challenge 2020 data set to classify foliar disease of apples. Applications in Plant Sciences, 8 (9), 2020.](https://bsapubs.onlinelibrary.wiley.com/doi/10.1002/aps3.11390)## AcknowledgmentsWe acknowledge financial support from [Cornell Initiative for Digital Agriculture (CIDA)](https://www.digitalagriculture.cornell.edu/) and special thanks to Zach Guillian for help with data collection.   *Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.* \"}, {'title': 'iWildCam 2020 - FGVC7', 'url': 'https://www.kaggle.com/competitions/iwildcam-2020-fgvc7', 'briefDescription': 'Categorize animals in the wild', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18294/logos/header.png?t=2020-01-12-18-11-26', 'tag': 'biology, multiclass classification, categorizationaccuracy', 'description': \"Camera Traps (or Wild Cams) enable the automatic collection of large quantities of image data. Biologists all over the world use camera traps to monitor biodiversity and population density of animal species. We have recently been making strides towards automatic species classification in camera trap images. However, as we try to expand the scope of these models we are faced with an interesting problem: how do we train models that perform well on new (unseen during training) camera trap locations? Can we leverage data from other modalities, such as citizen science data and remote sensing data?   In order to tackle this problem, we have prepared a challenge where the training data and test data are from different cameras spread across the globe. The set of species seen in each camera overlap, but are not identical. The challenge is to classify species in the test cameras correctly. To explore multimodal solutions, we allow competitors to train on the following data: (i) our camera trap training set (data provided by WCS), (ii) iNaturalist 2017-2019 data, and (iii) multispectral imagery (from [Landsat 8][9]) for each of the camera trap locations. On the competition [GitHub page][6] we provide the multispectral data, a taxonomy file mapping our classes into the iNat taxonomy, a subset of iNat data mapped into our class set, and a camera trap detection model (the MegaDetector) along with the corresponding detections.If you use this dataset in publication, please cite:```@article{beery2020iwildcam,    title={The iWildCam 2020 Competition Dataset},    author={Beery, Sara and Cole, Elijah and Gjoka, Arvi},    journal={arXiv preprint arXiv:2004.10340},    year={2020}}```This is an FGVCx competition as part of the [FGVC7][4] workshop at [CVPR 2020][5], and is sponsored by [Microsoft AI for Earth][3] and [Wildlife Insights][8]. There is a GitHub page for the competition [here][6]. Please open an issue if you have questions or problems with the dataset.     You can find the iWildCam 2018 Competition [here](https://github.com/visipedia/iwildcam_comp/blob/master/2018/readme.md), and the iWildCam 2019 Competition [here](https://github.com/visipedia/iwildcam_comp/blob/master/2019/readme.md).*Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.*   [1]: http://lila.science/datasets/wcscameratraps  [2]: https://github.com/visipedia/inat_comp  [3]: https://www.microsoft.com/en-us/ai/ai-for-earth  [4]: https://sites.google.com/view/fgvc7/home  [5]: http://cvpr2020.thecvf.com/  [6]: https://github.com/visipedia/iwildcam_comp  [7]: https://github.com/microsoft/CameraTraps/blob/master/megadetector.md  [8]: https://www.wildlifeinsights.org/  [9]: https://www.usgs.gov/land-resources/nli/landsat/landsat-8\"}, {'title': 'Herbarium 2020 - FGVC7', 'url': 'https://www.kaggle.com/competitions/herbarium-2020-fgvc7', 'briefDescription': 'Identify plant species from herbarium specimens. Data from New York Botanical Garden.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18627/logos/header.png?t=2020-03-03-16-04-31', 'tag': 'image, plants, macrofscore', 'description': 'The Herbarium 2020 FGVC7 Challenge is to identify vascular plant species from a large, long-tailed collection herbarium specimens provided by the [New York Botanical Garden](https://www.nybg.org/plant-research-and-conservation/) (NYBG).The Herbarium 2020 dataset contains over 1M images representing over 32,000 plant species. This is a dataset with a long tail; there are a minimum of 3 specimens per species. However, some species are represented by more than a hundred specimens. This dataset only contains vascular land plants which includes lycophytes, ferns, gymnosperms, and flowering plants. The extinct forms of lycophytes are the major component of coal deposits, ferns are indicators of ecosystem health, gymnosperms provide major habitats for animals, and flowering plants provide all of our crops, vegetables, and fruits.The teams with the most accurate models will be contacted, with the intention of using them on the un-named plant collections in the NYBG herbarium collection, and assessed by the NYBG plant specialists.## BackgroundThe New York Botanical Garden (NYBG) herbarium contains more than 7.8 million plant and fungal specimens. Herbaria are a massive repository of plant diversity data.  These collections not only represent a vast amount of plant diversity, but since herbarium collections include specimens dating back hundreds of years, they provide snapshots of plant diversity through time.  The integrity of the plant is maintained in herbaria as a pressed, dried specimen; a specimen collected nearly two hundred years ago by Darwin looks much the same as one collected a month ago by an NYBG botanist.  All specimens not only maintain their morphological features but also include collection dates and locations, and the name of the person who collected the specimen.  This information, multiplied by millions of plant collections, provides the framework for understanding plant diversity on a massive scale and learning how it has changed over time.## AboutThis is an FGVC competition hosted as part of the [FGVC7](https://sites.google.com/corp/view/fgvc7/home) workshop at [CVPR 2020](http://cvpr2020.thecvf.com/) and sponsored by [NYBG](https://www.nybg.org/plant-research-and-conservation/).Details of this competition are mirrored on the [github page](https://github.com/visipedia/herbarium_comp). Please post in the forum or open an issue if you have any questions or problems with the dataset.'}, {'title': 'M5 Forecasting - Accuracy', 'url': 'https://www.kaggle.com/competitions/m5-forecasting-accuracy', 'briefDescription': 'Estimate the unit sales of Walmart retail goods', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18599/logos/header.png?t=2020-02-21-17-36-55', 'tag': 'time series analysis, custom metric', 'description': '*Note: This is one of the two complementary competitions that together comprise the M5 forecasting challenge. Can you estimate, as precisely as possible, the point forecasts of the unit sales of various products sold in the USA by Walmart? If you are interested in estimating the uncertainty distribution of the realized values of the same series, be sure to check out its [companion competition](https://www.kaggle.com/c/m5-forecasting-uncertainty)*How much camping gear will one store sell each month in a year? To the uninitiated, calculating sales at this level may seem as difficult as predicting the weather. Both types of forecasting rely on science and historical data. While a wrong weather forecast may result in you carrying around an umbrella on a sunny day, inaccurate business forecasts could result in actual or opportunity losses.  In this competition, in addition to traditional forecasting methods you’re also challenged to use machine learning to improve forecast accuracy.The Makridakis Open Forecasting Center (MOFC) at the University of Nicosia conducts cutting-edge forecasting research and provides business forecast training. It helps companies achieve accurate predictions, estimate the levels of uncertainty, avoiding costly mistakes, and apply best forecasting practices. The MOFC is well known for its Makridakis Competitions, the first of which ran in the 1980s.In this competition, the fifth iteration, you will use hierarchical sales data from Walmart, the world’s largest company by revenue, to forecast daily sales for the next 28 days. The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. Together, this robust dataset can be used to improve forecasting accuracy.If successful, your work will continue to advance the theory and practice of forecasting. The methods used can be applied in various business areas, such as setting up appropriate inventory or service levels. Through its business support and training, the MOFC will help distribute the tools and knowledge so others can achieve more accurate and better calibrated forecasts, reduce waste and be able to appreciate uncertainty and its risk implications.**Acknowledgements**Additional thanks go to other partner organizations and prize sponsors, National Technical University of Athens (NTUA), INSEAD, Google, Uber and IIF.'}, {'title': 'M5 Forecasting - Uncertainty', 'url': 'https://www.kaggle.com/competitions/m5-forecasting-uncertainty', 'briefDescription': ' Estimate the uncertainty distribution of Walmart unit sales.  ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18600/logos/header.png?t=2020-02-21-17-32-51', 'tag': 'time series analysis, custom metric', 'description': '*Note: This is one of the two complementary competitions that together comprise the M5 forecasting challenge. Can you estimate, as precisely as possible, the uncertainty distribution of the unit sales of various products sold in the USA by Walmart? This specific competition is the first of its kind, opening up new directions for both academic research and how uncertainty could be assessed and used in organizations. If you are interested in providing point (accuracy) forecasts for the same series, be sure to check out its [companion competition.](https://www.kaggle.com/c/m5-forecasting-accuracy)*How much camping gear will one store sell each month in a year? To the uninitiated, calculating sales at this level may seem as difficult as predicting the weather. Both types of forecasting rely on science and historical data. While a wrong weather forecast may result in you carrying around an umbrella on a sunny day, inaccurate business forecasts could result in actual or opportunity losses.  In this competition, in addition to traditional forecasting methods you’re also challenged to use machine learning to improve forecast accuracy.The Makridakis Open Forecasting Center (MOFC) at the University of Nicosia conducts cutting-edge forecasting research and provides business forecast training. It helps companies achieve accurate predictions, estimate the levels of uncertainty, avoiding costly mistakes, and apply best forecasting practices. The MOFC is well known for its Makridakis Competitions, the first of which ran in the 1980s.In this competition, the fifth iteration, you will use hierarchical sales data from Walmart, the world’s largest company by revenue, to forecast daily sales for the next 28 days and to make uncertainty estimates for these forecasts. The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. Together, this robust dataset can be used to improve forecasting accuracy.If successful, your work will continue to advance the theory and practice of forecasting. The methods used can be applied in various business areas, such as setting up appropriate inventory or service levels. Through its business support and training, the MOFC will help distribute the tools and knowledge so others can achieve more accurate and better calibrated forecasts, reduce waste and be able to appreciate uncertainty and its risk implications.**Acknowledgements**Additional thanks go to other partner organizations and prize sponsors, National Technical University of Athens (NTUA), INSEAD, Google, Uber and IIF.'}, {'title': 'University of Liverpool - Ion Switching', 'url': 'https://www.kaggle.com/competitions/liverpool-ion-switching', 'briefDescription': 'Identify the number of channels open at each time point', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18045/logos/header.png?t=2020-02-21-18-37-17', 'tag': 'biology, macrofscore', 'description': 'Think you can use your data science skills to make big predictions at a submicroscopic level?Many diseases, including cancer, are believed to have a contributing factor in common. Ion channels are pore-forming proteins present in animals and plants. They encode learning and memory, help fight infections, enable pain signals, and stimulate muscle contraction. If scientists could better study ion channels, which may be possible with the aid of machine learning, it could have a far-reaching impact.When ion channels open, they pass electric currents. Existing methods of detecting these state changes are slow and laborious. Humans must supervise the analysis, which imparts considerable bias, in addition to being tedious. These difficulties limit the volume of ion channel current analysis that can be used in research. Scientists hope that technology could enable rapid automatic detection of ion channel current events in raw data.The University of Liverpool’s Institute of Ageing and Chronic Disease is working to advance ion channel research. Their team of scientists have asked for your help. In this competition, you’ll use ion channel data to better model automatic identification methods. If successful, you’ll be able to detect individual ion channel events in noisy raw signals. The data is simulated and injected with real world noise to emulate what scientists observe in laboratory experiments.Technology to analyze electrical data in cells has not changed significantly over the past 20 years. If we better understand ion channel activity, the research could impact many areas related to cell health and migration. From human diseases to how climate change affects plants, faster detection of ion channels could greatly accelerate solutions to major world problems.Acknowledgements:This would not be possible without the help of the [Biotechnology and Biological Sciences Research Council (BBSRC)](https://bbsrc.ukri.org/). '}, {'title': 'Google Cloud & NCAA® March Madness Analytics', 'url': 'https://www.kaggle.com/competitions/march-madness-analytics-2020', 'briefDescription': 'Uncover the madness of March Madness®', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/11999/logos/header.png?t=2019-02-12-18-56-32', 'tag': 'sports, basketball, logloss', 'description': 'There\\'s a reason why it\\'s called March *Madness*®. Upsets happen, underdogs become \"cinderellas,\" and games that analysts expected to be blowouts become nail-biters through the final seconds. A team\\'s competitiveness is what keeps games exciting and the tournament truly \"mad.\" In addition to the predictive modeling competitions we typically host (NCAA Men\\'s and Women’s), we are hosting a separate competition using Kaggle Notebooks that challenges you to present an exploratory analysis of the “Madness.” Can you quantify competitiveness? Can you explain \"cinderella...ness\"? Or perhaps, can you determine what dictates the ability of a team to “stay in the game” and increase their chance to win late in the contest? This may or may not be a scalar metric. It might be a clustering of types of competitiveness and then a rating within each. Does this metric have predictive power? The interpretation is up to you.Your challenge is to tell a data story about college basketball through a combination of both narrative text and data exploration. A “story” could be defined any number of ways, and that’s deliberate. You are to deeply explore (through data) the mania of the Men’s and Women’s NCAA College Basketball tournaments. That story can be examined in the macro (for example: How does “competitiveness” differ from the regular season to their decisions in the tournament?) or the micro (for example: Does effectively neutralizing an opponent’s star players increase their ability to “stay in the game”?). This is an opportunity to be creative and tell the story of a community you identify with or are passionate about!'}, {'title': 'Google Cloud & NCAA® ML Competition 2020-NCAAM', 'url': 'https://www.kaggle.com/competitions/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament', 'briefDescription': 'Apply Machine Learning to NCAA® March Madness®', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/11999/logos/header.png?t=2019-02-12-18-56-32', 'tag': 'tabular, basketball, logloss', 'description': \"## Update: this competition has been cancelled on account of the COVID-19 pandemic. As a result of the continued collaboration between Google Cloud and the NCAA®, the seventh annual Kaggle-backed March Madness® competition is underway! Another year, another chance to anticipate the upsets, call the probabilities, and put your bracketology skills to the leaderboard test. Kagglers will join the millions of fans who attempt to forecast the outcomes of March Madness during this year's NCAA Division I Men’s and Women’s Basketball Championships. But unlike most fans, you will pick your bracket using a combination of NCAA’s historical data and your computing power, while the ground truth unfolds on national television.In the first stage of the competition, Kagglers will rely on results of past tournaments to build and test models. We encourage you to post any useful external data as a dataset.In the second stage, competitors will forecast outcomes of all possible matchups in the 2020 NCAA Division I Men’s and Women’s Basketball Championships. You don't need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2020 results.As the official public cloud provider of the NCAA, Google is proud to provide a competition to help participants strengthen their knowledge of basketball, statistics, data modeling, and cloud technology. As part of its journey to the cloud, the NCAA has migrated 80+ years of historical and play-by-play data, from 90 championships and 24 sports, to Google Cloud Platform (GCP). The NCAA has tapped into decades of historical basketball data using BigQuery, Cloud Spanner, Datalab, Cloud Machine Learning and Cloud Dataflow, to power the analysis of team and player performance. The mission of the NCAA has long been about serving the needs of schools, their teams and students. Google Cloud is proud to support that mission by helping the NCAA use data and machine learning to better engage with its millions of fans, 500,000 student-athletes, and more than 19,000 teams. Game on! This page is for the NCAA Division I Men's tournament. Check out the NCAA Division I Women's tournament here.  If you want to extend your analysis then try out our Analytics Competition here\"}, {'title': 'Google Cloud & NCAA® ML Competition 2020-NCAAW', 'url': 'https://www.kaggle.com/competitions/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament', 'briefDescription': 'Apply Machine Learning to NCAA® March Madness®', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12000/logos/header.png?t=2019-02-12-18-48-27', 'tag': 'tabular, basketball, logloss', 'description': \"## Update: this competition has been cancelled on account of the COVID-19 pandemic. As a result of the continued collaboration between Google Cloud and the NCAA®, the seventh annual Kaggle-backed March Madness® competition is underway! Another year, another chance to anticipate the upsets, call the probabilities, and put your bracketology skills to the leaderboard test. Kagglers will join the millions of fans who attempt to forecast the outcomes of March Madness during this year's NCAA Division I Men’s and Women’s Basketball Championships. But unlike most fans, you will pick your bracket using a combination of NCAA’s historical data and your computing power, while the ground truth unfolds on national television.In the first stage of the competition, Kagglers will rely on results of past tournaments to build and test models. We encourage you to post any useful external data as a dataset.In the second stage, competitors will forecast outcomes of all possible matchups in the 2020 NCAA Division I Men’s and Women’s Basketball Championships. You don't need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2020 results.As the official public cloud provider of the NCAA, Google Cloud is proud to provide a competition to help participants strengthen their knowledge of basketball, statistics, data modeling, and cloud technology. As part of its journey to the cloud, the NCAA has migrated 80+ years of historical and play-by-play data, from 90 championships and 24 sports, to Google Cloud Platform (GCP). The NCAA has tapped into decades of historical basketball data using BigQuery, Cloud Spanner, Datalab, Cloud Machine Learning and Cloud Dataflow, to power the analysis of team and player performance. The mission of the NCAA has long been about serving the needs of schools, their teams and students. Google Cloud is proud to support that mission by helping the NCAA use data and machine learning to better engage with its millions of fans, 500,000 student-athletes and more than 19,000 teams. Game on! This page is for the NCAA Division I Women's tournament. Check out the NCAA Division I Men's tournament here. If you want to extend your analysis then try out our Analytics Competition here\"}, {'title': 'Abstraction and Reasoning Challenge', 'url': 'https://www.kaggle.com/competitions/abstraction-and-reasoning-challenge', 'briefDescription': 'Create an AI capable of solving reasoning tasks it has never seen before', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18329/logos/header.png?t=2020-02-07-16-38-49', 'tag': 'artificial intelligence, meanbesterroratk', 'description': \"![ARC Example](https://storage.googleapis.com/kaggle-media/competitions/ARC/arc_example.png)Can a computer learn complex, abstract tasks from just a few examples?Current machine learning techniques are data-hungry and brittle—they can only make sense of patterns they've seen before. Using current methods, an algorithm can gain new skills by exposure to large amounts of data, but cognitive abilities that could broadly generalize to *many* tasks remain elusive. This makes it very challenging to create systems that can handle the variability and unpredictability of the real world, such as domestic robots or self-driving cars.However, alternative approaches, like inductive programming, offer the potential for more human-like abstraction and reasoning. The Abstraction and Reasoning Corpus (ARC) provides a benchmark to measure AI skill-acquisition on unknown tasks, with the constraint that only a handful of demonstrations are shown to learn a complex task. It provides a glimpse of a future where AI could quickly learn to solve new problems on its own. The Kaggle Abstraction and Reasoning Challenge invites you to try your hand at bringing this future into the present!This competition is hosted by [François Chollet](https://fchollet.com/), creator of the Keras neural networks library. [Chollet’s paper on measuring intelligence](https://arxiv.org/abs/1911.01547) provides the context and motivation behind the ARC benchmark.In this competition, you’ll create an AI that can solve reasoning tasks it has never seen before. Each ARC task contains 3-5 pairs of train inputs and outputs, and a test input for which you need to predict the corresponding output with the pattern learned from the train examples.If successful, you’ll help bring computers closer to human cognition and you'll open the door to completely new AI applications!\"}, {'title': 'DS4G - Environmental Insights Explorer', 'url': 'https://www.kaggle.com/competitions/ds4g-environmental-insights-explorer', 'briefDescription': 'Exploring alternatives for emissions factor calculations', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/17907/logos/header.png?t=2019-12-19-18-33-03', 'tag': 'geospatial analysis, environment, pollution', 'description': '# PROJECT OVERVIEW**Develop a methodology to calculate an average historical emissions factor of electricity generated for a sub-national region, using remote sensing data and techniques.**The Environmental Insights Explorer team at Google is keen to gather insights on ways to improve calculations of global emissions factors for sub-national regions. The ultimate goal of this challenge is to test if calculations of emissions factors using remote sensing techniques are possible and on par with calculations of emissions factors from current methodologies.# PROBLEM STATEMENTCurrent [emissions factors methodologies](https://www.epa.gov/air-emissions-factors-and-quantification/basic-information-air-emissions-factors-and-quantification#About%20Emissions%20Factors) are based on time-consuming data collection and may include errors derived from a lack of access to granular datasets, inability to refresh data on a frequent basis, overly general modeling assumptions, and inaccurate reporting of emissions sources like fuel consumption.  This begs the question: What if there was a different way to calculate or measure emissions factors? We’re challenging the Kaggle community to see if it’s possible to use remote sensing techniques to better model emissions factors. You will develop a methodology to calculate an [average historical emissions factor](https://www.eia.gov/tools/faqs/faq.php?id=74&t=11) for electricity generation in a sub-national region.We’ve provided an initial list of datasets covering the geographic boundary of Puerto Rico to serve as the foundation for this analysis. As an island, there are fewer confounding factors from nearby areas. Puerto Rico also offers a unique fuel mix and distinctive energy system layout that should make it easier to isolate pollution attributable to power generation in the remote sensing data. Participants will be tasked with developing a methodology to calculate an average annual historical emissions factor for the sub-national region. Participants will also be asked to provide an explanation of the conditions that would result in a higher/lower emissions factor, as well as a recommendation for how the methodology could be applied to calculate the emissions factor of electricity for another geospatial area using similar techniques. Bonus points will be awarded for smaller time slices of the average historical emissions factors, such as one per month for the 12-month period, and additional bonus points will be awarded for participants that develop methodologies for calculating [marginal emissions factors](https://www.bloomenergy.com/sites/default/files/watttime_the_rocky_mountain_institute.pdf) for the sub-national region.# HOW TO PARTICIPATETo make a submission, complete the [submission form](https://www.kaggle.com/page/environmental-insights-explorer-submission-form). Only one submission will be judged per participant, so if you make multiple submissions we will only review the most recent entry.To be valid, a submission must be contained in one or more notebook, and made public on or before the submission deadline. Participants are free to use any datasets in addition to the [official Kaggle dataset](https://www.kaggle.com/c/ds4g-environmental-insights-explorer), but those datasets must also be publicly available on either Earth Engine or Kaggle for the submission to be valid.'}, {'title': 'Flower Classification with TPUs', 'url': 'https://www.kaggle.com/competitions/flower-classification-with-tpus', 'briefDescription': 'Use TPUs to classify 104 types of flowers\\n', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/18278/logos/header.png?t=2020-01-31-23-42-27', 'tag': 'tpu, image, plants, macrofscore', 'description': 'Tensor Processing Units (TPUs) are Now Available on KaggleTensor Processing Unit (TPU) quotas are now available on Kaggle, at no cost to you!TPUs are powerful hardware accelerators specialized in deep learning tasks. They were developed (and first used) by Google to process large image databases, such as extracting all the text from Street View. This competition is designed for you to give TPUs a try.The latest Tensorflow release (TF 2.1) was focused on TPUs and they’re now supported both through the Keras high-level API and at a lower level, in models using a custom training loop.We can’t wait to see how your solutions are accelerated by TPUs!The ChallengeIt’s difficult to fathom just how vast and diverse our natural world is.There are over 5,000 species of mammals, 10,000 species of birds, 30,000 species of fish – and astonishingly, over 400,000 different types of flowers.In this competition, you’re challenged to build a machine learning model that identifies the type of flowers in a dataset of images (for simplicity, we’re sticking to just over 100 types).To get started with TPUs:Read the TPU documentation one-pagerThen jump right into the Getting Started Notebook for this competitionQuick note: a TPU is a network-connected accelerator and requires a couple extra lines in your code. Flipping the TPU switch in your notebook will not, by itself, accelerate your code.Have Questions?Martin Görner, Google Developer Advocate and author of Tensorflow without a PhD will be actively engaged in the competition forum. If you have a question or need help troubleshooting, that’s the best place to find help.'}, {'title': 'Connect X', 'url': 'https://www.kaggle.com/competitions/connectx', 'briefDescription': 'Connect your checkers in a row before your opponent!', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/17592/logos/header.png?t=2020-03-30-14-54-24', 'tag': 'custom metric', 'description': \"We’re excited to announce a **beta-version** of a brand-new type of ML competition called Simulations. In Simulation Competitions, you’ll compete against a set of rules, rather than against an evaluation metric. To enter, [accept the rules](/c/connectx/rules) and create a python submission file that can “play” against a computer, or another user.## The ChallengeIn this game, your objective is to get a certain number of your checkers in a row horizontally, vertically, or diagonally on the game board before your opponent. When it's your turn, you “drop” one of your checkers into one of the columns at the top of the board. Then, let your opponent take their turn. This means each move may be trying to either win for you, or trying to stop your opponent from winning. The default number is four-in-a-row, but we’ll have other options to come soon.## Background HistoryFor the past 10 years, our competitions have been mostly focused on supervised machine learning. The field has grown, and we want to continue to provide the data science community cutting-edge opportunities to challenge themselves and grow their skills.So, what’s next? Reinforcement learning is clearly a crucial piece in the next wave of data science learning. We hope that Simulation Competitions will provide the opportunity for Kagglers to practice and hone this burgeoning skill.## How is this Competition Different?Instead of submitting a CSV file, or a Kaggle Notebook, you will submit a Python .py file (more submission options are in development). You’ll also notice that the leaderboard is not based on how accurate your model is but rather how well you’ve performed against other users. See [Evaluation](/c/connectx/overview/evaluation) for more details.## We’d Love Your FeedbackThis competition is a low-stakes, trial-run introduction. We’re considering this a beta launch – there are complicated new mechanics in play and we’re still working on refining the process. We’d love your help testing the experience and want to hear your feedback.Please note that we may make changes throughout the competition that could include things like resetting the leaderboard, invalidating episodes, making changes to the interface, or changing the environment configuration (e.g. modifying the number of columns, rows, or tokens in a row required to win, etc).\"}, {'title': 'Categorical Feature Encoding Challenge II', 'url': 'https://www.kaggle.com/competitions/cat-in-the-dat-ii', 'briefDescription': 'Binary classification, with every feature a categorical (and interactions!)', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/17000/logos/header.png?t=2019-11-08-19-16-42', 'tag': 'binary classification, auc', 'description': \"Can you find more cat in your dat?We loved the participation and engagement with the first Cat in the Dat competition.Because this is such a common task and important skill to master, we've put together a dataset that contains only categorical features, and includes:binary featureslow- and high-cardinality nominal featureslow- and high-cardinality  ordinal features(potentially) cyclical featuresThis follow-up competition offers an even more challenging dataset so that you can continue to build your skills with the common machine learning task of encoding categorical variables.  This challenge adds the additional complexity of feature interactions, as well as missing data.This Playground competition will give you the opportunity to try different encoding schemes for different algorithms to compare how they perform. We encourage you to share what you find with the community.If you're not sure how to get started, you can check out the Categorical Variables  section of Kaggle's Intermediate Machine Learning course.Have Fun!\"}, {'title': 'Santa 2019 - Revenge of the Accountants', 'url': 'https://www.kaggle.com/competitions/santa-2019-revenge-of-the-accountants', 'briefDescription': 'Oh what fun it is to revise . . .', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/17800/logos/header.png?t=2019-12-23-21-40-18', 'tag': 'optimization, holidays and cultural events, custom metric', 'description': 'Santa was *thrilled* with the Kaggle community for [minimizing his workshop costs](https://www.kaggle.com/c/santa-workshop-tour-2019/leaderboard)! He had heard rumors that Kagglers were adept at cracking holiday challenges, but, wow, even Santa was surprised at this one.Unfortunately, the North Pole accountants were less pleased. It turns out, the accountants didn\\'t like being one-upped by machine learning experts on the internet.To complicate matters, they\\'ve decided to allow an additional 1,000 families attend the workshop. And they\\'ve also \"fine tuned\" their accounting formula to try and trip up those fancy solvers some people have at their disposal.Of course, we know that *nothing* trips up the Kaggle community! (Well, except for maybe over-fitting. But fortunately, that doesn\\'t apply here!)So this is a **bonus** Santa competition for those who want an additional challenge and the opportunity to continue to improve their optimization skills. Since Santa used up all his budget on accounting fees, this is strictly a Playground competition, with the chance to win some coveted Kaggle Swag.Have fun, and Happy Holidays from the Kaggle Team!### AttributionBanner/Listing Photo by Helloquence on Unsplash'}, {'title': 'Bengali.AI Handwritten Grapheme Classification', 'url': 'https://www.kaggle.com/competitions/bengaliai-cv19', 'briefDescription': 'Classify the components of handwritten Bengali', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14897/logos/header.png?t=2019-12-16-21-37-33', 'tag': 'image, multiclass classification, weightedcategorizationaccuracy', 'description': '**Challenge and dataset summary paper available at [https://arxiv.org/abs/2010.00170](https://arxiv.org/abs/2010.00170)**Bengali is the 5th most spoken language in the world with hundreds of million of speakers. It’s the official language of Bangladesh and the second most spoken language in India. Considering its reach, there’s significant business and educational interest in developing AI that can optically recognize images of the language handwritten. This challenge hopes to improve on approaches to Bengali recognition.Optical character recognition is particularly challenging for Bengali. While Bengali has 49 letters (to be more specific 11 vowels and 38 consonants) in its alphabet, there are also 18 potential diacritics, or accents. This means that there are many more graphemes, or the smallest units in a written language. The added complexity results in ~13,000 different grapheme variations (compared to English’s 250 graphemic units).Bangladesh-based non-profit [Bengali.AI](https://bengali.ai/) is focused on helping to solve this problem. They build and release crowdsourced, metadata-rich datasets and open source them through research competitions. Through this work, Bengali.AI hopes to democratize and accelerate research in Bengali language technologies and to promote machine learning education.For this competition, you’re given the image of a handwritten Bengali grapheme and are challenged to separately classify three constituent elements in the image: grapheme root, vowel diacritics, and consonant diacritics.By participating in the competition, you’ll hopefully accelerate Bengali handwritten optical character recognition research and help enable the digitalization of educational resources. Moreover, the methods introduced in the competition will also empower cousin languages in the Indian subcontinent.Acknowledgements:Apurba: Apurba is the exclusive sponsor of Bengali.AI for this competition. Apurba Technologies Inc. is founded by a group of technology veterans who have been working at the cutting edge of software development in Silicon Valley for many years. Apart from its many ventures, Apurba is a pioneer in Bengali NLP research today and is accelerating AI research in Bangladesh through its contributions.  Intelligent Machines Limited: Intelligent Machines Limited is the technical partner of Bengali.AI for this competition and is providing compute support to Bangladeshi students. IML is an Artificial Intelligence and Advanced Analytics startup offering customized solutions to businesses in Bangladesh. IML believes in the strength of Bangladeshi talented resources and in the possibility of a far greater and developed Bangladesh in the coming days.**If you use this dataset in your research, please cite this paper**@inproceedings{alam2021large,  title={A Large Multi-target Dataset of Common Bengali Handwritten Graphemes},  author={Alam, Samiul and Reasat, Tahsin and Sushmit, Asif Shahriyar and Siddique, Sadi Mohammad and Rahman, Fuad and Hasan, Mahady and Humayun, Ahmed Imtiaz},  booktitle={International Conference on Document Analysis and Recognition},  pages={383--398},  year={2021},  organization={Springer}}'}, {'title': 'Deepfake Detection Challenge', 'url': 'https://www.kaggle.com/competitions/deepfake-detection-challenge', 'briefDescription': 'Identify videos with facial or voice manipulations', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/16880/logos/header.png?t=2019-12-02-22-11-52', 'tag': 'video data, logloss', 'description': \"**This competition is closed for submissions. Participants' selected code submissions were re-run by the host on a privately-held test set and the [private leaderboard results have been finalized](https://www.kaggle.com/c/deepfake-detection-challenge/discussion/157925). Late submissions will not be opened, due to an inability to replicate the unique design of this competition.**Deepfake techniques, which present realistic AI-generated videos of people doing and saying fictional things, have the potential to have a significant impact on how people determine the legitimacy of information presented online. These content generation and modification technologies may affect the quality of public discourse and the safeguarding of human rights—especially given that deepfakes may be used maliciously as a source of misinformation, manipulation, harassment, and persuasion. Identifying manipulated media is a technically demanding and rapidly evolving challenge that requires collaborations across the entire tech industry and beyond. AWS, Facebook, Microsoft, the Partnership on AI’s Media Integrity Steering Committee, and academics have come together to build the Deepfake Detection Challenge (DFDC). The goal of the challenge is to spur researchers around the world to build innovative new technologies that can help detect deepfakes and manipulated media.Challenge participants must submit their code into a black box environment for testing. Participants will have the option to make their submission open or closed when accepting the prize. Open proposals will be eligible for challenge prizes as long as they abide by the open source licensing terms. Closed proposals will be proprietary and not be eligible to accept the prizes. Regardless of which track is chosen, all submissions will be evaluated in the same way. Results will be shown on the leaderboard. The PAI Steering Committee has emphasized the need to ensure that all technical efforts incorporate attention to how the resulting code and products based on it can be made as accessible and useful as possible to key frontline defenders of information quality such as journalists and civic leaders around the world. The DFDC results will be a contribution to this effort and building a robust response to the emergent threat deepfakes pose globally. \"}, {'title': \"Santa's Workshop Tour 2019\", 'url': 'https://www.kaggle.com/competitions/santa-workshop-tour-2019', 'briefDescription': 'In the notebook we can build a model, and pretend that it will optimize...', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/17233/logos/header.png?t=2019-11-21-22-35-57', 'tag': 'optimization, holidays and cultural events, custom metric', 'description': \"Hammers ring, are you listenin’In the shop, toys are glistenin’Should they see the sights?There might be a fight…Walkin’ ‘round the Workshop WonderlandFamilies said, they want to see itSanta said, he’d guarantee itThey pick a dateBut they may have to waitWalkin’  ‘round the Workshop WonderlandWe told Santa that he was a madmanHe just wants to make sure they all smileHe’ll say “Are you flexible?“, They’ll say “Yeah man,But can you help us make it worth our while?”“Give them food, or sweaterthe more they wait, the gifts get better”Please help us rankOr we’ll break the bank!Walkin’ ’round the Workshop WonderlandSanta has exciting news! For 100 days before Christmas, he opened up tours to his workshop. Because demand was so strong, and because Santa wanted to make things as fair as possible, he let each of the 5,000 families that will visit the workshop choose a list of dates they'd like to attend the workshop.Now that all the families have sent Santa their preferences, he's realized it's impossible for everyone to get their top picks, so he's decided to provide extra perks for families that don't get their preferences. In addition, Santa's accounting department has told him that, depending on how families are scheduled, there may be some unexpected and hefty costs incurred.Santa needs the help of the Kaggle community to optimize which day each family is assigned to attend the workshop in order to minimize any extra expenses that would cut into next years toy budget! Can you help Santa out?### AttributionBanner/Listing Photo by Nathan Lemon on UnsplashDescription Photo by Markus Spiske on Unsplash\"}, {'title': 'NFL 1st and Future - Analytics', 'url': 'https://www.kaggle.com/competitions/nfl-playing-surface-analytics', 'briefDescription': 'Can you investigate the relationship between the playing surface and the injury and performance of NFL athletes?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12125/logos/header.png?t=2018-11-30-18-08-32', 'tag': 'tabular, sports', 'description': \"# Welcome In this challenge, you're tasked to investigate the relationship between the playing surface and the injury and performance of National Football League (NFL) athletes and to examine factors that may contribute to lower extremity injuries.You'll also notice there isn't a leaderboard, and you are not required to develop a predictive model. This isn't a traditional supervised Kaggle machine learning competition. For more information on this challenge format, see this [forum thread](https://www.kaggle.com/c/nfl-playing-surface-analytics/discussion/118974). This challenge is part of NFL 1st & Future, the NFL’s annual Super Bowl competition designed to spur innovation in player health, safety and performance.## The ChallengeIn the NFL, 12 stadiums have fields with synthetic turf.  Recent investigations of lower limb injuries among football athletes have indicated significantly higher injury rates on synthetic turf compared with natural turf (Mack et al., 2018; Loughran et al., 2019).  In conjunction with the epidemiologic investigations, biomechanical studies of football cleat-surface interactions have shown that synthetic turf surfaces do not release cleats as readily as natural turf and may contribute to the incidence of non-contact lower limb injuries (Kent et al., 2015).  Given these differences in cleat-turf interactions, it has yet to be determined whether player movement patterns and other measures of player performance differ across playing surfaces and how these may contribute to the incidence of lower limb injury.   Now, the NFL is challenging Kagglers to help them examine the effects that playing on synthetic turf versus natural turf can have on player movements and the factors that may contribute to lower extremity injuries.  NFL player tracking, also known as Next Gen Stats, is the capture of real time location data, speed and acceleration for every player, every play on every inch of the field. As part of this challenge, the NFL has provided full player tracking of on-field position for 250 players over two regular season schedules.  One hundred of the athletes in the study data set sustained one or more injuries during the study period that were identified as a non-contact injury of a type that may have turf interaction as a contributing factor to injury.  The remaining 150 athletes serve as a representative sample of the larger NFL population that did not sustain a non-contact lower-limb injury during the study period.  Details of the surface type and environmental parameters that may influence performance and outcome are also provided.  Your challenge is to characterize any differences in player movement between the playing surfaces and identify specific scenarios (e.g., field surface, weather, position, play type, etc.) that interact with player movement to present an elevated risk of injury.  More details on the entry criteria are available in [Evaluation Tab](https://www.kaggle.com/c/nfl-playing-surface-analytics/overview/evaluation).## About The NFLThe National Football League is America's most popular sports league, comprised of 32 franchises that compete each year to win the Super Bowl, the world's biggest annual sporting event. Founded in 1920, the NFL developed the model for the successful modern sports league, including national and international distribution, extensive revenue sharing, competitive excellence, and strong franchises across the country.The NFL is committed to advancing progress in the diagnosis, prevention and treatment of sports-related injuries. The NFL's ongoing health and safety efforts include support for independent medical research and engineering advancements and a commitment to work to better protect players and make the game safer, including enhancements to medical protocols and improvements to how our game is taught and played.As more is learned, the league evaluates and changes rules to evolve the game and try to improve protections for players. Since 2002 alone, the NFL has made 50 rules changes intended to eliminate potentially dangerous tactics and reduce the risk of injuries.For more information about the NFL's health and safety efforts, please visit www.PlaySmartPlaySafe.com----------[Evaluation][2]  [1]: https://www.kaggle.com/c/NFL-Punt-Analytics-Competition/discussion/73664  [2]: https://www.kaggle.com/c/NFL-playing-surface-Analytics#evaluation\"}, {'title': 'Google QUEST Q&A Labeling', 'url': 'https://www.kaggle.com/competitions/google-quest-challenge', 'briefDescription': 'Improving automated understanding of complex question answer content', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7968/logos/header.png?t=2017-12-01-22-29-43', 'tag': 'nlp, text, mcspearmanr', 'description': 'Computers are really good at answering questions with single, verifiable answers. But, humans are often still better at answering questions about opinions, recommendations, or personal experiences. Humans are better at addressing subjective questions that require a deeper, multidimensional understanding of context - something computers aren\\'t trained to do well...yet.. Questions can take many forms - some have multi-sentence elaborations, others may be simple curiosity or a fully developed problem. They can have multiple intents, or seek advice and opinions. Some may be helpful and others interesting. Some are simple right or wrong. ![](https://storage.googleapis.com/kaggle-media/competitions/google-research/human_computable_dimensions_1.png)Unfortunately, it’s hard to build better subjective question-answering algorithms because of a lack of data and predictive models. That’s why the [CrowdSource](https://crowdsource.google.com/) team at Google Research, a group dedicated to advancing NLP and other types of ML science via crowdsourcing, has collected data on a number of these quality scoring aspects.In this competition, you’re challenged to use this new dataset to build predictive algorithms for different subjective aspects of question-answering. The question-answer pairs were gathered from nearly 70 different websites, in a \"common-sense\" fashion. Our raters received minimal guidance and training, and relied largely on their subjective interpretation of the prompts. As such, each prompt was crafted in the most intuitive fashion so that raters could simply use their common-sense to complete the task. By lessening our dependency on complicated and opaque rating guidelines, we hope to increase the re-use value of this data set. What you see is what you get!Demonstrating these subjective labels can be predicted reliably can shine a new light on this research area. Results from this competition will inform the way future intelligent Q&A systems will get built, hopefully contributing to them becoming more human-like.'}, {'title': '2019 Kaggle Machine Learning & Data Science Survey', 'url': 'https://www.kaggle.com/competitions/kaggle-survey-2019', 'briefDescription': 'The most comprehensive dataset available on the state of ML and data science', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/16394/logos/header.png?t=2019-10-17-20-37-58', 'tag': 'jobs and career, survey analysis', 'description': '# OverviewWelcome to Kaggle\\'s third annual Machine Learning and Data Science Survey ― and our second-ever survey data challenge.  [You can read our executive summary here](https://www.kaggle.com/kaggle-survey-2019).This year, as in [2017][1] and [2018](https://www.kaggle.com/kaggle/kaggle-survey-2018/), we set out to conduct an industry-wide survey that presents a truly comprehensive view of the state of data science and machine learning. The survey was live for three weeks in October, and after cleaning the data we finished with 19,717 responses!There\\'s a lot to explore here. The results include raw numbers about who is working with data, what’s happening with machine learning in different industries, and the best ways for new data scientists to break into the field. We\\'ve published the data in as raw a format as possible without compromising anonymization, which makes it an unusual example of a survey dataset.---# ChallengeThis year Kaggle is launching the second annual Data Science Survey Challenge, where we will be awarding a prize pool of $30,000 to notebook authors who tell a rich story about a subset of the data science and machine learning community.In our third year running this survey, we were once again awed by the global, diverse, and dynamic nature of the data science and machine learning industry. This [survey data EDA][4] provides an overview of the industry on an aggregate scale, but it also leaves us wanting to know more about the many specific communities comprised within the survey. For that reason, we’re inviting the Kaggle community to dive deep into the survey datasets and help us tell the diverse stories of data scientists from around the world.  **The challenge objective:** tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration. A “story” could be defined any number of ways, and that’s deliberate. The challenge is to deeply explore (through data) the impact, priorities, or concerns of a specific group of data science and machine learning practitioners. That group can be defined in the macro (for example: anyone who does most of their coding in Python) or the micro (for example: female data science students studying machine learning in masters programs). This is an opportunity to be creative and tell the story of a community you identify with or are passionate about! Submissions will be evaluated on the following:  - Composition - Is there a clear narrative thread to the story that’s articulated and supported by data? The subject should be well defined, well researched, and well supported through the use of data and visualizations.  - Originality - Does the reader learn something new through this submission? Or is the reader challenged to think about something in a new way? A great entry will be informative, thought provoking, and fresh all at the same time.   - Documentation - Are your code, and notebook, and additional data sources well documented so a reader can understand what you did? Are your sources clearly cited? A high quality analysis should be concise and clear at each step so the rationale is easy to follow and the process is reproducible To be valid, a submission must be contained in one notebook, made public on or before the submission deadline. Participants are free to use any datasets in addition to the Kaggle Data Science survey, but those datasets must also be publicly available on Kaggle by the deadline for a submission to be valid. ---# How to Participate To make a submission, complete the [submission form][3]. Only one submission will be judged per participant, so if you make multiple submissions we will review the last (most recent) entry. No submission is necessary for the Weekly Notebook Award. To be eligible, a notebook must be public and use the 2019 Data Science Survey as a data source. Submission deadline: 11:59PM UTC, December 2nd, 2019.---# Survey Methodology - This survey received 19,717 usable respondents from 171 countries and   territories. If a country or territory received less than 50   respondents, we grouped them into a group named “Other” for   anonymity.    - We excluded respondents who were flagged by our survey system as   “Spam”.    - Most of our respondents were found primarily through Kaggle channels,   like our email list, discussion forums and social media channels.    - The survey was live from October 8th to October 28th. We allowed   respondents to complete the survey at any time during that window.    The median response time for those who participated in the survey was   approximately 10 minutes.    - Not every question was shown to every respondent. You can learn more   about the different segments we used in the survey_schema.csv file.  In general, respondents with more experience were asked more questions and respondents with less experience were asked less questions.    - To protect the respondents’ identity, the answers to multiple choice   questions have been separated into a separate data file from the   open-ended responses. We do not provide a key to match up the   multiple choice and free form responses. Further, the free form   responses have been randomized column-wise such that the responses   that appear on the same row did not necessarily come from the same   survey-taker. - Multiple choice single response questions fit into individual columns whereas multiple choice multiple response questions were split into multiple columns. Text responses were encoded to protect user privacy and countries with fewer than 50 respondents were grouped into the category \"other\".Data has been released under a CC 2.0 license: https://creativecommons.org/licenses/by/2.0/__________________________________________________  [1]: https://www.kaggle.com/kaggle/kaggle-survey-2017  [2]: http://blog.kaggle.com/  [3]: https://www.kaggle.com/page/2019-data-science-survey-challenge-submission  [4]: https://www.kaggle.com/paultimothymooney/how-to-explore-the-2019-kaggle-survey-data'}, {'title': 'TensorFlow 2.0 Question Answering', 'url': 'https://www.kaggle.com/competitions/tensorflow2-question-answering', 'briefDescription': 'Identify the answers to real user questions about Wikipedia page content', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12863/logos/header.png?t=2019-10-10-15-55-15', 'tag': 'text, text mining, custom metric', 'description': \"*“Why is the sky blue?”*This is a question an [open-domain question answering](https://en.wikipedia.org/wiki/Question_answering#Open_domain_question_answering) (QA) system should be able to respond to. QA systems emulate how people look for information by reading the web to return answers to common questions. Machine learning can be used to improve the accuracy of these answers.Existing natural language models have been focused on extracting answers from a short paragraph rather than reading an entire page of content for proper context. As a result, the responses can be complicated or lengthy. A good answer will be both succinct and relevant.In this competition, your goal is to predict short and long answer responses to real questions about Wikipedia articles. The dataset is provided by [Google's Natural Questions](https://ai.google.com/research/NaturalQuestions/dataset), but contains its own unique private test set. A [visualization of examples](https://ai.google.com/research/NaturalQuestions/visualization) shows long and—where available—short answers. In addition to prizes for the top teams, there is a special set of awards for using TensorFlow 2.0 APIs. If successful, this challenge will help spur the development of more effective and robust QA systems.### About TensorFlowTensorFlow is an open source platform for machine learning. With TensorFlow 2.0, tf.keras is the preferred high-level API for TensorFlow, to make model building easier and more intuitive. You may use the [tf.keras built-in compile()/fit() methods](https://www.tensorflow.org/guide/keras/train_and_evaluate#part_i_using_build-in_training_evaluation_loops), or write your own [custom training loops](https://www.tensorflow.org/guide/keras/train_and_evaluate#part_ii_writing_your_own_training_evaluation_loops_from_scratch). See the [Effective TensorFlow 2.0 guide](https://www.tensorflow.org/guide/effective_tf2) and the [tf.keras guide](https://www.tensorflow.org/guide/keras/) for more details.TensorFlow 2.0 was [recently released](https://medium.com/tensorflow/tensorflow-2-0-is-now-available-57d706c2a9ab) and this competition is to challenge Kagglers to use TensorFlow 2.0’s APIs focused on usability, and easier, more intuitive development, to make advancements on Question Answering. \"}, {'title': '2019 Data Science Bowl', 'url': 'https://www.kaggle.com/competitions/data-science-bowl-2019', 'briefDescription': 'Uncover the factors to help measure how young children learn', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/16531/logos/header.png?t=2019-10-11-20-50-18', 'tag': 'education, video games, people, quadraticweightedkappa', 'description': '### Illuminate Learning. Ignite Possibilities.Uncover new insights in early childhood education and how media can support learning outcomes. Participate in our fifth annual Data Science Bowl, presented by Booz Allen Hamilton and Kaggle.PBS KIDS, a trusted name in early childhood education for decades, aims to gain insights into how media can help children learn important skills for success in school and life.  In this challenge, you’ll use anonymous gameplay data, including knowledge of videos watched and games played, from the PBS KIDS Measure Up! app, a game-based learning tool developed as a part of the CPB-PBS Ready To Learn Initiative with funding from the U.S. Department of Education. Competitors will be challenged to predict scores on in-game assessments and create an algorithm that will lead to better-designed games and improved learning outcomes. Your solutions will aid in discovering important relationships between engagement with high-quality educational media and learning processes.Data Science Bowl is the world’s largest data science competition focused on social good. Each year, this competition gives Kagglers a chance to use their passion to change the world. Over the last four years, more than 50,000+ Kagglers have submitted over 114,000+ submissions, to improve everything from lung cancer and heart disease detection to ocean health. For more information on the Data Science Bowl, please visit [DataScienceBowl.com](https://datasciencebowl.com/)## Where does the data for the competition come from?The data used in this competition is anonymous, tabular data of interactions with the PBS KIDS Measure Up! app. Select data, such as a user’s in-app assessment score or their path through the game, is collected by the PBS KIDS Measure Up! app, a game-based learning tool. PBS KIDS is committed to creating a safe and secure environment that family members of all ages can enjoy. The PBS KIDS Measure Up! app does not collect any personally identifying information, such as name or location. All of the data used in the competition is anonymous. To view the full PBS KIDS privacy policy, please visit: pbskids.org/privacy.No one will be able to download the entire data set and the participants do not have access to any personally identifiable information about individual users. The Data Science Bowl and the use of data for this year’s competition has been reviewed to ensure that it meets requirements of applicable child privacy regulations by PRIVO, a leading global industry expert in children’s online privacy.## What is the PBS KIDS Measure Up! app?In the PBS KIDS Measure Up! app, children ages 3 to 5 learn early STEM concepts focused on length, width, capacity, and weight while going on an adventure through Treetop City, Magma Peak, and Crystal Caves. Joined by their favorite PBS KIDS characters, children can also collect rewards and unlock digital toys as they play. To learn more about PBS KIDS Measure Up!, please click [here](https://pbskids.org/apps/pbs-kids-measure-up.html).*PBS KIDS and the PBS KIDS Logo are registered trademarks of PBS. Used with permission. The contents of PBS KIDS Measure Up! were developed under a grant from the Department of Education. However, those contents do not necessarily represent the policy of the Department of Education, and you should not assume endorsement by the Federal Government. The app is funded by a Ready To Learn grant (PR/AWARD No. U295A150003, CFDA No. 84.295A) provided by the Department of Education to the Corporation for Public Broadcasting.*'}, {'title': 'Peking University/Baidu - Autonomous Driving', 'url': 'https://www.kaggle.com/competitions/pku-autonomous-driving', 'briefDescription': 'Can you predict vehicle angle in different settings?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9993/logos/header.png?t=2019-04-30-14-21-21', 'tag': 'image, computer vision, custom metric', 'description': \"Who do you think hates traffic more - humans or self-driving cars? The position of nearby automobiles is a key question for autonomous vehicles ― and it's at the heart of our newest challenge. Self-driving cars have come a long way in recent years, but they're still not flawless. Consumers and lawmakers remain wary of adoption, in part because of doubts about vehicles’ ability to accurately perceive objects in traffic.Baidu's Robotics and Autonomous Driving Lab (RAL), along with Peking University, hopes to close the gap once and for all with this challenge. They’re providing Kagglers with more than 60,000 labeled 3D car instances from 5,277 real-world images, based on industry-grade CAD car models.Your challenge: develop an algorithm to estimate the absolute pose of vehicles (6 degrees of freedom) from a single image in a real-world traffic environment.Succeed and you'll help improve computer vision. That, in turn, will bring autonomous vehicles a big step closer to widespread adoption, so they can help reduce the environmental impact of our growing societies. Please cite the following paper when using the dataset:ApolloCar3D: A Large 3D Car Instance Understanding Benchmark for Autonomous Driving@inproceedings{song2019apollocar3d,  title={Apollocar3d: A large 3d car instance understanding benchmark for autonomous driving},  author={Song, Xibin and Wang, Peng and Zhou, Dingfu and Zhu, Rui and Guan, Chenye and Dai, Yuchao and Su, Hao and Li, Hongdong and Yang, Ruigang},  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},  pages={5452--5462},  year={2019}}\"}, {'title': 'ASHRAE - Great Energy Predictor III', 'url': 'https://www.kaggle.com/competitions/ashrae-energy-prediction', 'briefDescription': 'How much energy will a building consume?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9994/logos/header.png?t=2019-10-04-23-03-48', 'tag': 'tabular, energy, rmsle', 'description': 'Q: How much does it cost to cool a skyscraper in the summer?A: A lot! And not just in dollars, but in environmental impact.Thankfully, significant investments are being made to improve building efficiencies to reduce costs and emissions. The question is, are the improvements working? That’s where you come in. Under pay-for-performance financing, the building owner makes payments based on the difference between their real energy consumption and what they would have used without any retrofits. The latter values have to come from a model. Current methods of estimation are fragmented and do not scale well. Some assume a specific meter type or don’t work with different building types.In this competition, you’ll develop accurate models of metered building energy usage in the following areas: chilled water, electric, hot water, and steam meters. The data comes from over 1,000 buildings over a three-year timeframe. With better estimates of these energy-saving investments, large scale investors and financial institutions will be more inclined to invest in this area to enable progress in building efficiencies.**About the Host**![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1095143%2Ff9ab8963dea5e7c1716f47310daa96ab%2FASHRAE_Logo_25.jpg?generation=1570808142334850&alt=media)Founded in 1894, [ASHRAE](https://www.ashrae.org/) serves to advance the arts and sciences of heating, ventilation, air conditioning refrigeration and their allied fields. ASHRAE members represent building system design and industrial process professionals around the world. With over 54,000 members serving in 132 countries, [ASHRAE](https://www.ashrae.org/) supports research, standards writing, publishing and continuing education - shaping tomorrow’s built environment today.Banner photo by Federico Beccari on Unsplash'}, {'title': 'NFL Big Data Bowl', 'url': 'https://www.kaggle.com/competitions/nfl-big-data-bowl-2020', 'briefDescription': 'How many yards will an NFL player gain after receiving a handoff?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/15696/logos/header.png?t=2019-10-04-16-16-53', 'tag': 'sports, football, crps', 'description': \"*“The running back takes the handoff… he breaks a tackle...spins... and breaks free! One man to beat! Past the 50-yard-line! To the 40! The 30! He! Could! Go! All! The! Way!”*But will he?American football is a complex sport. From the 22 players on the field to specific characteristics that ebb and flow throughout the game, it can be challenging to quantify the value of specific plays and actions within a play.  Fundamentally, the goal of football is for the offense to run (rush) or throw (pass) the ball to gain yards, moving towards, then across, the opposing team’s side of the field in order to score. And the goal of the defense is to prevent the offensive team from scoring. In the National Football League (NFL), roughly a third of teams’ offensive yardage comes from run plays.. Ball carriers are generally assigned the most credit for these plays, but their teammates (by way of blocking), coach (by way of play call), and the opposing defense also play a critical role. Traditional metrics such as ‘yards per carry’ or ‘total rushing yards’ can be flawed; in this competition, the NFL aims to provide better context into what contributes to a successful run play.As an “armchair quarterback” watching the game, you may think you can predict the result of a play when a ball carrier takes the handoff - but what does the data say? In this competition, you will develop a model to predict how many yards a team will gain on given rushing plays as they happen. You'll be provided game, play, and player-level data, including the position and speed of players as provided in the NFL’s Next Gen Stats data. And the best part - you can see how your model performs from your living room, as the leaderboard will be updated week after week on the current season’s game data as it plays out. Deeper insight into rushing plays will help teams, media, and fans better understand the skill of players and the strategies of coaches. It will also assist the NFL and its teams evaluate the ball carrier, his teammates, his coach, and the opposing defense, in order to make adjustments as necessary.Additionally, the winning model will be provided to the NFL’s Next Gen Stats group to potentially share with teams. You could help the NFL Network generate models to use during games, or for pre-game/post-game breakdowns.\"}, {'title': 'Kannada MNIST', 'url': 'https://www.kaggle.com/competitions/Kannada-MNIST', 'briefDescription': 'MNIST like datatset for Kannada handwritten digits', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/16017/logos/header.png?t=2019-09-11-17-07-02', 'tag': 'image, computer vision, categorizationaccuracy', 'description': '### Bored of MNIST?The goal of this competition is to provide a simple extension to the classic [MNIST competition](https://www.kaggle.com/c/digit-recognizer/) we\\'re all familiar with. Instead of using Arabic numerals, it uses a recently-released dataset of Kannada digits.Kannada is a language spoken predominantly by people of Karnataka in southwestern India. The language has roughly 45 million native speakers and is written using the Kannada script. [Wikipedia](https://en.wikipedia.org/wiki/Kannada)![](https://storage.googleapis.com/kaggle-media/competitions/Kannada-MNIST/kannada.png)This competition uses the same format as the [MNIST competition](https://www.kaggle.com/c/digit-recognizer/) in terms of how the data is structured, but it\\'s different in that it is a synchronous re-run Kernels competition. You write your code in a Kaggle Notebook, and when you submit the results, your code is scored on both the public test set, as well as a private (unseen) test set.### Technical InformationAll details of the dataset curation has been captured in the paper titled: Prabhu, Vinay Uday. \"Kannada-MNIST: A new handwritten digits dataset for the Kannada language.\" arXiv preprint [arXiv:1908.01242 (2019)](https://arxiv.org/abs/1908.01242)The github repo of the author [can be found here](https://github.com/vinayprabhu/Kannada_MNIST).On the [originally-posted dataset](https://www.kaggle.com/higgstachyon/kannada-mnist), the author suggests some interesting questions you may be interested in exploring. Please note, although this dataset has been released in full, the purpose of this competition is for practice, not to find the labels to submit a perfect score. In addition to the _main_ dataset, the author also disseminated an additional real world handwritten dataset (with 10k images), termed as the \\'Dig-MNIST dataset\\' that can serve as an out-of-domain test dataset. It was created with the help of volunteers that were non-native users of the language, authored on a smaller sheet and scanned with different scanner settings compared to the _main_ dataset. This \\'dig-MNIST\\' dataset serves as a more difficult test-set (An accuracy of 76.1% was reported in the paper cited above) and achieving ~98+% accuracy on this test dataset would be rather commendable.### AcknowledgmentsKaggle thanks [Vinay Prabhu](https://www.kaggle.com/higgstachyon) for providing this interesting dataset for a Playground competition.Image reference: https://www.researchgate.net/figure/speech-for-Kannada-numbers_fig2_313113588'}, {'title': 'RSNA Intracranial Hemorrhage Detection', 'url': 'https://www.kaggle.com/competitions/rsna-intracranial-hemorrhage-detection', 'briefDescription': 'Identify acute intracranial hemorrhage and its subtypes', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13451/logos/header.png?t=2019-08-26-19-47-30', 'tag': 'image, weightedmeancolumnwiselogloss', 'description': 'Intracranial hemorrhage, bleeding that occurs inside the cranium, is a serious health problem requiring rapid and often intensive medical treatment. For example, intracranial hemorrhages account for approximately 10% of strokes in the U.S., where stroke is the fifth-leading cause of death. Identifying the location and type of any hemorrhage present is a critical step in treating the patient. Diagnosis requires an urgent procedure. When a patient shows acute neurological symptoms such as severe headache or loss of consciousness, highly trained specialists review medical images of the patient’s cranium to look for the presence, location and type of hemorrhage. The process is complicated and often time consuming. In this competition, your challenge is to build an algorithm to detect acute intracranial hemorrhage and [its subtypes](https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection/overview/hemorrhage-types). You’ll develop your solution using a rich image dataset provided by the Radiological Society of North America (RSNA®) in collaboration with members of the American Society of Neuroradiology and MD.ai. If successful, you’ll help the medical community identify the presence, location and type of hemorrhage in order to quickly and effectively treat affected patients.Challenge participants may be invited to present their AI models and methodologies during an award ceremony at the RSNA Annual Meeting which will be held in Chicago, Illinois, USA, from December 1-6, 2019.###CollaboratorsFour research institutions provided large volumes of de-identified CT studies that were assembled to create the challenge dataset: Stanford University, Thomas Jefferson University, Unity Health Toronto and Universidade Federal de São Paulo (UNIFESP), The American Society of Neuroradiology ([ASNR](https://www.asnr.org/)) organized a cadre of more than 60 volunteers to label over 25,000 exams for the challenge dataset. ASNR is the world’s leading organization for the future of neuroradiology representing more than 5,300 radiologists, researchers, interventionalists, and imaging scientists. MD.ai provided tooling and support for the data annotation process. The RSNA is an international society of radiologists, medical physicists and other medical professionals with more than 54,000 members from 146 countries across the globe. They see the potential for AI to assist in detection and classification of hemorrhages in order to prioritize and expedite their clinical work.[A full set of acknowledgments can be found on this page](https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection/overview/acknowledgments).'}, {'title': 'BigQuery-Geotab Intersection Congestion', 'url': 'https://www.kaggle.com/competitions/bigquery-geotab-intersection-congestion', 'briefDescription': 'Can you predict wait times at major city intersections?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14859/logos/header.png?t=2019-08-02-18-39-35', 'tag': 'tabular, regression, geospatial analysis, cities and urban areas, rmse', 'description': 'We’ve all been there: Stuck at a traffic light, only to be given mere seconds to pass through an intersection, behind a parade of other commuters. Imagine if you could help city planners and governments anticipate traffic hot spots ahead of time and reduce the stop-and-go stress of millions of commuters like you.[Geotab](https://www.geotab.com/) provides a [wide variety of aggregate datasets](https://data.geotab.com/intelligence-data) gathered from commercial vehicle telematics devices. Harnessing the insights from this data has the power to improve safety, optimize operations, and identify opportunities for infrastructure challenges.The dataset for this competition includes aggregate stopped vehicle information and intersection wait times. Your task is to predict congestion, based on an aggregate measure of stopping distance and waiting times, at intersections in 4 major US cities: Atlanta, Boston, Chicago & Philadelphia. This competition is being hosted in partnership with [BigQuery](https://cloud.google.com/bigquery/), a data warehouse for manipulating, joining, and querying large scale tabular datasets. BigQuery also offers BigQuery ML, an easy way for users to create and run machine learning models to generate predictions through a SQL query interface.Kaggle recently released a BigQuery integration within our kernels notebook environment, and [this starter kernel](https://www.kaggle.com/sirtorry/bigquery-ml-template-intersection-congestion) gives you a great starting point for how to use BQ & BQML. You’re encouraged to use your data savvy, resourcefulness & intuition to find and join in additional external datasets that will increase your models’ predictive power.Alright, stop waiting and get started!### Acknowledgments![Geotab](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F603584%2F2c4691c7ddb4cef68c23efaa16bcbf57%2Fgeotab-logo-300.jpg?generation=1566501523911770&alt=media)**A big thanks to Geotab for providing the dataset for this competition!** Geotab is advancing security, connecting commercial vehicles to the internet and providing web-based analytics to help customers better manage their fleets. Geotab’s open platform and Marketplace, offering hundreds of third-party solution options, allows both small and large businesses to automate operations by integrating vehicle data with their other data assets. As an IoT hub, the in-vehicle device provides additional functionality through IOX Add-Ons. Processing billions of data points a day, Geotab leverages data analytics and machine learning to help customers improve productivity, optimize fleets through the reduction of fuel consumption, enhance driver safety, and achieve strong compliance to regulatory changes. Geotab’s products are represented and sold worldwide through Authorized Geotab Resellers. To learn more, please visit [www.geotab.com](https://www.geotab.com/) and follow us [@GEOTAB](https://twitter.com/GEOTAB) and on [LinkedIn](https://www.linkedin.com/company/geotab/).  '}, {'title': 'Lyft 3D Object Detection for Autonomous Vehicles', 'url': 'https://www.kaggle.com/competitions/3d-object-detection-for-autonomous-vehicles', 'briefDescription': 'Can you advance the state of the art in 3D object detection? ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/15768/logos/header.png?t=2019-09-10-21-24-06', 'tag': 'image, custom metric', 'description': 'Self-driving technology presents a rare opportunity to improve the quality of life in many of our communities. Avoidable collisions, single-occupant commuters, and vehicle emissions are choking cities, while infrastructure strains under rapid urban growth. Autonomous vehicles are expected to redefine transportation and unlock a myriad of societal, environmental, and economic benefits. You can apply your data analysis skills in this competition to advance the state of self-driving technology.[Lyft](https://level5.lyft.com/), whose mission is to improve people’s lives with the world’s best transportation, is investing in the future of self-driving vehicles. Level 5, their self-driving division, is working on a fleet of autonomous vehicles, and currently has a team of 450+ across Palo Alto, London, and Munich working to build a leading self-driving system ([they’re hiring!](https://level5.lyft.com/#joinourteam)). Their goal is to democratize access to self-driving technology for hundreds of millions of Lyft passengers.From a technical standpoint, however,  the bar to unlock technical research and development on higher-level autonomy functions like perception, prediction, and planning is extremely high. This implies technical R&D on self-driving cars has traditionally been inaccessible to the broader research community.This dataset aims to democratize access to such data, and foster innovation in higher-level autonomy functions for everyone, everywhere. By conducting a competition, we hope to encourage the research community to focus on hard problems in this space—namely, 3D object detection over semantic maps. In this competition, you will build and optimize algorithms based on a large-scale dataset. This dataset features the raw sensor camera inputs as perceived by a fleet of multiple, high-end, autonomous vehicles in a restricted geographic area. If successful, you’ll make a significant contribution towards stimulating further development in autonomous vehicles and empowering communities around the world.'}, {'title': 'Categorical Feature Encoding Challenge', 'url': 'https://www.kaggle.com/competitions/cat-in-the-dat', 'briefDescription': 'Binary classification, with every feature a categorical', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14999/logos/header.png?t=2019-08-22-18-17-37', 'tag': 'tabular, binary classification, auc', 'description': \"Is there a cat in your dat?A common task in machine learning pipelines is encoding categorical variables for a given algorithm in a format that allows as much useful signal as possible to be captured.Because this is such a common task and important skill to master, we've put together a dataset that contains only categorical features, and includes:binary featureslow- and high-cardinality nominal featureslow- and high-cardinality  ordinal features(potentially) cyclical featuresThis Playground competition will give you the opportunity to try different encoding schemes for different algorithms to compare how they perform. We encourage you to share what you find with the community.If you're not sure how to get started, you can check out the Categorical Variables  section of Kaggle's Intermediate Machine Learning course.Have Fun!\"}, {'title': 'Understanding Clouds from Satellite Images', 'url': 'https://www.kaggle.com/competitions/understanding_cloud_organization', 'briefDescription': 'Can you classify cloud structures from satellites? ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13333/logos/header.png?t=2019-06-07-19-02-58', 'tag': 'image, atmospheric science, dice', 'description': \"![](https://storage.googleapis.com/kaggle-media/competitions/MaxPlanck/Teaser_AnimationwLabels.gif)Climate change has been at the top of our minds and on the forefront of important political decision-making for many years. We hope you can use this competition’s dataset to help demystify an important climatic variable. Scientists, like those at Max Planck Institute for Meteorology, are leading the charge with new research on the world’s ever-changing atmosphere and they need your help to better understand the clouds.Shallow clouds play a huge role in determining the Earth's climate. They’re also difficult to understand and to represent in climate models. By classifying different types of cloud organization, researchers at Max Planck hope to improve our physical understanding of these clouds, which in turn will help us build better climate models.There are many ways in which clouds can organize, but the boundaries between different forms of organization are murky. This makes it challenging to build traditional rule-based algorithms to separate cloud features. The human eye, however, is really good at detecting features—such as clouds that resemble flowers.In this challenge, you will build a model to classify cloud organization patterns from satellite images. If successful, you’ll help scientists to better understand how clouds will shape our future climate. This research will guide the development of next-generation models which could reduce uncertainties in climate projections.**Help us remove the haze from climate models and bring clarity to cloud identification.**_For more information on the scientific background and how the labels were created see the following [paper](https://arxiv.org/abs/1906.01906)._\"}, {'title': 'Ciphertext Challenge III', 'url': 'https://www.kaggle.com/competitions/ciphertext-challenge-iii', 'briefDescription': 'BRBTvl0LNstxQLyxulCEEq1czSFje0Z6iajczo6ktGmitTE=', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/15447/logos/header.png?t=2019-08-02-21-04-59', 'tag': 'text, categorizationaccuracy', 'description': '## Ciphertext Challenge III: Wherefore Art Thou, Simple Ciphers?We\\'ve done the [2010\\'s](https://www.kaggle.com/c/ciphertext-challenge-ii), the [1990s](https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge)... now it\\'s time for the 80s._The 1580s!!_In this new decryption competition\\'s dataset, we\\'ve gone from perfectly respectable sources of electronic horror to a time before computers—heck, before calculus was called \"calculus\"!  Shakespeare\\'s plays are encrypted, and we time travelers must un-encrypt them so people can do innovative stage productions with intricate makeup, costumes, and possibly—possibly!—Leonardo DiCaprio. Think about it, folks: _Leo_.\\\\*As in previous ciphertext challenges, [simple classic ciphers](https://www.kaggle.com/c/ciphertext-challenge-iii/data) have been used to encrypt this dataset, along with a _slightly_ less simple surprise that expands our definition of \"classic\" into the modern age. The mission is the same: to correctly match each piece of ciphertext with its corresponding piece of plaintext. Daunting! Meta-puzzles and difficulty await!Swag prizes go to the first three teams to crack all four ciphers OR to the top three teams on the leaderboard (in case the ciphers are not all cracked). Additionally, swag prizes will be awarded to the best *competition-related* kernels, in both visualization and cryptanalysis, based on upvotes.  Last, the coveted \"Phil Prize\"—for the team that correctly deduces the form AND key of the final cipher—is up for grabs again.Go ahead. Get cracking!\\\\* - _Leo!_## Acknowledgements*Many thanks to Kaggler [LiamLarson](https://www.kaggle.com/kingburrito666) for their excellent [Shakespeare dataset](https://www.kaggle.com/kingburrito666/shakespeare-plays).*'}, {'title': 'Severstal: Steel Defect Detection', 'url': 'https://www.kaggle.com/competitions/severstal-steel-defect-detection', 'briefDescription': 'Can you detect and classify defects in steel?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14241/logos/header.png?t=2019-06-17-15-52-00', 'tag': 'image, manufacturing, dice', 'description': 'Steel is one of the most important building materials of modern times. Steel buildings are resistant to natural and man-made wear which has made the material ubiquitous around the world. To help make production of steel more efficient, this competition will help identify defects.[Severstal][1] is leading the charge in efficient steel mining and production. They believe the future of metallurgy requires development across the economic, ecological, and social aspects of the industry—and they take corporate responsibility seriously. The company recently created the country’s largest industrial data lake, with petabytes of data that were previously discarded. Severstal is now looking to machine learning to improve automation, increase efficiency, and maintain high quality in their production.The production process of flat sheet steel is especially delicate. From heating and rolling, to drying and cutting, several machines touch flat steel by the time it’s ready to ship. Today, Severstal uses images from high frequency cameras to power a defect detection algorithm. In this competition, you’ll help engineers improve the algorithm by localizing and classifying surface defects on a steel sheet.If successful, you’ll help keep manufacturing standards for steel high and enable Severstal to continue their innovation, leading to a stronger, more efficient world all around us.  [1]: https://www.severstal.com/eng/'}, {'title': 'Kuzushiji Recognition', 'url': 'https://www.kaggle.com/competitions/kuzushiji-recognition', 'briefDescription': 'Opening the door to a thousand years of Japanese culture', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13578/logos/header.png?t=2019-04-24-22-47-58', 'tag': 'image, multiclass classification, history, japan, custom metric', 'description': \"###**Build a model to transcribe ancient Kuzushiji into contemporary Japanese characters**###Imagine the history contained in a thousand years of books. What stories are in those books? What knowledge can we learn from the world before our time? What was the weather like 500 years ago? What happened when Mt. Fuji erupted? How can one fold 100 cranes using only one piece of paper? The answers to these questions are in those books.Japan has millions of books and over a billion historical documents such as personal letters or diaries preserved nationwide. Most of them cannot be read by the majority of Japanese people living today because they were written in “Kuzushiji”.Even though Kuzushiji, a cursive writing style, had been used in Japan for over a thousand years, there are very few fluent readers of Kuzushiji today (only 0.01% of modern Japanese natives). Due to the lack of available human resources, there has been a great deal of interest in using Machine Learning to automatically recognize these historical texts and transcribe them into modern Japanese characters. Nevertheless, several challenges in Kuzushiji recognition have made the performance of existing systems extremely poor. (More information in [About Kuzushiji](https://www.kaggle.com/c/kuzushiji-recognition/overview/about-kuzushiji)) This is where you come in. The hosts need help from machine learning experts to transcribe Kuzushiji into contemporary Japanese characters. With your help, Center for Open Data in the Humanities (CODH) will be able to develop better algorithms for Kuzushiji recognition. The model is not only a great contribution to the machine learning community, but also a great help for making millions of documents more accessible and leading to new discoveries in Japanese history and culture.![](http://static.mxbi.net/umgy001-010-smallannomasked.jpg)##Hosts##**[Center for Open Data  in the Humanities (CODH)](http://codh.rois.ac.jp/)**  conducts research and development to enhance access to humanities data using state-of-the-art technology in informatics and statistics.**[The National Institute of Japanese Literature (NIJL)](https://www.nijl.ac.jp/en/)** is an institution which strives to serve researchers in the field of Japanese literature as well as those working in various other humanities, by collecting in one location a vast storage of materials related to Japanese literature gathered from all corners of the country. **[The National Institute of Informatics (NII)](https://www.nii.ac.jp/en/)** is Japan's only general academic research institution seeking to create future value in the new discipline of informatics. NII seeks to advance integrated research and development activities in information-related fields, including networking, software, and content.**Official Collaborators**Mikel Bober-Irizar ([anokas](https://www.kaggle.com/anokas)) Kaggle Grandmaster and Alex Lamb (MILA. Quebec Artificial Intelligence Institute)\"}, {'title': 'IEEE-CIS Fraud Detection', 'url': 'https://www.kaggle.com/competitions/ieee-fraud-detection', 'briefDescription': 'Can you detect fraud from customer transactions?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14242/logos/header.png?t=2019-07-11-17-52-31', 'tag': 'tabular, binary classification, auc', 'description': \"Imagine standing at the check-out counter at the grocery store with a long line behind you and the cashier not-so-quietly announces that your card has been declined. In this moment, you probably aren’t thinking about the data science that determined your fate.Embarrassed, and certain you have the funds to cover everything needed for an epic nacho party for 50 of your closest friends, you try your card again. Same result. As you step aside and allow the cashier to tend to the next customer, you receive a text message from your bank. “Press 1 if you really tried to spend $500 on cheddar cheese.”While perhaps cumbersome (and often embarrassing) in the moment, this fraud prevention system is actually saving consumers millions of dollars per year. Researchers from the [IEEE Computational Intelligence Society](https://cis.ieee.org/) (IEEE-CIS) want to improve this figure, while also improving the customer experience. With higher accuracy fraud detection,  you can get on with your chips without the hassle.IEEE-CIS works across a variety of AI and machine learning areas, including deep neural networks, fuzzy systems, evolutionary computation, and swarm intelligence. Today they’re partnering with the world’s leading payment service company, [Vesta Corporation](https://trustvesta.com/), seeking the best solutions for fraud prevention industry, and now you are invited to join the challenge.In this competition, you’ll benchmark machine learning models on a challenging large-scale dataset. The data comes from Vesta's real-world e-commerce transactions  and contains a wide range of features from device type to product features. You also have the opportunity to create new features to improve your results. If successful, you’ll improve the efficacy of fraudulent transaction alerts for millions of people around the world, helping hundreds of thousands of businesses reduce their fraud loss and increase their revenue. And of course, you will save party people just like you the hassle of false positives.*Acknowledgements*: Vesta Corporation provided the dataset for this competition. Vesta Corporation is the forerunner in guaranteed e-commerce payment solutions.  Founded in 1995, Vesta pioneered the process of fully guaranteed card-not-present (CNP) payment transactions for the telecommunications industry.  Since then, Vesta has firmly expanded data science and machine learning capabilities across the globe and solidified its position as the leader in guaranteed ecommerce payments. Today, Vesta guarantees more than $18B in transactions annually. Header Photo by Tim Evans on Unsplash\"}, {'title': 'Open Images 2019 - Instance Segmentation', 'url': 'https://www.kaggle.com/competitions/open-images-2019-instance-segmentation', 'briefDescription': 'Outline segmentation masks of objects in images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/15043/logos/header.png?t=2019-06-18-19-29-49', 'tag': 'image, custom metric', 'description': '#IntroductionComputer vision has advanced considerably but is still challenged in matching the precision of human perception.[Open Images](https://storage.googleapis.com/openimages/web/factsfigures.html) is a collaborative release of ~9 million images annotated with image-level labels, object bounding boxes, object segmentation masks, and visual relationships. This uniquely large and diverse dataset is designed to spur state of the art advances in analyzing and understanding images.This year’s [Open Images V5](https://g.co/dataset/openimages) release enabled the second [Open Images Challenge](https://storage.googleapis.com/openimages/web/challenge2019.html) to include the following 3 tracks: 1. [Object detection track](https://www.kaggle.com/c/open-images-2019-object-detection) for detecting bounding boxes around object instances, relaunched from 2018. 2. [Visual relationship detection track](https://www.kaggle.com/c/open-images-2019-visual-relationship) for detecting pairs of objects in particular relations, also relaunched from 2018. 3. [Instance segmentation track](https://www.kaggle.com/c/open-images-2019-instance-segmentation) for segmenting masks of objects in images, brand new for 2019.Google AI hopes that having a single dataset with unified annotations for image classification, object detection, visual relationship detection, and instance segmentation will stimulate progress towards genuine scene understanding.#Instance Segmentation TrackIn this track of the Challenge, you are asked **to provide segmentation masks of objects**.This track’s training set represents 2.1M segmentation masks for object instances in 300 categories; with a validation set containing an additional 23k masks. The train set masks were produced by our state-of-the-art [interactive segmentation process](https://arxiv.org/pdf/1903.10830.pdf), where professional human annotators iteratively correct the output of a segmentation neural network. The validation and test set masks have been annotated manually with a strong focus on quality. *Example train set annotations. Left: [Wuxi science park, 1995](https://www.flickr.com/photos/garysoup/3777131020) by [Gary Stevens](https://www.flickr.com/people/garysoup/). Right: [Cat Cafe Shinjuku calico](https://www.flickr.com/photos/picsoflife/6776736950) by [Ari Helminen](https://www.flickr.com/people/picsoflife/). Both images used under CC BY 2.0 license.*The results of this Challenge will be presented at a workshop at the [International Conference on Computer Vision](http://iccv2019.thecvf.com/).We are excited to partner with Open Images for this second year of competitions, including this brand new track!'}, {'title': 'Generative Dog Images', 'url': 'https://www.kaggle.com/competitions/generative-dog-images', 'briefDescription': 'Experiment with creating puppy pics', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/15062/logos/header.png?t=2019-06-20-21-54-47', 'tag': 'custom metric', 'description': '**This competition is closed and no longer accepting submissions. The private leaderboard has been finalized as of 8/28/2019.**> **Important Warning**: This competition has an experimental format and submission style (images as submission). Competitors **must** use generative methods to create their submission images and are not permitted to make submissions that include any images already classified as dogs or altered versions of such images. > To enforce and prevent cheating, we reserve the right to: (a) Visually inspect all participants\\' submitted images, (b) review any submitted source code, (c) use these reviews to identify violators or determine winners, and (d) disqualify participants from the competition who are found in violation. This is also specified in the [competition\\'s rules](https://www.kaggle.com/c/generative-dog-images/overview)Use your training skills to create images, rather than identify them. You’ll be using GANs, which are at the creative frontier of machine learning. You might think of GANs as robot artists in a sense—able to create eerily lifelike images, and even digital worlds.> *\"You might not think that programmers are artists, but programming is an extremely creative profession. It’s logic-based creativity. \\'\\'* -> John RomeroA generative adversarial network (GAN) is a class of machine learning system invented by Ian Goodfellow in 2014. Two neural networks compete with each other in a game. Given a training set, this technique learns to generate new data with the same statistics as the training set.In this competition, you’ll be training generative models to create images of dogs. Only this time… there’s no ground truth data for you to predict. Here, you’ll submit the images and be scored based on how well those images are classified as dogs from pre-trained neural networks.  Take these images, for example. Can you tell which are real vs. generated?![dogs][1]*Trick question; they are all generated!*Why dogs? We chose dogs because, well, who doesn’t love looking at photos of adorable pups? Moreover, dogs can be classified into many sub-categories (breed, color, size), making them ideal candidates for image generation.Generative methods (in particular, GANs) are currently used in various places on Kaggle for data augmentation. Their potential is vast; they can learn to mimic any distribution of data across any domain: photographs, drawings, music, and prose. If successful, not only will you help advance the state of the art in generative image creation, but you’ll enable us to create more experiments across a variety of domains in the future.> **This is a Kernels-only competition. Refer to [Kernels Requirements](https://www.kaggle.com/c/generative-dog-images/overview/Kernels-Requirements) for details.**  [1]: https://storage.googleapis.com/kaggle-media/competitions/GAN/dogs.png'}, {'title': 'APTOS 2019 Blindness Detection', 'url': 'https://www.kaggle.com/competitions/aptos2019-blindness-detection', 'briefDescription': \"Detect diabetic retinopathy to stop blindness before it's too late \", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14774/logos/header.png?t=2019-06-21-17-16-37', 'tag': 'image, multiclass classification, healthcare, medicine, quadraticweightedkappa', 'description': \"Imagine being able to detect blindness before it happened.Millions of people suffer from diabetic retinopathy, the leading cause of blindness among working aged adults. Aravind Eye Hospital in India hopes to detect and prevent this disease among people living in rural areas where medical screening is difficult to conduct. Successful entries in this competition will improve the hospital’s ability to identify potential patients. Further, the solutions will be spread to other Ophthalmologists through the 4th Asia Pacific Tele-Ophthalmology Society (APTOS) SymposiumCurrently, Aravind technicians travel to these rural areas to capture images and then rely on highly trained doctors to review the images and provide diagnosis. Their goal is to scale their efforts through technology; to gain the ability to automatically screen images for disease and provide information on how severe the condition may be.In this synchronous Kernels-only competition, you'll build a machine learning model to speed up disease detection. You’ll work with thousands of images collected in rural areas to help identify diabetic retinopathy automatically. If successful, you will not only help to prevent lifelong blindness, but these models may be used to detect other sorts of diseases in the future, like glaucoma and macular degeneration.Get started today!\"}, {'title': 'Recursion Cellular Image Classification', 'url': 'https://www.kaggle.com/competitions/recursion-cellular-image-classification', 'briefDescription': 'CellSignal: Disentangling biological signal from experimental noise in cellular images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14420/logos/header.png?t=2019-06-26-02-51-18', 'tag': 'classification, image, biology, research, categorizationaccuracy', 'description': \"The cost of some drugs and medical treatments has risen so high in recent years that many patients are having to go without. You can help with a classification project that could make researchers more efficient.One of the more surprising reasons behind the cost is how long it takes to bring new treatments to market. Despite improvements in technology and science, research and development continues to lag. In fact, finding new treatments takes, on average, more than 10 years and costs hundreds of millions of dollars. Recursion Pharmaceuticals, creators of the industry’s largest dataset of biological images, generated entirely in-house, believes AI has the potential to dramatically improve and expedite the drug discovery process. More specifically, your efforts could help them understand how drugs interact with human cells. This competition will have you disentangling experimental noise from real biological signals. Your entry will classify images of cells under one of 1,108 different genetic perturbations. You can help eliminate the noise introduced by technical execution and environmental variation between experiments.If successful, you could dramatically improve the industry’s ability to model cellular images according to their relevant biology. In turn, applying AI could greatly decrease the cost of treatments, and ensure these treatments get to patients faster.This competition is a part of the NeurIPS 2019 competition track. Winners will be invited to contribute their solutions towards the workshop presentation.AcknowledgmentsThank you to the following sponsors & supporters of this competition:Google Cloud: Google Cloud is widely recognized as a global leader in delivering a secure, open and intelligent enterprise cloud platform. Our technology is built on Google’s private network and is the product of nearly 20 years of innovation in security, network architecture, collaboration, artificial intelligence and open source software. We offer a simply engineered set of tools and unparalleled technology across Google Cloud Platform and G Suite that help bring people, insights and ideas together. Customers across more than 150 countries trust Google Cloud to modernize their computing environment for today’s digital world.DoiT: You have the cloud and we have your back. For nearly a decade, we’ve been helping businesses build and scale cloud solutions with our world-class cloud engineering support. We help our customers with technical support and consulting on building and operating complex large-scale distributed systems, developing better machine learning models and setting up big data solutions using Google Cloud, Amazon AWS and Microsoft Azure.NVIDIA: NVIDIA’s (NASDAQ: NVDA) invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing — with the GPU acting as the brain of computers, robots and self-driving cars that can perceive and understand the world. More information at http://nvidianews.nvidia.com.Lambda: Lambda provides Deep Learning workstations, servers, and GPU cloud services. Lambda Deep Learning infrastructure is used by the world's leading AI research & development organizations including Apple, Microsoft, MIT, Stanford, and the US Government. To learn more, visit www.lambdalabs.com.\"}, {'title': 'The 3rd YouTube-8M Video Understanding Challenge', 'url': 'https://www.kaggle.com/competitions/youtube8m-2019', 'briefDescription': 'Temporal localization of topics within video', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12716/logos/header.png?t=2019-04-29-17-47-47', 'tag': 'video data, custom metric', 'description': 'Imagine being able to search for the moment in any video where an adorable kitten sneezes, even though the uploader didn’t title or describe the video with such descriptive metadata. Now, apply that same concept to videos that cover important or special events like a baby’s first steps or a game-winning goal -- and now we have the ability to quickly [find and share special video moments](https://ai.googleblog.com/2019/04/capturing-special-video-moments-with.html). This technology is called temporal concept localization within video and Google Research can use your help to advance the state of the art in this area.  ![ExampleImage](https://storage.googleapis.com/kaggle-media/competitions/yt8m-2019/image5.gif)*An example of the detected action \"blowing out candles\"*In most web searches, video retrieval and ranking is performed by matching query terms to metadata and other video-level signals. However, we know that videos can contain an array of topics that aren’t always characterized by the uploader, and many of these miss localizations to brief but important moments within the video. Temporal localization can enable applications such as  improved video search (including search within video), video summarization and highlight extraction, action moment detection, improved video content safety, and many others.In previous years, participants worked on advancements in video-level annotations, building both [unconstrained](https://www.kaggle.com/c/youtube8m) and [constrained](https://www.kaggle.com/c/youtube8m-2018) models. In this third challenge based on the YouTube 8M dataset, Kagglers will localize video-level labels to the precise time in the video where the label actually appears, and do this at an unprecedented scale. To put it another way: at what point in the video does the cat sneeze?  If successful, your new machine learning models will significantly improve video understanding for all, by not only identifying the topics relevant to a video, but also pinpointing where in the video they appear.This competition is being hosted by [Google Research](https://ai.google/research/) as a part of the [International Conference on Computer Vision (ICCV) 2019](http://iccv2019.thecvf.com/) selected workshop session. Please refer to the [YouTube 8M Large-Scale Video Understanding Workshop Page](https://research.google.com/youtube8m/workshop2019/index.html) for details about the workshop.'}, {'title': 'SIIM-ACR Pneumothorax Segmentation', 'url': 'https://www.kaggle.com/competitions/siim-acr-pneumothorax-segmentation', 'briefDescription': 'Identify Pneumothorax disease in chest x-rays ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14652/logos/header.png?t=2019-05-17-18-25-20', 'tag': 'image, custom metric', 'description': 'Imagine suddenly gasping for air, helplessly breathless for no apparent reason. Could it be a collapsed lung? In the future, your entry in this competition could predict the answer.Pneumothorax can be caused by a blunt chest injury, damage from underlying lung disease, or most horrifying—it may occur for no obvious reason at all. On some occasions, a collapsed lung can be a life-threatening event.Pneumothorax is usually diagnosed by a radiologist on a chest x-ray, and can sometimes be very difficult to confirm. An accurate AI algorithm to detect pneumothorax would be useful in a lot of clinical scenarios. AI could be used to triage chest radiographs for priority interpretation, or to provide a more confident diagnosis for non-radiologists.The [Society for Imaging Informatics in Medicine (SIIM)](https://siim.org/) is the leading healthcare organization for those interested in the current and future use of informatics in medical imaging. Their mission is to advance medical imaging informatics across the enterprise through education, research, and innovation in a multi-disciplinary community. Today, they need your help.In this competition, you’ll develop a model to classify (and if present, segment) pneumothorax from a set of chest radiographic images. If successful, you could aid in the early recognition of pneumothoraces and save lives. If you’re up for the challenge, take a deep breath, and get started now.**Note:** As specified on the Data Page, the dataset must be retrieved from Cloud Healthcare. Review [this tutorial](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/overview/siim-cloud-healthcare-api-tutorial) (or [in pdf format](https://storage.googleapis.com/kaggle-media/competitions/siim/SIIM%20Cloud%20Healthcare%20API%20Documentation.pdf)) for instructions on how to do so.### Acknowledgments**SIIM Machine Learning Committee Co-Chairs, Steven G. Langer, PhD, CIIP and George Shih, MD, MS** for tirelessly leading this effort and making the challenge possible in such a short period of time.----------**SIIM Machine Learning Committee Members** for their dedication in annotating the dataset, helping to define the most useful metrics and running tests to prepare the challenge for launch.----------**SIIM Hackathon Committee**, especially Mohannad Hussain, for their crucial technical support with data conversion.----------![ACR Logo](https://storage.googleapis.com/kaggle-media/competitions/siim/ACR%20logo.jpg) **American College of Radiology (ACR)**, @RadiologyACR: For Co-hosting the challenge and Co-sponsoring  the Prizes----------![STR Logo](https://storage.googleapis.com/kaggle-media/competitions/siim/STR%20logo.jpg) **Society of Thoracic Radiology (STR)**, @thoracicrad: For their unparalleled expertise in adjudicating the dataset----------![MD.ai Logo](https://storage.googleapis.com/kaggle-media/competitions/siim/MDai.jpg) **MD.ai**: For providing the annotation tool and helping with the first layer of annotations'}, {'title': 'Open Images 2019 - Object Detection', 'url': 'https://www.kaggle.com/competitions/open-images-2019-object-detection', 'briefDescription': 'Detect objects in varied and complex images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14315/logos/header.png?t=2019-04-24-05-13-32', 'tag': 'image, computer vision, custom metric', 'description': '#IntroductionComputer vision has advanced considerably but is still challenged in matching the precision of human perception.[Open Images](https://storage.googleapis.com/openimages/web/factsfigures.html) is a collaborative release of ~9 million images annotated with image-level labels, object bounding boxes, object segmentation masks, and visual relationships. This uniquely large and diverse dataset is designed to spur state of the art advances in analyzing and understanding images.This year’s [Open Images V5](https://g.co/dataset/openimages) release enabled the second [Open Images Challenge](https://storage.googleapis.com/openimages/web/challenge2019.html) to include the following 3 tracks: 1. [Object detection track](https://www.kaggle.com/c/open-images-2019-object-detection) for detecting bounding boxes around object instances, relaunched from 2018. 2. [Visual relationship detection track](https://www.kaggle.com/c/open-images-2019-visual-relationship) for detecting pairs of objects in particular relations, also relaunched from 2018. 3. [Instance segmentation track](https://www.kaggle.com/c/open-images-2019-instance-segmentation) for segmenting masks of objects in images, brand new for 2019.Google AI hopes that having a single dataset with unified annotations for image classification, object detection, visual relationship detection, and instance segmentation will stimulate progress towards genuine scene understanding.#Object Detection TrackIn this track of the Challenge, you are asked **to predict a tight bounding box around object instances**.The training set contains 12.2M bounding-boxes across 500 categories on 1.7M images. The boxes have been largely manually drawn by professional annotators to ensure accuracy and consistency. The images are very diverse and often contain complex scenes with several objects (7 per image on average).![guitar](https://storage.googleapis.com/kaggle-media/competitions/open-images/guitarist.png)![house](https://storage.googleapis.com/kaggle-media/competitions/open-images/table.png)*Example annotations. Left: [Mark Paul Gosselaar plays the guitar](https://www.flickr.com/photos/rhysasplundh/5738556102) by [Rhys A](https://www.flickr.com/people/rhysasplundh/). Right: [the house](https://www.flickr.com/photos/krakluski/2950388100) by [anita kluska](https://www.flickr.com/photos/krakluski/). Both images used under CC BY 2.0 license.*Please refer to the [Open Images 2019 Challenge page](https://storage.googleapis.com/openimages/web/challenge2019.html) for additional details. The challenge contains a total of 3 tracks, which are linked above in the introduction. You are invited to explore and enter as many tracks as interest you.The results of this Challenge will be presented at a workshop at the [International Conference on Computer Vision](http://iccv2019.thecvf.com/).We are excited to partner with Open Images for this second year of competitions. See link here for last year’s [Object Detection](https://www.kaggle.com/c/google-ai-open-images-object-detection-track) competition.'}, {'title': 'Open Images 2019 - Visual Relationship', 'url': 'https://www.kaggle.com/competitions/open-images-2019-visual-relationship', 'briefDescription': 'Detect pairs of objects in particular relationships', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14316/logos/header.png?t=2019-04-24-20-30-14', 'tag': 'image, computer vision, custom metric', 'description': '#IntroductionComputer vision has advanced considerably but is still challenged in matching the precision of human perception.[Open Images](https://storage.googleapis.com/openimages/web/factsfigures.html) is a collaborative release of ~9 million images annotated with image-level labels, object bounding boxes, object segmentation masks, and visual relationships. This uniquely large and diverse dataset is designed to spur state of the art advances in analyzing and understanding images.This year’s [Open Images V5](https://g.co/dataset/openimages) release enabled the second [Open Images Challenge](https://storage.googleapis.com/openimages/web/challenge2019.html) to include the following 3 tracks: 1. [Object detection track](https://www.kaggle.com/c/open-images-2019-object-detection) for detecting bounding boxes around object instances, relaunched from 2018. 2. [Visual relationship detection track](https://www.kaggle.com/c/open-images-2019-visual-relationship) for detecting pairs of objects in particular relations, also relaunched from 2018. 3. [Instance segmentation track](https://www.kaggle.com/c/open-images-2019-instance-segmentation) for segmenting masks of objects in images, brand new for 2019.Google AI hopes that having a single dataset with unified annotations for image classification, object detection, visual relationship detection, and instance segmentation will stimulate progress towards genuine scene understanding.#Visual Relationship TrackIn this track of the Challenge, you are asked **to detect pairs of objects and the relationships that connect them**.The training set contains 329 relationship triplets with 375k training samples. These include both human-object relationships (e.g. \"woman playing guitar\", \"man holding microphone\"), object-object relationships (e.g. \"beer on table\", \"dog inside car\"), and also considers object-attribute relationships (e.g.\"handbag is made of leather\" and \"bench is wooden\").![man playing guitar](https://storage.googleapis.com/kaggle-media/competitions/open-images/man%20playing%20guitar.png)![chair at table](https://storage.googleapis.com/kaggle-media/competitions/open-images/chair%20at%20table.png)*Left: Example of ‘man playing guitar’ - [Radiofiera - Villa Cordellina Lombardi, Montecchio Maggiore (VI) - agosto 2010](https://www.flickr.com/photos/tomjoad/4938460850) by [Andrea Sartorati](https://www.flickr.com/photos/tomjoad/). Right: Example of ‘chair at table’ - [Epic Fireworks - Loads A Room](https://www.flickr.com/photos/epicfireworks/4843249505) by [Epic Fireworks](https://www.flickr.com/photos/epicfireworks/)*Please refer to the [Open Images 2019 Challenge page](https://storage.googleapis.com/openimages/web/challenge2019.html) for additional details. The challenge contains a total of 3 tracks, which are linked above in the introduction. You are invited to explore and enter as many tracks as interest you.The results of this Challenge will be presented at a workshop at the [International Conference on Computer Vision](http://iccv2019.thecvf.com/).We are excited to partner with Open Images for this second year of competitions. See link here for last year’s [Visual Representation Detection](https://www.kaggle.com/c/google-ai-open-images-visual-relationship-track) competition.'}, {'title': 'Predicting Molecular Properties', 'url': 'https://www.kaggle.com/competitions/champs-scalar-coupling', 'briefDescription': 'Can you measure the magnetic interactions between a pair of atoms?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14313/logos/header.png?t=2019-05-16-16-54-31', 'tag': 'tabular, regression, chemistry, custom metric', 'description': 'Think you can use your data science smarts to make big predictions at a molecular level?This challenge aims to predict interactions between atoms. Imaging technologies like MRI enable us to see and understand the molecular composition of tissues. Nuclear Magnetic Resonance (NMR) is a closely related technology which uses the same principles to understand the structure and dynamics of proteins and molecules.Researchers around the world conduct NMR experiments to further understanding of the structure and dynamics of molecules, across areas like environmental science, pharmaceutical science, and materials science.  This competition is hosted by members of the CHemistry and Mathematics in Phase Space (CHAMPS) at the University of Bristol, Cardiff University, Imperial College and the University of Leeds. Winning teams will have an opportunity to partner with this multi-university research program on an academic publicationYour ChallengeIn this competition, you will develop an algorithm that can predict the magnetic interaction between two atoms in a molecule (i.e., the scalar coupling constant).Once the competition finishes, CHAMPS would like to invite the top teams to present their work, discuss the details of their models, and work with them to write a joint research publication which discusses an open-source implementation of the solution.About Scalar CouplingUsing NMR to gain insight into a molecule’s structure and dynamics depends on the ability to accurately predict so-called “scalar couplings”. These are effectively the magnetic interactions between a pair of atoms. The strength of this magnetic interaction depends on intervening electrons and chemical bonds that make up a molecule’s three-dimensional structure.Using state-of-the-art methods from quantum mechanics, it is possible to accurately calculate scalar coupling constants given only a 3D molecular structure as input. However, these quantum mechanics calculations are extremely expensive (days or weeks per molecule), and therefore have limited applicability in day-to-day workflows.A fast and reliable method to predict these interactions will allow medicinal chemists to gain structural insights faster and cheaper, enabling scientists to understand how the 3D chemical structure of a molecule affects its properties and behavior. Ultimately, such tools will enable researchers to make progress in a range of important problems, like designing molecules to carry out specific cellular tasks, or designing better drug molecules to fight disease.Join the CHAMPS Scalar Coupling challenge to apply predictive analytics to chemistry and chemical biology.'}, {'title': 'Instant Gratification', 'url': 'https://www.kaggle.com/competitions/instant-gratification', 'briefDescription': 'A synchronous Kernels-only competition', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/14239/logos/header.png?t=2019-05-16-14-38-59', 'tag': 'tabular, binary classification, auc', 'description': \"Welcome to Instant (well, *almost*) Gratification!In 2015, Kaggle introduced Kernels as a resource to competition participants. It was a controversial decision to add a code-sharing tool to a competitive coding space. We thought it was important to make Kaggle more than a place where competitions are solved behind closed digital doors. Since then, Kernels has grown from its infancy--essentially a blinking cursor in a docker container--into its teenage years. We now have more compute, longer runtimes, better datasets, GPUs, and an improved interface.We have iterated and tested several Kernels-only (KO) competition formats with a true holdout test set, in particular deploying them when we would have otherwise substituted a [two-stage competition](https://www.kaggle.com/two-stage-frequently-asked-questions). However, the experience of submitting to a Kernels-only competition has typically been asynchronous and imperfect; participants wait many days after a competition has concluded for their selected Kernels to be rerun on the holdout test dataset, the leaderboard updated, and the winners announced. This flow causes heartbreak to participants whose Kernels fail on the unseen test set, leaving them with no way to correct tiny errors that spoil months of hard work.## Say Hello to Synchronous KOWe're now pleased to announce general support for a synchronous Kernels-only format. When you submit from a Kernel, Kaggle will run the code against both the public test set and private test set in real time. This small-but-substantial tweak improves the experience for participants, the host, and Kaggle: - With a truly withheld test set, we are practicing proper, rigorous machine learning. - We will be able to offer more varieties of competitions and intend to run many fewer confusing two-stage competitions. - You will be able to see if your code runs successfully on the withheld test set and have the leeway to intervene if it fails. - We will run all submissions against the private data, not just selected ones. Participants will get the complete and familiar public/private scores available in a traditional competition. - The final leaderboard can be released at the end of the competition, without the delay of rerunning Kernels.This competition is a low-stakes, trial-run introduction to our new synchronous KO implementation. We want to test that the process goes smoothly and gather feedback on your experiences. While it may feel like a normal KO competition, there are complicated new mechanics in play, such as the selection logic of Kernels that are still running when the deadline passes.Since the competition also presents an authentic machine learning problem, it will also award Kaggle medals and points. Have fun, good luck, and welcome to the world of synchronous Kernels competitions!\"}, {'title': 'Northeastern SMILE Lab - Recognizing Faces in the Wild', 'url': 'https://www.kaggle.com/competitions/recognizing-faces-in-the-wild', 'briefDescription': 'Can you determine if two individuals are related?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9992/logos/header.png?t=2019-01-09-19-48-28', 'tag': 'image, psychology, auc', 'description': 'Do you have your father’s nose? Blood relatives often share facial features. Now researchers at Northeastern University want to improve their algorithm for facial image classification to bridge the gap between research and other familial markers like DNA results. That will be your challenge in this new Kaggle competition.An automatic kinship classifier has been in the works at Northeastern since 2010. Yet this technology remains largely unseen in practice for a couple of reasons:1. Existing image databases for kinship recognition tasks aren\\'t large enough to capture and reflect the true data distributions of the families of the world.2. Many hidden factors affect familial facial relationships, so a more discriminant model is needed than the computer vision algorithms used most often for higher-level categorizations (e.g. facial recognition or object classification).In this competition, you’ll help researchers build a more complex model by determining if two people are blood-related based solely on images of their faces. If you think you can get it \"on the nose,\" this competition is for you.The SMILE Lab at Northeastern focuses on the frontier research of applied machine learning, social media analytics, human-computer interaction, and high-level image and video understanding. Their research is driven by the explosion of diverse multimedia from the Internet, including both personal and publicly-available photos and videos. They start by treating fundamental theory from learning algorithms as the soul of machine intelligence and arm it with visual perception. '}, {'title': 'Data Science for Good: City of Los Angeles', 'url': 'https://www.kaggle.com/competitions/data-science-for-good-city-of-los-angeles', 'briefDescription': 'Help the City of Los Angeles to structure and analyze its job descriptions', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13988/logos/header.png?t=2019-04-07-01-02-14', 'tag': 'image, nlp, text, employment', 'description': '# Data Science for Good: City of Los Angeles**Help the City of Los Angeles to structure and analyze its job descriptions**The City of Los Angeles faces a big hiring challenge: 1/3 of its 50,000 workers are eligible to retire by July of 2020. The city has partnered with Kaggle to create a competition to improve the job bulletins that will fill all those open positions.# Problem StatementThe content, tone, and format of job bulletins can influence the quality of the applicant pool. Overly-specific job requirements may discourage diversity. The Los Angeles Mayor’s Office wants to reimagine the city’s job bulletins by using text analysis to identify needed improvements.  The goal is to convert a folder full of plain-text job postings into a single structured CSV file and then to use this data to: (1) identify language that can negatively bias the pool of applicants; (2) improve the diversity and quality of the applicant pool; and/or (3) make it easier to determine which promotions are available to employees in each job class.# How to Participate1. Accept the Rules - Accept the [competition rules][1].  2. Make Your Submission - Follow the [submission instructions][2].WIth your help, Los Angeles will overcome a wave of retirements and fill those jobs with a strong and diverse workforce. Good luck and happy Kaggling!  [1]: https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles/rules  [2]: https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles/overview/submission-instructions    Do you think companies can find better candidates by improving their job postings? We hope to create an open-sourced body of work focused on this topic by hosting another Data Science for Good competition, this time in partnership with the City of Los Angeles.'}, {'title': 'iMaterialist (Fashion) 2019 at FGVC6 ', 'url': 'https://www.kaggle.com/competitions/imaterialist-fashion-2019-FGVC6', 'briefDescription': 'Fine-grained segmentation task for fashion and apparel', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13032/logos/header.png?t=2019-04-24-02-01-37', 'tag': 'custom metric', 'description': '![enter image description here][1]Designers know what they are creating, but what, and how, do people really wear their products? What combinations of products are people using? In this competition, we challenge you to develop algorithms that will help with an important step towards automatic product detection – to accurately assign segmentations and attribute labels for fashion images. Visual analysis of clothing is a topic that has received increasing attention in recent years. Being able to recognize apparel products and associated attributes from pictures could enhance the shopping experience for consumers, and increase work efficiency for fashion professionals.We present a new clothing dataset with the goal of introducing **a novel fine-grained segmentation task** by joining forces between the fashion and computer vision communities. The proposed task unifies both categorization and segmentation of rich and complete apparel attributes, an important step toward real-world applications. ![enter image description here][2]While early work in computer vision addressed related clothing recognition tasks, these are not designed with fashion insiders’ needs in mind, possibly due to the research gap in fashion design and computer vision. To address this, we first propose a fashion taxonomy built by fashion experts, informed by product description from the internet. To capture the complex structure of fashion objects and ambiguity in descriptions obtained from crawling the web, our standardized taxonomy contains 46 apparel objects (27 main apparel items and 19 apparel parts), and 92 related fine-grained attributes. Secondly, a total of 50K clothing images (10K with both segmentation and fine-grained attributes, 40K with apparel instance segmentation) in daily-life, celebrity events, and online shopping are labeled by both domain experts and crowd workers for fine-grained segmentation.Individuals/Teams with top submissions will be invited to present their work live at the [FGVC6 workshop][3] at the [Conference on Computer Vision and Pattern Recognition (CVPR) 2019][4]Checkout the [iMaterialist-Fashion Competition Github repo for the specifics of the dataset][5]. ### AcknowledgmentsThe iMat-Fashion Challenge 2019 is sponsored by Google AI, CVDF, Samasource and [Fashionpedia][6].![enter image description here][7]        ![enter image description here][8]        ![enter image description here][9]           ![enter image description here][10]   [1]: https://s3.amazonaws.com/ifashionist/Kaggle/Kaggle3.jpg  [2]: https://s3.amazonaws.com/ifashionist/Kaggle/dataset_example.jpg  [3]: https://sites.google.com/view/fgvc6/home?authuser=0  [4]: http://cvpr2019.thecvf.com/  [5]: https://github.com/visipedia/imat_comp  [6]: https://fashionpedia.github.io/home/index.html  [7]: https://s3.amazonaws.com/ifashionist/Kaggle/googleai.jpg  [8]: https://s3.amazonaws.com/ifashionist/Kaggle/cvdf-logo.png  [9]: https://s3.amazonaws.com/ifashionist/Kaggle/Fashionpedia_logo.jpg  [10]: https://s3.amazonaws.com/ifashionist/Kaggle/samasource-logo1.jpg'}, {'title': 'Google Landmark Recognition 2019', 'url': 'https://www.kaggle.com/competitions/landmark-recognition-2019', 'briefDescription': 'Label famous (and not-so-famous) landmarks in images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/11836/logos/header.png?t=2019-03-28-23-42-45', 'tag': 'custom metric', 'description': 'Did you ever go through your vacation photos and ask yourself: What is the name of this temple I visited in China? Who created this monument I saw in France? Landmark recognition can help! This technology can predict landmark labels directly from image pixels, to help people better understand and organize their photo collections.Today, a great obstacle to landmark recognition research is the lack of large annotated datasets. In this competition, we present the largest worldwide dataset to date, to foster progress in this problem. This competition challenges Kagglers to build models that recognize the correct landmark (if any) in a dataset of challenging test images.Many Kagglers are familiar with image classification challenges like the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), which aims to recognize 1K general object categories. Landmark recognition is a little different from that: it contains a much larger number of classes (there are more than 200K classes in this challenge), and the number of training examples per class may not be very large. Landmark recognition is challenging in its own way.This is the second edition of this challenge. Compared to the [first edition](https://www.kaggle.com/c/landmark-recognition-challenge), the new dataset is more comprehensive and diverse. See the [Data](https://www.kaggle.com/c/landmark-recognition-2019/data) tab for more in-depth discussion on the new released dataset.This challenge is organized in conjunction with the [Landmark Retrieval Challenge](https://www.kaggle.com/c/landmark-retrieval-2019 ). In particular, note that the test set for both challenges is the same, to encourage participants to compete in both. We encourage participants to use the training data from the recognition challenge (either from this year’s or last year’s dataset) to develop models which could be useful for the retrieval challenge.'}, {'title': 'Google Landmark Retrieval 2019', 'url': 'https://www.kaggle.com/competitions/landmark-retrieval-2019', 'briefDescription': 'Given an image, can you find all of the same landmarks in a dataset?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/11838/logos/header.png?t=2019-03-29-00-01-45', 'tag': 'map@{k}', 'description': 'Image retrieval is a fundamental problem in computer vision: given a query image, can you find similar images in a large database? This is especially important for query images containing landmarks, which accounts for a large portion of what people like to photograph.In this competition, Kagglers are given query images and, for each query, are expected to retrieve all database images containing the same landmarks (if any). The competition will proceed in two phases: The 1st phase will use the same test and index sets as last year, while for phase 2 we will release a completely new dataset that contains 700K images with more than 100K unique landmarks. We hope that this release will accelerate progress in this important research problem.This challenge is organized in conjunction with the [Landmark Recognition Challenge] (https://www.kaggle.com/c/landmark-recognition-2019). In particular, note that the test set for both challenges is the same, to encourage participants to compete in both. We also encourage participants to use the training data from the recognition challenge (either from this year’s or last year’s dataset) to develop models which could be useful for the retrieval challenge.'}, {'title': 'Freesound Audio Tagging 2019', 'url': 'https://www.kaggle.com/competitions/freesound-audio-tagging-2019', 'briefDescription': 'Automatically recognize sounds and apply tags of varying natures', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10700/logos/header.png?t=2019-03-08-16-57-14', 'tag': 'audio, weightedlabelrankingaverageprecision', 'description': \"One year ago, Freesound and Google’s Machine Perception hosted an audio tagging competition challenging Kagglers to build a general-purpose auto tagging system. This year they’re back and taking the challenge to the next level with multi-label audio tagging, doubled number of audio categories, and a noisier than ever training set. If you like raising your ML game, this challenge is for you.![Freesound][1]Here's the background: Some sounds are distinct and instantly recognizable, like a baby’s laugh or the strum of a guitar. Other sounds are difficult to pinpoint. If you close your eyes, could you tell the difference between the sound of a chainsaw and the sound of a blender?Because of the vastness of sounds we experience, no reliable automatic general-purpose audio tagging systems exist. A significant amount of manual effort goes into tasks like annotating sound collections and providing captions for non-speech events in audiovisual content.To tackle this problem, Freesound (an initiative by MTG-UPF that maintains a collaborative database with over 400,000 Creative Commons Licensed sounds) and Google Research’s Machine Perception Team  (creators of AudioSet, a large-scale dataset of manually annotated audio events with over 500 classes) have teamed up to develop the dataset for this new competition.To win this competition, Kagglers will develop an algorithm to tag audio data automatically using a diverse vocabulary of 80 categories.If successful, your systems could be used for several applications, ranging from automatic labelling of sound collections to the development of systems that automatically tag video content or recognize sound events happening in real time.Ready to raise your game? Join the competition!Note, this competition is similar in nature to this competition  with a new dataset, and multi-class labels. ## Organizers - Eduardo Fonseca, MTG-UPF, Barcelona - Manoj Plakal, Google's Sound Understanding, New York - Frederic Font, MTG-UPF, Barcelona - Dan Ellis, Google's Sound Understanding, New York>**This is a Kernels-only competition. Refer to Kernels Requirements for details.**  [1]: https://storage.googleapis.com/kaggle-media/competitions/freesound/task2_freesound_audio_tagging.png\"}, {'title': 'iNaturalist 2019 at FGVC6', 'url': 'https://www.kaggle.com/competitions/inaturalist-2019-fgvc6', 'briefDescription': 'Fine-grained classification spanning a thousand species', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13747/logos/header.png?t=2019-03-27-18-34-42', 'tag': 'meanbesterroratk', 'description': \"![](https://www.dropbox.com/s/kltgq0ahtb05v4x/iNat_2019_github.gif?dl=1)As part of the FGVC6 workshop at CVPR 2019 we are conducting the iNat Challenge 2019 large scale species classification competition,  sponsored by Microsoft. It is estimated that the natural world contains several million species of plants and animals. Without expert knowledge, many of these species are extremely difficult to accurately classify due to their visual similarity. The goal of this competition is to push the state of the art in automatic image classification for real world data that features a large number of fine-grained categories.Previous versions of the challenge have focused on classifying large numbers of species. This year features a smaller number of highly similar categories captured in a wide variety of situations, from all over the world. In total, the iNat Challenge 2019 dataset contains 1,010 species, with a combined training and validation set of 268,243 images that have been collected and verified by multiple users from iNaturalist.Teams with top submissions, at the discretion of the workshop organizers, will be invited to present their work at the FGVC6 workshop.  Participants who make a submission that beats the sample submission can fill out this [form][2] to receive $150 in Google Cloud credits. ![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Microsoft_logo_%282012%29.svg/200px-Microsoft_logo_%282012%29.svg.png)Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.  [1]: http://inaturalist.org  [2]: https://www.kaggle.com/GCP-Credits-CVPR2019\"}, {'title': 'Jigsaw Unintended Bias in Toxicity Classification', 'url': 'https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification', 'briefDescription': 'Detect toxicity across a diverse range of conversations', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12500/logos/header.png?t=2019-03-13-21-49-15', 'tag': 'nlp, text, custom metric', 'description': 'Can you help detect toxic comments ― *and* minimize unintended model bias? That\\'s your challenge in this competition.The Conversation AI team, a research initiative founded by [Jigsaw](https://jigsaw.google.com/) and Google (both part of Alphabet), builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything *rude, disrespectful or otherwise likely to make someone leave a discussion*. Last year, in the [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge#description), you built multi-headed models to recognize toxicity and several subtypes of toxicity. This year\\'s competition is a related challenge: building toxicity models that operate fairly across a diverse range of conversations. Here’s the background: When the Conversation AI team first built toxicity models, they found that the models [incorrectly learned to associate](https://medium.com/the-false-positive/unintended-bias-and-names-of-frequently-targeted-groups-8e0b81f80a23) the names of frequently attacked identities with toxicity. Models predicted a high likelihood of toxicity for comments containing those identities (e.g. \"gay\"), even when those comments were not actually toxic (such as \"I am a gay woman\"). This happens because training data was pulled from available sources where unfortunately, certain identities are overwhelmingly referred to in offensive ways. Training a model from data with these imbalances risks simply mirroring those biases back to users.In this competition, you\\'re challenged to build a model that recognizes toxicity and minimizes this type of unintended bias with respect to mentions of identities. You\\'ll be using a dataset labeled for identity mentions and optimizing a metric designed to measure unintended bias. Develop strategies to reduce unintended bias in machine learning models, and you\\'ll help the Conversation AI team, and the entire industry, build models that work well for a wide range of conversations.*Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.*### AcknowledgmentsThe Conversation AI team would like to thank Civil Comments for making this dataset available publicly and the [Online Hate Index Research Project](http://dh.berkeley.edu/projects/online-hate-index-ohi-research-project?utm_source=BCNM+Subscribers&utm_campaign=d5d78bba5e-natasha-schull-oct12_COPY_01&utm_medium=email&utm_term=0_eb59bfff9e-d5d78bba5e-281420185) at [D-Lab](https://dlab.berkeley.edu/), University of California, Berkeley, whose labeling survey/instrument informed the dataset labeling. We\\'d also like to thank everyone who has contributed to Conversation AI\\'s research, especially those who took part in our last competition, the success of which led to the creation of this challenge.  > **This is a Kernels-only competition. Refer to [Kernels Requirements](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/Kernels-Requirements) for details.**'}, {'title': 'iMet Collection 2019 - FGVC6', 'url': 'https://www.kaggle.com/competitions/imet-2019-fgvc6', 'briefDescription': 'Recognize artwork attributes from The Metropolitan Museum of Art', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13251/logos/header.png?t=2019-03-14-16-01-52', 'tag': 'art, image, meanfscorebeta', 'description': 'The Metropolitan Museum of Art in New York, also known as The Met, has a diverse collection of over 1.5M objects of which over 200K have been digitized with imagery. The online cataloguing information is generated by Subject Matter Experts (SME) and includes a wide range of data. These include, but are not limited to: multiple object classifications, artist, title, period, date, medium, culture, size, provenance, geographic location, and other related museum objects within The Met’s collection. While the SME-generated annotations describe the object from an art history perspective, they can also be indirect in describing finer-grained attributes from the museum-goer’s understanding. Adding fine-grained attributes to aid in the visual understanding of the museum objects will enable the ability to search for visually related objects.   ## AboutThis is an FGVCx competition hosted as part of the [FGVC6 workshop](https://sites.google.com/view/fgvc6/home) at [CVPR 2019](http://cvpr2019.thecvf.com/). View the [github page](https://github.com/visipedia/imet-fgvcx) for more details.> **This is a Kernels-only competition. Refer to [Kernels Requirements](https://www.kaggle.com/c/imet-2019-fgvc6/overview/Kernels-Requirements) for details.**'}, {'title': 'Ciphertext Challenge II', 'url': 'https://www.kaggle.com/competitions/ciphertext-challenge-ii', 'briefDescription': '553398 418126 467884 411 374106 551004 356535 539549 487091 290502 121468 556912 469347 515719 201909 101', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13503/logos/header.png?t=2019-03-25-21-55-31', 'tag': 'internet, text, categorizationaccuracy', 'description': \"## Ciphertext Challenge II: The Challengening!It's baaaaaaack!In our first [ciphertext competition][1], we hunted the wilds of the '90s-era internet. This time around, we're exploring the dark slow-broadband-y wastelands of 2011, with the [Movie Review Dataset][2]. In 2011 most of the internet hadn't even been *invented* yet\\\\*, so wow, you're in for a treat.Again, [simple classic ciphers][3] have been used to encrypt this dataset. Your mission this time: to correctly match each piece of ciphertext with its corresponding piece of plaintext. Daunting! Also, there are some new ciphers in play this time, which will involve some meta-puzzling. Enjoy!Swag prizes go to the first three teams to crack all four ciphers OR to the top three teams on the LB (in case the ciphers are not all cracked). Additionally, swag prizes will be awarded to the best *competition-related* kernels, in both visualization and cryptanalysis, based on upvotes.Go ahead. Get cracking!\\\\* - This is not true.## Acknowledgements*Maas, A., Daly, R., Pham, P., Huang, D., Ng, A. and Potts, C. (2011). Learning Word Vectors for Sentiment Analysis: Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. [online] Portland, Oregon, USA: Association for Computational Linguistics, pp. 142–150.* [Available here][4].  [1]: https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge  [2]: http://ai.stanford.edu/~amaas/data/sentiment/  [3]: https://www.kaggle.com/c/ciphertext-challenge-ii/data  [4]: http://www.aclweb.org/anthology/P11-1015.\"}, {'title': 'iWildCam 2019 - FGVC6', 'url': 'https://www.kaggle.com/competitions/iwildcam-2019-fgvc6', 'briefDescription': 'Categorize animals in the wild', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12961/logos/header.png?t=2019-03-06-01-18-20', 'tag': 'image, multiclass classification, macrofscore', 'description': \"Camera Traps (or Wild Cams) enable the automatic collection of large quantities of image data. Biologists all over the world use camera traps to monitor biodiversity and population density of animal species. We have recently been making strides towards automating the species classification challenge in camera traps, but as we try to expand the scope of these models from specific regions where we have collected training data to nearby areas we are faced with an interesting probem: how do you classify a species in a new region that you may not have seen in previous training data?In order to tackle this problem, we have prepared a challenge where the training data and test data are from different regions, namely The American Southwest and the American Northwest. The species seen in each region overlap, but are not identical, and the challenge is to classify the test species correctly. To this end, we will allow training on our American Southwest data (from [CaltechCameraTraps][1]), on [iNaturalist 2017/2018][2] data, and on simulated data generated from [Microsoft AirSim][3]. We have provided a taxonomy file mapping our classes into the iNat taxonomy.This is an FGVCx competition as part of the [FGVC6][4] workshop at [CVPR 2019][5], and is sponsored by [Microsoft AI for Earth](https://www.microsoft.com/en-us/ai/ai-for-earth).  There is a github page for the competition [here][6]. Please open an issue if you have questions or problems with the dataset.If you use this dataset in publication, please cite:```@article{beery2019iwildcam,    title={The iWildCam 2019 Challenge Dataset},    author={Beery, Sara and Morris, Dan and Perona, Pietro},    journal={arXiv preprint arXiv:1907.07617},    year={2019}}```Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.  [1]: https://beerys.github.io/CaltechCameraTraps/  [2]: https://github.com/visipedia/inat_comp  [3]: https://github.com/Microsoft/AirSim  [4]: https://sites.google.com/view/fgvc6/home  [5]: http://cvpr2019.thecvf.com/  [6]: https://github.com/visipedia/iwildcam_comp\"}, {'title': 'CareerCon 2019 - Help Navigate Robots ', 'url': 'https://www.kaggle.com/competitions/career-con-2019', 'briefDescription': 'Compete to get your resume in front of our sponsors', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13242/logos/header.png?t=2019-03-12-23-32-42', 'tag': 'tabular, signal processing, robotics, categorizationaccuracy', 'description': \"CareerCon 2019 is upon us!CareerCon is a digital event all about landing your first data science job — and registration is now open! Ahead of the event, we have a fun competition to get you started. See below for a unique challenge and opportunity to share your resume with select CareerCon sponsors.___________________________________The CompetitionRobots are smart… by design. To fully understand and properly navigate a task, however, they need input about their environment.In this competition, you’ll help robots recognize the floor surface they’re standing on using data collected from Inertial Measurement Units (IMU sensors).We’ve collected IMU sensor data while driving a small mobile robot over different floor surfaces on the university premises. The task is to predict which one of the nine floor types (carpet, tiles, concrete) the robot is on using sensor data such as acceleration and velocity.Succeed and you'll help improve the navigation of robots without assistance across many different surfaces, so they won’t fall down on the job.Special thanks for making this competition possible:The data for this competition has been collected by Heikki Huttunen and Francesco Lomio from the Department of Signal Processing and Damoon Mohamadi, Kaan Celikbilek, Pedram Ghazi and Reza Ghabcheloo from the Department of Automation and Mechanical  Engineering both from Tampere University, Finland. We at Kaggle would like thank them all for kindly donating the data that has made this competition possible!\"}, {'title': 'Aerial Cactus Identification', 'url': 'https://www.kaggle.com/competitions/aerial-cactus-identification', 'briefDescription': 'Determine whether an image contains a columnar cactus', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/13435/logos/header.png?t=2019-03-07-17-24-10', 'tag': 'earth and nature, image, plants, auc', 'description': \"To assess the impact of climate change on Earth's flora and fauna, it is vital to quantify how human activities such as logging, mining, and agriculture are impacting our protected natural areas. Researchers in Mexico have created the [VIGIA project](https://jivg.org/research-projects/vigia/), which aims to build a system for autonomous surveillance of protected areas. A first step in such an effort is the ability to recognize the vegetation inside the protected areas. In this competition, you are tasked with creation of an algorithm that can identify a specific type of cactus in aerial imagery.**This is a kernels-only competition, meaning you must submit predictions using Kaggle Kernels. [Read the basics here](https://www.kaggle.com/docs/competitions#submitting-predictions).**### AcknowledgmentsKaggle is hosting this competition for the machine learning community to use for fun and practice. The original version of this data can be found [here](https://www.kaggle.com/irvingvasquez/cactus-aerial-photos), with details in the following paper:Efren López-Jiménez, Juan Irving Vasquez-Gomez, Miguel Angel Sanchez-Acevedo, Juan Carlos Herrera-Lozada, Abril Valeria Uriarte-Arcia, Columnar Cactus Recognition in Aerial Images using a Deep Learning Approach. Ecological Informatics. 2019.Acknowledgements to Consejo Nacional de Ciencia y Tecnología. Project cátedra 1507. Instituto Politècnico Nacional. Universidad de la Cañada. Contributors: Eduardo Armas Garca, Rafael Cano Martnez and Luis Cresencio Mota Carrera. J.I. Vasquez-Gomez, JC. Herrera Lozada. Abril Uriarte, Miguel Sanchez.\"}, {'title': 'Data Science for Good: CareerVillage.org', 'url': 'https://www.kaggle.com/competitions/data-science-for-good-careervillage', 'briefDescription': 'Match career advice questions with professionals in the field', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12814/logos/header.png?t=2019-02-27-19-49-34', 'tag': 'education, people', 'description': \"# WelcomeIn this competition you'll notice there isn't a leaderboard, and you are not required to develop a predictive model. This isn't a traditional supervised Kaggle machine learning competition. CareerVillage.org is a nonprofit that crowdsources career advice for underserved youth. Founded in 2011 in four classrooms in New York City, the platform has now served career advice from 25,000 volunteer professionals to over 3.5M online learners. The platform uses a Q&A style similar to StackOverflow or Quora to provide students with answers to any question about any career. In this Data Science for Good challenge, CareerVillage.org, in partnership with Google.org, is inviting you to help recommend questions to appropriate volunteers. To support this challenge, CareerVillage.org has supplied five years of data. ## Problem StatementThe U.S. has almost 500 students for every guidance counselor. Underserved youth lack the network to find their career role models, making CareerVillage.org the only option for millions of young people in America and around the globe with nowhere else to turn. To date, 25,000 volunteers have created profiles and opted in to receive emails when a career question is a good fit for them. This is where your skills come in. To help students get the advice they need, the team at CareerVillage.org needs to be able to send the right questions to the right volunteers. The notifications sent to volunteers seem to have the greatest impact on how many questions are answered.**Your objective: develop a method to recommend relevant questions to the professionals who are most likely to answer them.** ## Criteria for Measuring Solutions**Performance**: How well does the solution match professionals to the questions they would be motivated to answer? CareerVillage.org will not be able to live-test every submission, so a strong entry will clearly articulate why it will be effective at motivating answers.**Easy to implement**: The CareerVillage.org team wants to put the winning submissions to work, quickly.  A good entry will be well documented and easy to test in production.**Extensibility**: In the future, CareerVillage.org aims to add more data features and to accommodate new objectives. Winning submissions should allow for this and other augmentations to be added in the future. \"}, {'title': \"Google Cloud & NCAA® ML Competition 2019-Men's\", 'url': 'https://www.kaggle.com/competitions/mens-machine-learning-competition-2019', 'briefDescription': 'Apply Machine Learning to NCAA® March Madness®', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/11999/logos/header.png?t=2019-02-12-18-56-32', 'tag': 'sports, basketball, logloss', 'description': \" As a result of the continued collaboration between Google Cloud and the NCAA, the sixth annual Kaggle-backed March Madness competition is underway! Another year, another chance to anticipate the upsets, call the probabilities, and put your bracketology skills to the leaderboard test. Kagglers will join the millions of fans who attempt to forecast the outcomes of March Madness during this year's NCAA Division I Men’s and Women’s Basketball Championships. But unlike most fans, you will pick your bracket using a combination of NCAA’s historical data and your computing power, while the ground truth unfolds on national television.In the first stage of the competition, Kagglers will rely on results of past tournaments to build and test models. We encourage you to post any useful external data as a dataset. In the second stage, competitors will forecast outcomes of all possible matchups in the 2019 NCAA Division I Men’s and Women’s Basketball Championships. You don't need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2019 results. As the official public cloud provider of the NCAA, Google is proud to provide a competition to help participants strengthen their knowledge of basketball, statistics, data modeling, and cloud technology. As part of its journey to the cloud, the NCAA has migrated 80+ years of historical and play-by-play data, from 90 championships and 24 sports, to Google Cloud Platform (GCP). The NCAA has tapped into decades of historical basketball data using BigQuery, Cloud Spanner, Datalab, Cloud Machine Learning and Cloud Dataflow, to power the analysis of team and player performance. The mission of the NCAA has long been about serving the needs of schools, their teams and students. Google Cloud is proud to support that mission by helping the NCAA use data and machine learning to better engage with its millions of fans, 500,000 student-athletes, and more than 19,000 teams. Game on! This page is for the NCAA Division I Men's tournament. Check out the NCAA Division I Women's tournament here. \"}, {'title': \"Google Cloud & NCAA® ML Competition 2019-Women's\", 'url': 'https://www.kaggle.com/competitions/womens-machine-learning-competition-2019', 'briefDescription': 'Apply Machine Learning to NCAA® March Madness®', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12000/logos/header.png?t=2019-02-12-18-48-27', 'tag': 'sports, basketball, logloss', 'description': \" As a result of the continued collaboration between Google Cloud and the NCAA®, the sixth annual Kaggle-backed March Madness competition is underway! Another year, another chance to anticipate the upsets, call the probabilities, and put your bracketology skills to the leaderboard test. Kagglers will join the millions of fans who attempt to forecast the outcomes of March Madness during this year's NCAA Division I Men’s and Women’s Basketball Championships. But unlike most fans, you will pick your bracket using a combination of NCAA’s historical data and your computing power, while the ground truth unfolds on national television.In the first stage of the competition, Kagglers will rely on results of past tournaments to build and test models. We encourage you to post any useful external data as a dataset. In the second stage, competitors will forecast outcomes of all possible matchups in the 2019 NCAA Division I Men’s and Women’s Basketball Championships. You don't need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2019 results. As the official public cloud provider of the NCAA, Google Cloud is proud to provide a competition to help participants strengthen their knowledge of basketball, statistics, data modeling, and cloud technology. As part of its journey to the cloud, the NCAA has migrated 80+ years of historical and play-by-play data, from 90 championships and 24 sports, to Google Cloud Platform (GCP). The NCAA has tapped into decades of historical basketball data using BigQuery, Cloud Spanner, Datalab, Cloud Machine Learning and Cloud Dataflow, to power the analysis of team and player performance. The mission of the NCAA has long been about serving the needs of schools, their teams and students. Google Cloud is proud to support that mission by helping the NCAA use data and machine learning to better engage with its millions of fans, 500,000 student-athletes and more than 19,000 teams. Game on! This page is for the NCAA Division I Women's tournament. Check out the NCAA Division I Men's tournament here. \"}, {'title': 'Santander Customer Transaction Prediction', 'url': 'https://www.kaggle.com/competitions/santander-customer-transaction-prediction', 'briefDescription': 'Can you identify who will make a transaction?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10385/logos/header.png?t=2018-09-12-18-50-51', 'tag': 'tabular, binary classification, banking, auc', 'description': 'At Santander  our mission is to help people and businesses prosper.  We are always looking for ways to help our customers understand their financial health and identify which products and services might help them achieve their monetary goals. Our data science team is continually challenging our machine learning algorithms, working with the global data science community to make sure  we can more accurately identify new ways to solve our most common challenge, binary classification problems such as: is a customer satisfied? Will a customer buy this product? Can a customer pay this loan?In this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem.'}, {'title': \"Don't Overfit! II\", 'url': 'https://www.kaggle.com/competitions/dont-overfit-ii', 'briefDescription': 'A Fistful of Samples', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12896/logos/header.png?t=2019-02-05-18-26-29', 'tag': 'tabular, binary classification, auc', 'description': \"### *Long ago, in the distant, fragrant mists of time, there was a competition...*It was not just any competition.It was a competition that challenged mere mortals to model a 20,000x200 matrix of continuous variables using only 250 training samples... _without overfitting_.Data scientists ― including Kaggle's very own Will Cukierski ― competed by the hundreds. Legends were made. (Will took 5th place, and eventually ended up working at Kaggle!) People overfit like crazy. It was a Kaggle-y, data science-y madhouse.So... we're doing it again.## Don't Overfit II: The OverfitteningThis is the next logical step in the evolution of weird competitions. Once again we have 20,000 rows of continuous variables, and a mere handful of training samples. Once again, we challenge you _not to overfit_. Do your best, model without overfitting, and add, perhaps, to your own legend.In addition to bragging rights, the winner also gets swag.  Enjoy!### AcknowledgmentsWe hereby salute the hard work that went into the [original competition][1], created by Phil Brierly. Thank you!  [1]: https://www.kaggle.com/c/overfitting\"}, {'title': 'TMDB Box Office Prediction', 'url': 'https://www.kaggle.com/competitions/tmdb-box-office-prediction', 'briefDescription': \"Can you predict a movie's worldwide box office revenue?\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10300/logos/header.png?t=2019-02-05-19-35-41', 'tag': 'tabular, movies and tv shows, rmsle', 'description': 'We\\'re going to make you an offer you can\\'t refuse: a Kaggle competition! In a world... where movies made an estimated $41.7 billion in 2018, the film industry is more popular than ever. But what movies make the most money at the box office? How much does a director matter? Or the budget? For some movies, it\\'s \"You had me at \\'Hello.\\'\" For others, the trailer falls short of expectations and you think \"What we have here is a failure to communicate.\"In this competition, you\\'re presented with metadata on over 7,000 past films from [The Movie Database][1] to try and predict their overall worldwide box office revenue. Data points provided include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries.  You can collect other publicly available data to use in your model predictions, but in the spirit of this competition, use only data that would have been available before a movie\\'s release.Join in, \"make our day\", and then \"you\\'ve got to ask yourself one question: \\'Do I feel lucky?\\'\"  [1]: https://www.themoviedb.org'}, {'title': 'Gendered Pronoun Resolution', 'url': 'https://www.kaggle.com/competitions/gendered-pronoun-resolution', 'briefDescription': 'Pair pronouns to their correct entities', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12797/logos/header.png?t=2019-02-01-18-45-25', 'tag': 'nlp, text, multiclassloss', 'description': \"Can you help end gender bias in pronoun resolution?Pronoun resolution is part of coreference resolution, the task of pairing an expression to its referring entity. This is an important task for natural language understanding, and the resolution of ambiguous pronouns is a longstanding challenge.Unfortunately, recent studies have suggested gender bias among state-of-the-art coreference resolvers.  Google AI Language aims to improve gender-fairness in modeling by releasing the Gendered Ambiguous Pronouns (GAP) dataset, containing gender-balanced pronouns (50% of its examples containing feminine pronouns, and 50% containing masculine pronouns).In this two-stage competition, Kagglers are challenged to build pronoun resolution systems that perform equally well regardless of pronoun gender. Stage two's final evaluation will use a new dataset following the same format. To encourage gender-fair modeling, the ratio of masculine to feminine examples in the official test data will not be known ahead of time.----------Please cite the original paper if you use GAP in your work:@inproceedings{webster2018gap,  title =     {Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns},  author =    {Webster, Kellie and Recasens, Marta and Axelrod, Vera and Baldridge, Jason},  booktitle = {Transactions of the ACL},  year =      {2018},  pages =     {to appear},}\"}, {'title': 'LANL Earthquake Prediction', 'url': 'https://www.kaggle.com/competitions/LANL-Earthquake-Prediction', 'briefDescription': 'Can you predict upcoming laboratory earthquakes?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/11000/logos/header.png?t=2019-01-04-23-26-44', 'tag': 'earth science, physics, signal processing, mae', 'description': 'Forecasting earthquakes is one of the most important problems in Earth science because of their devastating consequences. Current scientific studies related to earthquake forecasting focus on three key points: when the event will occur, where it will occur, and how large it will be.In this competition, you will address when the earthquake will take place. Specifically, you’ll predict the time remaining before laboratory earthquakes occur from real-time seismic data. If this challenge is solved and the physics are ultimately shown to scale from the laboratory to the field, researchers will have the potential to improve earthquake hazard assessments that could save lives and billions of dollars in infrastructure.This challenge is hosted by  Los Alamos National Laboratory which enhances national security by ensuring the safety of the U.S. nuclear stockpile, developing technologies to reduce threats from weapons of mass destruction, and solving problems related to energy, environment, infrastructure, health, and global security concerns. Acknowledgments: Geophysics Group: The competition builds on initial work from Bertrand Rouet-Leduc, Claudia Hulbert, and Paul Johnson. B. Rouet-Leduc prepared the data for the competition.Department of Geosciences: Data are from experiments performed by  Chas Bolton, Jacques Riviere, Paul Johnson and Prof. Chris Marone.Department of Physics & Astronomy: This competition stemmed from the DOE Council workshop “Information is in the Noise: Signatures of Evolving Fracture and Fracture Networks” held March 2018 that was organized by Prof. Laura J. Pyrak-Nolte.Department of EnergyOffice of Science, Basic Energy Sciences, Chemical Sciences, Geosciences and Biosciences Division: The Geosciences core research.Photo by Nik Shuliahin on Unsplash'}, {'title': 'PetFinder.my Adoption Prediction', 'url': 'https://www.kaggle.com/competitions/petfinder-adoption-prediction', 'briefDescription': 'How cute is that doggy in the shelter?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10686/logos/header.png?t=2018-12-19-11-59-43', 'tag': 'image, text, quadraticweightedkappa', 'description': \"Millions of stray animals suffer on the streets or are euthanized in shelters every day around the world. If homes can be found for them, many precious lives can be saved — and more happy families created.PetFinder.my has been Malaysia’s leading animal welfare platform since 2008, with a database of more than 150,000 animals. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.Animal adoption rates are strongly correlated to the metadata associated with their online profiles, such as descriptive text and photo characteristics. As one example, PetFinder is currently experimenting with a simple AI tool called the Cuteness Meter, which ranks how cute a pet is based on qualities present in their photos.In this competition you will be developing algorithms to predict the adoptability of pets - specifically, how quickly is a pet adopted? If successful, they will be adapted into AI tools that will guide shelters and rescuers around the world on improving their pet profiles' appeal, reducing animal suffering and euthanization.Top participants may be invited to collaborate on implementing their solutions into AI tools for assessing and improving pet adoption performance, which will benefit global animal welfare.Important NoteBe aware that this is being run as a Kernels Only Competition, requiring that all submissions be made via a Kernel output.   Photo by Krista Mangulsone on Unsplash \"}, {'title': 'VSB Power Line Fault Detection', 'url': 'https://www.kaggle.com/competitions/vsb-power-line-fault-detection', 'briefDescription': 'Can you detect faults in above-ground electrical lines?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10684/logos/header.png?t=2018-12-12-21-49-25', 'tag': 'tabular, binary classification, signal processing, matthewscorrelationcoefficient', 'description': \"Medium voltage overhead power lines run for hundreds of miles to supply power to cities. These great distances make it expensive to manually inspect the lines for damage that doesn't immediately lead to a power outage, such as a tree branch hitting the line or a flaw in the insulator. These modes of damage lead to a phenomenon known as partial discharge — an electrical discharge which does not bridge the electrodes between an insulation system completely. Partial discharges slowly damage the power line, so left unrepaired they will eventually lead to a power outage or start a fire. Your challenge is to detect partial discharge patterns in signals acquired from these power lines with a new meter designed at the ENET Centre at VŠB. Effective classifiers using this data will make it possible to continuously monitor power lines for faults.ENET Centre researches and develops renewable energy resources with the goal of reducing or eliminating harmful environmental impacts. Their efforts focus on developing technology solutions around transportation and processing of energy raw materials.By developing a solution to detect partial discharge you’ll help reduce  maintenance costs, and prevent power outages.\"}, {'title': 'Reducing Commercial Aviation Fatalities', 'url': 'https://www.kaggle.com/competitions/reducing-commercial-aviation-fatalities', 'briefDescription': 'Can you tell when a pilot is heading for trouble?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/11835/logos/header.png?t=2018-12-05-21-55-26', 'tag': 'multiclassloss', 'description': \"Most flight-related fatalities stem from a loss of “airplane state awareness.” That is, ineffective attention management on the part of pilots who may be distracted, sleepy or in other dangerous cognitive states.Your challenge is to build a model to detect troubling events from aircrew’s physiological data. You'll use data acquired from actual pilots in test situations, and your models should be able to run calculations in real time to monitor the cognitive states of pilots. With your help, pilots could then be alerted when they enter a troubling state, preventing accidents and saving lives.Reducing aircraft fatalities is just one of the complex problems that  Booz Allen Hamilton has been solving for business, government, and military leaders for over 100 years. Through devotion, candor, courage, and character, they produce original solutions where there are no roadmaps. Now you can help them find answers, save lives, and change the world.\"}, {'title': '20 Newsgroups Ciphertext Challenge', 'url': 'https://www.kaggle.com/competitions/20-newsgroups-ciphertext-challenge', 'briefDescription': 'V8g{9827\\x0c$A${?^*?}$$v7\\x10*.yig$w9.8}', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12133/logos/header.png?t=2018-11-29-02-51-36', 'tag': 'text, multiclass classification, macrofscore', 'description': \"This isn't your classic decoder ring puzzle found in a cereal box. There's a twist.Welcome to the Ciphertext Challenge! In this competition, we've encrypted parts of a well-known dataset -- the 20 Newsgroups dataset -- with several simple, classic ciphers.  This dataset is commonly used as a multi-class and NLP sample set, noted for its small size, varied nature, and the first-hand look it offers into the deep existential horrors of the 90s-era internet. With 20 fairly distinct classes and lots of clues, it allows for a wide variety of successful approaches.We've made the problem a little harder to solve.Fabulous Kaggle swag will go to the top competitors - the highest-scoring teams (which might be the first to crack the code!), and the most popular kernel.  Note that this is a short competition, so use your submissions wisely.* = Note: It is possible to apply a number of techniques using ONLY the ciphertext.AcknowledgementsKaggle is hosting this competition for the machine learning community to use for fun and practice. You can view and download the unencrypted dataset from Jason Rennie's homepage.  In the words of the host:The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of my knowledge, it was originally collected by Ken Lang, probably for his Newsweeder: Learning to filter netnews paper, though he does not explicitly mention this collection.If you use the dataset in a scientific publication, please reference (at a minimum) the above website.Photo by U.S. Air Force photo/Don Branum\"}, {'title': 'Microsoft Malware Prediction', 'url': 'https://www.kaggle.com/competitions/microsoft-malware-prediction', 'briefDescription': 'Can you predict if a machine will soon be hit with malware?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10683/logos/header.png?t=2018-09-19-16-54-46', 'tag': 'auc', 'description': 'The malware industry continues to be a well-organized, well-funded market dedicated to evading traditional security measures. Once a computer is infected by malware, criminals can hurt consumers and enterprises in many ways.  With more than one billion  enterprise and consumer customers, Microsoft takes this problem very seriously and is deeply invested in improving security.As one part of their overall strategy for doing so, Microsoft is challenging the data science community to develop techniques to predict if a machine will soon be hit with malware. As with their previous, Malware Challenge (2015), Microsoft is providing Kagglers with an unprecedented malware dataset to encourage open-source progress on effective techniques for predicting malware occurrences.Can you help protect more than one billion machines from damage BEFORE it happens?AcknowledgementsThis competition is hosted by Microsoft, Windows Defender ATP Research, Northeastern University College of Computer and Information Science, and Georgia Tech Institute for Information Security & Privacy. Microsoft contactsRob McCann (Robert.McCann@microsoft.com)Christian Seifert (chriseif@microsoft.com)Susan Higgs (Susan.Higgs@microsoft.com)Matt Duncan (Matthew.Duncan@microsoft.com)Northeastern University contactMansour Ahmadi (m.ahmadi@northeastern.edu)Georgia Tech contactsBrendan Saltaformaggio (brendan@ece.gatech.edu)Taesoo Kim (taesoo@gatech.edu)'}, {'title': 'NFL Punt Analytics Competition', 'url': 'https://www.kaggle.com/competitions/NFL-Punt-Analytics-Competition', 'briefDescription': 'Analyze NFL game data and suggest rules to improve player safety during punt plays', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/12125/logos/header.png?t=2018-11-30-18-08-32', 'tag': 'health, sports, football', 'description': \"# Welcome In this challenge you'll notice there isn't a leaderboard, and you are not required to develop a predictive model. This isn't a traditional supervised Kaggle machine learning competition. Instead, this challenge asks you to use data to propose specific rule modifications for the NFL that aim to reduce the occurrence of concussions during punt plays. For more information on this challenge format, see [this forum thread][1]. This challenge is part of NFL 1st & Future, presented by Arrow Electronics – the NFL’s annual Super Bowl competition designed to spur innovation in player health, safety and performance.## The ChallengeFor the 2018 season, the NFL [revised their kickoff rules](http://www.nfl.com/news/story/0ap3000000933891/article/owners-approve-changes-to-kickoff-use-of-helmet) in an effort to reduce the risk of injury during those plays. By examining injury reports, player position and velocity data, and game video, they were able to understand the game-play circumstances that may exacerbate the risk of injury to players. This comprehensive review showed that over the course of all games during the 2015-2017 seasons, the kickoff represented only six percent of plays but 12 percent of concussions. Players had approximately four times the risk of concussion on returned kickoffs compared to running or passing plays. The changes to the kickoff rule aim to address the components that posed the most risk, like the use of a two-man wedge. Now, the NFL is challenging Kagglers to help them perform the same examination, this time on punt play rules. They have provided data for all punt plays from the 2016 and 2017 NFL seasons that includes player rosters, on-field position data and video data, including the plays in which a player suffered a concussion.  Your challenge is to propose specific rule modifications (e.g. changes to the initial formation, tackling techniques, blocking rules etc.), supported by data, that may reduce the occurrence of concussions during punt plays. More details on the entry criteria are available in `Overview tab > Evaluation`. [][2]## About The NFLThe National Football League is America's most popular sports league, comprised of 32 franchises that compete each year to win the Super Bowl, the world's biggest annual sporting event. Founded in 1920, the NFL developed the model for the successful modern sports league, including national and international distribution, extensive revenue sharing, competitive excellence, and strong franchises across the country.The NFL is committed to advancing progress in the diagnosis, prevention and treatment of sports-related injuries. The NFL's ongoing health and safety efforts include support for independent medical research and engineering advancements and a commitment to look at anything and everything to protect players and make the game safer, including enhancements to medical protocols and improvements to how our game is taught and played.As more is learned, the league evaluates and changes rules to evolve the game and try to improve protections for players. Since 2002 alone, the NFL has made 50 rules changes intended to eliminate potentially dangerous tactics and reduce the risk of injuries.For more information about the NFL's health and safety efforts, please visit [www.PlaySmartPlaySafe.com](https://www.PlaySmartPlaySafe.com).----------[Evaluation][2]  [1]: https://www.kaggle.com/c/NFL-Punt-Analytics-Competition/discussion/73664  [2]: https://www.kaggle.com/c/NFL-Punt-Analytics-Competition#evaluation\"}, {'title': 'Humpback Whale Identification', 'url': 'https://www.kaggle.com/competitions/humpback-whale-identification', 'briefDescription': 'Can you identify a whale by its tail?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6961/logos/header.png', 'tag': 'image, animals, map@{k}', 'description': \"After centuries of intense whaling, recovering whale populations still have a hard time adapting to warming oceans and struggle to compete every day with the industrial fishing industry for food.To aid whale conservation efforts, scientists use photo surveillance systems to monitor ocean activity. They use the shape of whales’ tails and unique markings found in footage to identify what species of whale they’re analyzing and meticulously log whale pod dynamics and movements. For the past 40 years, most of this work has been done manually by individual scientists, leaving a huge trove of data untapped and underutilized.In this competition, you’re challenged to build an algorithm to identify individual whales in images. You’ll analyze Happywhale’s database of over 25,000 images, gathered from research institutions and public contributors. By contributing, you’ll help to open rich fields of understanding for marine mammal population dynamics around the globe.Note, this competition is similar in nature to this competition  with an expanded and updated dataset. We'd like to thank Happywhale  for providing this data and problem. Happywhale is a platform that uses image process algorithms to let anyone to submit their whale photo and have it automatically identified.\"}, {'title': 'Elo Merchant Category Recommendation', 'url': 'https://www.kaggle.com/competitions/elo-merchant-category-recommendation', 'briefDescription': 'Help understand customer loyalty', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10445/logos/header.png?t=2018-10-24-17-13-50', 'tag': 'tabular, regression, banking, rmse', 'description': 'Imagine being hungry in an unfamiliar part of town and getting restaurant recommendations served up, based on your personal preferences, at just the right moment. The recommendation comes with an attached discount from your credit card provider for a local place around the corner!Right now, Elo, one of the largest payment brands in Brazil, has built partnerships with merchants in order to offer promotions or discounts to cardholders. But do these promotions work for either the consumer or the merchant? Do customers enjoy their experience? Do merchants see repeat business? Personalization is key.Elo has built machine learning models to understand the most important aspects and preferences in their customers’ lifecycle, from food to shopping. But so far none of them is specifically tailored for an individual or profile. This is where you come in.In this competition, Kagglers will develop algorithms to identify and serve the most relevant opportunities to individuals, by uncovering signal in customer loyalty. Your input will improve customers’ lives and help Elo reduce unwanted campaigns, to create the right experience for customers.'}, {'title': \"Don't call me turkey!\", 'url': 'https://www.kaggle.com/competitions/dont-call-me-turkey', 'briefDescription': 'Thanksgiving Edition: Find the turkey in the sound bite', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/11880/logos/header.png?t=2018-11-15-19-27-55', 'tag': 'tabular, binary classification, animals, auc', 'description': \"Hungry for a new competition? Give thanks for this opportunity to avoid those awkward family political dinner discussions and endless holiday movie marathons over the Thanksgiving break. Spend time with your Kaggle family instead to find the real turkey! In this competition you are tasked with finding the turkey sound signature from pre-extracted audio features. A simple binary problem, or is it? What does a turkey really sound like? How many sounds are similar? Will you be able to find the turkey or will you go a-fowl? This is a short, fun, holiday, playground competition. Please, do not ruin the fun for yourself and for everyone by using a model trained on the answers.  Don't be a turkey!\"}, {'title': 'Traveling Santa 2018 - Prime Paths', 'url': 'https://www.kaggle.com/competitions/traveling-santa-2018-prime-paths', 'briefDescription': 'But does your code recall, the most efficient route of all?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10733/logos/header.png?t=2018-10-19-18-23-20', 'tag': 'optimization, custom metric', 'description': \"Rudolph the red-nosed reindeerHad some very tired hoovesBut he had a job to finishCould he do it with the shortest moves?All of the other reindeerUsed to laugh and mock his codeThey always said poor RudolphCouldn't handle the workloadThen one foggy Christmas EveSanta came to sayI see you've taken number theoryPlease make this night a bit less dreary?Then how the reindeer loved himand each enrolled in an AI degreeRudolph the red-nosed reindeerWe get to go to bed early!Rudolph has always believed in working smarter, not harder. And what better way to earn the respect of Comet and Blitzen than showing the initiative to improve Santa's annual route for delivering toys on Christmas Eve?This year,  Rudolph believes he can motivate the overworked Reindeer team by wisely choosing the order in which they visit the houses on Santa's list. The houses in prime cities always leave carrots for the Reindeers alongside the usual cookies and milk. These carrots are just the sustenance the Reindeers need to keep pace. In fact, Rudolph has found that if the Reindeer team doesn't originate from a prime city exactly every 10th step, it takes the 10% longer than it normally would to make their next destination!Can you help Rudolph solve the Traveling Santa problem subject to his carrot constraint? His team--and Santa--are counting on you!Attributions:Reindeer Photo:\\xa0Norman TsuiStocking Photo:  Wesley Tingey\"}, {'title': 'Histopathologic Cancer Detection', 'url': 'https://www.kaggle.com/competitions/histopathologic-cancer-detection', 'briefDescription': 'Identify metastatic tissue in histopathologic scans of lymph node sections', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/11848/logos/header.png?t=2018-11-15-01-52-19', 'tag': 'cancer, medicine, research, auc', 'description': 'In this competition, you must create an algorithm to identify metastatic cancer in small image patches taken from larger digital pathology scans. The data for this competition is a slightly modified version of the PatchCamelyon (PCam) benchmark dataset (the original PCam dataset contains duplicate images due to its probabilistic sampling, however, the version presented on Kaggle does not contain duplicates).PCam is highly interesting for both its size, simplicity to get started on, and approachability. In the authors\\' words: [PCam] packs the clinically-relevant task of metastasis detection into a straight-forward binary image classification task, akin to CIFAR-10 and MNIST. Models can easily be trained on a single GPU in a couple hours, and achieve competitive scores in the Camelyon16 tasks of tumor detection and whole-slide image diagnosis. Furthermore, the balance between task-difficulty and tractability makes it a prime suspect for fundamental machine learning research on topics as active learning, model uncertainty, and explainability.  Acknowledgements Kaggle is hosting this competition for the machine learning community to use for fun and practice. This dataset was provided by Bas Veeling, with additional input from Babak Ehteshami Bejnordi, Geert Litjens, and Jeroen van der Laak. You may view and download the official Pcam dataset from  GitHub. The data is provided under the CC0 License, following the license of Camelyon16.If you use PCam in a scientific publication, please reference the following papers:[1] B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling. \"Rotation Equivariant CNNs for Digital Pathology\".  arXiv:1806.03962[2] Ehteshami Bejnordi et al. Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA: The Journal of the American Medical Association, 318(22), 2199–2210. doi:jama.2017.14585Photo by Ousa Chea'}, {'title': 'Quora Insincere Questions Classification', 'url': 'https://www.kaggle.com/competitions/quora-insincere-questions-classification', 'briefDescription': 'Detect toxic content to improve online conversations', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10737/logos/header.png?t=2018-10-24-22-07-48', 'tag': 'text, binary classification, custom metric', 'description': \"An existential problem for any major website today is how to handle toxic and divisive content. Quora wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world.Quora is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers.In this competition, Kagglers will develop models that identify and flag insincere questions. To date, Quora has employed both machine learning and manual review to address this problem. With your help, they can develop more scalable methods to detect toxic and misleading content.Here's your chance to combat online trolls at scale. Help Quora uphold their policy of “Be Nice, Be Respectful” and continue to be a place for sharing and growing the world’s knowledge.Important NoteBe aware that this is being run as a Kernels Only Competition, requiring that all submissions be made via a Kernel output. Please read the Kernels FAQ and the data page very carefully to fully understand how this is designed.\"}, {'title': 'PUBG Finish Placement Prediction (Kernels Only)', 'url': 'https://www.kaggle.com/competitions/pubg-finish-placement-prediction', 'briefDescription': 'Can you predict the battle royale finish of PUBG Players?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10335/logos/header.png?t=2018-10-02-21-04-56', 'tag': 'tabular, video games, mae', 'description': 'So, where we droppin\\' boys and girls?Battle Royale-style video games have taken the world by storm. 100 players are dropped onto an island empty-handed and must explore, scavenge, and eliminate other players until only one is left standing, all while the play zone continues to shrink. PlayerUnknown\\'s BattleGrounds (PUBG) has enjoyed massive popularity. With over 50 million copies sold, it\\'s the fifth best selling game of all time, and has millions of active monthly players.  The team at PUBG has made official game data available for the public to explore and scavenge outside of \"The Blue Circle.\" This competition is not an official or affiliated PUBG site - Kaggle collected data made possible through the PUBG Developer API.You are given over 65,000 games\\' worth of anonymized player data, split into training and testing sets, and asked to predict final placement from final in-game stats and initial player ratings. What\\'s the best strategy to win in PUBG? Should you sit in one spot and hide your way into victory, or do you need to be the top shot? Let\\'s let the data do the talking!'}, {'title': 'Human Protein Atlas Image Classification', 'url': 'https://www.kaggle.com/competitions/human-protein-atlas-image-classification', 'briefDescription': 'Classify subcellular protein patterns in human cells', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10418/logos/header.png?t=2018-08-20-03-03-58', 'tag': 'classification, image, macrofscore', 'description': \"In this competition, Kagglers will develop models capable of classifying mixed patterns of proteins in microscope images.\\xa0The Human Protein Atlas\\xa0will use these models to build a tool integrated with their smart-microscopy system to identify a protein's location(s) from a high-throughput image.Proteins are “the doers” in the human cell, executing many functions that together enable life. Historically, classification of proteins has been limited to single patterns in one or a few cell types, but in order to fully understand the complexity of the human cell, models must classify mixed patterns across a range of different human cells.Images visualizing proteins in cells are commonly used for biomedical research, and these cells could hold the key for the next breakthrough in medicine. However, thanks to advances in high-throughput microscopy, these images are generated at a far greater pace than what can be manually evaluated. Therefore, the need is greater than ever for automating biomedical image analysis to accelerate the understanding of human cells and disease.\\xa0Nature Methods\\xa0has indicated interest in considering a paper discussing the outcome and approaches of the challenge. The Human Protein Atlas team would like to invite top performing teams to join as co-authors in the writing of this paper.Top performing teams will also be eligible to compete for the special prize. Additional information for both the special prize and co-authoring for Nature Methods will become available through the Discussion posts once the main competition is complete.\\xa0AcknowledgementsThe Human Protein Atlas is a Sweden-based initiative aimed at mapping all human proteins in cells, tissues and organs. All the data in the knowledge resource is open access to allow anyone to pursue exploration of the human proteome. In a recent publication, the Human Protein Atlas team has demonstrated the promise of both citizen science and artificial intelligence approaches in describing the location of human proteins in images, however current results are yet to approach expert-level annotations (Sullivan et al, Nature Biotechnology, Oct 2018).\"}, {'title': 'PLAsTiCC Astronomical Classification', 'url': 'https://www.kaggle.com/competitions/PLAsTiCC-2018', 'briefDescription': 'Can you help make sense of the Universe?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10384/logos/header.png?t=2018-09-12-20-57-06', 'tag': 'tabular, astronomy, weightedmulticlassloss', 'description': \"Help some of the world's leading astronomers grasp the deepest properties of the universe.The human eye has been the arbiter for the classification of astronomical sources in the night sky for hundreds of years. But a new facility -- the Large Synoptic Survey Telescope (LSST) -- is about to revolutionize the field, discovering 10 to 100 times more astronomical sources that vary in the night sky than we've ever known. Some of these sources will be completely unprecedented!The Photometric LSST Astronomical Time-Series Classification Challenge (PLAsTiCC) asks Kagglers to help prepare to classify the data from this new survey. Competitors will classify astronomical sources that vary with time into different classes, scaling from a small training set to a very large test set of the type the LSST will discover. More background information is available here.AcknowledgementsPLAsTiCC is funded through LSST Corporation Grant Award # 2017-03 and administered by the University of Toronto.  Financial support for LSST comes from the National Science Foundation (NSF) through Cooperative Agreement No. 1258333, the Department of Energy (DOE) Office of Science under Contract No. DE-AC02-76SF00515, and private funding raised by the LSST Corporation. The NSF-funded LSST Project Office for construction was established as an operating center under management of the Association of Universities for Research in Astronomy (AURA).  The DOE-funded effort to build the LSST camera is managed by the SLAC National Accelerator Laboratory (SLAC).The National Science Foundation (NSF) is an independent federal agency created by Congress in 1950 to promote the progress of science. NSF supports basic research and people to create knowledge that transforms the future.    Photo Credit: M. Park/Inigo Films/LSST/AURA/NSF  [1]: https://arxiv.org/abs/1810.00001\"}, {'title': 'Quick, Draw! Doodle Recognition Challenge', 'url': 'https://www.kaggle.com/competitions/quickdraw-doodle-recognition', 'briefDescription': 'How accurately can you identify a doodle?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10200/logos/header.png?t=2018-09-28-21-51-34', 'tag': 'image, map@{k}', 'description': '\"Quick, Draw!\" was released as an experimental game to educate the public in a playful way about how AI works. The game prompts users to draw an image depicting a certain category, such as ”banana,” “table,” etc. The game generated more than 1B drawings, of which a subset was publicly released as the basis for this competition’s training set. That subset contains 50M drawings encompassing 340 label categories.Sounds fun, right? Here\\'s the challenge: since the training data comes from the game itself, drawings can be incomplete or may not match the label. You’ll need to build a recognizer that can effectively learn from this noisy data and perform well on a manually-labeled test set from a different distribution.Your task is to build a better classifier for the existing Quick, Draw! dataset. By advancing models on this dataset, Kagglers can improve pattern recognition solutions more broadly. This will have an immediate impact on handwriting recognition and its robust applications in areas including OCR (Optical Character Recognition), ASR (Automatic Speech Recognition) & NLP (Natural Language Processing).'}, {'title': 'Two Sigma: Using News to Predict Stock Movements', 'url': 'https://www.kaggle.com/competitions/two-sigma-financial-news', 'briefDescription': 'Use news analytics to predict stock price performance', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9933/logos/header.png?t=2018-08-22-18-55-34', 'tag': 'finance, news, currencies and foreign exchange, custom metric', 'description': \"**August 2019 Update: this competition is closed and is no longer accepting submissions.  The data has been removed from this competition and is not available for use. Thanks for participating!**Can we use the content of news analytics to predict stock price performance? The ubiquity of data today enables investors at any scale to make better investment decisions. The challenge is ingesting and interpreting the data to determine which data is useful, finding the signal in this sea of information. Two Sigma  is passionate about this challenge and is excited to share it with the Kaggle community.As a scientifically driven investment manager, Two Sigma has been applying technology and data science to financial forecasts for over 17 years. Their pioneering advances in big data, AI, and machine learning have pushed the investment industry forward. Now, they're eager to engage with Kagglers in this continuing pursuit of innovation.By analyzing news data to predict stock prices, Kagglers have a unique opportunity to advance the state of research in understanding the predictive power of the news. This power, if harnessed, could help predict financial outcomes and generate significant economic impact all over the world. Data for this competition comes from the following sources:Market data provided by Intrinio.News data provided by Thomson Reuters. Copyright Thomson Reuters, 2017. All Rights Reserved. Use, duplication, or sale of this service, or data contained herein, except as described in the Competition Rules, is strictly prohibited.The THOMSON REUTERS Kinesis Logo and THOMSON REUTERS are trademarks of Thomson Reuters and its affiliated companies in the United States and other countries and used herein under license.\"}, {'title': 'Google Analytics Customer Revenue Prediction', 'url': 'https://www.kaggle.com/competitions/ga-customer-revenue-prediction', 'briefDescription': 'Predict how much GStore customers will spend', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10038/logos/header.png?t=2018-06-21-23-13-17', 'tag': 'tabular, regression, rmse', 'description': 'The 80/20 rule has proven true for many businesses–only a small percentage of customers produce most of the revenue. As such, marketing teams are challenged to make appropriate investments in promotional strategies.RStudio, the developer of free and open tools for R and enterprise-ready products for teams to scale and share work, has partnered with Google Cloud and Kaggle to demonstrate the business impact that thorough data analysis can have.In this competition, you’re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. Hopefully, the outcome will be more actionable operational changes and a better use of marketing budgets for those companies who choose to use data analysis on top of GA data.'}, {'title': 'Inclusive Images Challenge', 'url': 'https://www.kaggle.com/competitions/inclusive-images-challenge', 'briefDescription': 'Stress test image classifiers across new geographic distributions', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10386/logos/header.png?t=2018-08-27-20-05-33', 'tag': 'image, multiclass classification, meanfscorebeta', 'description': 'Making products that work for people all over the globe is an important value at Google AI. In the field of classification, this means developing models that work well for regions all over the world. Today, the dataset a model is trained on greatly dictates the performance of that model. A system trained on a dataset that doesn’t represent a broad range of localities could perform worse on images drawn from geographic regions underrepresented in the training data. Google and the industry at large are working to create more diverse & representative datasets. But it is also important for the field to make progress in understanding how to build models when the data available may not cover all audiences a model is meant to reach.Google AI is challenging Kagglers to develop models that are robust to blind spots that might exist in a data set, and to create image recognition systems that can perform well on test images drawn from different geographic distributions than the ones they were trained on.By finding ways to teach image classifiers to generalize to new geographic and cultural contexts, we hope the community will make even more progress in inclusive machine learning that benefits everyone, everywhere.Note: This competition is run in two stages. Refer to the FAQ for an explanation of how this works & the Timeline for specific dates.This competition is a part of the NIPS 2018 competition track. Winners will be invited to attend and present their solutions at the workshop. Shankar et al. \"No Classification without Representation: Assessing Geodiversity Issues in Open Data Sets for the Developing World\" NIPS 2017 Workshop on Machine Learning for the Developing World '}, {'title': 'RSNA Pneumonia Detection Challenge', 'url': 'https://www.kaggle.com/competitions/rsna-pneumonia-detection-challenge', 'briefDescription': 'Can you build an algorithm that automatically detects potential pneumonia cases?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10338/logos/header.png?t=2018-08-21-19-48-11', 'tag': 'image, medicine, custom metric', 'description': 'In this competition, you’re challenged to build an algorithm to detect a visual signal for pneumonia in medical images. Specifically, your algorithm needs to automatically locate lung opacities on chest radiographs.Here’s the backstory and why solving this problem matters.Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally. In 2015, 920,000 children under the age of 5 died from the disease. In the United States, pneumonia accounts for over 500,000 visits to emergency departments [1] and over 50,000 deaths in 2015 [2], keeping the ailment on the list of top 10 causes of death in the country.While common, accurately diagnosing pneumonia is a tall order. It requires review of a chest radiograph (CXR) by highly trained specialists and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity [3] on CXR. However, the diagnosis of pneumonia on CXR is complicated because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis.CXRs are the most commonly performed diagnostic imaging study. A number of factors such as positioning of the patient and depth of inspiration can alter the appearance of the CXR [4], complicating interpretation further. In addition, clinicians are faced with reading high volumes of images every shift.To improve the efficiency and reach of diagnostic services, the Radiological Society of North America (RSNA®) has reached out to Kaggle’s machine learning community and collaborated with the US National Institutes of Health, The Society of Thoracic Radiology, and MD.ai to develop a rich dataset for this challenge.![RSNA Banner][1]The RSNA is an international society of radiologists, medical physicists and other medical professionals with more than 54,000 members from 146 countries across the globe. They see the potential for ML to automate initial detection (imaging screening) of potential pneumonia cases in order to prioritize and expedite their review.Challenge participants may be invited to present their AI models and methodologies during an award ceremony at the RSNA Annual Meeting which will be held in Chicago, Illinois, USA, from November 25-30, 2018.AcknowledgementsThank you to the National Institutes of Health Clinical Center for publicly providing the Chest X-Ray dataset [5].* NIH News release: [NIH Clinical Center provides one of the largest publicly available chest x-ray datasets to scientific community][2]* [Original source files and documents][3]Also, [a big thank you][4] to the competition organizers!References1.    Rui P, Kang K. National Ambulatory Medical Care Survey: 2015 Emergency Department Summary Tables.  Table 27.  Available from: [www.cdc.gov/nchs/data/nhamcs/web_tables/2015_ed_web_tables.pdf][5]2.    Deaths: Final Data for 2015.  Supplemental Tables. Tables I-21, I-22.  Available from: [www.cdc.gov/nchs/data/nvsr/nvsr66/nvsr66_06_tables.pdf][6]3.    Franquet T.  Imaging of community-acquired pneumonia.  J Thorac Imaging 2018 (epub ahead of print).  PMID 300362974.    Kelly B.  The Chest Radiograph. Ulster Med J 2012;81(3):143-1485.    Wang X, Peng Y, Lu L, Lu Z, Bagheri M, Summers RM. ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases. IEEE CVPR 2017, http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf  [1]: https://storage.googleapis.com/kaggle-media/competitions/rsna/Kaggle_Banner.jpg \"RSNA-Banner\"  [2]: https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community  [3]: https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345  [4]: https://www.kaggle.com/c/rsna-pneumonia-detection-challenge#Acknowledgements  [5]: http://www.cdc.gov/nchs/data/nhamcs/web_tables/2015_ed_web_tables.pdf  [6]: http://www.cdc.gov/nchs/data/nvsr/nvsr66/nvsr66_06_tables.pdf'}, {'title': 'Airbus Ship Detection Challenge', 'url': 'https://www.kaggle.com/competitions/airbus-ship-detection', 'briefDescription': 'Find ships on satellite images as quickly as possible', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9988/logos/header.png?t=2018-07-16-11-04-58', 'tag': 'image, intersectionoverunionobjectsegmentationbeta', 'description': \"Airbus is excited to challenge Kagglers to build a model that detects all ships in satellite images as quickly as possible. Can you find them even in imagery with clouds or haze? Here’s the backstory: Shipping traffic is growing fast. More ships increase the chances of infractions at sea like environmentally devastating ship accidents, piracy, illegal fishing, drug trafficking, and illegal cargo movement. This has compelled many organizations, from environmental protection agencies to insurance companies and national government authorities, to have a closer watch over the open seas.Airbus offers comprehensive maritime monitoring services by building a meaningful solution for wide coverage, fine details, intensive monitoring, premium reactivity and interpretation response.Combining its proprietary-data with highly-trained analysts, they help to support the maritime industry to increase knowledge, anticipate threats, trigger alerts, and improve efficiency at sea.A lot of work has been done over the last 10 years to automatically extract objects from satellite images with significative results but no effective operational effects.  Now Airbus is turning to Kagglers to increase the accuracy and  speed of automatic ship detection.Algorithm Speed Prize: After the Kaggle challenge is complete,  competitors may submit their model via a private Kaggle kernel for a speed evaluation based upon the inference time on over 40.000  images chips (typical size of a full satellite image) to win a special algorithm speed prize.\\xa0If you're interested to explore more Airbus data, you are welcomed to check out the OneAtlas Sandbox. And for more insights on our Maritime Surveillance capabilities, have a look at Airbus Intelligence page.\"}, {'title': 'New York City Taxi Fare Prediction', 'url': 'https://www.kaggle.com/competitions/new-york-city-taxi-fare-prediction', 'briefDescription': \"Can you predict a rider's taxi fare?\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10170/logos/header.png?t=2018-07-12-22-07-30', 'tag': 'tabular, regression, rmse', 'description': 'In this playground competition, hosted in partnership with Google Cloud and Coursera, you are tasked with predicting the fare amount (inclusive of tolls) for a taxi ride in New York City given the pickup and dropoff locations.  While you can get a basic estimate based on just the distance between the two points, this will result in an RMSE of $5-$8, depending on the model used (see [the starter code][1] for an example of this approach in Kernels). Your challenge is to do better than this using Machine Learning techniques! To learn how to handle large datasets with ease and solve this problem using TensorFlow, consider taking the [Machine Learning with TensorFlow on Google Cloud Platform][2] specialization on Coursera -- the taxi fare problem is one of several real-world problems that are used as case studies in the series of courses. To make this easier, head to [Coursera.org/NEXTextended][3] to claim this specialization for free for the first month!  [1]: https://www.kaggle.com/dster/nyc-taxi-fare-starter-kernel-simple-linear-model  [2]: https://www.coursera.org/specializations/machine-learning-tensorflow-gcp?utm_source=googlecloud&utm_medium=institutions&utm_campaign=kaggle_competition_email  [3]: https://www.coursera.org/promo/NEXTExtended?utm_source=googlecloud&utm_medium=institutions&utm_campaign=kaggle_competition_2018'}, {'title': 'TGS Salt Identification Challenge', 'url': 'https://www.kaggle.com/competitions/tgs-salt-identification-challenge', 'briefDescription': \"Segment salt deposits beneath the Earth's surface\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10151/logos/header.png?t=2018-07-18-15-01-00', 'tag': 'image, geology, custom metric', 'description': 'Several areas of Earth with large accumulations of oil and gas also have huge deposits of salt below the surface.But unfortunately, knowing where large salt deposits are precisely is very difficult. Professional seismic imaging still requires expert human interpretation of salt bodies. This leads to very subjective, highly variable renderings. More alarmingly, it leads to potentially dangerous situations for oil and gas company drillers.To create the most accurate seismic images and 3D renderings, TGS (the world’s leading geoscience data company) is hoping Kaggle’s machine learning community will be able to build an algorithm that automatically and accurately identifies if a subsurface target is salt or not.'}, {'title': 'Costa Rican Household Poverty Level Prediction', 'url': 'https://www.kaggle.com/competitions/costa-rican-household-poverty-prediction', 'briefDescription': 'Can you identify which households have the highest need for social welfare assistance?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9840/logos/header.png?t=2018-07-11-23-24-08', 'tag': 'tabular, multiclass classification, macrofscore', 'description': \"The Inter-American Development Bank is asking the Kaggle community for help with income qualification for some of the world's poorest families. Are you up for the challenge?Here's the backstory: Many social programs have a hard time making sure the right people are given enough aid. It’s especially tricky when a program focuses on the poorest segment of the population. The world’s poorest typically can’t provide the necessary income and expense records to prove that they qualify.In Latin America, one popular method uses an algorithm to verify income qualification. It’s called the Proxy Means Test (or PMT). With PMT, agencies use a model that considers a family’s observable household attributes like the material of their walls and ceiling, or the assets found in the home to classify them and predict their level of need.While this is an improvement, accuracy remains a problem as the region’s population grows and poverty declines.To improve on PMT, the IDB (the largest source of development financing for Latin America and the Caribbean) has turned to the Kaggle community. They believe that new methods beyond traditional econometrics, based on a dataset of Costa Rican household characteristics, might help improve PMT’s performance.Beyond Costa Rica, many countries face this same problem of inaccurately assessing social need. If Kagglers can generate an improvement, the new algorithm could be implemented in other countries around the world.This is a Kernels-Only Competition, so you must submit your code through Kernels, rather than uploading .csv predictions. You can create private Kernels and even share/edit your work with teammates by adding them as collaborators.\"}, {'title': 'Google AI Open Images - Visual Relationship Track', 'url': 'https://www.kaggle.com/competitions/google-ai-open-images-visual-relationship-track', 'briefDescription': 'Detect pairs of objects in particular relationships.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9951/logos/header.png?t=2018-06-15-18-26-32', 'tag': 'custom metric', 'description': 'IntroductionGoogle AI (Google’s AI research arm, tasked with advancing AI for everyone) is challenging you to build an algorithm that detects objects automatically using an absolutely massive training dataset ― one with more varied and complex bounding-box annotations and object classes than ever before.Here\\'s the background. Computers are getting better and better at vision. But in a few critical ways, they still can\\'t match a human’s intuitive perception.For example, what do you see when you look at this photo?Most of us would answer, “a sandy beach, the ocean, a few people walking, some trees, grass, and buildings…a woman walking her dog right there! Oh yeah, and there is a man holding a plastic cup.”Can a computer provide as precise an image description? Google AI wants to further push the capabilities of computer vision. We hope that providing very large training set will stimulate research into more sophisticated object and relationship detection models that will exceed current state-of-the-art performance.The results of this Challenge will be presented at a workshop at the European Conference on Computer Vision 2018.Visual Relationship Detection TrackIdentifying different objects (man and cup) is an important problem on its own, but identifying the relationship between them (holding) is critical for many real world use cases.In this Visual Relationship Detection track Challenge you’re asked to build an algorithm that detects pairs of objects in particular relations: things like \"woman playing guitar,\" \"beer on table,\" or \"dog inside car.\"The Challenge dataset includes both object bounding boxes and visual relationship annotations. The training set contains annotations for 329 distinct relationship triplets, occurring a total of 374,768 times.  In this track of the Challenge, you are asked to build the best performing algorithm for automatically detecting relationships triplets.  Please refer to the Open Images Challenge page for additional details on the dataset.This competition is one of two tracks in the Open Images Challenge.  Find the Object Detection track of this competition using the entire training set here. Example of ‘man playing guitar’ Radiofiera - Villa Cordellina Lombardi, Montecchio Maggiore (VI) - agosto 2010 by Andrea SartoratiExample of ‘chair at table’ Epic Fireworks - Loads A Room by Epic Fireworks'}, {'title': 'Google AI Open Images - Object Detection Track', 'url': 'https://www.kaggle.com/competitions/google-ai-open-images-object-detection-track', 'briefDescription': 'Detect objects in varied and complex images.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9949/logos/header.png?t=2018-06-15-18-13-31', 'tag': 'custom metric', 'description': 'IntroductionGoogle AI (Google’s AI research arm, tasked with advancing AI for everyone) is challenging you to build an algorithm that detects objects automatically using an absolutely massive training dataset ― one with more varied and complex bounding-box annotations and object classes than ever before.Here\\'s the background. Computers are getting better and better at vision. But in a few critical ways, they still can\\'t match a human’s intuitive perception.For example, what do you see when you look at this photo?Most of us would answer, “a sandy beach, the ocean, a few people walking, some trees, grass, and buildings…a woman walking her dog right there! Oh yeah, and there is a man holding a plastic cup.”Can a computer provide as precise an image description? Google AI wants to further push the capabilities of computer vision. We hope that providing very large training set will stimulate research into more sophisticated object and relationship detection models that will exceed current state-of-the-art performance.The results of this Challenge will be presented at a workshop at the European Conference on Computer Vision 2018.Object Detection TrackObject detection is a central task in computer vision, with applications ranging across search, robotics, self-driving cars, and many others.  As deep network solutions become deeper and more complex, they are often limited by the amount of training data available.With this in mind, to spur advances in analyzing and understanding images, Google AI has publicly released the Open Images dataset.  Open Images follows the tradition of PASCAL VOC, ImageNet and COCO, now at an unprecedented scale.The Open Images Challenge is based on Open Images dataset. The training set of the Challenge contains:12M bounding-box annotations for 500 object classes on 1.7M training imagesImages of complex scenes with several objects–an average of 7 boxes per imageHighly varied images that contain brand new objects like “fedora” and “snowman”Class hierarchy that reflects the relationships between classes of Open Images. In this track of the Challenge, you are asked to build the best performing algorithm for automatically detecting objects. Please refer to the Open Images Challenge page for additional details on the dataset.In addition to this Object Detection track, the Challenge also includes a Visual Relationship Detection track to detect pairs of objects in particular relations, e.g. \"woman playing guitar,\" \"beer on table,\" \"dog inside car\", \"man holding coffee\", etc. The Visual Relationship Detection track is available here.Example annotations. Left: Mark Paul Gosselaar plays the guitar by Rhys A. Right: the house by anita kluska. Both images used under CC BY 2.0 license.'}, {'title': 'Store Item Demand Forecasting Challenge', 'url': 'https://www.kaggle.com/competitions/demand-forecasting-kernels-only', 'briefDescription': 'Predict 3 months of item sales at different stores ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9999/logos/header.png?t=2018-06-28-21-19-41', 'tag': 'tabular, smape', 'description': \"This competition is provided as a way to explore different time series techniques on a relatively simple and clean dataset. You are given 5 years of store-item sales data, and asked to predict 3 months of sales for 50 different items at 10 different stores.What's the best way to deal with seasonality? Should stores be modeled separately, or can you pool them together? Does deep learning work better than ARIMA? Can either beat xgboost?This is a great competition to explore different models and improve your skills in forecasting.\"}, {'title': 'Flavours of Physics: Finding τ  →  μμμ (Kernels Only)', 'url': 'https://www.kaggle.com/competitions/flavours-of-physics-kernels-only', 'briefDescription': 'Identify a rare decay phenomenon', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10014/logos/header.png?t=2018-06-20-19-58-34', 'tag': 'custom metric', 'description': 'The aim of this playground challenge is to find a phenomenon that is not already known to exist – charged lepton flavour violation – thereby helping to establish \"new physics\".\\xa0Flavours of Physics 101The laws of nature ensure that some physical quantities, such as energy or momentum, are conserved. From Noether’s theorem, we know that each conservation law is associated with a fundamental symmetry. For example, conservation of energy is due to the time-invariance (the outcome of an experiment would be the same today or tomorrow) of physical systems. The fact that physical systems behave the same, regardless of where they are located or how they are oriented, gives rise to the conservation of linear and angular momentum.Symmetries are also crucial to the structure of the Standard Model\\xa0of particle physics, our present theory of interactions at microscopic scales. Some are built into the model, while others appear accidentally from it. In the Standard Model, lepton flavour, the number of electrons and electron-neutrinos, muons and muon-neutrinos, and tau and tau-neutrinos, is one such conserved quantity.Interestingly, in many proposed extensions to the Standard Model, this symmetry doesn’t exist, implying decays that do not conserve lepton flavour are possible. One decay searched for at the LHC is τ → μμμ (or τ → 3μ). Observation of this decay would be a clear indication of the violation of lepton flavour and a sign of long-sought new physics.Competition DesignYou will be working with\\xa0real data from the LHCb experiment\\xa0at the LHC, mixed with simulated datasets of the decay. The metric used\\xa0in this challenge includes checks that physicists do in their analysis to make sure the\\xa0results are unbiased. These\\xa0checks have been built into the\\xa0competition design to help ensure that\\xa0the results will be useful for physicists in\\xa0future studies.\\xa0To get started, review the\\xa0Data Page, and be sure to download\\xa0the Starter Kit. The Starter Kit\\xa0will help you to get used to the unique submission procedure for this competition.Competition Video TutorialYou\\'ve got lots of questions.\\xa0Researchers at CERN & LCHb have the answers. - What is the goal of this competition? (1:56) - Why is finding τ → μμμ exciting? (2:18) - What are flavours? (4:10) - Why use machine learning to find τ → μμμ? (4:57) - How did you decide on the size of the dataset? (5:31) - Why is weighted AUC the evaluation metric? (6:09) - Why use Ds → φπ data for the Agreement Test? (7:53) - Why do we need a Correlation Check? (8:44) - How will the competition results impact what you do? (11:38) - How will the competition results be used at CERN? (12:17)ResourcesFlavour of Physics, Research DocumentationRoel Aaij et al., Search for the lepton flavour violating decay τ → µµµ, 2015, JHEP, 1502:121, 2015New approaches for boosting to uniformityAcknowledgementsThis competition is brought to you by:\\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0Co-sponsored by:Additional support from:\\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0 \\xa0\\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0'}, {'title': \"What's Cooking? (Kernels Only)\", 'url': 'https://www.kaggle.com/competitions/whats-cooking-kernels-only', 'briefDescription': 'Use recipe ingredients to categorize the cuisine', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10012/logos/header.png?t=2018-06-20-19-44-38', 'tag': 'text, food, multiclass classification, categorizationaccuracy', 'description': \"Picture yourself strolling\\xa0through your local, open-air market...\\xa0What do you see? What do you smell? What will you make for dinner tonight?If you're in Northern California, you'll be\\xa0walking past the inevitable\\xa0bushels of leafy greens, spiked with dark purple kale\\xa0and the bright pinks and yellows of chard. Across the world in South Korea, mounds of bright red kimchi greet you, while the smell of the sea draws your attention to squids squirming nearby. India’s market is perhaps the most colorful, awash in the rich hues and aromas of dozens of spices: turmeric, star anise, poppy seeds, and garam masala as far as the eye can see.Some of our strongest geographic and cultural associations are tied to a\\xa0region's local foods. This playground competitions\\xa0asks you to predict the category of a dish's cuisine given a\\xa0list of its ingredients.\\xa0AcknowledgementsWe\\xa0want to thank Yummly\\xa0for\\xa0providing this unique dataset. Kaggle is hosting this playground competition for fun and practice.\"}, {'title': 'Movie Review Sentiment Analysis (Kernels Only)', 'url': 'https://www.kaggle.com/competitions/movie-review-sentiment-analysis-kernels-only', 'briefDescription': 'Classify the sentiment of sentences from the Rotten Tomatoes dataset', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/10025/logos/header.png?t=2018-06-21-18-32-17', 'tag': 'text, multiclass classification, categorizationaccuracy', 'description': '\"There\\'s a thin line between likably old-fashioned and fuddy-duddy, and The Count of Monte Cristo ... never quite settles on either side.\"The Rotten Tomatoes movie review dataset is a corpus of movie reviews used for sentiment analysis, originally collected by Pang and Lee [1]. In their work on sentiment treebanks, Socher et al. [2] used Amazon\\'s Mechanical Turk to create fine-grained labels for all parsed phrases in the corpus. This competition presents a chance to benchmark your sentiment-analysis ideas on the Rotten Tomatoes dataset. You are asked to label phrases\\xa0on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive. Obstacles like sentence negation, sarcasm, terseness, language ambiguity, and many others make this task very challenging.Kaggle is hosting this competition for the machine learning community to use for fun and practice. This competition was inspired by the work of Socher et al [2].\\xa0We encourage participants to explore the accompanying (and dare we say, fantastic) website that accompanies the paper:http://nlp.stanford.edu/sentiment/There you will find have source code, a live demo, and even an online interface to help train the model.[1]\\xa0Pang and L. Lee. 2005. Seeing stars: Exploiting class\\xa0relationships for sentiment categorization with respect\\xa0to rating scales. In ACL, pages 115–124.[2]\\xa0Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank, Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Chris Manning, Andrew Ng and Chris Potts. Conference on Empirical Methods in Natural Language Processing (EMNLP 2013).'}, {'title': 'Forest Cover Type (Kernels Only)', 'url': 'https://www.kaggle.com/competitions/forest-cover-type-kernels-only', 'briefDescription': 'Use cartographic variables to classify forest categories', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9985/logos/header.png?t=2018-06-19-16-26-02', 'tag': 'tabular, forestry, categorizationaccuracy', 'description': \"Random forests?\\xa0Cover trees?\\xa0Not so fast, computer nerds. We're talking about the real thing.In this competition you are asked to predict the forest cover type (the predominant\\xa0kind\\xa0of tree cover) from cartographic variables. The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were then derived from data obtained from the US Geological Survey and USFS. The data is in raw form and contains binary columns of data for qualitative independent variables such as wilderness areas and soil type.This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.This competition originally ran in 2015. We are relaunching it as a kernels-only version here.AcknowledgementsKaggle is hosting this competition for the machine learning community to use for fun and practice. This dataset was\\xa0provided by Jock A. Blackard and Colorado State University.\\xa0We also thank the UCI machine learning repository for hosting the dataset. If you use the problem in publication, please cite:Bache, K. & Lichman, M. (2013). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science\"}, {'title': 'Santander Value Prediction Challenge', 'url': 'https://www.kaggle.com/competitions/santander-value-prediction-challenge', 'briefDescription': 'Predict the value of transactions for potential customers.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9717/logos/header.png?t=2018-05-15-23-00-08', 'tag': 'finance, banking, rmsle', 'description': \"According to Epsilon research, 80% of customers are more likely to do business with you if you provide personalized service. Banking is no exception. The digitalization of everyday lives means that customers expect services to be delivered in a personalized and timely manner… and often before they´ve even realized they need the service. In their 3rd Kaggle competition, Santander Group aims to go a step beyond recognizing that there is a need to provide a customer a financial service and intends to determine the amount or value of the customer's transaction.  This means anticipating customer needs in a more concrete, but also simple and personal way.  With so many choices for financial services, this need is greater now than ever before. In this competition, Santander Group is asking Kagglers to help them identify the value of transactions for each potential customer. This is a first step that Santander needs to nail in order to personalize their services at scale.\"}, {'title': 'The 2nd YouTube-8M Video Understanding Challenge', 'url': 'https://www.kaggle.com/competitions/youtube8m-2018', 'briefDescription': 'Can you create a constrained-size model to predict video labels?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9301/logos/header.png?t=2018-05-08-18-21-41', 'tag': 'video data, custom metric', 'description': 'The world is generating and consuming an enormous amount of video content. Currently on YouTube, people watch over 1 billion hours of video every single day.To spur advances in analyzing and understanding video,  Google AI has publicly released a large-scale video dataset that consists of millions of YouTube video features and associated labels from a diverse vocabulary of 3,700+ visual entities called the YouTube-8M Dataset. Last year, we successfully hosted Google Cloud & YouTube-8M Video Understanding Challenge, with 742 participating teams with 946 individual competitors from 60 countries. This competition is the second Kaggle competition based on YouTube 8M dataset, and is focused on learning video representation under budget constraints.For a lot of video tasks where there are a large number of classes, like recommending new videos or automatic video classification, compact models need to meet memory and computational requirements. This is true even if working in cloud computational environments. Also, compact models make it possible to have limited-memory or catalog indexes on devices in order to do personalized and privacy-preserving computation on user’s personal mobile phones.In this competition, you’re challenged to produce a compact video classification model. Your model size must not exceed 1 GB (this is strictly enforced, through model upload). We encourage participants to train a model that most efficiently uses this budget, rather than ensembles of lots of models. This competition is being hosted by Google AI (previously known as Google Research) as a part of the European Conference on Computer Vision (ECCV) 2018 selected workshop session. Please refer to the YouTube 8M Large-Scale Video Understanding Workshop Page for details about the workshop.'}, {'title': 'Home Credit Default Risk', 'url': 'https://www.kaggle.com/competitions/home-credit-default-risk', 'briefDescription': 'Can you predict how capable each applicant is of repaying a loan?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/9120/logos/header.png?t=2018-04-02-23-51-59', 'tag': 'tabular, banking, auc', 'description': \"Many people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders.Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data--including telco and transactional information--to predict their clients' repayment abilities.While Home Credit is currently using various statistical and machine learning methods to make these predictions, they're challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are not rejected and that loans are given with a principal, maturity, and repayment calendar that will empower their clients to be successful.\"}, {'title': 'TrackML Particle Tracking Challenge', 'url': 'https://www.kaggle.com/competitions/trackml-particle-identification', 'briefDescription': 'High Energy Physics particle tracking in CERN detectors', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7707/logos/header.png?t=2017-11-07-20-38-12', 'tag': 'tabular, physics, custom metric', 'description': 'To explore what our universe is made of, scientists at CERN are colliding protons, essentially recreating mini big bangs, and meticulously observing these collisions with intricate silicon detectors.While orchestrating the collisions and observations is already a massive scientific accomplishment, analyzing the enormous amounts of data produced from the experiments is becoming an overwhelming challenge.Event rates have already reached hundreds of millions of collisions per second, meaning physicists must sift through tens of petabytes of data per year. And, as the resolution of detectors improve, ever better software is needed for real-time pre-processing and filtering of the most promising events, producing even more data.To help address this problem, a team of Machine Learning experts and physics scientists working at CERN (the world largest high energy physics laboratory),  has partnered with Kaggle and prestigious sponsors to answer the question: can machine learning assist high energy physics in discovering and characterizing new particles?Specifically, in this competition, you’re challenged to build an algorithm that quickly reconstructs particle tracks from 3D points left in the silicon detectors. This challenge consists of two phases:The Accuracy phase has run on Kaggle from May to 13th August 2018 (Winners to be announced by end September). Here we’ll be focusing on the highest score, irrespective of the evaluation time. This phase is an official IEEE WCCI competition (Rio de Janeiro, Jul 2018). The Throughput phase will run on Codalab starting in September 2018. Participants will submit their software which is evaluated by the platform. Incentive is on the throughput (or speed) of the evaluation while reaching a good score. This phase is an official NIPS competition (Montreal, Dec 2018).All the necessary information for the Accuracy phase is available here on Kaggle site. The overall TrackML challenge web site is there.'}, {'title': 'Avito Demand Prediction Challenge', 'url': 'https://www.kaggle.com/competitions/avito-demand-prediction', 'briefDescription': 'Predict demand for an online classified ad', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8586/logos/header.png?t=2018-02-21-02-09-25', 'tag': 'tabular, image, text, rmse', 'description': 'When selling used goods online, a combination of tiny, nuanced details in a product description can make a big difference in drumming up interest. Details like:And, even with an optimized product listing, demand for a product may simply not exist–frustrating sellers who may have over-invested in marketing.Avito, Russia’s largest classified advertisements website, is deeply familiar with this problem. Sellers on their platform sometimes feel frustrated with both too little demand (indicating something is wrong with the product or the product listing) or too much demand (indicating a hot item with a good description was underpriced).In their fourth Kaggle competition, Avito is challenging you to predict demand for an online advertisement based on its full description (title, description, images, etc.), its context (geographically where it was posted, similar ads already posted) and historical demand for similar ads in similar contexts. With this information, Avito can inform sellers on how to best optimize their listing and provide some indication of how much interest they should realistically expect to receive.'}, {'title': 'CVPR 2018 WAD Video Segmentation Challenge', 'url': 'https://www.kaggle.com/competitions/cvpr-2018-autonomous-driving', 'briefDescription': 'Can you segment each objects within image frames captured by vehicles?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8899/logos/header.png?t=2018-03-27-11-33-05', 'tag': 'custom metric', 'description': \"When you're driving, how important is it to be able to quickly tell the difference between a person vs. a stop sign? It's a hugely important, but typically very simple, distinction that you would make reflexively. Autonomous vehicles are not able to do this quite as effortlessly. This challenge, hosted by the 2018 CVPR workshop on autonomous driving ([WAD][1]), asks you to help give autonomously driven vehicles the same edge. Using an unprecedented dataset, you're asked to segment movable objects, such as cars and pedestrians, at instance level within image frames.![Segmented image][2]By participating in this competition, you'll be helping to further our understand of the current status of computer vision algorithms in solving environmental perception problems for autonomous driving.This challenge is a truly unique opportunity to work on a tremendously high value and high profile problem. The dataset presented here contains over 10 times more fine-labeled images than the largest public dataset of its type.## Acknowledgements ##This competition is hosted by the 2018 CVPR workshop on autonomous driving (WAD), with dataset and evaluation metric contributed by Baidu Inc.   [1]: http://www.wad.ai/  [2]: https://storage.googleapis.com/kaggle-media/competitions/cvpr/image_example.jpg\"}, {'title': 'iMaterialist Challenge (Fashion) at FGVC5', 'url': 'https://www.kaggle.com/competitions/imaterialist-challenge-fashion-2018', 'briefDescription': 'Image classification of fashion products.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8219/logos/header.png?t=2018-03-20-05-38-55', 'tag': 'meanfscorebeta', 'description': \"As shoppers move online, it would be a dream come true to have products in photos classified automatically. But, automatic product recognition is tough because for the same product, a picture can be taken in different lighting, angles, backgrounds, and levels of occlusion. Meanwhile different fine-grained categories may look very similar, for example, royal blue vs turquoise in color. Many of today’s general-purpose recognition machines simply cannot perceive such subtle differences between photos, yet these differences could be important for shopping decisions.Tackling issues like this is why the Conference on Computer Vision and Pattern Recognition (CVPR) has put together a workshop specifically for data scientists focused on fine-grained visual categorization called the FGVC5 workshop. As part of this workshop, CVPR is partnering with Google, Wish, and Malong Technologies to challenge the data science community to help push the state of the art in automatic image classification.In this competition, FGVC workshop organizers with Wish and Malong Technologies challenge you to develop algorithms that will help with an important step towards automatic product detection – to accurately assign attribute labels for fashion images. Individuals/Teams with top submissions will be invited to present their work live at the FGVC5 workshop.Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.\"}, {'title': 'Freesound General-Purpose Audio Tagging Challenge', 'url': 'https://www.kaggle.com/competitions/freesound-audio-tagging', 'briefDescription': 'Can you automatically recognize sounds from a wide range of real-world environments?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8900/logos/header.png?t=2018-03-18-23-07-32', 'tag': 'map@{k}', 'description': \"Some sounds are distinct and instantly recognizable, like a baby’s laugh or the strum of a guitar.Other sounds aren’t clear and are difficult to pinpoint. If you close your eyes, can you tell which of the sounds below is a chainsaw versus a blender?Moreover, we often experience a mix of sounds that create an ambience – like the clamoring of construction, a hum of traffic from outside the door, blended with loud laughter from the room, and the ticking of the clock on your wall. The sound clip below is of a busy food court in the UK.Partly because of the vastness of sounds we experience, no reliable automatic general-purpose audio tagging systems exist. Currently, a lot of manual effort is required for tasks like annotating sound collections and providing captions for non-speech events in audiovisual content.To tackle this problem, Freesound (an initiative by MTG-UPF that maintains a collaborative database with over 370,000 Creative Commons Licensed sounds) and Google Research’s Machine Perception Team (creators of AudioSet, a large-scale dataset of manually annotated audio events with over 500 classes) have teamed up to develop the dataset for this competition.You’re challenged to build a general-purpose automatic audio tagging system using a dataset of audio files covering a wide range of real-world environments. Sounds in the dataset include things like musical instruments, human sounds, domestic sounds, and animals from Freesound’s library, annotated using a vocabulary of more than 40 labels from Google’s AudioSet ontology. To succeed in this competition your systems will need to be able to recognize an increased number of sound events of very diverse nature, and to leverage subsets of training data featuring annotations of varying reliability (see Data section for more information).## Organizers - Eduardo Fonseca, MTG-UPF, Barcelona - Manoj Plakal, Google's Sound Understanding, New York - Frederic Font, MTG-UPF, Barcelona - Dan Ellis, Google's Sound Understanding, New York\"}, {'title': 'iMaterialist Challenge (Furniture) at FGVC5', 'url': 'https://www.kaggle.com/competitions/imaterialist-challenge-furniture-2018', 'briefDescription': 'Image Classification of Furniture & Home Goods.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8220/logos/header.png?t=2018-03-05-22-37-53', 'tag': 'meanbesterroratk', 'description': \"As shoppers move online, it’d be a dream come true to have products in photos classified automatically. But, automatic product recognition is challenging because for the same product, a picture can be taken in different lighting, angles, backgrounds, and levels of occlusion. Meanwhile different fine-grained categories may look very similar, for example, ball chair vs egg chair for furniture, or dutch oven vs french oven for cookware. Many of today’s general-purpose recognition machines simply can’t perceive such subtle differences between photos, yet these differences could be important for shopping decisions.Tackling issues like this is why the\\xa0Conference on Computer Vision and Pattern Recognition (CVPR)\\xa0has put together a workshop specifically for data scientists focused on fine-grained visual categorization called the\\xa0FGVC5 workshop. As part of this workshop, CVPR is partnering with Google, Malong Technologies and Wish to challenge the data science community to help push the state of the art in automatic image classification.In this competition, FGVC5 workshop organizers and Malong Technologies challenge you to develop algorithms that will help with an important step towards automatic product recognition – to accurately assign category labels for furniture and home goods images. Individuals/Teams with top submissions will be invited to present their work live at the FGVC5 workshop.Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.\\xa0\"}, {'title': 'TalkingData AdTracking Fraud Detection Challenge', 'url': 'https://www.kaggle.com/competitions/talkingdata-adtracking-fraud-detection', 'briefDescription': 'Can you detect fraudulent click traffic for mobile app ads?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8540/logos/header.png?t=2018-02-13-21-32-27', 'tag': 'auc', 'description': \"Fraud risk is everywhere, but for companies that advertise online, click fraud can happen at an overwhelming volume, resulting in misleading click data and wasted money. Ad channels can drive up costs by simply clicking on the ad at a large scale. With over 1 billion smart mobile devices in active use every month, China is the largestmobile market in the world and therefore suffers from huge volumes of fradulent traffic.[TalkingData][1], China’s largest independent big data service platform, covers over 70% of active mobile devices nationwide. They handle 3 billion clicks per day, of which 90% are potentially fraudulent. Their current approach to prevent click fraud for app developers is to measure the journey of a user’s click across their portfolio, and flag IP addresses who produce lots of clicks, but never end up installing apps. With this information, they've built an IP blacklist and device blacklist.While successful, they want to always be one step ahead of fraudsters and have turned to the Kaggle community for help in further developing their solution. In their 2nd competition with Kaggle, you’re challenged to build an algorithm that predicts whether a user will download an app after clicking a mobile app ad. To support your modeling, they have provided a generous dataset covering approximately 200 million clicks over 4 days!  [1]: https://www.talkingdata.com/\"}, {'title': 'DonorsChoose.org Application Screening', 'url': 'https://www.kaggle.com/competitions/donorschoose-application-screening', 'briefDescription': \"Predict whether teachers' project proposals are accepted\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8426/logos/header.png?t=2018-02-03-04-51-52', 'tag': 'binary classification, crowdfunding, auc', 'description': \"Founded in 2000 by a high school teacher in the Bronx, [DonorsChoose.org][1] empowers public school teachers from across the country to request much-needed materials and experiences for their students. At any given time, there are thousands of classroom requests that can be brought to life with a gift of any amount.DonorsChoose.org receives hundreds of thousands of project proposals each year for classroom projects in need of funding. Right now, a large number of volunteers is needed to manually screen each submission before it's approved to be posted on the DonorsChoose.org website. Next year, DonorsChoose.org expects to receive close to 500,000 project proposals. As a result, there are three main problems they need to solve:1. How to scale current manual processes and resources to screen 500,000 projects so that they can be posted as quickly and as efficiently as possible2. How to increase the consistency of project vetting across different volunteers to improve the experience for teachers3. How to focus volunteer time on the applications that need the most assistanceThe goal of the competition is to predict whether or not a DonorsChoose.org project proposal submitted by a teacher will be approved, using the text of project descriptions as well as additional metadata about the project, teacher, and school. DonorsChoose.org can then use this information to identify projects most likely to need further review before approval.With an algorithm to pre-screen applications, DonorsChoose.org can auto-approve some applications quickly so that volunteers can spend their time on more nuanced and detailed project \\u200bvetting processes, including doing more to help teachers develop projects that qualify for specific funding opportunities. Your machine learning algorithm can help more teachers get funded more quickly, and with less cost to DonorsChoose.org, allowing them to channel even more funding directly to classrooms across the country. ### Getting Started with KernelsGet familiar with the competition data and the machine learning objective quickly using Kernels. Google's engineering education team has put together [a starter tutorial implementing benchmark linear classification model][2]. ### Acknowledgments[Machine Learning Crash Course][3] was created by Google's engineering education team in partnership with numerous Machine Learning subject matter experts across Google.  [1]: https://www.donorschoose.org/  [2]: https://www.kaggle.com/skleinfeld/getting-started-with-the-donorschoose-data-set  [3]: https://developers.google.com/machine-learning/crash-course/\"}, {'title': ' iNaturalist Challenge at FGVC5', 'url': 'https://www.kaggle.com/competitions/inaturalist-2018', 'briefDescription': 'Long tailed classification challenge spanning 8,000 species.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8243/logos/header.png?t=2018-01-27-22-37-21', 'tag': 'meanbesterroratk', 'description': '![](https://www.dropbox.com/s/vabfx4adfao7l9q/promo.jpg?dl=1)As part of the FGVC5 workshop at CVPR 2018 we are conducting the iNat Challenge 2018 large scale species classification competition. It is estimated that the natural world contains several million species of plants and animals. Without expert knowledge, many of these species are extremely difficult to accurately classify due to their visual similarity. The goal of this competition is to push the state of the art in automatic image classification for real world data that features a large number of fine-grained categories with high class imbalance.The iNat Challenge 2018 dataset contains over 8,000 species, with a combined training and validation set of 450,000 images that have been collected and verified by multiple users from [iNaturalist][1]. The dataset features many visually similar species, captured in a wide variety of situations, from all over the world.Teams with top submissions, at the discretion of the workshop organizers, will be invited to present their work at the FGVC5 workshop.  The iNat Challenge 2018 is sponsored by Microsoft.![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Microsoft_logo_%282012%29.svg/200px-Microsoft_logo_%282012%29.svg.png)  [1]: http://inaturalist.org'}, {'title': \"Google Cloud & NCAA® ML Competition 2018-Women's\", 'url': 'https://www.kaggle.com/competitions/womens-machine-learning-competition-2018', 'briefDescription': 'Apply machine learning to NCAA® March Madness®', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8311/logos/header.png?t=2018-02-23-21-04-19', 'tag': 'logloss', 'description': \"Google Cloud and NCAA® have teamed up to bring you this year’s version of the Kaggle machine learning competition. Another year, another chance to anticipate the upsets, call the probabilities, and put your bracketology skills to the leaderboard test. Kagglers will join the millions of fans who attempt to forecast the outcomes of March Madness® during this year's NCAA Division I Men’s and Women’s Basketball Championships. But unlike most fans, you will pick your bracket using a combination of NCAA’s historical data and your computing power, while the ground truth unfolds on national television.In the first stage of the competition, Kagglers will rely on results of past tournaments to build and test models. We encourage you to post any useful external data as a dataset. In the second stage, competitors will forecast outcomes of all possible match-ups in the 2018 NCAA Division I Men’s and Women’s Basketball Championships. You don't need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2018 results.This page is for the NCAA Division I Women's tournament. Check out the NCAA Division I Men's tournament here. \"}, {'title': \"Google Cloud & NCAA® ML Competition 2018-Men's\", 'url': 'https://www.kaggle.com/competitions/mens-machine-learning-competition-2018', 'briefDescription': 'Apply Machine Learning to NCAA® March Madness®', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8310/logos/header.png?t=2018-02-23-21-05-08', 'tag': 'basketball, logloss', 'description': \"Google Cloud and NCAA® have teamed up to bring you this year’s version of the Kaggle machine learning competition. Another year, another chance to anticipate the upsets, call the probabilities, and put your bracketology skills to the leaderboard test. Kagglers will join the millions of fans who attempt to forecast the outcomes of March Madness® during this year's NCAA Division I Men’s and Women’s Basketball Championships. But unlike most fans, you will pick your bracket using a combination of NCAA’s historical data and your computing power, while the ground truth unfolds on national television.In the first stage of the competition, Kagglers will rely on results of past tournaments to build and test models. We encourage you to post any useful external data as a dataset. In the second stage, competitors will forecast outcomes of all possible match-ups in the 2018 NCAA Division I Men’s and Women’s Basketball Championships. You don't need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2018 results.This page is for the NCAA Division I Men's tournament. Check out the NCAA Division I Women's tournament here. \"}, {'title': 'Predict Future Sales', 'url': 'https://www.kaggle.com/competitions/competitive-data-science-predict-future-sales', 'briefDescription': 'Final project for \"How to win a data science competition\" Coursera course', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8587/logos/header.png?t=2018-02-17-16-28-16', 'tag': 'tabular, rmse', 'description': 'This challenge serves as final project for the  \"How to win a data science competition\" Coursera course.In this competition you will work with a challenging time-series dataset consisting of daily\\xa0sales data, kindly provided by one of the largest Russian software firms - 1C Company.\\xa0We are asking you to predict total sales for every product and store in the next month. By solving this competition you will be able to apply and enhance\\xa0your data science skills.'}, {'title': 'Google Landmark Retrieval Challenge', 'url': 'https://www.kaggle.com/competitions/landmark-retrieval-challenge', 'briefDescription': 'Given an image, can you find all of the same landmarks in a dataset?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8396/logos/header.png?t=2018-02-01-17-57-10', 'tag': 'image, map@{k}', 'description': '**[UPDATE] 2019 challenge launched:** https://kaggle.com/c/landmark-retrieval-2019Image retrieval is a fundamental problem in computer vision: given a query image, can you find similar images in a large database? This is especially important for query images containing landmarks, which accounts for a large portion of what people like to photograph.In this competition, Kagglers are given query images and, for each query, are expected to retrieve all database images containing the same landmarks (if any).The new dataset is the largest worldwide dataset for image retrieval research, comprising more than a million images of 15K unique landmarks. We hope that this release will accelerate progress in this important research problem.This challenge is organized in conjunction with the Landmark Recognition Challenge (https://www.kaggle.com/c/landmark-recognition-challenge). In particular, note that the test set for both challenges is the same, to encourage participants to compete in both. We also encourage participants to use the training data from the recognition challenge to train models which could be useful for the retrieval challenge. Note, however, that there are no landmarks in common between the training/index sets of the two challenges.'}, {'title': 'Google Landmark Recognition Challenge', 'url': 'https://www.kaggle.com/competitions/landmark-recognition-challenge', 'briefDescription': 'Label famous (and not-so-famous) landmarks in images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7456/logos/header.png?t=2018-01-30-21-42-08', 'tag': 'image, custom metric', 'description': '**[UPDATE] 2019 challenge launched:** https://kaggle.com/c/landmark-recognition-2019Did you ever go through your vacation photos and ask yourself: What is the name of this temple I visited in China? Who created this monument I saw in France? Landmark recognition can help! This technology can predict landmark labels directly from image pixels, to help people better understand and organize their photo collections.Today, a great obstacle to landmark recognition research is the lack of large annotated datasets. In this competition, we present the largest worldwide dataset to date, to foster progress in this problem. This competition challenges Kagglers to build models that recognize the correct landmark (if any) in a dataset of challenging test images.Many Kagglers are familiar with image classification challenges like the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), which aims to recognize 1K general object categories. Landmark recognition is a little different from that: it contains a much larger number of classes (there are a total of 15K classes in this challenge), and the number of training examples per class may not be very large. Landmark recognition is challenging in its own way.This challenge is organized in conjunction with the Landmark Retrieval Challenge ( https://www.kaggle.com/c/landmark-retrieval-challenge ). In particular, note that the test set for both challenges is the same, to encourage participants to compete in both. We also encourage participants to use the training data from the recognition challenge to train models which could be useful for the retrieval challenge. Note, however, that there are no landmarks in common between the training/index sets of the two challenges.'}, {'title': '2018 Data Science Bowl ', 'url': 'https://www.kaggle.com/competitions/data-science-bowl-2018', 'briefDescription': 'Find the nuclei in divergent images to advance medical discovery', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8089/logos/header.png?t=2018-01-10-17-54-22', 'tag': 'biology, custom metric', 'description': 'Spot Nuclei. Speed Cures.Imagine speeding up research for almost every disease, from lung cancer and heart disease to rare disorders. The 2018 Data Science Bowl offers our most ambitious mission yet: create an algorithm to automate nucleus detection.We’ve all seen people suffer from diseases like cancer, heart disease, chronic obstructive pulmonary disease, Alzheimer’s, and diabetes. Many have seen their loved ones pass away. Think how many lives would be transformed if cures came faster.By automating nucleus detection, you could help unlock cures faster—from rare disorders to the common cold. Want a snapshot about the 2018 Data Science Bowl? View this video.Why nuclei?Identifying the cells’ nuclei is the starting point for most analyses because most of the human body’s 30 trillion cells contain a nucleus full of DNA, the genetic code that programs each cell. Identifying nuclei allows researchers to identify each individual cell in a sample, and by measuring how cells react to various treatments, the researcher can understand the underlying biological processes at work.By participating, teams will work to automate the process of identifying nuclei, which will  allow for more efficient drug testing, shortening the 10 years it takes for each new drug to come to market. Check out this video overview to find out more.What will participants do?Teams will create a computer model that can identify a range of nuclei across varied conditions. By observing patterns, asking questions, and building a model, participants will have a chance to push state-of-the-art technology farther.Visit DataScienceBowl.com to:  • Sign up to\\xa0receive news about the competition • Learn about the\\xa0history of the Data Science Bowl and past competitions • Read our\\xa0latest insights on emerging analytics techniques'}, {'title': 'Humpback Whale Identification Challenge', 'url': 'https://www.kaggle.com/competitions/whale-categorization-playground', 'briefDescription': 'Can you identify a whale by the picture of its fluke?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6961/logos/header.png', 'tag': 'image, animals, map@{k}', 'description': \"After centuries of intense whaling, recovering whale populations still have a hard time adapting to warming oceans and struggle to compete every day with the industrial fishing industry for food.To aid whale conservation efforts, scientists use photo surveillance systems to monitor ocean activity. They use the shape of whales’ tails and unique markings found in footage to identify what species of whale they’re analyzing and meticulously log whale pod dynamics and movements. For the past 40 years, most of this work has been done manually by individual scientists, leaving a huge trove of data untapped and underutilized.In this competition, you’re challenged to build an algorithm to identifying whale species in images. You’ll analyze Happy Whale’s database of over 25,000 images, gathered from research institutions and public contributors. By contributing, you’ll help to open rich fields of understanding for marine mammal population dynamics around the globe.We'd like to thank Happy Whale  for providing this data and problem. Happy Whale is a platform that uses image process algorithms to let anyone to submit their whale photo and have it automatically identified.\"}, {'title': 'ImageNet Object Localization Challenge', 'url': 'https://www.kaggle.com/competitions/imagenet-object-localization-challenge', 'briefDescription': 'Identify the objects in images', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6799/logos/header.png', 'tag': 'image, custom metric', 'description': \"While It's pretty easy for people to identify subtle differences in photos, computers still have a ways to go. Visually similar items are tough for computers to count, like this overlapping bunch of bananas:Or, consider this photo of a family of foxes camouflaged in the wild - where do the foxes end and where does the grass begin? To solve this problem and enhance the state of the art in object detection and classification, the annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) began in 2010. Kaggle is excited and honored to be the new home of the official ImageNet Object Localization competition. Participants are challenged with identifying all objects within an image so those images can then be classified and annotated.  Already, because of this competition, there’s been a 4.2× reduction in image classification error (from 28.2% to 6.7%) and a 1.7× reduction in localization error (from 42.5% to 25.3%) between 2010 and 2014 alone. Can you improve the accuracy even further?### Competition OverviewThe validation and test data will consist of 150,000 photographs, collected from Flickr and other search engines, hand labeled with the presence or absence of 1000 object categories. The 1000 object categories contain both internal nodes and leaf nodes of ImageNet, but do not overlap with each other.A random subset of 50,000 of the images with labels will be released as the training set along with a list of the 1000 categories. The remaining images will be used as the test set.The validation and test data for this competition are not contained in the ImageNet training data.\"}, {'title': \"IEEE's Signal Processing Society - Camera Model Identification\", 'url': 'https://www.kaggle.com/competitions/sp-society-camera-model-identification', 'briefDescription': 'Identify from which camera an image was taken', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8078/logos/header.png?t=2017-12-22-17-32-04', 'tag': 'image, weightedcategorizationaccuracy', 'description': \"Finding footage of a crime caught on tape is an investigator's dream. But even with crystal clear, damning evidence, one critical question always remains–is the footage real?Today, one way to help authenticate footage is to identify the camera that the image was taken with. Forgeries often require splicing together content from two different cameras. But, unfortunately, the most common way to do this now is using image metadata, which can be easily falsified itself.This problem is actively studied by several researchers around the world. Many machine learning solutions have been proposed in the past: least-squares estimates of a camera's color demosaicing filters as classification features, co-occurrences of pixel value prediction errors as features that are passed to sophisticated ensemble classifiers, and using CNNs to learn camera model identification features. However, this is a problem yet to be sufficiently solved.For this competition, the IEEE Signal Processing Society is challenging you to build an algorithm that  identifies which camera model captured an image by using traces intrinsically left in the image. Helping to solve this problem would have a big impact on the verification of evidence used in criminal and civil trials and even news reporting.\"}, {'title': 'Toxic Comment Classification Challenge', 'url': 'https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge', 'briefDescription': 'Identify and classify toxic online comments', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8076/logos/header.png?t=2017-12-15-21-30-35', 'tag': 'text, mcauc', 'description': 'Discussing things you care about can be difficult. The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments.The Conversation AI team, a research initiative founded by Jigsaw and Google (both a part of Alphabet) are working on tools to help improve online conversation. One area of focus is the study of negative online behaviors, like toxic comments (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion). So far they’ve built a range of publicly available models served through the Perspective API, including toxicity. But the current models still make errors, and they don’t allow users to select which types of toxicity they’re interested in finding (e.g. some platforms may be fine with profanity, but not with other types of toxic content).In this competition, you’re challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. You’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.Disclaimer: the dataset for this competition contains text that may be considered profane, vulgar, or offensive.'}, {'title': 'Nomad2018 Predicting Transparent Conductors', 'url': 'https://www.kaggle.com/competitions/nomad2018-predict-transparent-conductors', 'briefDescription': 'Predict the key properties of novel transparent semiconductors', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7299/logos/header.png?t=2017-12-01-16-08-27', 'tag': 'chemistry, mcrmsle', 'description': 'Innovative materials design is needed to tackle some of the most important health, environmental, energy, social, and economic challenges of this century. In particular, improving the properties of materials that are intrinsically connected to the generation and utilization of energy is crucial if we are to mitigate environmental damage due to a growing global demand. Transparent conductors\\xa0are an important class of compounds that are both electrically conductive and have a low absorption in the visible range, which are typically competing properties. A combination of both of these characteristics is key for the operation of a variety of technological devices such as photovoltaic cells, light-emitting diodes for flat-panel displays, transistors, sensors, touch screens, and lasers. However, only a small number of compounds are currently known to display both transparency and conductivity suitable enough to be used as transparent conducting materials. Aluminum\\xa0(Al), gallium\\xa0(Ga), indium\\xa0(In) sesquioxides are some of the most promising transparent conductors because of a combination of both large\\xa0bandgap\\xa0energies, which leads to optical transparency over the visible range, and high\\xa0conductivities. These materials are also chemically stable and relatively inexpensive to produce. Alloying of these binary compounds in ternary or quaternary mixtures could enable the design of a new material at a specific composition with improved properties over what is current possible. These alloys are described by the formula \\\\((Al_{x}Ga_{y}In_{z})_{2N}O_{3N}\\\\); where x, y, and z can vary but are limited by the constraint x+y+z = 1. The total number of atoms in the '}, {'title': 'Santa Gift Matching Challenge', 'url': 'https://www.kaggle.com/competitions/santa-gift-matching', 'briefDescription': 'Down through the chimney with lots of toys...', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/8011/logos/header.png?t=2017-12-07-22-37-01', 'tag': 'custom metric', 'description': '‘Tis the night before Christmasyear: two thousand seventeen.Santa’s grown grouchy,borderline mean.What used to be simple for Old St. Nick,is now too puzzling, it’s making him sick!See, Santa always knew, deep down in his gut, what toy each kid wanted–no ifs, ands, or buts.But fierce population growth, more twins, and toy innovation,has left too complex a problem, in dire need of optimization.“Don’t worry, Mr. Santa”, said an Elf named McMaggle,“I have a solution! Have you heard of Kaggle?”As she explained Kaggle in-depth, Santa’s doubt began turning,he became a believer in the magic of...machine learning.So, Santa’s team needs YOU more than ever this year,to solve this painful problem and save Christmas cheer.The ChallengeIn this playground competition, you’re challenged to build a toy matching algorithm that maximizes happiness by pairing kids with toys they want. In the dataset, each kid has 10 preferences for their gift (from 1000) and Santa has 1000 preferred kids for every gift available. What makes this extra difficult is that 0.4% of the kids are twins, and by their parents’ request, require the same gift. '}, {'title': 'Recruit Restaurant Visitor Forecasting', 'url': 'https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting', 'briefDescription': 'Predict how many future visitors a restaurant will receive', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7277/logos/header.png', 'tag': 'rmsle', 'description': \"Running a thriving local restaurant isn't always as charming as first impressions appear. There are often all sorts of unexpected troubles popping up that could hurt business.One common predicament is that restaurants need to know how many customers to expect each day to effectively purchase ingredients and schedule staff members. This forecast isn't easy to make because many unpredictable factors affect restaurant attendance, like weather and local competition. It's even harder for newer restaurants with little historical data.Recruit Holdings has unique access to key datasets that could make automated future customer prediction possible. Specifically, Recruit Holdings owns Hot Pepper Gourmet (a restaurant review service), AirREGI (a restaurant point of sales service), and Restaurant Board (reservation log management software).In this competition, you're challenged to use reservation and visitation data to predict the total number of visitors to a restaurant for future dates. This information will help restaurants be much more efficient and allow them to focus on creating an enjoyable dining experience for their customers.\"}, {'title': 'Plant Seedlings Classification', 'url': 'https://www.kaggle.com/competitions/plant-seedlings-classification', 'briefDescription': 'Determine the species of a seedling from an image', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7880/logos/header.png?t=2017-11-21-19-51-20', 'tag': 'image, multiclass classification, plants, meanfscore', 'description': \"Can you differentiate a weed from a crop seedling?The ability to do so effectively can mean better crop yields and better stewardship of the environment.The Aarhus University Signal Processing group, in collaboration with University of Southern Denmark, has recently released a dataset containing images of approximately 960 unique plants belonging to 12 species at several growth stages.We're hosting this dataset as a Kaggle competition in order to give it wider exposure, to give the community an opportunity to experiment with different image recognition techniques, as well to provide a place to cross-pollenate ideas.### AcknowledgmentsWe extend our appreciation to the Aarhus University Department of Engineering Signal Processing Group for hosting the [original data](https://vision.eng.au.dk/plant-seedlings-dataset/). ### Citation[A Public Image Database for Benchmark of Plant Seedling Classification Algorithms](https://arxiv.org/abs/1711.05458)\"}, {'title': 'Mercari Price Suggestion Challenge', 'url': 'https://www.kaggle.com/competitions/mercari-price-suggestion-challenge', 'briefDescription': 'Can you automatically suggest product prices to online sellers?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7559/logos/header.png?t=2017-11-02-11-21-36', 'tag': 'rmsle', 'description': \"It can be hard to know how much something’s really worth. Small details can mean big differences in pricing. For example, one of these sweaters cost $335 and the other cost $9.99. Can you guess which one’s which?Product pricing gets even harder at scale, considering just how many products are sold online. Clothing has strong seasonal pricing trends and is heavily influenced by brand names, while electronics have fluctuating prices based on product specs.Mercari, Japan’s biggest community-powered shopping app, knows this problem deeply. They’d like to offer pricing suggestions to sellers, but this is tough because their sellers are enabled to put just about anything, or any bundle of things, on Mercari's marketplace.In this competition, Mercari’s challenging you to build an algorithm that automatically suggests the right product prices. You’ll be provided user-inputted text descriptions of their products, including details like product category name, brand name, and item condition.Note that, because of the public nature of this data, this competition is a “Kernels Only” competition. In the second stage of the challenge, files will only be available through Kernels and you will not be able to modify your approach in response to new data. Read more details in the data tab and Kernels FAQ page.\"}, {'title': 'TensorFlow Speech Recognition Challenge', 'url': 'https://www.kaggle.com/competitions/tensorflow-speech-recognition-challenge', 'briefDescription': 'Can you build an algorithm that understands simple speech commands?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7634/logos/header.png?t=2017-11-01-00-40-21', 'tag': 'categorizationaccuracy', 'description': \"We might be on the verge of too many screens. It seems like everyday, new versions of common objects are “re-invented” with built-in wifi and bright touchscreens. A promising antidote to our screen addiction are voice interfaces.But, for independent makers and entrepreneurs, it’s hard to build a simple speech detector using free, open data and code. Many voice recognition datasets require preprocessing before a neural network model can be built on them. To help with this, TensorFlow recently released the Speech Commands Datasets. It includes 65,000 one-second long utterances of 30 short words, by thousands of different people.In this competition, you're challenged to use the Speech Commands Dataset to build an algorithm that understands simple spoken commands. By improving the recognition accuracy of open-sourced voice interface tools, we can improve product effectiveness and their accessibility.\"}, {'title': 'Spooky Author Identification', 'url': 'https://www.kaggle.com/competitions/spooky-author-identification', 'briefDescription': 'Share code and discuss insights to identify horror authors from their writings', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7516/logos/header.png', 'tag': 'multiclass classification, literature, linguistics, multiclassloss', 'description': 'As I scurried across the candlelit chamber, manuscripts in hand, I thought I\\'d made it. Nothing would be able to hurt me anymore. Little did I know there was one last fright lurking around the corner.DING! My phone pinged me with a disturbing notification. It was Will, the scariest of Kaggle moderators, sharing news of another data leak. \"ph’nglui mglw’nafh Cthulhu R’lyeh wgah’nagl fhtagn!\" I cried as I clumsily dropped my crate of unbound, spooky books. Pages scattered across the chamber floor. How will I ever figure out how to put them back together according to the authors who wrote them? Or are they lost, forevermore? Wait, I thought... I know, machine learning!In this year\\'s Halloween playground competition, you\\'re challenged to predict the author of excerpts from horror stories by Edgar Allan Poe, Mary Shelley, and HP Lovecraft. We\\'re encouraging you (with cash prizes!) to share your insights in the competition\\'s discussion forum and code in Kernels. We\\'ve designated prizes to reward authors of kernels and discussion threads that are particularly valuable to the community. Click the \"Prizes\" tab on this overview page to learn more.Getting StartedNew to Kernels or working with natural language data? We\\'ve put together some starter kernels in Python and R to help you hit the ground running.'}, {'title': 'Statoil/C-CORE Iceberg Classifier Challenge', 'url': 'https://www.kaggle.com/competitions/statoil-iceberg-classifier-challenge', 'briefDescription': 'Ship or iceberg, can you decide from space?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7380/logos/header.png', 'tag': 'image, binary classification, weather and climate, logloss', 'description': 'Drifting icebergs present threats to navigation and activities in areas such as offshore of the East Coast of Canada.Currently, many institutions and companies use aerial reconnaissance and shore-based support to monitor environmental conditions and assess risks from icebergs.  However, in remote areas with particularly harsh weather, these methods are not feasible, and the only viable monitoring option is via satellite.Statoil, an international energy company operating worldwide, has worked closely with companies like C-CORE. C-CORE have been using satellite data for over 30 years and have built a computer vision based surveillance system. To keep operations safe and efficient, Statoil is interested in getting a fresh new perspective on how to use machine learning to more accurately detect and discriminate against threatening icebergs as early as possible.In this competition, you’re challenged to build an algorithm that automatically identifies if a remotely sensed target is a ship or iceberg. Improvements made will help drive the costs down for maintaining safe working conditions.'}, {'title': 'Corporación Favorita Grocery Sales Forecasting', 'url': 'https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting', 'briefDescription': 'Can you accurately predict sales for a large grocery chain?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7391/logos/header.png', 'tag': 'tabular, regression, food, custom metric', 'description': 'Brick-and-mortar grocery stores are always in a delicate dance with purchasing and sales forecasting. Predict a little over, and grocers are stuck with overstocked, perishable goods. Guess a little under, and popular items quickly sell out, leaving money on the table and customers fuming.The problem becomes more complex as retailers add new locations with unique needs, new products, ever transitioning seasonal tastes, and unpredictable product marketing. Corporación Favorita, a large Ecuadorian-based grocery retailer, knows this all too well. They operate hundreds of supermarkets, with over 200,000 different products on their shelves.Corporación Favorita has challenged the Kaggle community to build a model that more accurately forecasts product sales. They currently rely on subjective forecasting methods with very little data to back them up and very little automation to execute plans. They’re excited to see how machine learning could better ensure they please customers by having just enough of the right products at the right time.'}, {'title': 'Porto Seguro’s Safe Driver Prediction', 'url': 'https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction', 'briefDescription': 'Predict if a driver will file an insurance claim next year.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7082/logos/header.png', 'tag': 'tabular, binary classification, normalizedgini', 'description': 'Nothing ruins the thrill of buying a brand new car more quickly than seeing your new insurance bill. The sting’s even more painful when you know you’re a good driver. It doesn’t seem fair that you have to pay so much if you’ve been cautious on the road for years.Porto Seguro, one of Brazil’s largest auto and homeowner insurance companies, completely agrees. Inaccuracies in car insurance company’s claim predictions raise the cost of insurance for good drivers and reduce the price for bad ones.In this competition, you’re challenged to build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year. While Porto Seguro has used machine learning for the past 20 years, they’re looking to Kaggle’s machine learning community to explore new, more powerful methods. A more accurate prediction will allow them to further tailor their prices, and hopefully make auto insurance coverage more accessible to more drivers.'}, {'title': 'Dog Breed Identification', 'url': 'https://www.kaggle.com/competitions/dog-breed-identification', 'briefDescription': 'Determine the breed of a dog in an image', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7327/logos/header.png', 'tag': 'image, multiclass classification, animals, multiclassloss', 'description': \"Who's a good dog? Who likes ear scratches? Well, it seems those fancy deep neural networks don't have *all* the answers. However, maybe they can answer that ubiquitous question we all ask when meeting a four-legged stranger: what kind of good pup is that?In this playground competition, you are provided a strictly canine subset of [ImageNet][2] in order to practice fine-grained image categorization. How well you can tell your Norfolk Terriers from your Norwich Terriers? With 120 breeds of dogs and a limited number training images per class, you might find the problem more, err, ruff than you anticipated.![Border collies][1]### AcknowledgmentsWe extend our gratitude to the creators of the [Stanford Dogs Dataset][3] for making this competition possible: Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Fei-Fei Li.  [1]: https://storage.googleapis.com/kaggle-competitions/kaggle/3333/media/border_collies.png  [2]: https://www.kaggle.com/c/imagenet-object-detection-challenge  [3]: http://vision.stanford.edu/aditya86/ImageNetDogs/\"}, {'title': \"WSDM - KKBox's Music Recommendation Challenge\", 'url': 'https://www.kaggle.com/competitions/kkbox-music-recommendation-challenge', 'briefDescription': 'Can you build the best music recommendation system?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7162/logos/header.png', 'tag': 'auc', 'description': 'The 11th ACM International Conference on Web Search and Data Mining (WSDM 2018) is challenging you to build a better music recommendation system using a donated dataset from KKBOX. WSDM (pronounced \"wisdom\") is one of the the premier conferences on web inspired research involving search and data mining. They\\'re committed to publishing original, high quality papers and presentations, with an emphasis on practical but principled novel models.Not many years ago, it was inconceivable that the same person would listen to the Beatles, Vivaldi, and Lady Gaga on their morning commute. But, the glory days of Radio DJs have passed, and musical gatekeepers have been replaced with personalizing algorithms and unlimited streaming services.While the public’s now listening to all kinds of music, algorithms still struggle in key areas. Without enough historical data, how would an algorithm know if listeners will like a new song or a new artist? And, how would it know what songs to recommend brand new users?WSDM has challenged the Kaggle ML community to help solve these problems and build a better music recommendation system. The dataset is from KKBOX, Asia’s leading music streaming service, holding the world’s most comprehensive Asia-Pop music library with over 30 million tracks. They currently use a collaborative filtering based algorithm with matrix factorization and word embedding in their recommendation system but believe new techniques could lead to better results.Winners will present their findings at the conference February 6-8, 2018 in Los Angeles, CA.  For more information on the conference, click here, and don\\'t forget to check out the other KKBox/WSDM competition: KKBox Music Churn Prediction Challenge '}, {'title': \"WSDM - KKBox's Churn Prediction Challenge\", 'url': 'https://www.kaggle.com/competitions/kkbox-churn-prediction-challenge', 'briefDescription': 'Can you predict when subscribers will churn?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7163/logos/header.png', 'tag': 'binary classification, logloss', 'description': 'The 11th ACM International Conference on Web Search and Data Mining (WSDM 2018) is challenging you to build an algorithm that predicts whether a subscription user will churn using a donated dataset from KKBOX. WSDM (pronounced \"wisdom\") is one of the the premier conferences on web inspired research involving search and data mining. They\\'re committed to publishing original, high quality papers and presentations, with an emphasis on practical but principled novel models.For a subscription business, accurately predicting churn is critical to long-term success. Even slight variations in churn can drastically affect profits.KKBOX is Asia’s leading music streaming service, holding the world’s most comprehensive Asia-Pop music library with over 30 million tracks. They offer a generous, unlimited version of their service to millions of people, supported by advertising and paid subscriptions. This delicate model is dependent on accurately predicting churn of their paid users.In this competition you’re tasked to build an algorithm that predicts whether a user will churn after their subscription expires. Currently, the company uses survival analysis techniques to determine the residual membership life time for each subscriber. By adopting different methods, KKBOX anticipates they’ll discover new insights to why users leave so they can be proactive in keeping users dancing.Winners will present their findings at the WSDM conference February 6-8, 2018 in Los Angeles, CA.  For more information on the conference, click here.'}, {'title': 'Cdiscount’s Image Classification Challenge', 'url': 'https://www.kaggle.com/competitions/cdiscount-image-classification-challenge', 'briefDescription': 'Categorize e-commerce photos', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7115/logos/header.png', 'tag': 'multiclass classification, categorizationaccuracy', 'description': \"Rules Update: The CDiscount team has updated their rules to allow for use of this dataset for research and academic purposes only. To access the data, go to rules and accept the terms to download the data.Cdiscount.com generated nearly 3 billion euros last year, making it France’s largest non-food e-commerce company. While the company already sells everything from TVs to trampolines, the list of products is still rapidly growing. By the end of this year, Cdiscount.com will have over 30 million products up for sale. This is up from 10 million products only 2 years ago. Ensuring that so many products are well classified is a challenging task.Currently, Cdiscount.com applies machine learning algorithms to the text description of the products in order to automatically predict their category. As these methods now seem close to their maximum potential, Cdiscount.com believes that the next quantitative improvement will be driven by the application of data science techniques to images.In this challenge you will be building a model that automatically classifies the products based on their images. As a quick tour of Cdiscount.com's website can confirm, one product can have one or several images. The data set Cdiscount.com is making available is unique and characterized by superlative numbers in several ways:Almost 9 million products: half of the current catalogueMore than 15 million images at 180x180 resolutionMore than 5000 categories: yes this is quite an extreme multi-class classification!\"}, {'title': 'Text Normalization Challenge - Russian Language', 'url': 'https://www.kaggle.com/competitions/text-normalization-challenge-russian-language', 'briefDescription': 'Convert Russian text from written expressions into spoken forms', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7043/logos/header.png', 'tag': 'text, languages, linguistics, categorizationaccuracy', 'description': 'As many of us can attest, learning another language is tough. Picking up on nuances like slang, dates and times, and local expressions, can often be a distinguishing factor between proficiency and fluency. This challenge is even more difficult for a machine.Many speech and language applications, including text-to-speech synthesis (TTS) and automatic speech recognition (ASR), require text to be converted from written expressions into appropriate \"spoken\" forms. This is a process known as text normalization, and helps convert 12:47 to \"twelve forty-seven\" and $3.16 into \"three dollars, sixteen cents.\"\\xa0However, one of the biggest challenges when developing a TTS or ASR system for a new language is to develop and test the grammar for all these rules, a task that\\xa0requires quite a bit of linguistic sophistication and native speaker intuition.Проверено    \\t<self>12 февраля 2013    двенадцатого февраля две тысячи тринадцатого года,    silАрхивировано    <self>из    <self>первоисточника    <self>15 февраля 2013    февраля две тысячи тринадцатого года.    silIn this competition, you are challenged\\xa0to automate the process of developing\\xa0text normalization grammars via\\xa0machine learning.\\xa0This track will focus on Russian, while a separate will focus on English here:\\xa0English Text Normalization ChallengeAbout the sponsorGoogle\\'s Text Normalization Research Group conducts research and creates tools for the detection, normalization and denormalization of non-standard words such as abbreviations, numbers or currency expressions; and semiotic classes -- text tokens and token sequences that represent particular entities that are semantically constrained, such as measure phrases, addresses or dates. Applications of this work include text-to-speech synthesis, automatic speech recognition, and information extraction/retrieval.'}, {'title': 'Text Normalization Challenge - English Language', 'url': 'https://www.kaggle.com/competitions/text-normalization-challenge-english-language', 'briefDescription': 'Convert English text from written expressions into spoken forms', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/7042/logos/header.png', 'tag': 'text, languages, linguistics, categorizationaccuracy', 'description': 'As many of us can attest, learning another language is tough. Picking up on nuances like slang, dates and times, and local expressions, can often be a distinguishing factor between proficiency and fluency. This challenge is even more difficult for a machine.Many speech and language applications, including text-to-speech synthesis (TTS) and automatic speech recognition (ASR), require text to be converted from written expressions into appropriate \"spoken\" forms. This is a process known as text normalization, and helps convert 12:47 to \"twelve forty-seven\" and $3.16 into \"three dollars, sixteen cents.\"\\xa0However, one of the biggest challenges when developing a TTS or ASR system for a new language is to develop and test the grammar for all these rules, a task that\\xa0requires quite a bit of linguistic sophistication and native speaker intuition.A    <self>baby    <self>giraffe    <self>is    <self>6ft    six feettall    <self>and    <self>weighs    <self>150lb    one hundred fifty pounds.    silIn this competition, you are challenged\\xa0to automate the process of developing\\xa0text normalization grammars via\\xa0machine learning.\\xa0This track will focus on English, while a separate will focus on Russian here:\\xa0Russian Text Normalization ChallengeAbout the sponsorGoogle\\'s Text Normalization Research Group conducts research and creates tools for the detection, normalization and denormalization of non-standard words such as abbreviations, numbers or currency expressions; and semiotic classes -- text tokens and token sequences that represent particular entities that are semantically constrained, such as measure phrases, addresses or dates. Applications of this work include text-to-speech synthesis, automatic speech recognition, and information extraction/retrieval.'}, {'title': 'Carvana Image Masking Challenge', 'url': 'https://www.kaggle.com/competitions/carvana-image-masking-challenge', 'briefDescription': 'Automatically identify the boundaries of the car in an image', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6927/logos/header.png', 'tag': 'image, automobiles and vehicles, dice', 'description': 'As with any big purchase, full information and transparency are key. While most everyone describes buying a used car as frustrating, it’s just as annoying to sell one, especially online. Shoppers want to know everything about the car but they must rely on often blurry pictures and little information, keeping used car sales a largely inefficient, local industry.Carvana, a successful online used car startup, has seen opportunity to build long term trust with consumers and streamline the online buying process.An interesting part of their innovation is a custom rotating photo studio that automatically captures and processes 16 standard images of each vehicle in their inventory. While Carvana takes high quality photos,  bright reflections and cars with similar colors as the background cause automation errors, which requires a skilled photo editor to change.In this competition, you’re challenged to develop an algorithm that automatically removes the photo studio background. This will allow Carvana to superimpose cars on a variety of backgrounds. You’ll be analyzing a dataset of photos, covering different vehicles with a wide variety of year, make, and model combinations.'}, {'title': 'New York City Taxi Trip Duration', 'url': 'https://www.kaggle.com/competitions/nyc-taxi-trip-duration', 'briefDescription': 'Share code and data to improve ride time predictions', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6960/logos/header.png', 'tag': 'tabular, regression, rmsle', 'description': 'In this competition, Kaggle is challenging you to build a model that predicts the total ride duration of taxi trips in New York City. Your primary dataset is one released by the NYC Taxi and Limousine Commission, which includes pickup time, geo-coordinates, number of passengers, and several other variables.Longtime Kagglers will recognize that this competition objective is similar to the ECML/PKDD trip time challenge we hosted in 2015. But, this challenge comes with a twist. Instead of awarding prizes to the top finishers on the leaderboard, this playground competition was created to reward collaboration and collective learning. We are encouraging you (with cash prizes!) to publish additional training data that other participants can use for their predictions. We also have designated bi-weekly and final prizes to reward authors of kernels that are particularly insightful or valuable to the community.'}, {'title': 'Web Traffic Time Series Forecasting', 'url': 'https://www.kaggle.com/competitions/web-traffic-time-series-forecasting', 'briefDescription': 'Forecast future traffic to Wikipedia pages', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6768/logos/header.png', 'tag': 'internet, tabular, smape', 'description': \"This competition focuses on the problem of forecastingthe future values of multiple time series, as it has always been one of the most challengingproblems in the field. More specifically, we aim the competition at testing state-of-the-artmethods designed by the participants, on the problem of forecasting future web traffic forapproximately 145,000 Wikipedia articles.Sequential or temporal observations emerge in many key real-world problems, rangingfrom biological data, financial markets, weather forecasting, to audio and video processing.The field of time series encapsulates many different problems, ranging from analysis andinference to classification and forecast. What can you do to help predict future views? This competition will run as two stages and involves prediction of actual future events. There will be a training stage during which the leaderboard is based on historical data, followed by a stage where participants are scored on real future events.You have complete freedom in how to produce your forecasts: e.g. use of univariate vs multi-variate models, use of metadata (article identifier), hierarchical time series modeling (for different types of traffic), data augmentation (e.g. using Google Trends data to extend the dataset), anomaly and outlier detection and cleaning, different strategies for missing value imputation, and many more types of approaches.We thank Google Inc. and Voleon for sponsorship of this competition, and Oren Anava and Vitaly Kuznetsov for organizing it.Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.\"}, {'title': 'NIPS 2017: Defense Against Adversarial Attack', 'url': 'https://www.kaggle.com/competitions/nips-2017-defense-against-adversarial-attack', 'briefDescription': 'Create an image classifier that is robust to adversarial attacks', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6867/logos/header.png', 'tag': 'image, adversarial learning, custom metric', 'description': \"***This research competition doesn't follow Kaggle's normal submission process. See the Submission Format tab for more details.***Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake.Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model.To accelerate research on adversarial examples, [Google Brain](http://g.co/brain) is organizing **Competition on Adversarial Attacks and Defenses** within the [NIPS 2017 competition track](https://nips.cc/Conferences/2017/CompetitionTrack).The competition on Adversarial Attacks and Defenses consist of three sub-competitions:- [Non-targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack). The goal of the non-targeted attack is to slightly modify source image in a way that image will be classified incorrectly by generally unknown machine learning classifier.- [Targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-targeted-adversarial-attack). The goal of the targeted attack is to slightly modify source image in a way that image will be classified as specified target class by generally unknown machine learning classifier.- [Defense Against Adversarial Attack](https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack). The goal of the defense is to build machine learning classifier which is robust to adversarial example, i.e. can classify adversarial images correctly.In each of the sub-competitions you're invited to make and submit a program which solves the corresponding task. In the end of the competition we will run all attacks against all defenses to evaluate how each of the attacks performs against each of the defenses.*Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, rules, quality, or topic will be addressed by them.*\"}, {'title': 'NIPS 2017: Targeted Adversarial Attack', 'url': 'https://www.kaggle.com/competitions/nips-2017-targeted-adversarial-attack', 'briefDescription': 'Develop an adversarial attack that causes image classifiers to predict a specific target class', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6866/logos/header.png', 'tag': 'image, adversarial learning, custom metric', 'description': \"***This research competition doesn't follow Kaggle's normal submission process. See the Submission Format tab for more details.***Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake.Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model.To accelerate research on adversarial examples, [Google Brain](http://g.co/brain) is organizing **Competition on Adversarial Attacks and Defenses** within the [NIPS 2017 competition track](https://nips.cc/Conferences/2017/CompetitionTrack).The competition on Adversarial Attacks and Defenses consist of three sub-competitions:- [Non-targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack). The goal of the non-targeted attack is to slightly modify source image in a way that image will be classified incorrectly by generally unknown machine learning classifier.- [Targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-targeted-adversarial-attack). The goal of the targeted attack is to slightly modify source image in a way that image will be classified as specified target class by generally unknown machine learning classifier.- [Defense Against Adversarial Attack](https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack). The goal of the defense is to build machine learning classifier which is robust to adversarial example, i.e. can classify adversarial images correctly.In each of the sub-competitions you're invited to make and submit a program which solves the corresponding task. In the end of the competition we will run all attacks against all defenses to evaluate how each of the attacks performs against each of the defenses.*Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, rules, quality, or topic will be addressed by them.*\"}, {'title': 'NIPS 2017: Non-targeted Adversarial Attack', 'url': 'https://www.kaggle.com/competitions/nips-2017-non-targeted-adversarial-attack', 'briefDescription': 'Imperceptibly transform images in ways that fool classification models', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6864/logos/header.png', 'tag': 'image, adversarial learning, custom metric', 'description': \"***This research competition doesn't follow Kaggle's normal submission process. See the Submission Format tab for more details.***Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake.Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model.To accelerate research on adversarial examples, [Google Brain](http://g.co/brain) is organizing **Competition on Adversarial Attacks and Defenses** within the [NIPS 2017 competition track](https://nips.cc/Conferences/2017/CompetitionTrack).The competition on Adversarial Attacks and Defenses consist of three sub-competitions:- [Non-targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack). The goal of the non-targeted attack is to slightly modify source image in a way that image will be classified incorrectly by generally unknown machine learning classifier.- [Targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-targeted-adversarial-attack). The goal of the targeted attack is to slightly modify source image in a way that image will be classified as specified target class by generally unknown machine learning classifier.- [Defense Against Adversarial Attack](https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack). The goal of the defense is to build machine learning classifier which is robust to adversarial example, i.e. can classify adversarial images correctly.In each of the sub-competitions you're invited to make and submit a program which solves the corresponding task. In the end of the competition we will run all attacks against all defenses to evaluate how each of the attacks performs against each of the defenses.*Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, rules, quality, or topic will be addressed by them.*\"}, {'title': 'Personalized Medicine: Redefining Cancer Treatment', 'url': 'https://www.kaggle.com/competitions/msk-redefining-cancer-treatment', 'briefDescription': 'Predict the effect of Genetic Variants to enable Personalized Medicine', 'coverImageUrl': None, 'tag': 'text, multiclass classification, genetics, multiclassloss', 'description': \"A lot has been said during the past several years about how precision medicine and, more concretely, how genetic testing is going to disrupt the way diseases like cancer are treated.But this is only partially happening due to the huge amount of manual work still required. Memorial Sloan Kettering Cancer Center (MSKCC) launched this competition, accepted by the NIPS 2017 Competition Track, \\xa0because we need your help to take personalized medicine to its full potential.Once sequenced, a cancer tumor can have thousands of genetic mutations. But the challenge is distinguishing the mutations that contribute to tumor growth (drivers) from the neutral mutations (passengers).\\xa0Currently this interpretation of genetic mutations is being done manually. This is a very time-consuming task where a clinical pathologist has to manually review and classify every single genetic mutation based on evidence from text-based clinical literature.For this competition MSKCC is making available an expert-annotated knowledge base where world-class researchers and oncologists have manually annotated thousands of mutations.We need your help to develop a Machine Learning algorithm that, using this knowledge base as a baseline, automatically classifies genetic variations.Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.\"}, {'title': 'Passenger Screening Algorithm Challenge', 'url': 'https://www.kaggle.com/competitions/passenger-screening-algorithm-challenge', 'briefDescription': \"Improve the accuracy of the Department of Homeland Security's threat recognition algorithms\", 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6775/logos/header.png', 'tag': 'image, logloss', 'description': 'While long lines and frantically shuffling luggage into plastic bins isn’t a fun experience, airport security is a critical and necessary requirement for safe travel.No one understands the need for both thorough security screenings and short wait times more than U.S. Transportation Security Administration (TSA). They’re responsible for all U.S. airport security, screening more than two million passengers daily.As part of their Apex Screening at Speed Program, DHS has identified high false alarm rates as creating significant bottlenecks at the airport checkpoints. Whenever TSA’s sensors and algorithms predict a potential threat, TSA staff needs to engage in a secondary, manual screening process that slows everything down. And as the number of travelers increase every year and new threats develop, their prediction algorithms need to continually improve to meet the increased demand.Currently, TSA purchases updated algorithms exclusively from the manufacturers of the scanning equipment used. These algorithms are proprietary, expensive, and often released in long cycles. In this competition, TSA is stepping outside their established procurement process and is challenging the broader data science community to help improve the accuracy of their threat prediction algorithms. Using a dataset of images collected on the latest generation of scanners, participants are challenged to identify the presence of simulated threats under a variety of object types, clothing types, and body types. Even a modest decrease in false alarms will help TSA significantly improve the passenger experience while maintaining high levels of security.This is a two-stage competition. Please read our two-stage FAQs to understand more about what this means.All persons contained in the dataset are volunteers who have agreed to have their images used for this competition. The images may contain sensitive content. We kindly request that you conduct yourself with professionalism, respect, and maturity when working with this data.'}, {'title': 'iMaterialist Challenge at FGVC 2017', 'url': 'https://www.kaggle.com/competitions/imaterialist-challenge-FGVC2017', 'briefDescription': 'Can you assign accurate description labels to images of apparel products?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6539/logos/header.png', 'tag': 'clothing and accessories, image, meanbesterroratk', 'description': \"As shoppers move online, it’d be a dream come true to have product attributes in photos detected automatically. But, automatic product recognition is tough because for the same product, a picture can be taken in different lighting, angles, backgrounds, and levels of occlusion. Meanwhile different fine grained attribute labels may look very similar, for example, royal blue vs turquoise in color. Many of today’s general-purpose recognition machines simply can’t perceive such subtle differences between photos.Tackling issues like this is why the Conference on Computer Vision and Pattern Recognition (CVPR) has put together a workshop specifically for data scientists focused on fine-grained visual categorization called the FGVC4 workshop. As part of this workshop, CVPR is partnering with Google to challenge the data science community to help push the state of the art in automatic image classification.In this competition, FGVC workshop organizers and Google challenge you to develop algorithms that will help with the an important step towards automatic product detection–accurately assigning attribute labels for product images. Individuals/Teams with top submissions will be invited to present their work live at the FGVC4 workshop.Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.\"}, {'title': 'iNaturalist Challenge at FGVC 2017', 'url': 'https://www.kaggle.com/competitions/inaturalist-challenge-at-fgvc-2017', 'briefDescription': 'Fine-grained classification challenge spanning 5,000 species.', 'coverImageUrl': None, 'tag': 'image, animals, plants, meanbesterroratk', 'description': \"With so much diversity, accurately classifying animals and plants is a tough challenge. Check out the photos below. Alpaca or Llama? Donkey or mule? Roses or kale?It’s estimated that our planet contains several million species of plants and animals–many that look really similar to each other. Because of this, a lot of species in the natural world are too hard to classify without an expert.As part of the FGVC4 workshop\\xa0at CVPR 2017\\xa0we are conducting the iNat Challenge 2017 large scale species classification competition, sponsored by Google. It is estimated that the natural world contains several million species of plants and animals. Without expert knowledge, many of these species are extremely difficult to accurately classify due to their visual similarity. The goal of this competition is to push the state of the art in automatic image classification for real world data that features fine-grained categories, big class imbalances, and large numbers of classes.The iNat Challenge 2017 dataset contains 5,089\\xa0species, with a combined training and validation set of 675,000 images that have been collected and verified by multiple users from inaturalist.org. The dataset features many visually similar species, captured in a wide variety of situations, from all over the world.\\xa0 Example images, along with their unique GBIF\\xa0ID numbers (where available), can be viewed here.Teams with top submissions, at the discretion of the workshop organizers, will be invited to present their work at the\\xa0FGVC4 workshop.\\xa0Kaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.\"}, {'title': 'Mercedes-Benz Greener Manufacturing', 'url': 'https://www.kaggle.com/competitions/mercedes-benz-greener-manufacturing', 'briefDescription': 'Can you cut the time a Mercedes-Benz spends on the test bench?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6565/logos/header.png', 'tag': 'tabular, regression, automobiles and vehicles, r2score', 'description': 'Since the first automobile, the Benz Patent Motor Car in 1886, Mercedes-Benz has stood for important automotive innovations. These include, for example, the passenger safety cell with crumple zone, the airbag and intelligent assistance systems. Mercedes-Benz applies for nearly 2000 patents per year, making the brand the European leader among premium car makers. Daimler’s Mercedes-Benz cars are leaders in the premium car industry. With a huge selection of features and options, customers can choose the customized Mercedes-Benz of their dreams. .To ensure the safety and reliability of each and every unique car configuration before they hit the road, Daimler’s engineers have developed a robust testing system. But, optimizing the speed of their testing system for so many possible feature combinations is complex and time-consuming without a powerful algorithmic approach. As one of the world’s biggest manufacturers of premium cars, safety and efficiency are paramount on Daimler’s production lines.In this competition, Daimler is challenging Kagglers to tackle the curse of dimensionality and reduce the time that cars spend on the test bench. Competitors will work with a dataset representing different permutations of Mercedes-Benz car features to predict the time it takes to pass testing. Winning algorithms will contribute to speedier testing, resulting in lower carbon dioxide emissions without reducing Daimler’s standards.'}, {'title': 'Zillow Prize: Zillow’s Home Value Prediction (Zestimate)', 'url': 'https://www.kaggle.com/competitions/zillow-prize-1', 'briefDescription': 'Can you improve the algorithm that changed the world of real estate?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6649/logos/header.png', 'tag': 'real estate, housing, custom metric', 'description': 'Zillow’s Zestimate home valuation has shaken up the U.S. real estate industry since first released 11 years ago.A home is often the largest and most expensive purchase a person makes in his or her lifetime. Ensuring homeowners have a trusted way to monitor this asset is incredibly important. The Zestimate was created to give consumers as much information as possible about homes and the housing market, marking the first time consumers had access to this type of home value information at no cost.“Zestimates” are estimated home values based on 7.5 million statistical and machine learning models that analyze hundreds of data points on each property.   And, by continually improving the median margin of error (from 14% at the onset to 5% today), Zillow has since become established as one of the largest, most trusted marketplaces for real estate information in the U.S. and a leading example of impactful machine learning.Zillow Prize, a competition with a one million dollar grand prize, is challenging the data science community to help push the accuracy of the Zestimate even further. Winning algorithms stand to impact the home values of  110M homes across the U.S.In this million-dollar competition, participants will develop an algorithm that makes predictions about the future sale prices of homes. The contest is structured into two rounds, the qualifying round which opens May 24, 2017 and the private round for the 100 top qualifying teams that opens  on Feb 1st, 2018. In the qualifying round, you’ll be building a model to improve the Zestimate residual error. In the final round, you’ll build a home valuation algorithm from the ground up, using external data sources to help engineer new features that give your model an edge over the competition.Because real estate transaction data is public information, there will be a three-month sales tracking period after each competition round closes where your predictions will be evaluated against the actual sale prices of the homes. The final leaderboard won’t be revealed until the close of the sales tracking period.'}, {'title': 'Instacart Market Basket Analysis', 'url': 'https://www.kaggle.com/competitions/instacart-market-basket-analysis', 'briefDescription': 'Which products will an Instacart consumer purchase again?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6644/logos/header.png', 'tag': 'food, meanfscore', 'description': 'Whether you shop from meticulously planned grocery lists or let whimsy guide your grazing, our unique food rituals define who we are. Instacart, a grocery ordering and delivery app, aims to make it easy to fill your refrigerator and pantry with your personal favorites and staples when you need them. After selecting products through the Instacart app, personal shoppers review your order and do the in-store shopping and delivery for you.Instacart’s data science team plays a big part in providing this delightful shopping experience. Currently they use transactional data to develop models that predict which products a user will buy again, try for the first time, or add to their cart next during a session. Recently, Instacart open sourced this data - see their blog post on 3 Million Instacart Orders, Open Sourced.In this competition, Instacart is challenging the Kaggle community to use this anonymized data on customer orders over time to predict which previously purchased products will be in a user’s next order. They’re not only looking for the best model, Instacart’s also looking for machine learning engineers to grow their team.Winners of this competition will receive both a cash prize and a fast track through the recruiting process. For more information about exciting opportunities at Instacart, check out their careers page here or e-mail their recruiting team directly at ml.jobs@instacart.com.'}, {'title': 'Invasive Species Monitoring', 'url': 'https://www.kaggle.com/competitions/invasive-species-monitoring', 'briefDescription': 'Identify images of invasive hydrangea', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6469/logos/header.png', 'tag': 'image, plants, auc', 'description': 'Tangles of kudzu overwhelm trees in Georgia while cane toads threaten habitats in over a dozen countries worldwide. These are just two invasive species of many which can have damaging effects on the environment, the economy, and even human health. Despite widespread impact, efforts to track the location and spread of invasive species are so costly that they’re difficult to undertake at scale.Currently, ecosystem and plant distribution monitoring depends on expert knowledge. Trained scientists visit designated areas and take note of the species inhabiting them. Using such a highly qualified workforce is expensive, time inefficient, and insufficient since humans cannot cover large areas when sampling.Because scientists cannot sample a large quantity of areas, some machine learning algorithms are used in order to predict the presence or absence of invasive species in areas that have not been sampled. The accuracy of this approach is far from optimal, but still contributes to approaches to solving ecological problems.In this playground competition, Kagglers are challenged to develop algorithms to more accurately identify whether images of forests and foliage contain invasive hydrangea or not. Techniques from computer vision alongside other current technologies like aerial imaging can make invasive species monitoring cheaper, faster, and more reliable.AcknowledgmentsData providers: Christian Requena Mesa, Thore Engel, Amrita Menon, Emma Bradley.'}, {'title': 'Sberbank Russian Housing Market', 'url': 'https://www.kaggle.com/competitions/sberbank-russian-housing-market', 'briefDescription': 'Can you predict realty price fluctuations in Russia’s volatile economy?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6392/logos/header.png', 'tag': 'tabular, regression, banking, housing, rmsle', 'description': 'Housing costs demand a significant investment from both consumers and developers. And when it comes to planning a budget—whether personal or corporate—the last thing anyone needs is uncertainty about one of their biggets expenses. Sberbank, Russia’s oldest and largest bank, helps their customers by making predictions about realty prices so renters, developers, and lenders are more confident when they sign a lease or purchase a building.Although the housing market is relatively stable in Russia, the country’s volatile economy makes forecasting prices as a function of apartment characteristics a unique challenge. Complex interactions between housing features such as number of bedrooms and location are enough to make pricing predictions complicated. Adding an unstable economy to the mix means Sberbank and their customers need more than simple regression models in their arsenal.In this competition, Sberbank is challenging Kagglers to develop algorithms which use a broad spectrum of features to predict realty prices. Competitors will rely on a rich dataset that includes housing data and macroeconomic patterns. An accurate forecasting model will allow Sberbank to provide more certainty to their customers in an uncertain economy.'}, {'title': 'Planet: Understanding the Amazon from Space', 'url': 'https://www.kaggle.com/competitions/planet-understanding-the-amazon-from-space', 'briefDescription': 'Use satellite data to track the human footprint in the Amazon rainforest', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6322/logos/header.png', 'tag': 'image, forestry, meanfscorebeta', 'description': \"Every minute, the world loses an area of forest the size of 48 football fields. And deforestation in the Amazon Basin accounts for the largest share, contributing to reduced biodiversity, habitat loss, climate change, and other devastating effects. But better data about the location of deforestation and human encroachment on forests can help governments and local stakeholders respond more quickly and effectively.Planet, designer and builder of the world’s largest constellation of Earth-imaging satellites, will soon be collecting daily imagery of the entire land surface of the earth at 3-5 meter resolution. While considerable research has been devoted to tracking changes in forests, it typically depends on coarse-resolution imagery from Landsat (30 meter pixels) or MODIS (250 meter pixels). This limits its effectiveness in areas where small-scale deforestation or forest degradation dominate.Furthermore, these existing methods generally cannot differentiate between human causes of forest loss and natural causes. Higher resolution imagery has already been shown to be exceptionally good at this, but robust methods have not yet been developed for Planet imagery.In this competition, Planet and its Brazilian partner SCCON are challenging Kagglers to label satellite image chips with atmospheric conditions and various classes of land cover/land use. Resulting algorithms will help the global community better understand where, how, and why deforestation happens all over the world - and ultimately how to respond.To dig into/explore more Planet data, sign up for a free account.And if you're interested in building applications on Planet data, check out our Application Developer Program.Getting Started Review the data page, which includes detailed information about the labels and the labeling process.Download a subsample of the data to get familiar with how it looks.Explore the subsample on Kernels. We’ve created a notebook for you to get started.\"}, {'title': 'NOAA Fisheries Steller Sea Lion Population Count', 'url': 'https://www.kaggle.com/competitions/noaa-fisheries-steller-sea-lion-population-count', 'briefDescription': 'How many sea lions do you see?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6116/logos/header.png', 'tag': 'image, animals, water bodies, mcrmse', 'description': \"Steller sea lions in the western Aleutian Islands have declined 94 percent in the last 30 years. The endangered western population, found in the North Pacific, are the focus of conservation efforts which require annual population counts. Specially trained scientists at NOAA Fisheries Alaska Fisheries Science Center conduct these surveys using airplanes and unoccupied aircraft systems to collect aerial images. Having accurate population estimates enables us to better understand factors that may be contributing to lack of recovery of Stellers in this area.Currently, it takes biologists up to four months to count sea lions from the thousands of images NOAA Fisheries collects each year. Once individual counts are conducted, the tallies must be reconciled to confirm their reliability. The results of these counts are time-sensitive.In this competition, Kagglers are invited to develop algorithms which accurately count the number of sea lions in aerial photographs. Automating the annual population count will free up critical resources allowing NOAA Fisheries to focus on ensuring we hear the sea lion’s roar for many years to come. Plus, advancements in computer vision applied to aerial population counts may also greatly benefit other endangered species.ResourcesLearn more about research being done to better understand what's going on with the endangered Steller sea lion populations by joining scientists on a research vessel to the western Aleutian Islands in the video below.\"}, {'title': 'Quora Question Pairs', 'url': 'https://www.kaggle.com/competitions/quora-question-pairs', 'briefDescription': 'Can you identify question pairs that have the same intent?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6277/logos/header.png', 'tag': 'internet, tabular, text, linguistics, logloss', 'description': \"Where else but Quora\\xa0can a physicist help a chef with a math problem and get cooking tips in return? Quora is a place to gain and share knowledge—about anything. It’s a platform to ask questions and connect with people who contribute unique insights and quality answers. This empowers people to learn from each other and to better understand the world.Over 100 million people visit Quora every month, so it's no surprise that many people ask similarly worded questions. Multiple questions with the same intent can cause seekers to spend more time finding the best answer to their question, and make writers feel they need to answer multiple versions of the same question. Quora values canonical questions because they provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.Currently, Quora uses a Random Forest model to identify duplicate questions. In this competition, Kagglers are challenged to tackle this natural language processing problem by applying advanced techniques to classify whether question pairs are duplicates or not. Doing so will make it easier to find high quality answers to questions resulting in an improved experience for Quora writers, seekers, and readers.\"}, {'title': 'Intel & MobileODT Cervical Cancer Screening', 'url': 'https://www.kaggle.com/competitions/intel-mobileodt-cervical-cancer-screening', 'briefDescription': 'Which cancer treatment will be most effective?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6243/logos/header.png', 'tag': 'image, multiclass classification, healthcare, multiclassloss', 'description': \"Cervical cancer is so easy to prevent if caught in its pre-cancerous stage that every woman should have access to effective, life-saving treatment no matter where they live. Today, women worldwide in low-resource settings are benefiting from programs where cancer is identified and treated in a single visit. However, due in part to lacking expertise in the field, one of the greatest challenges of these cervical cancer screen and treat programs is determining the appropriate method of treatment which can vary depending on patients’ physiological differences.Especially in rural parts of the world, many women at high risk for cervical cancer are receiving treatment that will not work for them due to the position of their cervix. This is a tragedy: health providers are able to identify high risk patients, but may not have the skills to reliably discern which treatment which will prevent cancer in these women. Even worse, applying the wrong treatment has a high cost. A treatment which works effectively for one woman may obscure future cancerous growth in another woman, greatly increasing health risks.Currently, MobileODT offers a Quality Assurance workflow to support remote supervision which helps healthcare providers make better treatment decisions in rural settings. However, their workflow would be greatly improved given the ability to make real-time determinations about patients’ treatment eligibility based on cervix type.In this competition, Intel is partnering with MobileODT to challenge Kagglers to develop an algorithm which accurately identifies a woman’s cervix type based on images. Doing so will prevent ineffectual treatments and allow healthcare providers to give proper referral for cases that require more advanced treatment.Competition PartnerMobileODT has developed and sells the Enhanced Visual Assessment (EVA) System, a digital toolkit for health care workers of every level to provide expert services to patients, anchored at the point-of-care by an FDA-approved, intelligent, mobile-phone based medical device. Combining the algorithmic power of biomedical optics with the computational capabilities and connectivity of mobile phones, MobileODT's connected, intelligent medical systems can be used everywhere, under nearly any conditions. MobileODT's first product, the FDA approved EVA System for colposcopy, is in use by health providers in 31 hospital systems across the US, and in 22 countries, to better screen and treat women for cervical cancer and to conduct forensic colposcopy.\"}, {'title': 'Google Cloud & YouTube-8M Video Understanding Challenge', 'url': 'https://www.kaggle.com/competitions/youtube8m', 'briefDescription': 'Can you produce the best video tag predictions?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/6049/logos/header.png', 'tag': 'internet, image, custom metric', 'description': \"Video captures a cross-section of our society. And major advances in analyzing and understanding video have the potential to touch all aspects of life from learning and communication to entertainment and play. In this competition, Google is inviting the Kaggle community to join efforts to accelerate research in large-scale video understanding, while giving participants access to the Google Cloud Machine Learning Engine.Today, one of the greatest obstacles to rapid improvements in video understanding research has been the lack of large-scale, labeled datasets open to the public. For example, the availability of large, labeled datasets such as ImageNet\\xa0has enabled continued breakthroughs in machine learning and machine perception. To that end, Google’s recent release of the YouTube-8M (YT-8M) dataset\\xa0represents a significant step in this direction. Making this resource open to everyone from students and industry professionals is expected to kickstart innovation in areas such as representation learning and video modeling architectures.In this competition, you are challenged to develop classification algorithms which accurately assign video-level labels using the new and improved YT-8M V2 dataset. The dataset was created from over 7 million YouTube videos (450,000 hours of video) and includes video labels from a vocabulary of 4716 classes (3.4 labels/video on average).  It also comes with pre-extracted audio & visual features from every second of video (3.2B feature vectors in total). By taking part, Kagglers will not only play a pivotal role in setting state-of-the-art benchmarks, but also improve search and organization of video archives.Getting StartedReview the data\\xa0page for special instructions\\xa0on how\\xa0to access the competition's data.\\xa0It will be hosted on Google Cloud. Participants have the option to download the data to work locally or work within the Google Cloud ML beta Platform.Review the tutorial on Getting Started with Google Cloud, and try the starter code.Sign up for a Google Cloud ML Platform free trial account. The free trial account includes $300 in credits!We've also provided a subsample of the data to explore on Kernels. Take a look at this Python notebook and create your own.Don't forget to review the prize eligibility details, which includes requirements for code open-sourcing and a paper submission.Because Cloud ML is currently a beta product, Google\\xa0welcomes the opportunity to hear your feedback about using the tool. Please share your questions and thoughts on the competition's forums. Additional resources specific to the YT-8M dataset and Google Cloud ML can be found here.AcknowledgementsGoogle Cloud Machine Learning, Competition SponsorGoogle Cloud Machine Learning is a managed service that enables you to easily build machine learning models, that work on any type of data, of any size. Create your model with the powerful TensorFlow framework that powers many Google products, from GooglePhotos to Google Cloud Speech. Build models of any size with our managed scalable infrastructure. Your trained model is immediately available for use with our global prediction platform that can support thousands of users and TBs of data. The service is integrated with Google Cloud Dataflow for pre-processing, allowing you to access data from Google Cloud Storage, Google BigQuery, and others.\"}, {'title': 'Two Sigma Connect: Rental Listing Inquiries', 'url': 'https://www.kaggle.com/competitions/two-sigma-connect-rental-listing-inquiries', 'briefDescription': 'How much interest will a new rental listing on RentHop receive?', 'coverImageUrl': None, 'tag': 'tabular, text, multiclass classification, housing, multiclassloss', 'description': \"Finding the perfect place to call your new home should be more than browsing through endless listings. RentHop makes apartment search smarter by using data to sort rental listings by quality. But while looking for the perfect apartment is difficult enough, structuring and making sense of all available real estate data programmatically is even harder. Two Sigma and RentHop, a portfolio company of Two Sigma Ventures, invite Kagglers to unleash their creative engines to uncover business value in this unique recruiting competition.Two Sigma invites you to apply your talents in this recruiting competition featuring rental listing data from RentHop. Kagglers will predict the number of inquiries a new listing receives based on the listing’s creation date and other features. Doing so will help RentHop better handle fraud control, identify potential listing quality issues, and allow owners and agents to better understand renters’ needs and preferences.Two Sigma has been at the forefront of applying technology and data science to financial forecasts. While their pioneering advances in big data, AI, and machine learning in the financial world have been pushing the industry forward, as with all other scientific progress, they are driven to make continual progress. This challenge is an opportunity for competitors to gain a sneak peek into Two Sigma's data science work outside of finance.AcknowledgmentsThis competition is co-hosted by Two Sigma and RentHop (a portfolio company of Two Sigma Ventures, which is a division of Two Sigma Investments) to encourage creativity in using real world data to solve everyday problems.\"}, {'title': 'March Machine Learning Mania 2017', 'url': 'https://www.kaggle.com/competitions/march-machine-learning-mania-2017', 'briefDescription': 'Predict the 2017 NCAA Basketball Tournament', 'coverImageUrl': None, 'tag': 'sports, basketball, logloss', 'description': \"Another year, another chance to predict the upsets, call the probabilities, and put your bracketology skills to the leaderboard test. In our fourth annual March Machine Learning Mania competition, Kagglers will once again join the millions of fans who attempt to predict the outcomes of this year's US men's college basketball tournament. But unlike most fans, you will pick the winners and losers using a combination of rich historical data and computing power, while the ground truth unfolds on national television.In the first stage of the competition, Kagglers will rely on results of past tournaments to build and test models. We encourage you to post any useful external data as a dataset. In the second stage, competitors will forecast outcomes of all possible match-ups in the 2017 tournament. You don't need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2017 results.\"}, {'title': 'Data Science Bowl 2017', 'url': 'https://www.kaggle.com/competitions/data-science-bowl-2017', 'briefDescription': 'Can you improve lung cancer detection?', 'coverImageUrl': None, 'tag': 'image, binary classification, healthcare, logloss', 'description': \"In the United States, lung cancer strikes 225,000 people every year, and accounts for $12 billion in health care costs. Early detection is critical to give patients the best chance at recovery and survival.One year ago, the office of the U.S. Vice President spearheaded a bold new initiative, the Cancer Moonshot, to make a decade's worth of progress in cancer prevention, diagnosis, and treatment in just 5 years.In 2017, the Data Science Bowl will be a critical milestone in support of the Cancer Moonshot by convening the data science and medical communities to develop lung cancer detection algorithms.Using a data set of thousands of high-resolution lung scans provided by the National Cancer Institute, participants will develop algorithms that accurately determine when lesions in the lungs are cancerous. This will dramatically reduce the false positive rate that plagues the current detection technology, get patients earlier access to life-saving interventions, and give radiologists more time to spend with their patients.This year, the Data Science Bowl will award $1 million in prizes to those who observe the right patterns, ask the right questions, and in turn, create unprecedented impact around cancer screening care and prevention. The funds for the prize purse will be provided by the Laura and John Arnold Foundation.Visit DataScienceBowl.com to: • Sign up to\\xa0receive news about the competition• Learn about the\\xa0history of the Data Science Bowl and past competitions• Read our\\xa0latest insights on emerging analytics techniquesAcknowledgmentsThe Data Science Bowl is presented byCompetition SponsorsLaura and John Arnold FoundationCancer Imaging Program of the National Cancer InstituteAmerican College of RadiologyAmazon Web ServicesNVIDIAData Support ProvidersNational Lung Screening TrialThe Cancer Imaging ArchiveDiagnostic Image Analysis Group, Radboud UniversityLahey Hospital & Medical CenterCopenhagen University HospitalSupporting Organizations\\xa0Bayes ImpactBlack Data Processng AssociatesCode the ChangeData Community DCDataKindGalvanizeGreat Minds in STEMHortonworksINFORMSLesbians Who TechNSBESociety of Asian Scientists & EngineersSociety of Women EngineersUniversity of Texas Austin, Business Analytics Program,McCombs School of BusinessUS Dept. of Health and Human ServicesUS Food and Drug AdministrationWomen in TechnologyWomen of Cyberjutsu\"}, {'title': \"Santa's Uncertain Bags\", 'url': 'https://www.kaggle.com/competitions/santas-uncertain-bags', 'briefDescription': \"♫ Bells are ringing, children singing, all is merry and bright. Santa's elves made a big mistake, now he needs your help tonight ♫\", 'coverImageUrl': None, 'tag': 'tabular, custom metric', 'description': \"All was well in Santa's workshop. The gifts were made, the route was planned, the naughty and nice list complete. Santa thought this would finally be the year he didn't need Kaggle's help with his combinatorial conundrums. At last, the Claus family could take the elves and reindeer on that\\xa0well deserved vacation to the South Pole.Then, with just days until the big night, Santa received an email from a panicked database admin elf. Attached was a server log with the\\xa0six least\\xa0jolly words a jolly old St. Nick could read:ALTER TABLE\\xa0GiftsDROP COLUMN\\xa0WeightOne of the North Pole elf\\xa0interns had mistakenly deleted the weights for all of the inventory\\xa0in the workshop! Santa didn't have a backup (remember, this is a guy who\\xa0makes a list and checks it twice) and, without knowing each present's weight, he\\xa0didn't know how he would safely pack his\\xa0many gift bags. Gifts were already on their\\xa0way to the sleigh packing facility and there\\xa0wasn't time to re-weigh all the\\xa0presents. It was once again necessary to summon the holiday talents of\\xa0Kaggle's elite.Can you help Santa fill his multiple bags with sets of uncertain gifts? Save the season by turning Santa's uncertain\\xa0probabilities into presents for good little boys and girls.\"}, {'title': 'Dstl Satellite Imagery Feature Detection', 'url': 'https://www.kaggle.com/competitions/dstl-satellite-imagery-feature-detection', 'briefDescription': 'Can you train an eye in the sky?', 'coverImageUrl': None, 'tag': 'image, multiclass classification, custom metric', 'description': 'The proliferation of satellite imagery has given us a radically improved understanding of our planet. It has enabled us to better achieve everything from mobilizing resources during disasters to monitoring effects of global warming. What is often taken for granted is that advancements such as these have relied on labeling features\\xa0of significance like building footprints and roadways fully by hand or through imperfect semi-automated methods.As these large, complex datasets continue to increase exponentially in number, the Defence Science and Technology Laboratory (Dstl)\\xa0is seeking novel solutions to alleviate the burden on their image analysts. In this competition, Kagglers are challenged to accurately classify features\\xa0in overhead imagery. Automating feature\\xa0labeling will not only help Dstl make smart decisions more quickly around the defense and security of the UK, but also bring innovation to computer vision methodologies applied to satellite imagery.'}, {'title': 'Two Sigma Financial Modeling Challenge', 'url': 'https://www.kaggle.com/competitions/two-sigma-financial-modeling', 'briefDescription': 'Can you uncover predictive value in an uncertain world?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/5484/logos/header.png', 'tag': 'finance, custom metric', 'description': 'How can we use the world’s tools and intelligence to forecast economic outcomes that can never be entirely predictable? This question is at the core of countless economic activities around the world – including at Two Sigma Investments, who\\xa0has been applying technology and systematic strategies to financial trading since 2001.For over 15 years, Two Sigma has been at the forefront of applying technology and data science to financial forecasts. While their pioneering advances in big data, AI, and machine learning in the financial world have been pushing the industry forward, as with all other scientific progress, they are driven to make continual progress. Through this exclusive partnership, Two Sigma is excited to explore what untapped value Kaggle\\'s diverse\\xa0data science community can discover in the financial markets.Economic opportunity depends on the ability to deliver singularly accurate forecasts in a world of uncertainty. By accurately predicting financial movements, Kagglers will learn about scientifically-driven approaches to\\xa0unlocking\\xa0significant predictive capability.\\xa0Two Sigma is excited to find predictive value and gain a better understanding of the skills\\xa0offered by the global data science crowd.What is a Code Competition?Welcome to Kaggle\\'s very first Code Competition! In contrast to our traditional competitions, where competitors submit only prediction outputs, participants in\\xa0Code Competitions\\xa0will submit their code via Kaggle Kernels. All kernels are private by default in Code Competitions. You\\xa0can\\xa0build your models in Kernels by running them on a training set and, once\\xa0you\\'re ready to submit your code, your\\xa0model\\'s performance will be evaluated against the test set and your score and public leaderboard position revealed. As with our traditional competitions, we\\xa0still maintain a private leaderboard test set, which your code is also evaluated against for final scoring, but is\\xa0not\\xa0revealed until the competition closes.Since Code Competitions are brand new, we ask for your patience if you encounter bugs or frustrating platform quirks. Please report any issues you find in the forums and we\\'ll do our best to respond.Who owns my code?You do. Even though you are submitting code, the intellectual property exchange here works similarly to a standard prediction competition, whereby prize winners have the option to grant a non-exclusive license in exchange for a prize. There is a new addition to the terms for Code Competitions: Kaggle and the competition host reserve a right to review submissions \"for purposes related to evaluation and scoring in this Competition, including but not limited to the assessment of potential cheating behavior.\" Please refer to the official competition rules for full details.Getting StartedReview the data page\\xa0for details about the data and the evaluation metric. You may\\xa0download\\xa0the train set for local training.Take a look at the tutorial covering the\\xa0new code submission process under\\xa0the submission instructions tab. You\\'ll find step-by-step instructions,\\xa0some helpful pointers, plus details on environment constraints.Get feedback on your\\xa0benchmark code and share exploratory analyses with the community by making any of your kernels public.Improve your score!Note: there is no cost of entry for participation.'}, {'title': 'The Nature Conservancy Fisheries Monitoring', 'url': 'https://www.kaggle.com/competitions/the-nature-conservancy-fisheries-monitoring', 'briefDescription': 'Can you detect and classify species of fish?', 'coverImageUrl': None, 'tag': 'image, multiclass classification, multiclassloss', 'description': 'Nearly half of the world depends on seafood for their main source of protein. In the Western and Central Pacific, where 60% of the world’s tuna is caught, illegal, unreported, and unregulated fishing practices are threatening marine ecosystems, global seafood supplies and local livelihoods.\\xa0The Nature Conservancy\\xa0is working with local, regional and global partners to preserve this fishery for the future.Currently, the Conservancy is looking to the future by using cameras to dramatically scale the monitoring of fishing activities to fill critical science and compliance monitoring data gaps. Although these electronic monitoring systems work well and are ready for wider deployment, the amount of raw data produced is cumbersome and expensive to process manually.The Conservancy is inviting the Kaggle community to develop algorithms to automatically detect and classify species of tunas, sharks and more\\xa0that fishing boats catch, which will accelerate the video review process. Faster review and more reliable data will enable countries to reallocate human capital to management and enforcement activities which will have a positive impact on conservation and our planet.Machine learning has the ability to transform what we know about our oceans and how we manage them. You can be part of the solution.ResourcesYou can learn more about this competition and The Nature Conservancy\\xa0in the video below.'}, {'title': 'Ghouls, Goblins, and Ghosts... Boo! ', 'url': 'https://www.kaggle.com/competitions/ghouls-goblins-and-ghosts-boo', 'briefDescription': 'Can you classify monsters haunting Kaggle?', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, categorizationaccuracy', 'description': \"Get out your dowsing rods, electromagnetic sensors, … and gradient boosting machines. Kaggle is haunted and we need your help. After a month of making scientific observations and taking careful measurements, we’ve determined that 900 ghouls, ghosts, and goblins are infesting our halls and frightening our data scientists. When\\xa0trying garlic, asking politely, and using reverse psychology didn't work, it became clear that machine learning is the only answer to banishing\\xa0our unwanted guests.So now the hour has come to put the data we’ve collected in your hands. We’ve managed to identify 371 of the ghastly creatures, but need your help to vanquish the rest. And only an accurate classification algorithm can thwart them. Use bone length measurements, severity of rot, extent of soullessness, and other characteristics to distinguish (and extinguish) the intruders. Are you ghost-busters up for the challenge?\"}, {'title': 'Transfer Learning on Stack Exchange Tags', 'url': 'https://www.kaggle.com/competitions/transfer-learning-on-stack-exchange-tags', 'briefDescription': 'Predict tags from models trained on unrelated topics', 'coverImageUrl': None, 'tag': 'tabular, text, multiclass classification, meanfscore', 'description': 'What does physics have in common with biology, cooking, cryptography, diy, robotics, and travel? If you answered \"all pursuits are governed by the immutable laws of physics\" we\\'ll begrudgingly give you partial\\xa0credit. If you answered \"all were chosen randomly by a scheming\\xa0Kaggle employee\\xa0for a twisted\\xa0transfer learning competition\", congratulations, we accept your answer and mark the question as solved.In this competition, we provide the titles, text, and tags of Stack Exchange questions from six different sites. We then ask for tag predictions on unseen physics questions. Solving this problem via\\xa0a\\xa0standard machine approach might\\xa0involve training an algorithm on a corpus of related text. Here, you are challenged to train on material\\xa0from outside the field. Can an\\xa0algorithm learn appropriate physics tags from \"extreme-tourism Antarctica\"? Let\\'s find out.Kaggle is hosting this competition for the data science community to use for fun and education. This dataset originates from the Stack Exchange data dump.'}, {'title': 'Santander Product Recommendation', 'url': 'https://www.kaggle.com/competitions/santander-product-recommendation', 'briefDescription': 'Can you pair products with people?', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, banking, map@{k}', 'description': \"Ready to make a downpayment on your first house? Or looking to leverage the equity in the home you have? To support needs for a range of\\xa0financial decisions, Santander Bank\\xa0offers a lending hand to their customers through personalized product recommendations.Under their current system, a small number of Santander’s customers receive many recommendations while many others rarely see any resulting in an uneven customer experience. In their second competition, Santander is challenging Kagglers to predict which products their existing customers will use in the next month based on their past behavior and that of similar customers.With a more effective recommendation system in place, Santander can better meet the individual needs of all customers and ensure their satisfaction no matter where they are in life.Disclaimer:\\xa0This data set\\xa0does not include any real Santander Spain's customer, and thus it is not representative of Spain's customer base.\\xa0\"}, {'title': 'Allstate Claims Severity', 'url': 'https://www.kaggle.com/competitions/allstate-claims-severity', 'briefDescription': 'How severe is an insurance claim?', 'coverImageUrl': None, 'tag': 'tabular, regression, mae', 'description': 'When you’ve been devastated by a serious car accident, your focus is on the things that matter the most: family, friends, and other loved ones. Pushing paper with your insurance agent is the last place you want your time or mental energy spent. This is why Allstate, a personal insurer in the United States, is continually seeking fresh ideas to improve their claims service for the over 16 million households they protect.Allstate is currently developing automated methods of predicting the cost, and hence severity, of claims. In this recruitment challenge, Kagglers are invited to show off their creativity and flex their technical chops by creating\\xa0an algorithm which accurately predicts claims severity. Aspiring competitors will demonstrate\\xa0insight into better ways to predict claims severity for the chance to be part of Allstate’s efforts to ensure a worry-free customer experience.New to Kaggle? This competition is a recruiting competition, your chance to get a foot in the door with the hiring team at Allstate.'}, {'title': 'Outbrain Click Prediction', 'url': 'https://www.kaggle.com/competitions/outbrain-click-prediction', 'briefDescription': 'Can you predict which recommended content each user will click?', 'coverImageUrl': None, 'tag': 'internet, tabular, map@{k}', 'description': 'The internet is a stimulating treasure trove of possibility. Every day we stumble on news stories relevant to our communities or experience the serendipity of finding an article covering our next travel destination. Outbrain, the web’s leading content discovery platform, delivers these moments while we surf our favorite sites.Currently, Outbrain pairs relevant content with curious readers in about 250 billion personalized recommendations every month across many thousands of sites. In this competition, Kagglers are challenged to predict which pieces of content its global base of users are likely to click on. Improving Outbrain’s recommendation algorithm will mean more users uncover stories that satisfy their individual tastes.'}, {'title': 'Dogs vs. Cats Redux: Kernels Edition', 'url': 'https://www.kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition', 'briefDescription': 'Distinguish images of dogs from cats', 'coverImageUrl': None, 'tag': 'image, binary classification, animals, logloss', 'description': \"In 2013, we hosted one of our favorite for-fun competitions: \\xa0Dogs vs. Cats. Much has since changed in the machine learning landscape, particularly in deep learning and image analysis. Back then, a\\xa0tensor flow was the\\xa0diffusion of the creamer in a bored mathematician's cup of coffee. Now, even the cucumber farmers\\xa0are neural netting their way to a bounty.Much has changed at Kaggle as well. Our online coding environment Kernels\\xa0didn't exist in 2013, and so it was that we approached sharing\\xa0by scratching primitive glpyhs\\xa0on cave walls with sticks and sharp objects.\\xa0No more. Now, Kernels have taken over as the way to share code on Kaggle. IPython is out and Jupyter Notebook\\xa0is in. We even have TensorFlow.\\xa0What more could a data scientist ask for? But seriously, what more? Pull requests welcome.We are excited to bring back the infamous Dogs vs. Cats classification problem\\xa0as a playground competition with kernels enabled. Although modern techniques may make light of this once-difficult\\xa0problem, it is through practice of\\xa0new techniques on old datasets that we will make light of machine learning's future challenges.\"}, {'title': 'Melbourne University AES/MathWorks/NIH Seizure Prediction', 'url': 'https://www.kaggle.com/competitions/melbourne-university-seizure-prediction', 'briefDescription': 'Predict seizures in long-term human intracranial EEG recordings ', 'coverImageUrl': None, 'tag': 'healthcare, diseases, auc', 'description': \"Epilepsy afflicts nearly 1% of the world's population, and is characterized by the occurrence of spontaneous seizures. For many patients, anticonvulsant medications can be given at sufficiently high doses to prevent seizures, but patients frequently suffer side effects. For 20-40% of patients with epilepsy, medications are not effective. Even after surgical removal of epilepsy, many patients continue to experience spontaneous seizures. Despite the fact that seizures occur infrequently, patients with epilepsy experience persistent anxiety due to the possibility of a seizure occurring.Seizure forecasting systems have the potential to help patients with epilepsy lead more normal lives. In order for electrical brain activity (EEG) based seizure forecasting systems to work effectively, computational algorithms must reliably identify periods of increased probability of seizure occurrence. If these seizure-permissive brain states can be identified, devices designed to warn patients of impeding seizures would be possible. Patients could avoid potentially dangerous activities like driving or swimming, and medications could be administered only when needed to prevent impending seizures, reducing overall side effects.The CompetitionTransitioning from the Kaggle contests held on seizure detection and seizure prediction in 2014 that primarily involved long-term electrical brain activity recordings from dogs, the current contest focuses on seizure prediction using long-term electrical brain activity recordings from humans obtained from the world-first clinical trial of the implantable NeuroVista Seizure Advisory System.Human brain activity was recorded in the form of intracranial EEG (iEEG), which involves electrodes positioned on the surface of the cerebral cortex and the recording of electrical signals with an ambulatory monitoring system.\\xa0These are long duration recordings, spanning multiple months up to multiple years and recording large numbers of seizures in some humans.\\xa0The challenge is to distinguish between ten minute long data clips covering an hour prior to a seizure, and ten minute iEEG clips of interictal activity.\\xa0Acknowledgments\\xa0This competition is sponsored by MathWorks, the National Institutes of Health (NINDS), the American Epilepsy Society and the University of Melbourne, and organised in partnership with the Alliance for Epilepsy Research, the University of Pennsylvania and the Mayo Clinic.\\xa0\\xa0\\xa0\\xa0\\xa0References\"}, {'title': 'House Prices - Advanced Regression Techniques', 'url': 'https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques', 'briefDescription': 'Predict sales prices and practice feature engineering, RFs, and gradient boosting', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/5407/logos/header.png?t=2021-04-23-18-16-53', 'tag': 'tabular, regression, rmsle', 'description': \"Start here if...You have some experience\\xa0with R or Python and\\xa0machine learning basics. This is a perfect competition for data science students\\xa0who have completed an online course in machine learning and are looking to expand their skill set before trying a featured competition.\\xa0Competition DescriptionAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.Practice SkillsCreative feature engineering\\xa0Advanced regression techniques like random forest and gradient boostingAcknowledgmentsThe Ames Housing\\xa0dataset\\xa0was compiled\\xa0by Dean De Cock for use in data science education. It's an incredible alternative\\xa0for data scientists looking for a modernized and expanded version of the often cited Boston Housing dataset.\\xa0Photo by Tom Thain on Unsplash.\"}, {'title': 'Leaf Classification', 'url': 'https://www.kaggle.com/competitions/leaf-classification', 'briefDescription': 'Can you see the random forest for the leaves?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/5408/logos/header.png', 'tag': 'image, multiclass classification, multiclassloss', 'description': \"There are estimated to be nearly half a million species of plant in the world. Classification of species has been historically problematic and often results in duplicate identifications.The objective of this playground competition is to use binary leaf images and extracted\\xa0features, including shape, margin & texture, to accurately identify 99\\xa0species of plants. Leaves, due to their volume, prevalence, and unique characteristics, are an effective means of differentiating plant species. They also provide a fun introduction to applying techniques that involve image-based features.As a first step, try building a classifier that uses the provided pre-extracted features. Next, try creating a set of your own features. Finally, examine the errors you're making and see what you can do to improve.AcknowledgmentsKaggle is hosting this competition for the data science community to use for fun and education. This dataset originates from leaf images collected by \\xa0James Cope, Thibaut Beghin, Paolo Remagnino, & Sarah Barman of the Royal Botanic Gardens, Kew, UK.Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.We thank the UCI machine learning repository for hosting the dataset.\"}, {'title': 'Bosch Production Line Performance', 'url': 'https://www.kaggle.com/competitions/bosch-production-line-performance', 'briefDescription': 'Reduce manufacturing failures', 'coverImageUrl': None, 'tag': 'tabular, binary classification, manufacturing, matthewscorrelationcoefficient', 'description': \"A good chocolate soufflé is decadent, delicious, and delicate. But, it's a challenge to prepare. When you pull a disappointingly deflated dessert out of the oven, you instinctively retrace your steps to identify at what point you went wrong. Bosch, one of the world's leading manufacturing companies, has an imperative to ensure that the recipes for the production of its advanced mechanical components are of the highest quality and safety standards. Part of doing so is closely monitoring its parts\\xa0as they progress through the manufacturing processes.Because\\xa0Bosch records data at every step along its assembly lines, they have the ability to apply advanced analytics to improve these manufacturing processes. However, the\\xa0intricacies of the data and complexities of the production line pose problems for current methods.In this competition, Bosch is challenging Kagglers to predict internal failures using thousands of measurements and tests made for each component along the assembly line. This would enable Bosch to bring quality products at lower costs to the end user.\"}, {'title': 'Predicting Red Hat Business Value', 'url': 'https://www.kaggle.com/competitions/predicting-red-hat-business-value', 'briefDescription': 'Classify customer potential', 'coverImageUrl': None, 'tag': 'business, tabular, auc', 'description': 'Like most companies, Red Hat is able to gather a great deal of information over time about the behavior of individuals who interact with them. They’re in search of better methods of using this behavioral data to predict which individuals they should approach—and even when and how to approach them.In this competition, Kagglers are challenged to create a classification algorithm that accurately identifies which customers have the most potential business value for Red Hat based on their characteristics and activities.With an improved prediction model in place, Red Hat will be able to more efficiently prioritize resources to generate more business and better serve their customers.'}, {'title': 'TalkingData Mobile User Demographics', 'url': 'https://www.kaggle.com/competitions/talkingdata-mobile-user-demographics', 'briefDescription': 'Get to know millions of mobile device users', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, demographics, mobile and wireless, multiclassloss', 'description': 'Nothing is more comforting than being greeted by your favorite drink just as you walk through the door of the corner café. While a thoughtful barista knows you take a macchiato every Wednesday morning at 8:15, it’s much more difficult in a digital space for your preferred brands to personalize your experience.TalkingData, China’s largest third-party mobile data platform, understands that everyday choices and behaviors paint a picture of who we are and what we value. Currently, TalkingData is seeking to leverage behavioral data from more than 70% of the 500 million mobile devices active daily in China to help its clients better understand and interact with their audiences.In this competition, Kagglers are challenged to build a model predicting users’ demographic characteristics based on their app usage, geolocation, and mobile device properties. Doing so will help millions of developers and brand advertisers around the world pursue\\xa0data-driven marketing efforts which are relevant to their users and catered to their preferences.Acknowledgements'}, {'title': 'Grupo Bimbo Inventory Demand', 'url': 'https://www.kaggle.com/competitions/grupo-bimbo-inventory-demand', 'briefDescription': 'Maximize sales and minimize returns of bakery goods', 'coverImageUrl': None, 'tag': 'tabular, food, rmsle', 'description': 'Planning a celebration is a balancing\\xa0act of preparing just enough food to go around\\xa0without being stuck eating\\xa0the same leftovers for the next week. The key is anticipating how many guests will come. Grupo Bimbo must weigh similar considerations as it strives to meet daily consumer demand for fresh bakery products on the shelves of over 1 million stores along its 45,000 routes across Mexico.Currently, daily inventory calculations are performed by direct delivery sales employees who must single-handedly predict the forces of supply, demand, and hunger based on their personal experiences with each store. With some breads carrying a one week shelf life, the acceptable margin for error is small.In this competition, Grupo Bimbo invites\\xa0Kagglers to develop a model to accurately forecast inventory demand based on historical sales data. Doing so will make sure consumers of its over 100 bakery products aren’t staring at empty shelves, while also reducing the amount spent on refunds to store owners with surplus product unfit for sale.'}, {'title': 'Integer Sequence Learning', 'url': 'https://www.kaggle.com/competitions/integer-sequence-learning', 'briefDescription': '1, 2, 3, 4, 5, 7?!', 'coverImageUrl': None, 'tag': 'tabular, categorizationaccuracy', 'description': \"7. You read that correctly. That's the start to a real integer sequence, the powers of primes. Want something easier? How about the next number in\\xa00, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55? If you answered 89, you may enjoy this challenge. Your computer may find it considerably\\xa0less enjoyable.The On-Line Encyclopedia of Integer Sequences\\xa0is a 50+ year effort by mathematicians the world over to catalog sequences of integers. If it has a pattern, it's probably in the OEIS, and probably described with amazing detail. This competition\\xa0challenges you create a machine learning algorithm capable of guessing\\xa0the next number in an integer sequence. While this sounds like pattern recognition\\xa0in its most basic form, a quick look at the data will\\xa0convince you this is anything\\xa0but\\xa0basic!AcknowledgmentsKaggle is hosting this competition for the data science community to use for fun and education. We thank the OEIS and its contributors for cataloging this data.\"}, {'title': 'Ultrasound Nerve Segmentation', 'url': 'https://www.kaggle.com/competitions/ultrasound-nerve-segmentation', 'briefDescription': 'Identify nerve structures in ultrasound images of the neck', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/5144/logos/header.png?t=2020-10-24-03-08-54', 'tag': 'image, healthcare, dice', 'description': \"Even the bravest patient cringes at the mention of a surgical procedure. Surgery inevitably brings discomfort, and oftentimes involves significant post-surgical\\xa0pain.\\xa0Currently, patient\\xa0pain is frequently managed through the use of narcotics that bring a bevy of unwanted side effects.This competition's sponsor\\xa0is working to improve pain management through the use of indwelling catheters that block or mitigate pain at the source. Pain management catheters reduce dependence on narcotics and speed up patient recovery.Accurately identifying nerve structures in ultrasound images is a critical step in effectively inserting a patient’s pain management catheter. In this competition, Kagglers are challenged to build a model that can identify nerve structures in\\xa0a dataset of ultrasound images of the neck. Doing so would improve catheter placement and contribute to a more pain free future.\\xa0\"}, {'title': 'Facebook V: Predicting Check Ins', 'url': 'https://www.kaggle.com/competitions/facebook-v-predicting-check-ins', 'briefDescription': 'Identify the correct place for check ins', 'coverImageUrl': None, 'tag': 'internet, tabular, multiclass classification, geography, map@{k}', 'description': \"Ever wonder what it's like to work at Facebook?\\xa0Facebook and Kaggle are launching a machine learning engineering competition for 2016. Trail blaze your way to the top of the leaderboard to earn an opportunity at interviewing for one of the 10+ open roles\\xa0as a software engineer, working on world class machine learning problems.The goal of this competition is to predict which place a person would like to check in to. For the purposes of this competition, Facebook created an artificial world consisting of more than 100,000 places located in a 10 km by 10 km square. For a given set of coordinates, your task is to return a ranked list of the most likely places. Data was fabricated to resemble location signals coming from mobile devices, giving you a flavor of what it takes to work with real data complicated by inaccurate and noisy values. Inconsistent and erroneous location data can disrupt experience for services like Facebook Check In.We highly encourage competitors to be active on Kaggle Scripts. Your work there will be thoughtfully included in the decision making process.Please note: You must compete as an individual in recruiting competitions. You may only use the data provided to make your predictions.\"}, {'title': 'Avito Duplicate Ads Detection', 'url': 'https://www.kaggle.com/competitions/avito-duplicate-ads-detection', 'briefDescription': 'Can you detect duplicitous duplicate ads?', 'coverImageUrl': None, 'tag': 'internet, auc', 'description': \"Online marketplaces make\\xa0it a breeze for users to both find and buy unique treasures or unload their dusty record collections in the spirit of spring cleaning. As one of the world's largest and fastest growing online classifieds, Avito\\xa0hosts high volumes of listings and competitive sellers often go to great lengths to get their wares noticed.\\xa0For some sellers,\\xa0this means posting the same ad several times with slightly altered text or photos taken from different angles.\\xa0To ensure that buyers can easily find what they're looking for without sifting through dozens of deceptively identical ads, Avito is asking Kagglers to develop a model that can\\xa0automatically spot duplicate ads.\\xa0With more accurate duplicate\\xa0ad detection, Avito will make it\\xa0much easier for buyers to find and make their next purchase with an honest seller.\"}, {'title': 'Painter by Numbers', 'url': 'https://www.kaggle.com/competitions/painter-by-numbers', 'briefDescription': 'Does every painter leave a fingerprint? ', 'coverImageUrl': None, 'tag': 'image, auc', 'description': \"With an original Picasso carrying a 106 million dollar price tag, identifying an authentic work of art from a forgery is a high-stakes industry. While algorithms have gotten good at telling us if a still life is of a basket of apples or a sunflower bouquet, they aren't yet able to tell us with certainty if both paintings are by van Gogh.\\xa0\\xa0In this\\xa0playground competition, we're challenging Kagglers to examine pairs of paintings and determine if they are by the same artist. This is an excellent opportunity to improve your\\xa0computer vision skills and engage with a unique dataset of art.\\xa0From the movement of brushstrokes to the use of light and dark, successful algorithms will likely incorporate many aspects of a painter's unique style.\\xa0Resourcesneural algorithmHow Do We See Art: An Eye-Tracker StudyAcknowledgmentsMany of the images in this dataset\\xa0were obtained from wikiart.org.\\xa0Additional paintings were provided by artists whose contributions will be acknowledged at the close of the competition.This playground competition and its datasets were prepared by\\xa0Small Yellow Duck (Kiri Nichol). This includes the design of the\\xa0pairwise-evaluation scheme.\"}, {'title': 'Draper Satellite Image Chronology', 'url': 'https://www.kaggle.com/competitions/draper-satellite-image-chronology', 'briefDescription': 'Can you put order to space and time? ', 'coverImageUrl': None, 'tag': 'image, maspearmanr', 'description': 'Imagine a world where we can use satellite images to help find better access to clean water, prevent poaching of wildlife, predict storms more efficiently, optimize traffic patterns more readily, and inform human behaviors to mitigate the spread of disease.Thanks to a marked increase of satellites in orbit, we will be able to capture images – and the information contained within – of nearly every place on Earth, every day by 2017. However, our ability to analyze datasets of these images has not advanced as quickly.\\xa0Changes from day to day in images of the same location are subtle, can be hard to detect, and are difficult to understand in terms of their significance.In this competition, Draper\\xa0provides a unique dataset of\\xa0images taken at the same locations over 5 days.\\xa0Kagglers are challenged to predict the chronological order of the photos taken at each location. Accurately doing so could uncover approaches that\\xa0have a global impact on commerce, science, and humanitarian works.'}, {'title': 'Expedia Hotel Recommendations', 'url': 'https://www.kaggle.com/competitions/expedia-hotel-recommendations', 'briefDescription': 'Which hotel type will an Expedia customer book?', 'coverImageUrl': None, 'tag': 'tabular, recommender systems, hotels and accommodations, map@{k}', 'description': \"Planning your dream vacation, or even a weekend escape, can be an overwhelming affair. With hundreds, even thousands, of hotels to choose from at every destination,\\xa0it's difficult to know which will suit your personal preferences. Should you go with an old standby with those pillow mints you like, or risk a new hotel with a\\xa0trendy pool bar?\\xa0Expedia wants to take the proverbial rabbit hole out of hotel search by providing personalized hotel recommendations to their users. This is no small task for a site with\\xa0hundreds of millions of visitors every month!Currently,\\xa0Expedia uses\\xa0search parameters to adjust their hotel recommendations, but there aren't enough customer specific data to personalize them\\xa0for each\\xa0user. In this competition, Expedia is challenging Kagglers to contextualize customer data and predict the likelihood a user will\\xa0stay at 100 different hotel groups.The data in this competition\\xa0is a random selection from Expedia and is not representative of the overall statistics.\\xa0\"}, {'title': 'Kobe Bryant Shot Selection', 'url': 'https://www.kaggle.com/competitions/kobe-bryant-shot-selection', 'briefDescription': 'Which shots did Kobe sink?', 'coverImageUrl': None, 'tag': 'tabular, binary classification, basketball, logloss', 'description': \"Kobe Bryant marked his retirement from the NBA\\xa0by scoring 60 points in his final game as a Los Angeles Laker on Wednesday, April 12, 2016. Drafted into the NBA at the age of 17, Kobe earned the sport’s highest accolades throughout his long career.Using 20 years of data on Kobe's swishes and misses, can you predict which shots will find the bottom of the net?\\xa0This competition\\xa0is well\\xa0suited\\xa0for practicing classification basics, feature engineering, and time series analysis. Practice got Kobe an eight-figure contract and 5 championship rings. What will it get you?AcknowledgementsKaggle is hosting this competition for the data science community to use for fun and education.\\xa0For more data on Kobe and other NBA greats, visit\\xa0stats.nba.com.\"}, {'title': 'State Farm Distracted Driver Detection', 'url': 'https://www.kaggle.com/competitions/state-farm-distracted-driver-detection', 'briefDescription': 'Can computer vision spot distracted drivers?', 'coverImageUrl': None, 'tag': 'image, automobiles and vehicles, multiclassloss', 'description': \"We've all been there: a light turns green and the car\\xa0in front of you doesn't\\xa0budge. Or, a previously unremarkable vehicle suddenly\\xa0slows\\xa0and starts swerving from side-to-side.When you pass the offending driver, what do you expect to see?\\xa0You certainly aren't\\xa0surprised when you spot a\\xa0driver who is texting, seemingly enraptured by social media, or in a lively hand-held conversation\\xa0on their phone.According to the CDC motor vehicle safety division, one in five car accidents\\xa0is caused by a distracted driver. Sadly, this translates to\\xa0425,000 people injured and 3,000 people killed by distracted driving every year.State Farm\\xa0hopes to improve these alarming statistics, and better insure their customers, by testing whether\\xa0dashboard cameras can\\xa0automatically detect drivers engaging in distracted behaviors.\\xa0Given a dataset of 2D dashboard camera images, State Farm is challenging Kagglers to classify each driver's\\xa0behavior. Are they driving attentively, wearing their\\xa0seatbelt, or taking a selfie with their friends in the backseat?\"}, {'title': 'Shelter Animal Outcomes', 'url': 'https://www.kaggle.com/competitions/shelter-animal-outcomes', 'briefDescription': 'Help improve outcomes for shelter animals', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, animals, multiclassloss', 'description': \"Every year, approximately 7.6 million companion animals end up in US\\xa0shelters. Many animals are\\xa0given up as unwanted by\\xa0their owners, while others are picked up after getting\\xa0lost or taken out\\xa0of cruelty situations. Many of these animals\\xa0find forever families to take them home, but just as many are not so lucky. 2.7 million dogs and cats are euthanized in the US every year.Using a dataset of intake information including breed, color, sex, and age from the Austin Animal Center, we're asking Kagglers to predict the outcome for each animal.We also believe this dataset can help us understand trends in animal outcomes. These insights\\xa0could help shelters focus their energy on specific animals who need a little extra help finding a\\xa0new home. We encourage you to publish your insights on Scripts\\xa0so they are publicly accessible.AcknowledgementsKaggle is hosting this competition for the machine learning community to use for data science practice and social good. The\\xa0dataset is brought to you by Austin Animal Center. Shelter animal statistics were taken from the ASPCA.Glamour shots of Kaggle's\\xa0shelter pets are pictured above. From left to right: Shelby, Bailey, Hazel, Daisy, and Yeti.\"}, {'title': 'Santander Customer Satisfaction', 'url': 'https://www.kaggle.com/competitions/santander-customer-satisfaction', 'briefDescription': 'Which customers are happy customers?', 'coverImageUrl': None, 'tag': 'tabular, binary classification, banking, auc', 'description': \"From frontline support\\xa0teams to C-suites, customer satisfaction is a key measure of success. Unhappy customers don't stick around. What's more,\\xa0unhappy customers rarely voice their dissatisfaction\\xa0before leaving.Santander\\xa0Bank\\xa0is asking Kagglers to help them identify dissatisfied\\xa0customers early in their relationship. Doing so would allow Santander to take proactive steps to improve a\\xa0customer's happiness before it's too late.In this competition, you'll work\\xa0with hundreds of anonymized features to predict if a customer is satisfied or dissatisfied with their banking experience.\"}, {'title': 'March Machine Learning Mania 2016', 'url': 'https://www.kaggle.com/competitions/march-machine-learning-mania-2016', 'briefDescription': 'Predict the 2016 NCAA Basketball Tournament', 'coverImageUrl': None, 'tag': 'tabular, sports, basketball, logloss', 'description': \"Update: although\\xa0the tournament is over, we're continuing our\\xa0analysis under the predictions dataset page.Back for its third year, March Machine Learning Mania challenges data scientists to predict winners and losers of the men's 2016 NCAA basketball tournament. You're provided\\xa0data covering three decades of historical NCAA games\\xa0and\\xa0freely\\xa0encouraged to use other sources of\\xa0data to gain a winning\\xa0edge.In stage one of this two-stage competition, participants will build and test their models against the previous four tournaments. In the second stage, participants will predict the outcome of the 2016 tournament. You don’t need to participate in the first stage to enter the second. The first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2016 results.AcknowledgmentsSAP is the presenting sponsor of March Machine Learning Mania 2016. Please see About the Sponsor\\xa0to read more.\"}, {'title': 'BNP Paribas Cardif Claims Management', 'url': 'https://www.kaggle.com/competitions/bnp-paribas-cardif-claims-management', 'briefDescription': \"Can you accelerate BNP Paribas Cardif's claims management process?\", 'coverImageUrl': None, 'tag': 'tabular, binary classification, banking, logloss', 'description': 'As a global specialist in personal insurance, BNP Paribas Cardif\\xa0serves 90 million clients in 36 countries across Europe, Asia and Latin America.In a world shaped by the emergence of new uses and lifestyles, everything is going faster and faster. When facing unexpected events, customers expect their insurer to support them as soon as possible. However, claims management may require different levels of check before a claim can be approved and a payment can be made. With the new practices and behaviors generated by the digital economy, this process needs adaptation thanks to data science\\xa0to\\xa0meet the new needs and expectations of customers.In this challenge, BNP Paribas Cardif is providing an anonymized database with two categories of claims:Kagglers are challenged to predict the category of a claim based on features available early in the process, helping BNP Paribas Cardif accelerate its claims process and therefore provide a better service to its customers.'}, {'title': 'Home Depot Product Search Relevance', 'url': 'https://www.kaggle.com/competitions/home-depot-product-search-relevance', 'briefDescription': 'Predict the relevance of search results on homedepot.com', 'coverImageUrl': None, 'tag': 'tabular, rmse', 'description': \"Shoppers rely on Home Depot’s product authority to find and buy the latest products and to get timely solutions to their home improvement needs. From installing a new ceiling fan to remodeling an entire kitchen, with the click of a mouse or tap of the screen, customers expect the correct results to their queries – quickly. Speed, accuracy and delivering a frictionless customer experience are essential.In this competition, Home Depot is asking Kagglers to help them improve their\\xa0customers' shopping experience by developing a model that can accurately predict the relevance of search results.Search relevancy is an implicit measure Home Depot uses to gauge how quickly they can get customers to the right products. Currently, human raters evaluate the impact of potential changes to their search algorithms, which is a slow and subjective process. By removing or minimizing human input in search relevance evaluation, Home Depot hopes to increase the number of iterations their team can perform on the current search algorithms.\"}, {'title': 'Yelp Restaurant Photo Classification', 'url': 'https://www.kaggle.com/competitions/yelp-restaurant-photo-classification', 'briefDescription': 'Predict attribute labels for restaurants using user-submitted photos', 'coverImageUrl': None, 'tag': 'internet, image, food, meanfscore', 'description': \"Does your favorite Ethiopian restaurant\\xa0take reservations? Will a\\xa0first date at that authentic\\xa0looking bistro break your wallet?\\xa0Is the\\xa0diner down the street a good call for breakfast?\\xa0Restaurant\\xa0labels\\xa0help Yelp users quickly answer questions like these, narrowing down their results to only restaurants\\xa0that fit their nuanced needs.In this competition, Yelp is challenging Kagglers to build a model that automatically tags restaurants with multiple labels\\xa0using\\xa0a dataset of user-submitted photos. Currently, restaurant labels are manually selected\\xa0by Yelp users\\xa0when they submit a review. Selecting the labels is optional, leaving some restaurants un- or only partially-categorized.\\xa0In an age of food selfies and photo-centric social storytelling, it may be no surprise to hear that\\xa0Yelp's users\\xa0upload an enormous amount\\xa0of photos every day alongside their written reviews. Can you turn their pictures into (less than a thousand) words?Yelp isn’t only looking for your best model; we’re looking for data mining engineers that can help us use our data in novel ways while pushing code to production. The prize for this competition is a fast track through the\\xa0recruiting process and an opportunity to show our data mining teams just what you’ve got!\\xa0For more information about exciting opportunities at Yelp, check out the Jobs at Yelp\\xa0competition page and Yelp's own\\xa0careers page.\"}, {'title': 'Second Annual Data Science Bowl', 'url': 'https://www.kaggle.com/competitions/second-annual-data-science-bowl', 'briefDescription': 'Transforming How We Diagnose Heart Disease', 'coverImageUrl': None, 'tag': 'image, healthcare, crps', 'description': \"We all have a heart. Although we often take it for granted, it's our heart that gives us the moments in life to imagine, create, and discover. Yet cardiovascular disease threatens to take away these moments. Each day, 1,500 people in the U.S. alone are diagnosed with heart failure—but together, we can help. We can use data science to transform how we diagnose heart disease. By putting data science to work in the cardiology field, we can empower doctors to help more people live longer lives and spend more time with those that they love.Declining cardiac function is a key indicator of heart disease. Doctors determine cardiac function by measuring end-systolic and end-diastolic volumes (i.e., the size of one chamber of the heart at the beginning and middle of each heartbeat), which are then used to derive the\\xa0ejection fraction (EF). EF is the percentage of blood ejected from the left ventricle with each heartbeat. Both the volumes and the ejection fraction are predictive of heart disease. While a number of technologies can measure volumes or EF, Magnetic Resonance Imaging (MRI) is considered the gold standard test to accurately assess the heart's squeezing ability.The challenge with using MRI to measure cardiac volumes and derive ejection fraction, however, is that the process is manual and slow. A skilled cardiologist must analyze MRI scans to determine EF. The process can take up to 20 minutes to complete—time the cardiologist could be spending with his or her patients. Making this measurement process more efficient will enhance doctors' ability to diagnose heart conditions early, and carries broad implications for advancing the science of heart disease treatment.The 2015 Data Science Bowl challenges you to create an algorithm to automatically measure end-systolic and end-diastolic volumes in cardiac MRIs. You will examine MRI images from more than 1,000 patients. This data set was compiled by the National Institutes of Health and Children's National Medical Center and is an order of magnitude larger than any cardiac MRI data set released previously. With it comes the opportunity for the data science community to take action to transform how we diagnose heart disease.This is not an easy task, but together we can push the limits of what's possible. We can give people the opportunity to spend more time with the ones they love, for longer than ever before.AcknowledgmentsThe Data Science Bowl is presented by:The National Heart, Lung, and Blood Institute (NHLBI) provided the MRI images for this competition. Special thanks to NHLBI Intramural Investigators Dr. Michael Hansen and Dr. Andrew Arai.Additional support for the Data Science Bowl was provided by NVIDIA:\"}, {'title': 'Cervical Cancer Screening', 'url': 'https://www.kaggle.com/competitions/cervical-cancer-screening', 'briefDescription': 'Help prevent cervical cancer by identifying at-risk populations', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/4494/logos/header.png?t=2020-12-21-22-34-54', 'tag': 'auc', 'description': 'This is a Masters competition. You must be a Kaggle Master\\xa0to participate.Cervical cancer is the third most common cancer in women worldwide, affecting over 500,000 women and resulting in approximately 275,000 deaths every year. After reading\\xa0these statistics, you may be surprised to hear that cervical cancer is potentially\\xa0preventable and curable.Cervical cancer can be prevented through early\\xa0administration of the HPV vaccine\\xa0and regular pap smear\\xa0screenings, which indicate the presence of\\xa0precancerous cells. It is also sometimes\\xa0curable by\\xa0the removal of the early-stage cancerous tissue that is\\xa0identified through pap smears. Screening and early treatment can lead to potential cures in about\\xa095% of women at risk for cervical cancer.Most women in the US have access to cervical cancer screening, yet 4,000 women die every year from cervical cancer in the US and it is estimated that 30% of US women do not receive regular pap screenings. We know little about who these women are and why they are not getting screened. Prior research suggests that lower screening rates are associated with low income, low education, lack of interaction with the healthcare system, and lack of\\xa0health insurance.\\xa0But research also shows that even in women with access to healthcare fail to get this preventive test, indicating that barriers like lack of education and not being comfortable with the procedure are influencing their behavior (Patient Survey).\\xa0There are many\\xa0patient advocacy\\xa0programs on the importance of pap smears in cervical cancer prevention. However, these widespread programs may not be reaching or effectively speaking to the most vulnerable populations. If one\\xa0could better identify these women, education campaigns could target them with content that speaks directly to their unique risk factors.\\xa0Identifying predictors of not receiving pap smears will provide important information to stakeholders in cervical cancer prevention who run awareness programs.With this Masters competition, Genentech is asking you to join their mission to help prevent\\xa0cervical cancer. Given\\xa0a dataset of de-identified health records, your challenge is to predict which women will not be screened for cervical cancer\\xa0on the recommended schedule. Identifying at-risk populations will make education and other intervention efforts more effective, ideally ultimately reducing the number of women who die from this disease.About GenentechFounded more than 35 years ago, Genentech is a leading biotechnology company that discovers, develops, manufactures and commercializes medicines to treat patients with serious or life-threatening medical conditions. The company, a member of the Roche Group, has headquarters in South San Francisco, California. For additional information about the company, please visit http://www.gene.com.AcknowledgementsThe dataset for this competition is provided by Symphony Health Solutions.\\xa0@Jotform.Show(35)'}, {'title': \"Santa's Stolen Sleigh\", 'url': 'https://www.kaggle.com/competitions/santas-stolen-sleigh', 'briefDescription': \"♫ Alarm\\xa0bells ring, are you listening?\\xa0Santa's sleigh has gone\\xa0missing\\xa0♫\", 'coverImageUrl': None, 'tag': 'tabular, custom metric', 'description': \"Fork this script and get started on the problemThe North Pole\\xa0is in an uproar over\\xa0news that Santa's magic sleigh has been stolen. Able to carry all the world's\\xa0presents in one trip, it was\\xa0considered crucial to successfully delivering holiday goodies across the globe\\xa0in one night.Unwilling to cancel\\xa0Christmas,\\xa0Santa is determined to deliver toys to all the good girls and boys using his\\xa0day-to-day, magic-less sleigh. With so little time to pull off this\\xa0plan, Santa is once again counting on Kagglers to\\xa0help.Given the sleigh's antiquated, weight-limited specifications, your challenge is to\\xa0optimize the routes and loads\\xa0Santa will take to and from the North Pole. And don't forget about Dasher, Dancer, Prancer, and Vixen; Santa is adamant that the best solutions will minimize the toll of this hectic night on his reindeer\\xa0friends.AcknowledgementsThis competition is brought to you by FICO.\"}, {'title': 'Airbnb New User Bookings', 'url': 'https://www.kaggle.com/competitions/airbnb-recruiting-new-user-bookings', 'briefDescription': 'Where will a new guest book their first travel experience?', 'coverImageUrl': None, 'tag': 'tabular, recommender systems, hotels and accommodations, ndcg@{k}', 'description': 'Instead of waking to overlooked\\xa0\"Do not disturb\" signs, Airbnb\\xa0travelers find themselves rising with the birds in a\\xa0whimsical treehouse, having their morning coffee on the deck of a houseboat,\\xa0or cooking a shared regional breakfast with their hosts.New users on Airbnb can book a place to stay in 34,000+ cities across 190+ countries. By accurately predicting\\xa0where\\xa0a new user will book their first travel experience, Airbnb can share more personalized content with their community, decrease the average time to first booking,\\xa0and better forecast demand.In this recruiting competition, Airbnb challenges you to predict in which country a new user will make his or her first booking. Kagglers who impress with their answer (and an explanation of how they got there) will be considered for an interview for the opportunity to join Airbnb\\'s Data Science and Analytics team.Wondering if you\\'re a good fit?\\xa0Check out this article\\xa0on how Airbnb scaled data science to all sides of their\\xa0organization, and visit their\\xa0careers page\\xa0for more on Airbnb\\'s\\xa0mission to create a world that inspires human connection.'}, {'title': 'Telstra Network Disruptions', 'url': 'https://www.kaggle.com/competitions/telstra-recruiting-network', 'briefDescription': \"Predict service faults on Australia's largest telecommunications network \", 'coverImageUrl': None, 'tag': 'internet, tabular, multiclass classification, multiclassloss', 'description': \"In their first recruiting competition, Telstra\\xa0is\\xa0challenging\\xa0Kagglers to predict the severity of service disruptions\\xa0on their network. Using a dataset of features from their service logs, you're tasked\\xa0with predicting if a disruption is a momentary glitch or a total interruption of connectivity.Telstra is on a journey to enhance the customer experience - ensuring everyone in the company is putting customers first. In terms of its expansive network, this means continuously advancing how it predicts the scope and timing of service disruptions. Telstra wants to see how you would help it drive customer advocacy by developing a more advanced predictive model for service disruptions and to help it better serve its customers.This challenge\\xa0was crafted as a simulation of the type of problem\\xa0you might tackle\\xa0as a member of the team at\\xa0Telstra.Kagglers who stand out will be considered for data science roles in Telstra's Big Data team in Telstra’s absolute discretion. Highly-ranked participants will combine technical expertise and intuition in data science problems with a keen business sense and an effortless ability to work with technical and non-technical staff to turn data into real changes that impact customers. Highly-ranked participants will be considered by Telstra for interviews for employment, based on their work in the Competition and ability to meet the selection criteria for any suitable open job vacancy in Melbourne and Sydney, Australia.\\xa0Participation in this Competition is not a recruitment process and Kaggle does not provide Telstra with recruitment services.\"}, {'title': 'Prudential Life Insurance Assessment', 'url': 'https://www.kaggle.com/competitions/prudential-life-insurance-assessment', 'briefDescription': 'Can you make buying life insurance easier?', 'coverImageUrl': None, 'tag': 'tabular, quadraticweightedkappa', 'description': \"Picture this. You are a data scientist in a start-up culture with the potential to have a very large impact on the business. Oh, and you are backed up by a company with 140 years' business experience.Curious? Great! You are the kind of person we are looking for.Prudential, one of the largest issuers\\xa0of life insurance in the USA, is hiring passionate data scientists to join a newly-formed Data Science group solving complex challenges and identifying opportunities. The results have been impressive so far but we want more.\\xa0The ChallengeIn a one-click shopping world with on-demand everything, the life insurance application process is antiquated. Customers provide extensive information to identify risk classification and eligibility, including scheduling medical exams, a process that takes an average of 30 days.The result? People are turned off. That’s why only 40% of U.S. households own individual life insurance.\\xa0Prudential wants to make it quicker and less labor intensive for new and existing customers to get a quote while maintaining privacy boundaries.By developing a predictive model that accurately classifies risk using a more automated approach, you can greatly impact public perception of the industry.The results will help Prudential better understand the predictive power of the data points in the existing assessment, enabling us to significantly streamline the process.\"}, {'title': 'Homesite Quote Conversion', 'url': 'https://www.kaggle.com/competitions/homesite-quote-conversion', 'briefDescription': 'Which customers will purchase a quoted insurance plan?', 'coverImageUrl': None, 'tag': 'tabular, binary classification, auc', 'description': \"Before\\xa0asking someone on a date or skydiving, it's important to know your likelihood of success. The same goes for quoting home insurance prices to a potential customer. Homesite,\\xa0a leading provider of homeowners insurance, does not currently\\xa0have a dynamic\\xa0conversion rate model that can give them confidence a quoted price will lead to a purchase.\\xa0Using an anonymized database of information on customer and sales activity, including property and coverage information, Homesite is challenging you\\xa0to predict which\\xa0customers will purchase a given quote.\\xa0Accurately predicting conversion\\xa0would help Homesite better understand the impact of proposed pricing changes and maintain an ideal portfolio of customer segments.\\xa0\"}, {'title': 'The Winton Stock Market Challenge', 'url': 'https://www.kaggle.com/competitions/the-winton-stock-market-challenge', 'briefDescription': 'Join a multi-disciplinary team of research scientists', 'coverImageUrl': None, 'tag': 'tabular, finance, wmae', 'description': \"Do you laugh (and then get down to work) in the face of\\xa0terabytes of noisy, non-stationary data? Winton Capital is looking for data scientists\\xa0who excel at finding the hidden signal in the proverbial haystack, and who are excited\\xa0by creating\\xa0novel statistical modelling and data mining techniques.\\xa0In this recruiting competition, Winton challenges you to take on the very difficult\\xa0task of predicting the future (stock returns). Given historical stock performance and a host of\\xa0masked features, can you predict\\xa0intra and end of day returns without being deceived by all the noise?\\xa0Research\\xa0scientists at Winton have crafted this competition to be\\xa0challenging and fun for the community while providing a taste of the types of problems they work on everyday. They're excited to connect with Kagglers who bring a\\xa0unique background and\\xa0creative approach to\\xa0the\\xa0competition.Winton is offering cash prizes to winning teams as a reward for their work, but the intent of the competition is not commercial. The intellectual property you create remains your own and will be evaluated in the context of suitability for employment.\\xa0For more on the culture at Winton, check out the About Winton\\xa0page or their\\xa0careers page.\"}, {'title': 'Walmart Recruiting: Trip Type Classification', 'url': 'https://www.kaggle.com/competitions/walmart-recruiting-trip-type-classification', 'briefDescription': 'Use market basket analysis to classify shopping trips', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, multiclassloss', 'description': 'Walmart uses both art and science to continually make progress on their core mission of better understanding and serving their customers. One way Walmart is able to improve customers\\' shopping experiences is by segmenting their store visits into different trip types.\\xa0Whether they\\'re on a last minute run for new puppy supplies or leisurely making their way through a weekly grocery list, classifying trip types\\xa0enables Walmart to create the best shopping experience for every customer.Currently, Walmart\\'s trip types are created from\\xa0a combination of existing customer insights (\"art\") and purchase history\\xa0data (\"science\").\\xa0In their third recruiting competition, Walmart\\xa0is challenging Kagglers to focus on the (data) science and classify\\xa0customer trips using only a transactional dataset\\xa0of the items they\\'ve purchased. Improving the science behind trip type\\xa0classification will help Walmart refine their segmentation process.Walmart\\xa0is hosting this competition to connect with data scientists who break the mold.'}, {'title': 'The Allen AI Science Challenge', 'url': 'https://www.kaggle.com/competitions/the-allen-ai-science-challenge', 'briefDescription': 'Is your model smarter than an 8th grader?', 'coverImageUrl': None, 'tag': 'tabular, text, multiclass classification, artificial intelligence, categorizationaccuracy', 'description': 'The\\xa0Allen Institute for Artificial Intelligence (AI2)\\xa0is working to improve\\xa0humanity through fundamental advances in artificial intelligence.\\xa0One critical\\xa0but challenging problem in\\xa0AI\\xa0is to demonstrate the ability to consistently\\xa0understand and correctly answer general questions about the world.\\xa0The\\xa0Aristo project\\xa0at AI2 is focused on building such a system. One way Aristo \"learns\" is by extracting facts from various sources and processing them into a structured knowledge base. When taking an exam, questions are parsed and processed along with any accompanying diagrams to determine a strategy for answering. Aristo then uses\\xa0entailment, statistical analysis, and inference methods to\\xa0select a final answer.While Aristo\\'s abilities have improved significantly\\xa0in the last two years, it\\xa0still doesn\\'t have\\xa0perfect, reliable methods of gathering knowledge, understanding questions, or reasoning through answers.Using a dataset of multiple choice question and answers from a standardized 8th grade science exam, AI2 is challenging\\xa0you to\\xa0create a model that\\xa0gets to the head of the class.'}, {'title': 'Rossmann Store Sales', 'url': 'https://www.kaggle.com/competitions/rossmann-store-sales', 'briefDescription': 'Forecast sales using store, promotion, and competitor data', 'coverImageUrl': None, 'tag': 'tabular, time series analysis, rootmeansquarepercentageerror', 'description': 'Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to\\xa0six weeks in advance. Store sales are influenced by many factors, including\\xa0promotions, competition, school and state holidays, seasonality, and locality. With\\xa0thousands of individual managers predicting sales based on their unique circumstances,\\xa0the accuracy of results can be quite varied.'}, {'title': 'How Much Did It Rain? II', 'url': 'https://www.kaggle.com/competitions/how-much-did-it-rain-ii', 'briefDescription': 'Predict hourly rainfall using data from polarimetric radars', 'coverImageUrl': None, 'tag': 'tabular, regression, mae', 'description': 'After incorporating\\xa0feedback from the Kaggle community, as well as scientific and educational partners, the\\xa0Artificial Intelligence Committee of the American Meteorological Society\\xa0is\\xa0excited to be running a second\\xa0iteration of the How Much Did It Rain?\\xa0competition.How Much Did It Rain? II is focused on solving the same core rain measurement prediction problem, but approaches it with a new and improved dataset and evaluation metric. This competition will go even further towards building a\\xa0useful educational tool for universities, as well as making a meaningful contribution to continued meteorological research.Competition\\xa0DescriptionRainfall is highly variable across space and time, making it notoriously tricky to measure. Rain gauges can be an\\xa0effective measurement tool for a specific location, but it is impossible to have them everywhere. In order to have widespread coverage, data from weather radars is\\xa0used to estimate rainfall nationwide.\\xa0Unfortunately, these predictions never exactly match the measurements taken\\xa0using rain gauges.Recently, in an effort to improve their rainfall predictors, the U.S. National Weather Service upgraded their radar network to be polarimetric. These polarimetric radars are able to provide higher quality\\xa0data than conventional Doppler radars\\xa0because they\\xa0transmit radio wave pulses with both horizontal and vertical orientations.\\xa0Dual pulses make it easier to infer the size and type of precipitation because rain drops become flatter as they increase in size,\\xa0whereas\\xa0ice crystals tend to be elongated vertically.In this competition, you are given snapshots of polarimetric radar values and asked to predict the hourly rain gauge total. A word of caution:\\xa0many of the gauge values in the training dataset are implausible (gauges may get clogged, for example). More details are on the data page.AcknowledgementsThis competition is sponsored by the Artificial Intelligence Committee\\xa0of the American Meteorological Society.\\xa0Climate Corporation\\xa0is providing\\xa0the prize pool.'}, {'title': \"What's Cooking?\", 'url': 'https://www.kaggle.com/competitions/whats-cooking', 'briefDescription': 'Use recipe ingredients to categorize the cuisine', 'coverImageUrl': None, 'tag': 'text, food, multiclass classification, categorizationaccuracy', 'description': \"Picture yourself strolling\\xa0through your local, open-air market...\\xa0What do you see? What do you smell? What will you make for dinner tonight?If you're in Northern California, you'll be\\xa0walking past the inevitable\\xa0bushels of leafy greens, spiked with dark purple kale\\xa0and the bright pinks and yellows of chard. Across the world in South Korea, mounds of bright red kimchi greet you, while the smell of the sea draws your attention to squids squirming nearby. India’s market is perhaps the most colorful, awash in the rich hues and aromas of dozens of spices: turmeric, star anise, poppy seeds, and garam masala as far as the eye can see.Some of our strongest geographic and cultural associations are tied to a\\xa0region's local foods. This playground competitions\\xa0asks you to predict the category of a dish's cuisine given a\\xa0list of its ingredients.\\xa0AcknowledgementsWe\\xa0want to thank Yummly\\xa0for\\xa0providing this unique dataset. Kaggle is hosting this playground competition for fun and practice.\"}, {'title': 'Right Whale Recognition', 'url': 'https://www.kaggle.com/competitions/noaa-right-whale-recognition', 'briefDescription': 'Identify endangered right whales in aerial photographs ', 'coverImageUrl': None, 'tag': 'image, animals, water bodies, multiclassloss', 'description': \"With fewer\\xa0than 500 North Atlantic right whales left in the world's oceans, knowing the health and status of each\\xa0whale is integral to\\xa0the efforts of researchers working to protect\\xa0the species from extinction.Currently, only a handful of very experienced researchers can\\xa0identify individual whales on sight while out on the water. For the majority of researchers, identifying individual whales takes time, making it difficult to effectively\\xa0target whales for biological samples, acoustic recordings, and necessary health assessments.To track and monitor the population, right whales are photographed during aerial surveys and then manually matched to an\\xa0online photo-identification catalog. Customized software has been developed to aid in this process (DIGITS), but this still relies on a manual inspection of the potential comparisons, and there is a lag time for those images to be incorporated into the database. The current identification process is extremely time consuming and requires special training. This\\xa0constrains\\xa0marine biologists, who work under tight deadlines with\\xa0limited budgets.This competition challenges you to automate the right whale recognition process using a dataset of aerial photographs of individual whales.\\xa0Automating the identification of right whales would\\xa0allow researchers to better focus on their\\xa0conservation efforts.\\xa0Recognizing a whale in real-time would also give researchers on the water access to potentially life-saving historical health and entanglement records as they struggle to free a whale that has been accidentally caught up in fishing gear.AcknowledgementsMathWorks\\xa0is sponsoring the competition prize pool. If your team is participating in this competition MathWorks is also providing complimentary\\xa0software.\\xa0Click here for more details on how to request your copy.Thanks to Christin Khan and Leah Crowe from NOAA\\xa0for hand labeling the images to create this one of a kind dataset and to the right whale research team at New England Aquarium\\xa0for maintaining the photo-identification catalog. Without their continued efforts, none of this would be possible.\\xa0\"}, {'title': 'Western Australia Rental Prices ', 'url': 'https://www.kaggle.com/competitions/deloitte-western-australia-rental-prices', 'briefDescription': 'Predict rental prices for properties across Western Australia', 'coverImageUrl': None, 'tag': 'rmsle', 'description': \"This is a Masters competition. You must be a Kaggle Master\\xa0to participate.Property\\xa0rental prices are a\\xa0key economic indicator, often signaling\\xa0significant changes in things like unemployment rate or\\xa0income. Accurately predicting rental prices\\xa0would help organizations offering public and commercial services with the ability to better plan for and price these services.Weekly rental values for properties vary due to a\\xa0broad mix of factors. Some measures are objective, like proximity to hospitals, schools, transport, and coastline. Others are more\\xa0subjective, like the aesthetic value\\xa0of your backyard garden.The rental market in Western Australia is unusually\\xa0diverse\\xa0and difficult\\xa0to predict\\xa0due to the region's varied landscape and small,\\xa0widely spread population.Currently, automated valuation models are used for over 90% of residential property estimates in Western Australia. Using data on location, property, zoning, past sales, and more, the\\xa0goal of this competition is to improve on existing models by\\xa0accurately estimating the weekly market rental value for residential properties across\\xa0Western Australia.@JotForm.Show(34)\"}, {'title': 'Springleaf Marketing Response', 'url': 'https://www.kaggle.com/competitions/springleaf-marketing-response', 'briefDescription': 'Determine whether to send a direct mail piece to a customer ', 'coverImageUrl': None, 'tag': 'tabular, binary classification, marketing, auc', 'description': \"Springleaf\\xa0puts\\xa0the humanity back into lending by offering their customers personal and auto loans that help them take control of their lives and their finances. Direct mail is one important way Springleaf's team can connect with customers whom may be in need of a loan.Direct offers provide huge value to customers who need them, and are a fundamental\\xa0part\\xa0of Springleaf's marketing strategy. In order to improve their targeted\\xa0efforts,\\xa0Springleaf must be sure they\\xa0are focusing on the customers who are likely to respond and be good candidates for their services.Using a large set\\xa0of anonymized features, Springleaf is asking you\\xa0to predict which customers will respond to a direct mail offer. You\\xa0are\\xa0challenged to construct new meta-variables and employ\\xa0feature-selection methods to approach this dauntingly wide dataset.\"}, {'title': 'Truly Native? ', 'url': 'https://www.kaggle.com/competitions/dato-native', 'briefDescription': 'Predict which web pages served by StumbleUpon are sponsored', 'coverImageUrl': None, 'tag': 'tabular, binary classification, marketing, auc', 'description': 'Online media companies rely more and more on paid advertising to keep their lights on and their content engines humming. \"Native advertising\" is a popular alternative to the unsightly banner ads and infuriating pop-ups of Internet Advertising 1.0.\\xa0Native ads mimic the core\\xa0content of the site they\\'re advertising on, ideally avoiding any interruption of\\xa0the\\xa0user\\'s experience.When native advertising is done right, users aren\\'t desperately scanning an ad for a hidden \"x\". In fact,\\xa0they don\\'t even know they\\'re viewing one.\\xa0To pull this off, native ads need to be just as\\xa0interesting, fun, and informative as the unpaid content on a\\xa0site.Dato\\xa0is sponsoring this competition with the noble goal of making native advertising live up to its name.\\xa0With a dataset of over 300,000 raw HTML files containing text, links, and downloadable images, they\\xa0also want to give Kagglers a challenge\\xa0that encourages creativity. Given the HTML of websites\\xa0served to users of\\xa0StumbleUpon, your challenge is to identify the\\xa0paid content disguised as just another internet gem\\xa0you\\'ve stumbled upon.If media companies can\\xa0better\\xa0identify poorly designed native ads, they can keep them off your feed and out of your user experience.\\xa0For details on using GraphLab Create for the competition, check out Dato\\'s post.Acknowledgements\\xa0\\xa0The dataset for this competition was generously provided by StumbleUpon.'}, {'title': 'Flavours of Physics: Finding τ  →  μμμ', 'url': 'https://www.kaggle.com/competitions/flavours-of-physics', 'briefDescription': 'Identify a rare decay phenomenon', 'coverImageUrl': None, 'tag': 'tabular, binary classification, physics, custom metric', 'description': 'Like last year\\'s\\xa0Higgs Boson Machine Learning Challenge,\\xa0this competition\\xa0deals with the \\xa0physics at the Large Hadron Collider (LHC).\\xa0However, the subject of last year\\'s challenge, the\\xa0Higgs Boson, was already known to exist. The aim of this year\\'s challenge is to find a phenomenon that is not already known to exist – charged lepton flavour violation – thereby helping to establish \"new physics\".\\xa0Flavours of Physics 101The laws of nature ensure that some physical quantities, such as energy or momentum, are conserved. From Noether’s theorem, we know that each conservation law is associated with a fundamental symmetry. For example, conservation of energy is due to the time-invariance (the outcome of an experiment would be the same today or tomorrow) of physical systems. The fact that physical systems behave the same, regardless of where they are located or how they are oriented, gives rise to the conservation of linear and angular momentum.Symmetries are also crucial to the structure of the Standard Model\\xa0of particle physics, our present theory of interactions at microscopic scales. Some are built into the model, while others appear accidentally from it. In the Standard Model, lepton flavour, the number of electrons and electron-neutrinos, muons and muon-neutrinos, and tau and tau-neutrinos, is one such conserved quantity.Interestingly, in many proposed extensions to the Standard Model, this symmetry doesn’t exist, implying decays that do not conserve lepton flavour are possible. One decay searched for at the LHC is τ → μμμ (or τ → 3μ). Observation of this decay would be a clear indication of the violation of lepton flavour and a sign of long-sought new physics.Competition DesignYou will be working with\\xa0real data from the LHCb experiment\\xa0at the LHC, mixed with simulated datasets of the decay. The metric used\\xa0in this challenge includes checks that physicists do in their analysis to make sure the\\xa0results are unbiased. These\\xa0checks have been built into the\\xa0competition design to help ensure that\\xa0the results will be useful for physicists in\\xa0future studies.\\xa0To get started, review the\\xa0Data Page, and be sure to download\\xa0the Starter Kit. The Starter Kit\\xa0will help you to get used to the unique submission procedure for this competition.Competition Video TutorialYou\\'ve got lots of questions.\\xa0Researchers at CERN & LCHb have the answers. - What is the goal of this competition? (1:56) - Why is finding τ → μμμ exciting? (2:18) - What are flavours? (4:10) - Why use machine learning to find τ → μμμ? (4:57) - How did you decide on the size of the dataset? (5:31) - Why is weighted AUC the evaluation metric? (6:09) - Why use Ds → φπ data for the Agreement Test? (7:53) - Why do we need a Correlation Check? (8:44) - How will the competition results impact what you do? (11:38) - How will the competition results be used at CERN? (12:17)ResourcesFlavour of Physics, Research DocumentationRoel Aaij et al., Search for the lepton flavour violating decay τ → µµµ, 2015, JHEP, 1502:121, 2015New approaches for boosting to uniformityAcknowledgementsThis competition is brought to you by:\\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0Co-sponsored by:Additional support from:\\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0 \\xa0\\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0'}, {'title': 'Coupon Purchase Prediction', 'url': 'https://www.kaggle.com/competitions/coupon-purchase-prediction', 'briefDescription': 'Predict which coupons a customer will buy', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, marketing, map@{k}', 'description': \"Recruit\\xa0Ponpare\\xa0is Japan's leading joint\\xa0coupon site, offering huge discounts on\\xa0everything from hot yoga, to gourmet sushi, to a summer concert bonanza. Ponpare's coupons open doors for customers they've only dreamed of stepping through. They can learn difficult to acquire\\xa0skills, go on unheard of adventures, and dine like (and with) the stars.Investing in a new experience is not cheap. We fear wasting our time and money on a product or service that we may not enjoy or fully understand. Ponpare takes the high price out of this equation, making it easier for you to take the leap towards your first sky-dive or\\xa0diamond engagement ring.Using past purchase and browsing behavior, this competition asks you to predict which coupons a customer will buy in a given period of time. The resulting models will be used to improve Ponpare's recommendation system, so they can make sure their customers don't miss out on their next favorite thing.\"}, {'title': 'Introducing Kaggle Scripts', 'url': 'https://www.kaggle.com/competitions/introducing-kaggle-scripts', 'briefDescription': 'Your code deserves better', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"Kaggle is first and foremost a community.\\xa0If you're here to learn, it is from the community. If you're here to compete, it's against the community. If you're here to share, it's with our\\xa0community. Continuing the theme, we've just launched a product called Scripts.The\\xa0concept\\xa0is simple: we'll host, version, & run your code for you.Why?\\xa0The community does a tremendous amount of data science tinkering each day on Kaggle. The fruits of this labor are too often lost on old drives, never checked into version control, never shared, never critiqued, never reproduced, never visualized, never assimilated into a\\xa0broader\\xa0knowledge. Scripts is not a better\\xa0IDE or better database or new language. It is the beginning of communal input, collaboration, and useful workflow features for\\xa0the data science that's done on Kaggle.You don't need a full tutorial to learn how to use scripts (it has one button and\\xa0runs code).\\xa0In lieu\\xa0of yet another iris dataset tutorial, we invite you to kick the tires and try it out. Punish our servers by setting ntree = 500 in that random forest call. You deserve it. To add to the experience, we're giving\\xa0out a truckload of\\xa0extremely\\xa0prestigious prizes.The details on Scripts:\\xa0Currently supports Python, R, and Julia, with more on the way Has\\xa0all the cool\\xa0data science packages installed. Just import them. Can run for 20 minutes and use\\xa0512\\xa0MB of\\xa0disk space Can't access the internet (sorry, spammers and botnets) Are open source and public by default Can be forked Can directly submit to competitions Can be hidden Are part of competitions, but will soon take on a life of their ownScripts Showcase - Intros to dplyrOur friend and data science educator Kevin Markham (the man behind the\\xa0dataschool.io\\xa0and the scikit-learn video series) kicks off the scripts action with two introductions to Hadley Wickham's dplyr package for data manipulation in R. Part 1 covers the basics, while part 2\\xa0covers useful new features in versions 0.3 and 0.4. If you're still using plyr, this is a great\\xa0chance to jump to its\\xa0faster, sleeker, more consistent cousin.Introduction to dplyr (Part 1)Introduction to dplyr (Part 2)You can view site-wide scripts\\xa0at\\xa0https://www.kaggle.com/scripts. We're also in the habit of naming naming our favorite scripts of the week\\xa0on the blog.\"}, {'title': 'Liberty Mutual Group: Property Inspection Prediction', 'url': 'https://www.kaggle.com/competitions/liberty-mutual-group-property-inspection-prediction', 'briefDescription': 'Quantify property hazards before time of inspection', 'coverImageUrl': None, 'tag': 'housing, normalizedgini', 'description': \"A Fortune 100 company, Liberty Mutual Insurance\\xa0has provided a wide range of insurance products and services designed to meet their\\xa0customers' ever-changing needs for over 100 years.To ensure that Liberty Mutual’s portfolio of home insurance policies aligns with their\\xa0business goals, many newly insured properties receive a home inspection. These inspections review the condition of key attributes of the property, including things like the foundation, roof, windows and siding.\\xa0The results of\\xa0an inspection help Liberty Mutual determine\\xa0if the property is one they want to insure.In this challenge, your task is to predict a transformed count of hazards or pre-existing damages using a dataset of property information. This will enable Liberty Mutual to more accurately identify high risk homes\\xa0that\\xa0require additional examination\\xa0to confirm their insurability.Liberty Mutual is interested in hiring predictive modelers like you to work on one of many growing analytics teams within our company. As a member of Liberty Mutual’s advanced analytics community, you will have the opportunity to apply sophisticated, cutting-edge techniques, similar to those used in this competition, to large data sets in departments such as Actuarial, Product, Claims, Marketing, Distribution, Human Resources, and Finance.\\xa0Click to view available positions.Because we seek to tap innovation both inside and outside the company, certain eligible Liberty Mutual employees are encouraged to participate in this challenge for development purposes. Refer to the competition rules\\xa0for the full details. \"}, {'title': 'Machinery Tube Pricing', 'url': 'https://www.kaggle.com/competitions/machinery-tube-pricing', 'briefDescription': 'Model quoted prices for industrial tube assemblies', 'coverImageUrl': None, 'tag': 'tabular, regression, manufacturing, rmsle', 'description': 'Construction machines rely on a complex set of tubes to keep the forklift lifting, the loader loading, and the bulldozer from dozing off. Tubes can vary across a number of dimensions, including base materials, number of bends, bend radius, bolt patterns, and end types.Tubes come from a variety manufacturers, each having their own unique pricing model. This competition provides detailed tube, component, and annual volume datasets, and challenges you to predict the price a supplier will quote for a given tube assembly.'}, {'title': 'Grasp-and-Lift EEG Detection', 'url': 'https://www.kaggle.com/competitions/grasp-and-lift-eeg-detection', 'briefDescription': 'Identify hand motions from EEG recordings', 'coverImageUrl': None, 'tag': 'multiclass classification, mcauc', 'description': \"Think back to this morning: turning off the alarm, getting dressed, brushing your teeth, making coffee, drinking coffee, and locking the door as you left\\xa0for work. Now imagine doing all those things again, without the use of your hands.\\xa0Patients who have lost hand function due to amputation or\\xa0neurological disabilities wake up to\\xa0this reality everyday. Restoring\\xa0a patient's\\xa0ability to perform these\\xa0basic activities of daily life with a brain-computer\\xa0interface\\xa0(BCI)\\xa0prosthetic device would greatly increase their independence and\\xa0quality of life. Currently, there are no realistic, affordable, or low-risk options for neurologically disabled patients to directly control external prosthetics with their brain activity.Recorded from the human scalp, EEG signals are evoked by brain activity.\\xa0The relationship between brain activity and EEG signals is complex and poorly understood outside of specific laboratory tests. Providing affordable, low-risk, non-invasive BCI devices is dependent on further advancements in interpreting EEG signals.\\xa0This competition challenges you to identify when a hand is grasping, lifting, and replacing an object using\\xa0EEG data that was taken from healthy subjects as they performed\\xa0these activities.\\xa0Better understanding the relationship between EEG signals and hand movements is critical to developing a BCI device that would\\xa0give patients with neurological disabilities the ability to move through the world with greater autonomy.\\xa0AcknowledgementsThis competition is sponsored by the WAY Consortium\\xa0(Wearable interfaces for hAnd function recoverY; FP7-ICT-288551).\"}, {'title': 'San Francisco Crime Classification', 'url': 'https://www.kaggle.com/competitions/sf-crime', 'briefDescription': 'Predict the category of crimes that occurred in the city by the bay ', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, crime, multiclassloss', 'description': \"From 1934 to 1963, San Francisco was infamous for housing some of the world's most notorious criminals on the inescapable island of Alcatraz.Today, the city is known more for its tech scene than its criminal past. But,\\xa0with rising wealth inequality, housing shortages, and a proliferation of expensive digital toys riding BART to work, there is no scarcity\\xa0of crime in the city by the bay.From Sunset to SOMA, and Marina to Excelsior, this competition's dataset provides nearly 12 years of crime reports from across all of San Francisco's neighborhoods.\\xa0Given time and location, you must predict the category of crime that occurred.We're also encouraging you to explore the dataset visually. What can we learn about the city through visualizations like this Top Crimes Map? The top most up-voted scripts\\xa0from this competition will receive official Kaggle swag as prizes.\\xa0AcknowledgementsKaggle is hosting this competition for the machine learning community to use for fun and practice. This\\xa0dataset is brought to you by SF OpenData,\\xa0the central clearinghouse for data published by the City and County of San Francisco.\"}, {'title': 'Avito Context Ad Clicks', 'url': 'https://www.kaggle.com/competitions/avito-context-ad-clicks', 'briefDescription': \"Predict if context ads will earn a user's click \", 'coverImageUrl': None, 'tag': 'tabular, marketing, logloss', 'description': \"In Russia, if you're looking to sell a tractor, a designer dress, a vintage lunchbox,\\xa0or even a house, your first stop will likely\\xa0be Avito.ru. As the largest general classified website in Russia, Avito connects buyers and sellers across the world's biggest country.Sellers\\xa0are highly motivated to place ads on Avito, hoping to gain attention from\\xa0the site's 70 million unique monthly visitors.\\xa0There are three different types of ads available to sellers on Avito: regular, highlighted, and context.\\xa0Context ads are seen as the best way to target users with goods and services.\\xa0Currently, Avito uses general statistics on ad performance to drive the placement of context ads. Their existing\\xa0model ignores individual user behavior, making it difficult to\\xa0predict which ad will\\xa0be the most relevant\\xa0for (and earn the most clicks from) each potential buyer.\\xa0In this competition, Avito is challenging you to improve on their model by\\xa0predicting if\\xa0individual users will click a given context ad. To create\\xa0the most robust model and fun competition possible, Avito has provided\\xa0eight comprehensive relational datasets for you to explore.\\xa0This competition will help Avito more accurately predict click-through rates for their ads, creating a world where both buyers and sellers win.\"}, {'title': 'Denoising Dirty Documents', 'url': 'https://www.kaggle.com/competitions/denoising-dirty-documents', 'briefDescription': 'Remove noise from printed text', 'coverImageUrl': None, 'tag': 'image, rmse', 'description': \"Optical Character Recognition\\xa0(OCR) is the process of getting type or handwritten documents\\xa0into\\xa0a digitized format. If you've read a classic novel on\\xa0a digital reading device or had your doctor pull up old healthcare records via the hospital computer system, you've probably benefited from OCR.OCR makes previously static content editable, searchable, and much easier to share. But, a lot of documents eager for digitization\\xa0are being held\\xa0back. Coffee stains, faded sun spots, dog-eared pages, and lot of wrinkles are keeping some printed documents offline and in the past.\\xa0This competition challenges you to give these documents a machine learning makeover. Given a dataset of images of scanned\\xa0text that has\\xa0seen better days, you're challenged\\xa0to remove the noise. Improving the ease of\\xa0document enhancement\\xa0will help us get that\\xa0rare mathematics book on our e-reader before the\\xa0next beach vacation.We've kicked off\\xa0the fun with a few\\xa0handy scripts to get you started on the dataset.AcknowledgementsKaggle is hosting this competition for the machine learning community to use for fun and practice. This dataset was created by RM.J. Castro-Bleda, S. España-Boquera, J. Pastor-Pellicer, F. Zamora-Martinez. We also thank the UCI machine learning repository for hosting the dataset. If you use the problem in publication, please cite:Bache, K. & Lichman, M. (2013). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science\"}, {'title': 'ICDM 2015: Drawbridge Cross-Device Connections', 'url': 'https://www.kaggle.com/competitions/icdm-2015-drawbridge-cross-device-connections', 'briefDescription': 'Identify individual users across their digital devices', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, meanfscorebeta', 'description': \"Imagine you're planning a summer holiday to Iceland: you read a travel blog on your smartphone on the subway to work, search for hotels on your laptop during lunch, browse Reykjavik restaurants on a\\xa0tablet while half-watching TV after dinner, and then download a travel book to\\xa0your e-reader to skim before bed.\\xa0As consumers move across devices to complete online tasks, their identity becomes fragmented. Marketers, hoping to target them\\xa0with meaningful messages, recommendations, and customized experiences, aren't always able to discern\\xa0when activity on different devices is tied to one user vs. many users.Given usage\\xa0data and a set of fabricated non-personally-identifiable\\xa0IDs, this competition tasks you with making\\xa0individual user connections across a variety of\\xa0digital devices. Improving marketers' ability to identify individual users\\xa0as they switch between\\xa0devices means you'll see relevant messages wherever you go, making it easy for you to plan the\\xa0best, most fjord-filled\\xa0trip ever.\\xa0AcknowledgementsThe competition dataset and prize pool have been generously provided by Drawbridge\\xa0in sponsorship\\xa0of the ICDM 2015\\xa0conference.\\xa0\"}, {'title': 'Crowdflower Search Results Relevance', 'url': 'https://www.kaggle.com/competitions/crowdflower-search-relevance', 'briefDescription': 'Predict the relevance of search results from eCommerce sites', 'coverImageUrl': None, 'tag': 'internet, tabular, quadraticweightedkappa', 'description': \"So many of our favorite daily activities are mediated by proprietary search algorithms.\\xa0Whether you're trying to find a stream of\\xa0that reality\\xa0TV show on cat herding or\\xa0shopping an eCommerce site for a new set of Japanese sushi knives, the relevance of search results is often responsible for your (un)happiness.\\xa0Currently, small online businesses have no good way of evaluating the performance of their search algorithms, making it difficult for them to provide an exceptional customer experience.The goal of this competition is to create an open-source model\\xa0that can be used to measure\\xa0the relevance of search results. In doing so, you'll be helping enable\\xa0small business owners to match the experience provided by\\xa0more resource rich competitors. It will also\\xa0provide more established\\xa0businesses a model\\xa0to test against.\\xa0Given the queries and resulting\\xa0product descriptions\\xa0from leading\\xa0eCommerce\\xa0sites, this competition asks you to evaluate the\\xa0accuracy of their search algorithms.Make a first submission with this Python benchmark\\xa0on Kaggle scripts.\\xa0The dataset for this competition was created using query-result pairings enriched on the\\xa0CrowdFlower\\xa0platform. They are sponsoring this competition as an investment in the open-source data science community. A dataset collected, cleaned, and labeled by CrowdFlower can make your supervised machine learning dreams come true.\"}, {'title': 'Facebook Recruiting IV: Human or Robot?', 'url': 'https://www.kaggle.com/competitions/facebook-recruiting-iv-human-or-bot', 'briefDescription': 'Predict if an online bid is made by a machine or a human', 'coverImageUrl': None, 'tag': 'internet, tabular, binary classification, auc', 'description': 'Ever wonder what it\\'s\\xa0like to work at Facebook?\\xa0Facebook and Kaggle are launching an Engineering competition for 2015. Trail blaze your way to the top of the leader board to earn an opportunity at\\xa0interviewing for a role\\xa0as a\\xa0software engineer, working on world class Machine Learning problems.\\xa0In this competition, you\\'ll be chasing down robots for an online auction site. Human bidders on the site are becoming increasingly frustrated with their inability to win auctions vs. their software-controlled counterparts. As a result, usage from the site\\'s core customer base is plummeting.In order to\\xa0rebuild customer happiness, the site owners need\\xa0to eliminate\\xa0computer generated bidding\\xa0from their auctions. Their attempt at building a\\xa0model to identify these\\xa0bids\\xa0using behavioral data, including bid frequency over short periods of time, has proven insufficient.\\xa0The goal of this competition is to identify online auction bids that are placed by \"robots\", helping the site owners easily flag these users for removal from their site to prevent unfair auction activity.\\xa0The data in this competition comes from an online platform, not from Facebook. Please note: You must compete as an individual in recruiting competitions. You may only use the data provided to make your predictions.\\xa0'}, {'title': 'ECML/PKDD 15: Taxi Trip Time Prediction (II)', 'url': 'https://www.kaggle.com/competitions/pkdd-15-taxi-trip-time-prediction-ii', 'briefDescription': 'Predict the total travel time of taxi trips based on their initial partial trajectories', 'coverImageUrl': None, 'tag': 'tabular, rmsle', 'description': 'This is the second of two data science challenges that share the same dataset. The Taxi Service Trajectory competition\\xa0predicts the final destination of taxi trips.\\xa0To improve the efficiency of electronic taxi dispatching systems it is important to be able to predict how long a driver will have his taxi occupied. If a dispatcher knew approximately when a\\xa0taxi driver would be ending their current ride, they would be better able to identify which driver\\xa0to assign to each pickup request.\\xa0In this challenge, we ask you to build a predictive framework that is able to infer the\\xa0trip time\\xa0of taxi rides in Porto, Portugal based on their (initial) partial trajectories. The output of such a framework must be the travel time of a particular taxi trip.This competition\\xa0is affiliated\\xa0with\\xa0the organization of ECML/PKDD 2015.'}, {'title': 'West Nile Virus Prediction', 'url': 'https://www.kaggle.com/competitions/predict-west-nile-virus', 'briefDescription': 'Predict West Nile virus in mosquitos across the city of Chicago', 'coverImageUrl': None, 'tag': 'tabular, binary classification, auc', 'description': \"West Nile virus\\xa0is most commonly spread to humans through infected mosquitos. Around\\xa020% of\\xa0people who become infected\\xa0with the virus develop symptoms\\xa0ranging from a\\xa0persistent fever, to serious neurological illnesses that can\\xa0result in\\xa0death.In 2002,\\xa0the first human cases of West Nile virus were reported in Chicago.\\xa0By\\xa02004 the City of Chicago and the Chicago Department of Public Health (CDPH) had established a\\xa0comprehensive surveillance and control program that is still in effect\\xa0today.Every week from\\xa0late spring through the fall, mosquitos in traps across the city are tested for the virus. The results of these tests\\xa0influence when and where the city will spray airborne pesticides to control adult mosquito populations.Given weather, location, testing, and spraying data, this competition\\xa0asks you to predict\\xa0when and where different species of mosquitos will test positive for West Nile virus.\\xa0A more accurate method of predicting outbreaks of West Nile virus in mosquitos will help the City of Chicago and CPHD more efficiently and effectively allocate resources\\xa0towards preventing transmission of this potentially deadly virus.\\xa0We've jump-started your analysis with some visualizations\\xa0and starter code\\xa0in\\xa0R and Python on Kaggle Scripts. No data download or local environment setup needed!Acknowledgements\\xa0This competition is sponsored by the Robert Wood Johnson Foundation.\\xa0Data is provided by the Chicago Department of Public Health.\"}, {'title': 'ECML/PKDD 15: Taxi Trajectory Prediction (I)', 'url': 'https://www.kaggle.com/competitions/pkdd-15-predict-taxi-service-trajectory-i', 'briefDescription': 'Predict the destination of taxi trips based on initial partial trajectories', 'coverImageUrl': None, 'tag': 'tabular, ahd@{type}', 'description': \"The taxi industry is evolving rapidly. New competitors and technologies are changing the way traditional taxi services do business. While this evolution has created new efficiencies, it has also created new problems.\\xa0One major shift is the widespread adoption of electronic dispatch systems that have replaced the VHF-radio dispatch systems of times past.\\xa0These mobile data terminals are installed in each vehicle and typically provide information on\\xa0GPS localization and taximeter state. Electronic dispatch systems make it easy to see where a taxi has been, but not necessarily where it is going. In most cases, taxi drivers operating with\\xa0an electronic dispatch system do not indicate the final destination of their current ride.Another recent change is the switch from broadcast-based (one to many) radio messages for service dispatching to unicast-based (one to one) messages. With unicast-messages, the dispatcher needs to correctly identify which taxi they should dispatch to a pick up location.\\xa0Since taxis using electronic dispatch systems do not usually enter their drop off location, it is extremely difficult for dispatchers to know which taxi to contact.\\xa0To improve the efficiency of electronic taxi dispatching systems it is important to be able to predict the final destination of a taxi while it is in service.\\xa0Particularly during periods of high demand, there is often a taxi whose current ride will end near or exactly at a requested pick up location from a new rider. If a dispatcher knew approximately where their taxi drivers would be ending their current rides, they would be able to identify which taxi to assign to each pickup request.The spatial trajectory of an occupied taxi could provide some hints as to where it is going. Similarly, given the taxi id, it might be possible to predict its final destination based on the regularity of pre-hired services. In a significant number of taxi rides (approximately 25%), the taxi has been called through the taxi call-center, and the passenger’s telephone id can be used to narrow the destination prediction based on historical ride data connected to their telephone id.In this challenge, we ask you to build a predictive framework that is able to infer the final destination of taxi rides in Porto, Portugal based on their (initial) partial trajectories. The output of such a framework must be the final trip's destination (WGS84 coordinates).This is the first\\xa0of two data science challenges that share the same dataset. The Taxi Service Trip Time\\xa0competition\\xa0predicts the total time of taxi rides.This competition\\xa0is affiliated\\xa0with\\xa0the organization of ECML/PKDD 2015.\"}, {'title': '15.071x - The Analytics Edge (Spring 2015)', 'url': 'https://www.kaggle.com/competitions/15-071x-the-analytics-edge-competition-spring-2015', 'briefDescription': 'Test your analytics skills by predicting which New York Times blog articles will be the most popular', 'coverImageUrl': None, 'tag': 'auc', 'description': 'IMPORTANT NOTE: This competition is only open to students of the MITx free, online course 15.071x - The Analytics Edge.What makes online news articles popular?Newspapers and online news aggregators like Google News need to understand which news articles will be the most popular, so that they can prioritize the order in which stories appear. In this competition, you will predict the popularity of a set of New York Times blog articles from the time period September 2014-December 2014.The following screenshot shows an example of the New York Times technology blog \"Bits\" homepage:Many blog articles are published each day, and the New York Times has to decide which articles should be featured. In this competition, we challenge you to develop an analytics model that will help the New York Times understand the features of a blog post that make it popular.To download the data and learn how this competition works, please be sure to read the \"Data\" page, as well as the \"Evaluation\" page, which can both be found in the panel on the left.AcknowledgementsThis competition is brought to you by MITx and edX.'}, {'title': 'Predict Closed Questions on Stack Overflow', 'url': 'https://www.kaggle.com/competitions/pycon-2015-tutorial-predict-closed-questions-on-stack-overflow', 'briefDescription': 'Predict which new questions asked on Stack Overflow will be closed', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'This competition is now complete. Congratulations to the  winners!Millions of programmers use Stack Overflow to get high quality answers to their programming questions every day. \\xa0We take quality very seriously, and have evolved an effective culture of moderation to safe-guard it.With more than six thousand new questions asked on\\xa0Stack Overflow\\xa0every weekday we\\'re looking to add more sophisticated software solutions to our moderation toolbox.Closing QuestionsCurrently about 6% of all new questions end up \"closed\". \\xa0Questions can be closed as off topic, not constructive, not a real question, or  too localized. \\xa0More in depth descriptions of each reason can be found in the\\xa0Stack Overflow FAQ. \\xa0The exact duplicate close reason has been excluded from this contest, since it depends on previous questions.Your goal is to build a classifier that predicts whether or not a question will be closed given the question as submitted, along with the reason that the question was closed. \\xa0Additional data about the user at question creation time is also available.'}, {'title': '15.071x - The Analytics Edge (Spring 2015)', 'url': 'https://www.kaggle.com/competitions/15-071x-the-analytics-edge-spring-20152', 'briefDescription': 'Test your analytics skills by predicting which New York Times blog articles will be the most popular.', 'coverImageUrl': None, 'tag': 'auc', 'description': 'IMPORTANT NOTE: This competition is only open to students of 15.071x - The Analytics Edge (https://www.edx.org/course/analytics-edge-mitx-15-071x)What makes online news articles popular?Newspapers and online news aggregators like Google News need to understand which news articles will be the most popular, so that they can prioritize the order in which stories appear. In this competition, you will predict the popularity of a set of New York Times blog articles from the time period September 2014-December 2014.\\xa0The following screenshot shows an example of the New York Times technology blog \"Bits\" homepage:Many blog articles are published each day, and the New York Times has to decide which articles should be featured. In this competition, we challenge you to develop an analytics model that will help the New York Times understand the features of a blog post that make it popular.\\xa0To download the data and learn how this competition works, please be sure to read the \"Data\" page, as well as the \"Evaluation\" page, which can both be found in the panel on the left.AcknowledgementsThis competition is brought to you by\\xa0MITx and edX.'}, {'title': 'Walmart Recruiting II: Sales in Stormy Weather', 'url': 'https://www.kaggle.com/competitions/walmart-recruiting-sales-in-stormy-weather', 'briefDescription': 'Predict how sales of weather-sensitive products are affected by snow and rain', 'coverImageUrl': None, 'tag': 'tabular, regression, rmsle', 'description': \"Walmart operates\\xa011,450 stores in 27 countries, managing inventory across varying climates and cultures. Extreme weather events, like hurricanes, blizzards, and floods, can have a huge impact on sales at the store and product level.\\xa0In their second Kaggle recruiting competition, Walmart challenges participants to accurately\\xa0predict the sales of 111 potentially weather-sensitive\\xa0products (like umbrellas, bread, and milk) around the time of major weather events at 45 of their retail locations.\\xa0Intuitively, we may expect an uptick in the sales of umbrellas before a big thunderstorm, but it's difficult\\xa0for replenishment managers to correctly predict the level of inventory needed to avoid being out-of-stock or\\xa0overstock during and after that storm.\\xa0Walmart relies on a variety of vendor tools to predict sales around extreme weather events, but it's an ad-hoc and time-consuming\\xa0process that lacks a systematic measure of effectiveness.\\xa0Helping Walmart better predict sales of weather-sensitive products\\xa0will keep valued customers out of the rain. It could also earn you a position at\\xa0one of the most data-driven retailers in the world!\\xa0Please note: You must compete as an individual in recruiting competitions. You may only use the data provided to make your predictions.\"}, {'title': 'Restaurant Revenue Prediction', 'url': 'https://www.kaggle.com/competitions/restaurant-revenue-prediction', 'briefDescription': 'Predict annual restaurant sales based on objective measurements', 'coverImageUrl': None, 'tag': 'tabular, regression, rmse', 'description': \"With over 1,200 quick service restaurants across the globe, TFI\\xa0is the company behind some of the world's most well-known brands: Burger King, Sbarro, Popeyes, Usta Donerci, and Arby’s. They employ over 20,000 people in\\xa0Europe and Asia and make significant daily investments in developing new restaurant sites.Right now, deciding when and where to open new restaurants is largely a subjective process based on the personal judgement and experience\\xa0of\\xa0development teams. This subjective data\\xa0is\\xa0difficult to accurately extrapolate across geographies and cultures.\\xa0New restaurant sites take large investments of time and capital to get up and running. When the wrong location for a restaurant brand is chosen, the site closes within 18 months and operating losses are incurred.\\xa0Finding a mathematical model to increase the effectiveness of investments in new restaurant sites would allow TFI\\xa0to invest more in other important business areas, like sustainability, innovation, and training for\\xa0new employees.\\xa0Using demographic, real estate, and commercial data, this competition challenges you to predict the annual restaurant\\xa0sales of 100,000 regional locations.TFI\\xa0would love to hire an expert Kaggler like you to head\\xa0up their growing data science team in Istanbul or Shanghai. You'd be tackling problems like the one featured in this competition\\xa0on a global scale.\\xa0See the job description here >>\"}, {'title': 'Otto Group Product Classification Challenge', 'url': 'https://www.kaggle.com/competitions/otto-group-product-classification-challenge', 'briefDescription': 'Classify products into the correct category', 'coverImageUrl': None, 'tag': 'internet, tabular, multiclassloss', 'description': 'Get started on this competition through Kaggle ScriptsThe Otto Group is one of the world’s biggest e-commerce companies, with subsidiaries in more than 20 countries, including Crate & Barrel (USA), Otto.de (Germany) and\\xa03 Suisses (France). We are selling millions of products worldwide every day, with several thousand products being added to our product line.A consistent analysis of the performance of our products is crucial. However, due to our diverse global infrastructure, many identical products get classified differently. Therefore, the quality of our product analysis depends heavily on the ability to accurately cluster similar products. The better the classification, the more insights we can generate about our product range.For this competition, we have provided a dataset with 93 features for more than 200,000 products. The objective is to build a predictive model which is able to distinguish between our main product categories. The winning models will be open sourced.'}, {'title': 'Diabetic Retinopathy Detection', 'url': 'https://www.kaggle.com/competitions/diabetic-retinopathy-detection', 'briefDescription': 'Identify signs of diabetic retinopathy in eye images', 'coverImageUrl': None, 'tag': 'image, binary classification, quadraticweightedkappa', 'description': 'Diabetic retinopathy\\xa0is the leading cause of blindness in the working-age population of the developed world. It is estimated to affect over 93 million people.The US Center for Disease Control and Prevention estimates that 29.1 million people in the US have diabetes and the World Health Organization estimates that 347 million people have the disease worldwide. Diabetic Retinopathy (DR) is an eye disease associated with long-standing diabetes. Around 40% to 45% of Americans with diabetes have some stage of the disease. Progression to vision impairment can be slowed or averted if DR is detected in time, however this can be difficult as the disease often shows few symptoms until it is too late to provide effective treatment.Currently, detecting DR is a time-consuming and manual process that requires a trained clinician to examine and evaluate digital color fundus photographs of the retina. By the time human readers submit their reviews, often a day or two later, the delayed results lead to lost follow up, miscommunication, and delayed treatment.Clinicians can identify DR by the presence of lesions associated with the vascular abnormalities caused by the disease.\\xa0While this approach is effective, its resource demands are high. The expertise and equipment required are often lacking in areas where the rate of diabetes in local populations is high and DR detection is most needed.\\xa0As the number of individuals with diabetes continues to grow, the infrastructure needed to prevent blindness due to DR will become even more insufficient.The need for a comprehensive and automated method of DR screening has long been recognized, and previous efforts have made good progress using image classification, pattern recognition, and machine learning. With color fundus photography as input, the goal of this competition is to push an automated detection system to the limit of what is possible – ideally resulting in models with realistic clinical potential. The winning models\\xa0will be open sourced to maximize the impact such a model can\\xa0have on improving DR detection.AcknowledgementsThis competition is sponsored by the California Healthcare Foundation.Retinal images were\\xa0provided by EyePACS, a free platform for retinopathy screening.'}, {'title': 'Microsoft Malware Classification Challenge (BIG 2015)', 'url': 'https://www.kaggle.com/competitions/malware-classification', 'briefDescription': 'Classify malware into families based on file content and characteristics', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/4117/logos/header.png?t=2018-12-13-20-11-47', 'tag': 'internet, text, multiclass classification, custom metric', 'description': 'March 2018 Update: when using this dataset, please cite http://arxiv.org/abs/1802.10135In recent years, the malware industry has become a well organized market\\xa0involving\\xa0large amounts of money. Well funded, multi-player syndicates invest heavily in technologies and capabilities built\\xa0to evade traditional protection, requiring anti-malware vendors to develop counter mechanisms\\xa0for finding and deactivating them. In the meantime, they inflict\\xa0real financial and emotional pain to users of computer systems.One of the major\\xa0challenges that anti-malware faces today is the vast amounts of data and files which need to be evaluated\\xa0for potential malicious intent. For example, Microsoft\\'s real-time detection anti-malware products are present on over\\xa0160M computers worldwide and inspect over\\xa0700M computers monthly. This generates\\xa0tens of millions of daily data points\\xa0to be analyzed\\xa0as potential malware. One of the main reasons\\xa0for these\\xa0high volumes of different files is the fact that,\\xa0in order to\\xa0evade detection, malware authors introduce polymorphism to the malicious components. This means that malicious files belonging to the same malware \"family\", with the same forms of malicious behavior, are constantly modified and/or obfuscated using various tactics, such that they look like many different files.In order to be effective in analyzing and classifying such large amounts of files, we need to be able to\\xa0group them into groups and identify their respective families. In addition, such grouping criteria\\xa0may be applied to new files encountered on computers in order to detect them\\xa0as malicious and of a certain family.For this challenge, Microsoft is\\xa0providing the\\xa0data science community with an unprecedented malware dataset and encouraging open-source progress on\\xa0effective techniques for grouping variants of malware files into\\xa0their respective families.AcknowledgementsThis competition is hosted by WWW 2015 /\\xa0BIG 2015 and the following Microsoft groups: Microsoft Malware Protection Center,\\xa0Microsoft Azure Machine Learning and Microsoft Talent Management. Microsoft contacts: Dr. Royi Ronen (royir@microsoft.com) and Corina Feuerstein (corinaf@microsoft.com) '}, {'title': 'March Machine Learning Mania 2015', 'url': 'https://www.kaggle.com/competitions/march-machine-learning-mania-2015', 'briefDescription': 'Predict the 2015 NCAA Basketball Tournament', 'coverImageUrl': None, 'tag': 'tabular, sports, basketball, logloss', 'description': \"At Kaggle HQ and in offices across the country, March is a month when bracketology is in bloom. Back by popular demand, our second annual March Machine Learning Mania competition pits you against the millions of sports fans and office-pool bandwagoners\\xa0who are hoping to win big by correctly predicting the outcome of the men's NCAA basketball\\xa0tournament.\\xa0While the odds of forecasting\\xa0a perfect bracket are astronomical, these odds are improved\\xa0by the growing amount of data collected throughout the season, including player statistics, tournament seeds, geographical factors and social media.How well can machine learning and statistical techniques improve the forecast? Presented by HP Software's industry leading Big Data group and the\\xa0HP Haven Big Data platform, this competition will test how well predictions based on data stack up against a (jump) shot in the dark.This competition allows\\xa0you to get creative with the datasets you use to create your model. We provide\\xa0data covering three\\xa0decades of historical games, but you're highly encouraged to pull in data from external sources.\\xa0The\\xa050+ REST APIs from HP IDOL OnDemand\\xa0are a great way to get started\\xa0augmenting\\xa0the\\xa0dataset. Developer accounts are free and includes free monthly quota! Begin by\\xa0extracting trending topics and\\xa0identifying entities\\xa0from the IDOL OnDemand news dataset\\xa0(accessed via the Query Text Index API) or by\\xa0analyzing public\\xa0sentiment about players and teams using data from\\xa0your social media feed.\\xa0In stage one of this two-stage competition, participants will build and test their models against the previous four\\xa0tournaments. In the second stage, participants will predict the outcome of the 2015 tournament. You don’t need to participate in the first stage to enter the second, but the first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2015 results, for which you’ll predict winning percentages for the likelihood of each possible matchup, not just a traditional bracket.\\xa0HP is sponsoring $15,000 in cash prizes for the winners.Please visit the FAQs for more information.AcknowledgementsMarch Machine Learning Mania 2015\\xa0is presented by HP.\\xa0Please see About the sponsor\\xa0to read\\xa0more.\"}, {'title': 'How Much Did It Rain?', 'url': 'https://www.kaggle.com/competitions/how-much-did-it-rain', 'briefDescription': 'Predict probabilistic distribution of hourly rain given polarimetric radar measurements', 'coverImageUrl': None, 'tag': 'tabular, crps', 'description': 'For agriculture, it is extremely important to know how much it rained on a particular field. However, rainfall is variable in space and time and it is impossible to have rain gauges everywhere. Therefore, remote sensing instruments such as radar are used to provide wide spatial coverage. Rainfall estimates drawn from remotely sensed observations will never exactly match the measurements that are\\xa0carried out using rain gauges, due to the inherent characteristics of both sensors. Currently, radar observations are \"corrected\" using nearby gauges and a single estimate of rainfall is provided to users who need to know how much it rained. This competition\\xa0will explore how to address this problem in a probabilistic manner. \\xa0Knowing the full probabilistic spread of rainfall amounts can be very useful to drive hydrological and agronomic models -- much more than a single estimate of rainfall.Image courtesy of\\xa0NOAAUnlike a conventional Doppler radar, a polarimetric radar transmits\\xa0radio wave pulses that have both horizontal and vertical orientations. Because rain drops become flatter as they increase in size and because ice crystals tend to be elongated vertically, whereas liquid droplets tend to be flattened, it is possible to infer the size of rain drops and the type of hydrometeor from the differential reflectivity of the two orientations.In this competition, you are given polarimetric radar values and derived quantities at a location over the period of one hour. You will need to produce a probabilistic distribution of the hourly rain gauge total. More details are on\\xa0the\\xa0data page.This competition is sponsored by the Artificial Intelligence Committee\\xa0of the American Meteorological Society. The Climate Corporation\\xa0has kindly agreed to\\xa0sponsor the prizes.'}, {'title': 'National Data Science Bowl', 'url': 'https://www.kaggle.com/competitions/datasciencebowl', 'briefDescription': 'Predict ocean health, one plankton at a time', 'coverImageUrl': None, 'tag': 'image, multiclass classification, water bodies, custom metric', 'description': 'Plankton are critically important to our ecosystem, accounting for more than half the primary productivity on earth and nearly half the total carbon fixed in the global carbon cycle. They form the foundation of aquatic food webs including those of large, important fisheries. Loss of plankton populations could result in ecological upheaval as well as negative societal impacts, particularly in indigenous cultures and the developing world. Plankton’s global significance makes their population levels an ideal measure of the health of the world’s oceans and ecosystems.Traditional methods for measuring and monitoring plankton populations are time consuming and cannot scale to the granularity or scope necessary for large-scale studies. Improved approaches are needed. One such approach is through the use of an underwater imagery sensor. This towed, underwater camera system captures microscopic, high-resolution images over large study areas. The images can then be analyzed to assess species populations and distributions.Manual analysis of the imagery is infeasible\\xa0– it would take a year or more to manually analyze the imagery volume captured in a single day. Automated image classification using machine learning tools is an alternative to the manual approach. Analytics will allow analysis at speeds and scales previously thought impossible. The automated system will have broad applications for assessment of ocean and ecosystem health.The National Data Science Bowl challenges you to build an algorithm to automate the image identification process. Scientists at the Hatfield Marine Science Center and beyond will use the algorithms you create to study marine food webs, fisheries, ocean conservation, and more. This is your chance to contribute to the\\xa0health of the world’s oceans, one plankton at a time.AcknowledgementsThe National Data Science Bowl\\xa0is presented\\xa0bywith data provided by the Hatfield Marine Science Center\\xa0at Oregon State University.'}, {'title': 'Driver Telematics Analysis', 'url': 'https://www.kaggle.com/competitions/axa-driver-telematics-analysis', 'briefDescription': 'Use telematic data to identify a driver signature', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, auc', 'description': 'For automobile insurers, telematics represents a growing\\xa0and valuable way to quantify driver risk. Instead of pricing\\xa0decisions on vehicle and driver characteristics, telematics gives\\xa0the\\xa0opportunity\\xa0to measure the quantity and quality of a driver\\'s behavior. This can\\xa0lead to savings for safe or\\xa0infrequent drivers, and transition\\xa0the burden to policies that represent increased\\xa0liability.AXA has provided a dataset of over 50,000 anonymized driver trips. The intent of this competition is to develop an algorithmic signature of driving type. Does\\xa0a\\xa0driver drive long trips? Short trips? Highway trips? Back roads? Do they accelerate hard from stops? Do they take turns at high speed? The answers to these questions combine to form\\xa0an aggregate profile that potentially\\xa0makes each driver unique.For this competition, Kaggle participants must come up with a \"telematic fingerprint\" capable of distinguishing\\xa0when a trip was driven by a given driver. The features of this\\xa0driver fingerprint\\xa0could\\xa0help assess\\xa0risk and form a crucial piece of a\\xa0larger telematics puzzle.'}, {'title': 'Bag of Words Meets Bags of Popcorn', 'url': 'https://www.kaggle.com/competitions/word2vec-nlp-tutorial', 'briefDescription': \"Use Google's Word2Vec for movie reviews\", 'coverImageUrl': None, 'tag': 'movies and tv shows, text, binary classification, auc', 'description': 'In this tutorial competition, we dig a little \"deeper\" into sentiment analysis. Google\\'s Word2Vec\\xa0is a deep-learning inspired method that focuses on the meaning of words. Word2Vec attempts to understand meaning\\xa0and semantic relationships among words. It works in a way that is similar to deep approaches, such as recurrent neural nets or deep neural nets, but is computationally more efficient. This tutorial focuses on Word2Vec for sentiment analysis.Sentiment analysis is a challenging subject in machine learning. People express their emotions in language that is often obscured by sarcasm, ambiguity, and plays on words, all of which could be very misleading for both humans and computers. There\\'s another Kaggle competition\\xa0for movie review sentiment analysis. In this tutorial we explore how Word2Vec can be applied to a similar problem.Deep learning has been in the news a lot over the past few years, even making it to the front page of the New York Times. These machine learning\\xa0techniques, inspired by the architecture of the human brain and made possible by recent advances in computing power, have been making waves via\\xa0breakthrough results in image recognition, speech processing, and natural language tasks. Recently, deep learning approaches won several Kaggle competitions, including a drug discovery\\xa0task, and\\xa0cat and dog image recognition.Tutorial OverviewThis tutorial will\\xa0help you get started with Word2Vec for natural language processing. It\\xa0has two goals:\\xa0Basic Natural Language Processing:\\xa0Part 1 of this tutorial is intended for beginners and covers basic natural language processing\\xa0techniques, which are needed for later parts of the tutorial.Deep Learning for Text\\xa0Understanding: In\\xa0Parts 2 and 3, we delve into how to train a model\\xa0using Word2Vec and how to use the resulting word vectors\\xa0for sentiment analysis.Since deep learning is a rapidly evolving field, large amounts of\\xa0the work has not yet been published, or exists only as\\xa0academic papers. Part 3 of the\\xa0tutorial is more exploratory than prescriptive -- we experiment with several ways of using Word2Vec rather than giving you a recipe for using the output.To achieve these goals, we rely on an\\xa0IMDB sentiment analysis data set, which has 100,000 multi-paragraph movie reviews, both positive and negative.\\xa0AcknowledgementsThis dataset was collected in association with the following publication:Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). \"Learning Word Vectors for Sentiment Analysis.\" The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011). (link)Please email the author of that paper if you use the data for any research applications. The tutorial was developed by Angela Chapman\\xa0during her summer 2014 internship at Kaggle.'}, {'title': 'Poker Rule Induction', 'url': 'https://www.kaggle.com/competitions/poker-rule-induction', 'briefDescription': 'Determine the poker hand of five playing cards', 'coverImageUrl': None, 'tag': 'tabular, multiclass classification, card games, categorizationaccuracy', 'description': 'Your friend bailed last minute on poker night? Before giving up on a much-needed evening of bad bluffs and quarter buy ins, light a\\xa0cigar and get familiar with the rules of the game. Each record in\\xa0this competition consists of five playing cards and an\\xa0attribute\\xa0representing\\xa0the poker hand.\\xa0You are asked to predict the best hand you can play based on the cards you\\'ve been dealt.\\xa0The order of cards is important, which means there are 480 possible Royal Flush hands instead of just four. Identify those, and the other 311,875,200\\xa0possible hands correctly, and you’re in the money!\"Isn\\'t this easy? I know two-of-a-kind when I see it\", you might rightfully wonder.And you\\'d be right. \\xa0The intent\\xa0of this challenge\\xa0is automatic rules induction, i.e. to learn the rules using\\xa0machine learning, without hand coding heuristics. Pretend you are in a foreign land, have never played the game before, are\\xa0given a history of thousands of games, and are\\xa0asked to come up with the rules.\\xa0It is potentially difficult to\\xa0discover rules that can correctly classify poker\\xa0hands, yet it is trivial for a\\xa0human to validate the\\xa0rules objectively. Remember, your algorithm will need to find rules that are general enough to be broadly useful, without being so broad that they end up being occasionally wrong. We suggest reading\\xa0the paper\\xa0by Cattral et al. for more background\\xa0on the topic.Playground competitions are an opportunity to build and stretch your machine learning muscles. Pull up a chair to the data science poker table and ante up.AcknowledgementsKaggle is hosting this competition for the machine learning community to use for fun and practice. This dataset was created\\xa0by Robert Cattral and Franz Oppacher.\\xa0We also thank the UCI machine learning repository for hosting the dataset. If you use the problem in publication, please cite:Bache, K. & Lichman, M. (2013). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science'}, {'title': \"Helping Santa's Helpers\", 'url': 'https://www.kaggle.com/competitions/helping-santas-helpers', 'briefDescription': 'Jingle bells, Santa tells ... ', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \" Every year Santa has to satisfy a grueling toy-production schedule.\\xa0Toy orders arrive all year long and the Elfin Workers Union is stronger than ever.\\xa0Let's help Santa develop a job scheduling algorithm that meets his toy target while\\xa0keeping his elves healthy and happy.Problem DescriptionIn this job scheduling problem, you will assign which elves work on which toys, at what time, and for how long. The goal is to complete all of the toys as early as possible, scaled by the natural log of the number of elves that work. Thus the objective S is\\\\[S = t_f * \\\\log(1 +n_e) \\\\]where\\\\\\\\(t_f\\\\\\\\) is the last minute the final toy is complete, from reference date Jan 1, 2014 at 12:00 AM\\\\\\\\(n_e\\\\\\\\) is the number of unique elves that were needed\\xa0to build the toysToysThere are 10\\xa0million toys that will need to be built by the elves. Each toy is described\\xa0by an id, the time the order for the toy arrives in Santa's workshop, and the amount of time\\xa0it takes to build the toy.\\xa0Work on toys cannot start before the order comes in but can start any time after it comes in. Once work on a toy starts, it must continue until the toy is complete, and it must be performed by only one elf. As a result,\\xa0an elf cannot start work one day, stop, and then resume the next morning, or have a different elf resume the work.All toys must be completely built for the submission to be\\xa0valid. Submissions with incomplete toys or where work starts too soon or too late will result in an invalid scoring exception.Working ConditionsSanta's Workshop opens for the year on January 1, 2014 at 9:00 am North Pole Time.\\xa0Sanctioned elf working hours are every day, 7 days a week, from 9:00 to 19:00 (10 hours per day). Work outside of these hours are unsanctioned and penalized.Every minute\\xa0worked during unsanctioned hours must be compensated with a rest period of equivalent time during sanctioned hours. If an elf works from 14:00-19:33, the next time he can work is the following day at 9:33. Thus 33 minutes overtime results in 33 minutes rest time. Submissions that have elves returning to work before the appropriate amount of rest time has passed will result in an invalid scoring exception.\\xa0An elf with no accrued resting period may start work at any time.ElvesThere are 900\\xa0elves in Santa's Workshop. Each elf is described\\xa0byAn elf's\\xa0productivity rating determines how efficiently he builds a toy. A productivity rating of 1.0 means a 120-min\\xa0toy takes 120 minutes\\xa0to build. A 1.25-rating means a 120-min toy\\xa0takes him\\xa0only 120-min/1.25 = 96 minutes to build. Minimum and maximum values for the productivity rating are 0.25 and 4.0, respectively. All elves start the year with a productivity rating of 1.0.An elf’s productivity rating changes as he completes toys. Ratings\\xa0are held constant during the building of a toy and updated once the toy is complete. The rating is calculated per the required time for a toy, not per the time he spends on a toy. The time\\xa0used in the productivity calculation will be toy_duration/elf_starting_productivity, e.g.: a 0.5-elf working on a 120-min toy uses 240 minutes in his productivity\\xa0calculation.\\xa0If a 1.0-rated elf is assigned to work on a 120-min\\xa0toy for 180 minutes, his productivity rating will only take into account the\\xa0120 minutes\\xa0of needed work. For each hour worked outside of the sanctioned hours, the rest period will apply (see Working Conditions described above).\\xa0For every hour worked on actively building a toy during sanctioned work hours, an elf's productivity increases as\\\\[p = p' * (1.02)^n\\\\]where p is the updated productivity, p' is the previous productivity, and n is the number of hours\\xa0(not minutes, can be a decimal value)\\xa0worked that contributed to the building of the toy.Work performed during unsanctioned hours decrease an elf's productivity:\\\\[p = p' * (0.9)^m\\\\]where m is the number of hours\\xa0(not minutes, can be a decimal value) worked\\xa0that contributed to the building of the toy.In practice, the productivity is updated in a single step once work is over as\\\\[p = p' * (1.02)^n * (0.9)^m\\\\]AcknowledgementsThis competition is brought to you by\\xa0\"}, {'title': 'BCI Challenge @ NER 2015', 'url': 'https://www.kaggle.com/competitions/inria-bci-challenge', 'briefDescription': 'A spell on you if you cannot detect errors!', 'coverImageUrl': None, 'tag': 'auc', 'description': \"This BCI Challenge is being proposed as part of the IEEE Neural Engineering Conference (NER2015). Participation is open without restriction, and the winners will be selected among participants who have submitted an abstract to the conference (see rules).Problem DescriptionAs humans think, we produce brain waves. These brain waves can be mapped to actual intentions. In this competition, you are given the brain wave data of people with the goal of spelling a word by only paying attention to visual stimuli.\\xa0The goal of the competition is to detect errors during the spelling task, given the subject's brain waves.\\xa0The SetupThe “P300-Speller” is a well-known brain-computer interface (BCI) paradigm which uses Electroencephalography (EEG) and the so-called P300 response evoked by rare and attended stimuli in order to select items displayed on a computer screen. In this\\xa0experiment, each subject was presented with letters and numbers (36 possible items displayed on a matrix) to spell words. Each item of a word is selected one at a time, by flashing screen items in group and in random order. The selected item is the one for which the online algorithm could most likely recognize the typical target response.The goal of this challenge is to determine when the selected item is not the correct one by analyzing the brain signals after the subject received feedback.Experimental DesignFor each participant, a prototypical target response was learned from a short calibration session prior to the test sessions.\\xa0In test sessions, the spelling performance is highly dependent upon the subject’s attentional effort towards the target item and his/her simultaneous effort to ignore the flashes of the irrelevant items. Since subjects' attention might fluctuate, performance does too (e.g. over time, with fatigue).\\xa0Two copy-spelling conditions were used, corresponding to short and long trials, respectively:A fast mode, more error-prone condition (each item was flashed 4 times);A slower, less error-prone one (each item was flashed 8 times).At each trial, after the last flash, the subject was instructed to keep looking at the screen and wait for the feedback. The feedback consisted in the selected item, displayed in the middle of the screen in large font. Even if the feedback was incorrect, the subject was asked to then look at the next target.Download sample videoTwenty-six healthy subjects took part in this study (13 male, mean age = 28.8±5.4 (SD), range 20-37). All subjects reported normal or corrected-to-normal vision and had no previous experience with the P300-Speller paradigm or any other BCI application. Subject’s brain activity was recorded with 56 passive Ag/AgCl EEG sensors (VSM-CTF compatible system) whose placement followed the extended 10-20 system. Their signals were sampled at 600 Hz and were all referenced to the nose. The ground electrode was placed on the shoulder and impedances were kept below 10 kΩ.The subjects had to go through five copy spelling sessions. Each session consisted of twelve 5-letter words, except the fifth which consisted of twenty 5-letter words.ObjectiveIn this paradigm and BCI in general, at least in situations where a discrete feedback can be presented to the user, the EEG evoked response to the feedback can be recorded and processed online in order to evaluate whether the item selection was correct or not. This decision, if reliable, could then be used to improve the BCI performance by implementing some error correction strategy. One possible strategy for online error detection and correction has been proposed in Perrin et al. 2012. Most of the data for this competition come from this study and this paper should be cited whenever the competition data will be used and results reported.In this competition, participants are asked to submit an Error Potential detection algorithm, capable of detecting the erroneous feedbacks online and to generalize across subjects (transfer learning).Perrin, M., Maby, E., Daligault, S., Bertrand, O., & Mattout, J. Objective and subjective evaluation of online error correction during P300-based spelling. Advances in Human-Computer Interaction, 2012, 4. (link)AcknowledgementsThis competition is brought to you by  \"}, {'title': 'Click-Through Rate Prediction', 'url': 'https://www.kaggle.com/competitions/avazu-ctr-prediction', 'briefDescription': 'Predict whether a mobile ad will be clicked', 'coverImageUrl': None, 'tag': 'logloss', 'description': 'In online advertising, click-through rate (CTR) is a very important metric\\xa0for evaluating ad performance.\\xa0As a result, click prediction systems are essential and widely used for sponsored search and real-time bidding.For this competition, we have provided 11 days worth of Avazu data to build and test prediction models. Can you find a strategy that\\xa0beats standard classification algorithms? The winning models\\xa0from this competition will be released under an open-source license.'}, {'title': 'Finding Elo', 'url': 'https://www.kaggle.com/competitions/finding-elo', 'briefDescription': \"Predict a chess player's FIDE Elo rating from one game\", 'coverImageUrl': None, 'tag': 'tabular, board games, mae', 'description': \"Elite chess players are rated, ranked, analyzed, and compared\\xa0in many\\xa0ways. Classical\\xa0methods of ranking chess players have focused on game histories, paying particular attention to the relative strength of the players involved. This includes the popular FIDE Elo\\xa0score, which was the focus of one of Kaggle's first ever competitions - Elo vs. the Rest of the World.Recent\\xa0work on\\xa0chess analysis has focused on\\xa0intrinsic performance ratings, where one assesses\\xa0skill based on the quality of decisions\\xa0rather than the outcomes of games. For an example of this kind of approach, see\\xa0this draft\\xa0by\\xa0Kenneth Regan.\\xa0Two\\xa0advantages of\\xa0an intrinsic approach are an\\xa0increased\\xa0sample size (there are many more moves than games)\\xa0and the ability to approach\\xa0new challenges, such as determining whether a player is cheating by performing moves above their skill level.This competition challenges Kagglers\\xa0to determine\\xa0players' FIDE Elo ratings at the time a game is played, based solely on the moves in one\\xa0game. Do a player's moves reflect their absolute skill? Does the opponent matter? How closely does one game reflect intrinsic ability? How well\\xa0can an algorithm do? Does computational horsepower increase accuracy? Let's find out!You do not need to be a chess expert -- or even know how to play chess -- to attempt this competition. You do need patience and a computer that doesn't mind some\\xa0heat.\\xa0The dataset includes 50,000 games between elite, ranked players. As a getting-started computational bonus, Kaggle has run these games through a\\xa0chess engine\\xa0to score each move.Good luck finding Elo!\"}, {'title': 'Tradeshift Text Classification', 'url': 'https://www.kaggle.com/competitions/tradeshift-text-classification', 'briefDescription': 'Classify text blocks in documents', 'coverImageUrl': None, 'tag': 'logloss', 'description': \"In the late 90's, Yann LeCun's team\\xa0pioneered the\\xa0successful application of\\xa0machine learning to optical character recognition. 25 years later,\\xa0machine learning continues to be an invaluable tool for text processing downstream from\\xa0the OCR process.Tradeshift has created a dataset with thousands of documents, representing millions of words. In each document, several bounding boxes containing text are selected. For each piece of text, many\\xa0features are extracted and certain labels are assigned.In this competition, participants are asked to create and open source an algorithm that correctly predicts the probability that\\xa0a\\xa0piece of text belongs to a given class.\"}, {'title': 'Africa Soil Property Prediction Challenge ', 'url': 'https://www.kaggle.com/competitions/afsis-soil-properties', 'briefDescription': 'Predict physical and chemical properties of soil using spectral measurements', 'coverImageUrl': None, 'tag': 'mcrmse', 'description': 'Advances in rapid, low cost analysis of soil samples using infrared spectroscopy, georeferencing of soil samples, and greater availability of earth remote sensing data provide new opportunities for predicting soil functional properties at unsampled locations. Soil functional properties are those properties related to a soil’s capacity to support essential ecosystem services such as primary productivity, nutrient and water retention, and resistance to soil erosion. Digital mapping of soil functional properties, especially in data sparse regions such as Africa, is important for planning sustainable agricultural intensification and natural resources management.Diffuse reflectance infrared spectroscopy has shown potential in numerous studies to provide a highly repeatable, rapid and low cost measurement of many soil functional properties. The amount of light absorbed by a soil sample is measured, with minimal sample preparation, at hundreds of specific wavebands across a range of wavelengths to provide an infrared spectrum (Fig. 1). The measurement can be typically performed in about 30 seconds, in contrast to conventional reference tests, which are slow and expensive and use chemicals.Conventional reference soil tests are calibrated to the infrared spectra on a subset of samples selected to span the diversity in soils in a given target geographical area. The calibration models are then used to predict the soil test values for the whole sample set. The predicted soil test values from georeferenced soil samples can in turn be calibrated to remote sensing covariates, which are recorded for every pixel at a fixed spatial resolution in an area, and the calibration model is then used to predict the soil test values for each pixel. The result is a digital map of the soil properties.This competition asks you to predict 5 target soil functional properties from diffuse reflectance infrared spectroscopy measurements.AcknowledgementsThis competition is sponsored by the Africa Soil Information Service.'}, {'title': 'American Epilepsy Society Seizure Prediction Challenge', 'url': 'https://www.kaggle.com/competitions/seizure-prediction', 'briefDescription': 'Predict seizures in intracranial EEG recordings', 'coverImageUrl': None, 'tag': 'auc', 'description': \"Seizure forecasting systems hold promise for improving the quality of life for patients with epilepsy.Epilepsy afflicts nearly 1% of the world's population, and is characterized by the occurrence of spontaneous seizures. For many patients, anticonvulsant medications can be given at sufficiently high doses to prevent seizures, but patients frequently suffer side effects. For 20-40% of patients with epilepsy, medications are not effective -- and even after surgical removal of epilepsy-causing brain tissue, many patients continue to experience spontaneous seizures. Despite the fact that seizures occur infrequently, patients with epilepsy experience persistent anxiety due to the possibility\\xa0of a seizure occurring.Seizure forecasting systems have the potential to help patients with epilepsy lead more normal lives. In order for EEG-based seizure forecasting systems to work effectively, computational algorithms must reliably identify periods of increased probability of seizure occurrence. If these seizure-permissive brain states can be identified, devices designed to warn patients of impeding seizures would be possible. Patients could avoid potentially dangerous activities like driving or swimming, and medications could be administered only when needed to prevent impending seizures, reducing overall side effects.There is emerging evidence that the temporal dynamics of brain activity can be classified into 4 states: Interictal (between seizures, or baseline), Preictal (prior to seizure), Ictal (seizure), and Post-ictal (after seizures). Seizure forecasting requires the ability to reliably identify a preictal state that can be differentiated from the interictal, ictal, and postictal state. The primary challenge in seizure forecasting is differentiating between the preictal and interictal states. The goal of the competition is to demonstrate the existence and accurate classification of the preictal brain state in dogs and humans with naturally occurring epilepsy.The CompetitionIntracranial EEG was recorded from dogs with naturally occurring epilepsy using an ambulatory monitoring system. EEG was sampled from 16 electrodes at 400 Hz, and recorded voltages were referenced to the group average. These are long duration recordings, spanning multiple months up to a year and recording up to a hundred seizures in some dogs.In addition, datasets from patients with epilepsy undergoing intracranial EEG monitoring to identify a region of brain that can be resected to prevent future seizures are included in the contest. These datasets have varying numbers of electrodes and are sampled at 5000 Hz, with recorded voltages referenced to an electrode outside the brain. The challenge is to distinguish between ten minute long data clips covering an hour prior to a seizure, and ten minute iEEG clips of interictal activity. Seizures are known to cluster, or occur in groups. Patients who typically have seizure clusters receive little benefit from forecasting follow-on seizures. For this contest only lead seizures, defined here as seizures occurring four hours or more after another seizure, are included in the training and testing data sets. In order to avoid any potential contamination between interictal, preictal, and post-ictal EEG signals interictal segments in the canine training and test data were restricted to be at least one week before or after any seizure. In the human data, where the entire monitoring session may last less than one week, interictal data segments were restricted to be at least four hours before or after any seizure. Interictal data segments were chosen at random within these restrictions for both canine and human subjects.Participants\\xa0are invited to visit the NIH-sponsored International Epilepsy Electrophysiology portal (http://ieeg.org) to review and download annotated interictal and preictal data from other patients and animal subjects. Using ieeg.org data for additional algorithm training is permitted.AcknowledgementsThis competition is sponsored by the National Institutes of Health (NINDS), the Epilepsy Foundation, and the American Epilepsy Society.\\xa0ReferencesHowbert JJ, Patterson EE, Stead SM, Brinkmann B, Vasoli V, Crepeau D, Vite CH, Sturges B, Ruedebusch V, Mavoori J, Leyde K, Sheffield WD, Litt B, Worrell GA (2014) Forecasting seizures in dogs with naturally occurring epilepsy. PLoS One 9(1):e81920.Cook MJ, O'Brien TJ, Berkovic SF, Murphy M, Morokoff A, Fabinyi G, D'Souza W, Yerra R, Archer J, Litewka L, Hosking S, Lightfoot P, Ruedebusch V, Sheffield WD, Snyder D, Leyde K, Himes D (2013) Prediction of seizure likelihood with a long-term, implanted seizure advisory system in patients with drug-resistant epilepsy: a first-in-man study. LANCET NEUROL 12:563-571.Park Y, Luo L, Parhi KK, Netoff T (2011) Seizure prediction with spectral power of EEG using cost-sensitive support vector machines. Epilepsia 52:1761-1770.Davis KA, Sturges BK, Vite CH, Ruedebusch V, Worrell G, Gardner AB, Leyde K, Sheffield WD, Litt B (2011) A novel implanted device to wirelessly record and analyze continuous intracranial canine EEG. Epilepsy Res 96:116-122.Andrzejak RG, Chicharro D, Elger CE, Mormann F (2009) Seizure prediction: Any better than chance? Clin Neurophysiol.Snyder DE, Echauz J, Grimes DB, Litt B (2008) The statistics of a practical seizure warning system. J Neural Eng 5: 392–401.Mormann F, Andrzejak RG, Elger CE, Lehnertz K (2007) Seizure prediction: the long and winding road. Brain 130: 314–333.Haut S, Shinnar S, Moshe SL, O'Dell C, Legatt AD. (1999) The association between seizure clustering and status epilepticus in patients with intractable complex partial seizures. Epilepsia 40:1832–1834.\"}, {'title': 'First Steps With Julia', 'url': 'https://www.kaggle.com/competitions/street-view-getting-started-with-julia', 'briefDescription': 'Use Julia to identify characters from Google Street View images', 'coverImageUrl': None, 'tag': 'image, categorizationaccuracy', 'description': \"This competition is designed to help you get\\xa0started with Julia. If you are looking for a good programming language for data science, or if you are already accustomed to one language, we encourage you to also try Julia. Julia\\xa0is a relatively new language\\xa0for technical computing that attempts to combine the strengths of other popular programming languages.\\xa0Here we introduce two tutorials to highlight some of Julia's features.\\xa0The first is focused on the basics of the language.\\xa0In the second, a complete implementation of the K Nearest Neighbor algorithm is presented, highlighting features such as parallelization and speed.\\xa0Both tutorials show that\\xa0it is easy to write code in Julia, due to its\\xa0intuitive syntax and design.\\xa0The tutorials also describe some basics of\\xa0image processing and some concepts of machine learning such as cross validation.\\xa0After reviewing\\xa0them, we hope you will be motivated to write your own machine learning algorithms in Julia.This tutorial focuses on\\xa0the task of\\xa0identifying characters from Google Street View images. It differs from traditional character recognition because the data set contains different character fonts and the background is not the same for all images.\\xa0AcknowledgementsThe data\\xa0was taken from the Chars74K dataset, which\\xa0consists of images of characters selected from Google Street View images. We ask that you cite the following reference in any publication resulting from your\\xa0work:T. E. de Campos, B. R. Babu and M. Varma, Character recognition in natural images, Proceedings of the International Conference on Computer Vision Theory and Applications (VISAPP), Lisbon, Portugal, February 2009.This tutorial was developed by Luis Tandalla\\xa0during his summer 2014 internship at Kaggle.\"}, {'title': 'Liberty Mutual Group - Fire Peril Loss Cost', 'url': 'https://www.kaggle.com/competitions/liberty-mutual-fire-peril', 'briefDescription': 'Predict expected fire losses for insurance policies', 'coverImageUrl': None, 'tag': 'normalizedweightedgini', 'description': \"A Fortune 100 company, Liberty Mutual Insurance has provided a wide range of insurance products and services designed to meet our customers' ever-changing needs for over 100 years.Within the business insurance industry, fire losses account for a significant portion of total property losses. High severity and low frequency, fire losses are inherently volatile, which makes modeling them difficult. In this challenge, your task is to predict the target, a transformed ratio of loss to total insured value, using the provided information. This will\\xa0enable more\\xa0accurate identification of each policyholder’s risk exposure and the ability to tailor the insurance coverage for their specific operation.Because we seek to tap innovation both inside and outside the company, certain eligible Liberty Mutual employees are encouraged to participate in this challenge for development purposes. Refer to the competition rules for the full details.\"}, {'title': 'Display Advertising Challenge', 'url': 'https://www.kaggle.com/competitions/criteo-display-ad-challenge', 'briefDescription': 'Predict click-through rates on display ads', 'coverImageUrl': None, 'tag': 'logloss', 'description': 'Display advertising is a billion dollar effort and one of the central uses of machine learning on the Internet. However, its\\xa0data and methods are usually kept under lock and key. In this research competition, CriteoLabs is sharing a week’s worth of data\\xa0for you to develop models predicting ad click-through rate (CTR). Given a user and the page he is visiting, what is the probability that he will click on a given ad?The goal of this challenge is to benchmark\\xa0the most accurate ML algorithms for CTR estimation. All winning models will be released under an open source license. As a participant, you are given a chance to access the traffic logs from Criteo that include various undisclosed features along with the click labels.\\xa0'}, {'title': 'The Hunt for Prohibited Content', 'url': 'https://www.kaggle.com/competitions/avito-prohibited-content', 'briefDescription': 'Predict which ads contain illicit content', 'coverImageUrl': None, 'tag': 'ap@{k}', 'description': \"Avito.ru is the largest general classified website in Russia that helps connect buyers with sellers across all Russian territories. There are more than 22 million active ads on Avito and each day a huge\\xa0number of ads are added or modified. The efficiency of Avito depends heavily on the content quality --\\xa0when buyers can quickly find relevant content, sellers can sell their items in hours.The larger and more popular Avito becomes the more attractive it becomes to sell illicit items or services. Some items that people try to sell are\\xa0completely illegal while others might seem allowable but are still\\xa0prohibited by our rules. This is why all new or modified ads are thoroughly moderated by our team of human moderators.\\xa0The moderators can remove the ad if it conflicts with the Russian legislation or with the internal rules of AVITO.ru.\\xa0However, with our growth it becomes more and more challenging to thoroughly\\xa0moderate all ads. This is where machine learning comes into play.The objective of this challenge is to create a predictive model that will learn from moderators' answers how to classify if an ad contains illicit content or not.\"}, {'title': 'MLSP 2014 Schizophrenia Classification Challenge', 'url': 'https://www.kaggle.com/competitions/mlsp-2014-mri', 'briefDescription': 'Diagnose schizophrenia using multimodal features from MRI scans', 'coverImageUrl': None, 'tag': 'auc', 'description': 'Schizophrenia is a severe and disabling\\xa0mental illnesses which has no well-established, non-invasive diagnosis biomarker. Currently, due to its symptom overlap with other mental illnesses (like bipolar disorder) it can only be diagnosed subjectively, by process of elimination.This competition invites you to automatically diagnose subjects with schizophrenia based on\\xa0multimodal features derived from their brain magnetic resonance imaging (MRI) scans.The features made available in this competition are a result from\\xa0current state-of-the art developments in neuroimaging and MRI data processing. Two modalities of MRI scans are used to obtain these features: functional and structural MRI.\\xa0One challenge in this competition is how to optimally combine this type of multimodal information and select features that enhance diagnosis. Optional additional information is provided that could be helpful with this particular aspect of the task.This is an official competition of the IEEE International Workshop on Machine Learning for Signal Processing (MLSP 2014)AcknowledgementsCollection of this dataset was made at the Mind Research Network\\xa0under an NIH NIGMS Centers of Biomedical Research Excellence (COBRE) grant 5P20RR021938/P20GM103472 to Vince Calhoun (PI).'}, {'title': 'Greek Media Monitoring Multilabel Classification (WISE 2014)', 'url': 'https://www.kaggle.com/competitions/wise-2014', 'briefDescription': 'Multi-label classification of printed media articles to topics', 'coverImageUrl': None, 'tag': 'meanfscore', 'description': 'In the past, gathering information was paramount only for top-tier companies. In the information age, mining and categorization of relevant information is necessary for all companies. Media monitoring - the activity of monitoring the output of the print, online and broadcast media - allows every company to search a wide range of media, from printed media to internet publications, and be informed on their area of expertise and remain competitive.This is a multi-label classification competition for articles coming from Greek\\xa0printed media. Raw data comes from the scanning of print media, article segmentation, and optical character segmentation, and therefore is quite noisy. Each article is examined by a human annotator and categorized to one or more of\\xa0the topics being monitored. Topics range from\\xa0specific persons, products, and companies\\xa0that can be\\xa0easily categorized based on keywords, to more general semantic concepts, such as environment or economy. Building multi-label classifiers for the automated annotation of articles into topics can support the work of human annotators by suggesting a list of all topics by order of relevance, or even automate the annotation process for media and/or categories that are easier to predict. This saves valuable time and\\xa0allows a media monitoring company to expand the portfolio of media being monitored.\\xa0\\xa0OrganizersThe competition is organized by media monitoring solutions company DataScouting, media monitoring services company ENIMEROSI\\xa0and the Deparment of Informatics of the Aristotle University of Thessaloniki.\\xa0It is the challenge accompanying the 15th International Conference on\\xa0Web Information System Engineering\\xa0(WISE 2014) that will be held in Thessaloniki, Greece on 12-14 October 2014.\\xa0\\xa0\\xa0ARISTOTLE \\xa0\\xa0\\xa0UNIVERSITY OF  \\xa0\\xa0\\xa0THESSALONIKI\\xa0'}, {'title': 'Random Acts of Pizza', 'url': 'https://www.kaggle.com/competitions/random-acts-of-pizza', 'briefDescription': 'Predicting altruism through free pizza', 'coverImageUrl': None, 'tag': 'internet, text, binary classification, auc', 'description': 'Get started on this competition through Kaggle ScriptsIn machine learning, it is often said\\xa0there are no free lunches.\\xa0How wrong we were.This competition contains a dataset with 5671 textual requests for pizza from the Reddit community Random Acts of Pizza\\xa0together with their outcome (successful/unsuccessful) and meta-data. Participants must create an algorithm\\xa0capable of predicting\\xa0which requests will garner a cheesy (but sincere!) act of\\xa0kindness.\"I\\'ll write a poem, sing a song, do a dance, play an instrument, whatever! I just want a pizza,\" says one hopeful poster. What about making an algorithm?Kaggle is hosting this competition for the machine learning community to use for fun and practice. This data\\xa0was collected and graciously shared by Althoff\\xa0et al. (Buy them a pizza -- data collection is a thankless and tedious job!) We encourage participants to explore their accompanying paper\\xa0and ask that you cite the following reference in any publications that result from your work:Tim Althoff, Cristian Danescu-Niculescu-Mizil, Dan Jurafsky.\\xa0How to Ask for a Favor: A Case Study on the Success of Altruistic Requests,\\xa0Proceedings of ICWSM, 2014.'}, {'title': 'Bike Sharing Demand', 'url': 'https://www.kaggle.com/competitions/bike-sharing-demand', 'briefDescription': 'Forecast use of a city bikeshare system', 'coverImageUrl': None, 'tag': 'tabular, time series analysis, cycling, rmsle', 'description': 'Get started\\xa0on this competition through Kaggle ScriptsBike sharing systems are a means of renting bicycles where the\\xa0process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using\\xa0these systems, people are\\xa0able rent a bike from a one\\xa0location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed\\xa0is explicitly recorded. Bike sharing systems therefore function as a\\xa0sensor network, which can be used for studying\\xa0mobility in a\\xa0city. In this competition, participants are asked to combine\\xa0historical usage\\xa0patterns with weather data in order to forecast bike\\xa0rental demand in\\xa0the Capital Bikeshare program in Washington, D.C.AcknowledgementsKaggle is hosting this competition for the machine learning community to use for fun and practice. This dataset was\\xa0provided by Hadi Fanaee Tork using data from\\xa0Capital Bikeshare.\\xa0We also thank the UCI machine learning repository for hosting the dataset. If you use the problem in publication, please cite:Fanaee-T, Hadi, and Gama, Joao, Event labeling combining ensemble detectors and background knowledge, Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg.'}, {'title': \"UPenn and Mayo Clinic's Seizure Detection Challenge\", 'url': 'https://www.kaggle.com/competitions/seizure-detection', 'briefDescription': 'Detect seizures in intracranial EEG recordings', 'coverImageUrl': None, 'tag': 'mcauc', 'description': \"For individuals with drug-resistant epilepsy, responsive neurostimulation systems hold promise for augmenting current therapies and transforming epilepsy care.Of the more than two million Americans who suffer from recurrent, spontaneous epileptic seizures, 500,000 continue to experience seizures despite multiple attempts to control the seizures with medication. For these patients responsive neurostimulation represents a possible therapy capable of aborting seizures before they affect a patient's normal activities.\\xa0In order for a responsive neurostimulation device to successfully stop seizures, a seizure must be detected and electrical stimulation applied as early as possible. A seizure that builds and generalizes beyond its area of origin will be very difficult to abort via neurostimulation. Current seizure detection algorithms in commercial responsive neurostimulatiIn addition, physicians and researchers working in epilepsy must often review large quantities of continuous EEG data to identify seizures, which in some patients may be quite subtle. Automated algorithms to detect seizures in large EEG datasets with low false positive and false negative rates would greatly assist clinical care and basic research.The Competition:Intracranial EEG was recorded from dogs with naturally occurring epilepsy using an ambulatory monitoring system. EEG was sampled from 16 electrodes at 400 Hz, and recorded voltages were referenced to the group average.\\xa0In addition, datasets from patients with epilepsy undergoing intracranial EEG monitoring to identify a region of brain that can be resected to prevent future seizures are included in the contest. These datasets have varying numbers of electrodes and are sampled at 500 Hz or 5000 Hz, with recorded voltages referenced to an electrode outside the brain.AcknowledgementsThis competition is sponsored by the National Institues of Health (NINDS), and the American Epilepsy Society.\"}, {'title': 'Forest Cover Type Prediction', 'url': 'https://www.kaggle.com/competitions/forest-cover-type-prediction', 'briefDescription': 'Use cartographic variables to classify forest categories', 'coverImageUrl': None, 'tag': 'multiclass classification, forestry, categorizationaccuracy', 'description': \"Get started on this competition with\\xa0Kaggle Scripts.\\xa0No data download or local environment needed!Random forests?\\xa0Cover trees?\\xa0Not so fast, computer nerds. We're talking about the real thing.In this competition you are asked to predict the forest cover type (the predominant\\xa0kind\\xa0of tree cover) from strictly cartographic variables (as opposed to remotely sensed data). The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were then derived from data obtained from the US Geological Survey and USFS. The data is in raw form (not scaled) and contains binary columns of data for qualitative independent variables such as wilderness areas and soil type.This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.AcknowledgementsKaggle is hosting this competition for the machine learning community to use for fun and practice. This dataset was\\xa0provided by Jock A. Blackard and Colorado State University.\\xa0We also thank the UCI machine learning repository for hosting the dataset. If you use the problem in publication, please cite:Bache, K. & Lichman, M. (2013). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science\"}, {'title': 'KDD Cup 2014 - Predicting Excitement at DonorsChoose.org', 'url': 'https://www.kaggle.com/competitions/kdd-cup-2014-predicting-excitement-at-donors-choose', 'briefDescription': 'Predict funding requests that deserve an A+', 'coverImageUrl': None, 'tag': 'auc', 'description': \"DonorsChoose.org is an online charity that makes it easy to help students in need through school donations. At any time, thousands of teachers in K-12 schools propose projects requesting materials to enhance the education of their students.\\xa0When a project reaches its funding goal, they\\xa0ship the materials to the school.The 2014 KDD Cup asks participants to help DonorsChoose.org\\xa0identify projects that are exceptionally exciting to the\\xa0business, at the time of posting. While all projects on the site fulfill some kind of need, certain projects have a quality\\xa0above and beyond what is typical. By identifying and recommending such projects early, they will improve funding outcomes, better the\\xa0user experience, and help more students receive the materials they need to learn.Successful predictions may\\xa0require a broad range of analytical\\xa0skills, from natural language processing on\\xa0the need statements to data mining and\\xa0classical supervised learning on the descriptive factors around each project.About KDDKDD 2014\\xa0is a premier interdisciplinary conference that brings together researchers and practitioners from all aspects of data science, data mining, knowledge discovery, large-scale data analytics, and big data.\\xa0This year's KDD features 4 keynotes, 151 Research Track papers, 44 Industry & Government Track papers, 24 workshops, 12 tutorials, and more.AcknowledgementsData and logistical support has been graciously provided by DonorsChoose.org. DonorsChoose.org\\xa0is an online charity and 501(c)(3) nonprofit organization that makes it easy for anyone to help students in need. Public school teachers from every corner of America post classroom project requests, and donors\\xa0can give any amount to the project that most inspires them.\"}, {'title': 'Higgs Boson Machine Learning Challenge', 'url': 'https://www.kaggle.com/competitions/higgs-boson', 'briefDescription': 'Use the ATLAS experiment to identify the Higgs boson', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'The evaluation metric is\\xa0the approximate median significance (AMS):\\\\[ \\\\text{AMS} = \\\\sqrt{2\\\\left((s+b+b_r) \\\\log \\\\left(1 + \\\\frac{s}{b + b_r}\\\\right)-s\\\\right)}\\\\]wheres, b : unnormalized true positive and false positive rates, respectively,b_r =10 is the constant regularization term,\\\\\\\\(\\\\log\\\\\\\\) is the natural log.More precisely, let \\\\\\\\((y_1, \\\\ldots, y_n) \\\\in \\\\{\\\\text{b},\\\\text{s}\\\\}^n\\\\\\\\) be the vector of true test labels, let \\\\\\\\((\\\\hat{y}_1, \\\\ldots, \\\\hat{y}_n) \\\\in \\\\{\\\\text{b},\\\\text{s}\\\\}^n\\\\\\\\) be the vector of predicted (submitted) test labels, and let \\\\\\\\((w_1, \\\\ldots, w_n) \\\\in {\\\\mathbb{R}^+}^n\\\\\\\\) be the vector of weights. Then\\\\[ s = \\\\sum_{i=1}^n w_i\\\\mathbb{1}\\\\{y_i = \\\\text{s}\\\\}\\xa0\\\\mathbb{1}\\\\{\\\\hat{y}_i = \\\\text{s}\\\\} \\\\]and\\\\[ b = \\\\sum_{i=1}^n w_i\\\\mathbb{1}\\\\{y_i = \\\\text{b}\\\\} \\\\mathbb{1}\\\\{\\\\hat{y}_i = \\\\text{s}\\\\}, \\\\]where the indicator function \\\\\\\\(\\\\mathbb{1}\\\\{A\\\\}\\\\\\\\) is 1 if its argument \\\\\\\\(A\\\\\\\\) is true and 0 otherwise.For more information on the statistical model and the derivation of the metric, see the technical documentation. We have provided python code for the metric is available from the Data page and a Python starting kit.Submission InstructionsThe submission file format is\\xa0EventId,RankOrder,Class1,2,b2,541234,s3,5,b4,1,b5,542456,s...Your submission file should have a header row and three columnsEventId is a unique identifier for each event. The list of EventIds must correspond to the exact list of EventIds in test.csv, but the ordering can be arbitrary.RankOrder is a permutation of the integer list [1,550000] . The higher the rank, the more signal-like is the event. Most predictors output a real-valued score for each event in the test set, in which case RankOrder is just the ordering of the test points according to the score. The RankOrder is not used for computing the AMS, but it allows the organizers to compute other metrics (e.g., ROC) related to the classification task, which is not captured entirely by the classification alone.Class is either \"b\" or \"s\", and it indicates if your prediction (yi above in the formal definition) for the event is background or signal. The AMS will be calculated based on the (hidden) weights of events that you mark \"s\"'}, {'title': 'Billion Word Imputation', 'url': 'https://www.kaggle.com/competitions/billion-word-imputation', 'briefDescription': 'Find and impute missing words in the billion word corpus', 'coverImageUrl': None, 'tag': 'text, linguistics, levenshteinmean', 'description': \"This competition uses the billion-word benchmark corpus provided by\\xa0Chelba et al.\\xa0for language modeling. Rather than ask participants to create a classic language model and evaluate sentence probabilities -- a task which is difficult to faithfully score\\xa0in Kaggle's supervised ML setting -- we have introduced a variation\\xa0on the\\xa0language modeling task.For each sentence in the test set, we have removed exactly one word. Participants must create a model capable of inserting back the\\xa0correct missing word at the correct location in the sentence. Submissions are scored using an edit distance to allow for partial credit.We extend our thanks to authors who created this corpus and shared it for the research community to use. Please cite this paper if you use this dataset in your research: Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp Koehn: One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling, CoRR, 2013.Note: the train/test split used in this competition is different than the published\\xa0version used for language modeling. If you are creating full language models and scoring perplexity, you should download the official version of the corpus from the authors' website.\"}, {'title': 'Learning Social Circles in Networks', 'url': 'https://www.kaggle.com/competitions/learning-social-circles', 'briefDescription': 'Model friend memberships to multiple circles', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'Social Circles\\xa0help users organize their personal social networks. \\xa0These are implemented as \"circles\" on Google+, and as \"lists\" on Facebook and Twitter.\\xa0Each circle consists of a subset of a particular user\\'s friends. Such circles may be disjoint, overlap, or be hierarchically nested.The goal of this competition is to\\xa0automatically infer\\xa0users\\' social circles. You are provided\\xa0a set of users, each of whose circles must be inferred. To do this, participants have access to:A list of the user\\'s friendsAnonymized Facebook profiles of each of those friendsA network of connections between those friends (their \"ego network\")To give you an idea of how to use this data, the problem of detecting social circles has been discussed (in an academic setting) in\\xa0http://i.stanford.edu/~julian/pdfs/nips2012.pdfThose of you who\\'ve been around Kaggle for a while may remember\\xa0that we called upon you\\xa0to create this data set.\\xa0We extend our thanks to those of you who helped out. As a reward, you might be able to find yourself in the data and gain a one-row advantage?!'}, {'title': 'DecMeg2014 - Decoding the Human Brain', 'url': 'https://www.kaggle.com/competitions/decoding-the-human-brain', 'briefDescription': 'Predict visual stimuli from MEG recordings of human brain activity', 'coverImageUrl': None, 'tag': 'categorizationaccuracy', 'description': 'Understanding how the human brain works is a primary goal in neuroscience research. Non-invasive functional neuroimaging techniques, such as magnetoencephalography (MEG), are able to capture the brain activity as multiple timeseries. When a subject is presented a stimulus and the concurrent brain activity is recorded, the relation between the pattern of recorded signal\\xa0and the category of the stimulus may provide insights on the underlying mental process. Among the approaches to analyse the relation between brain activity and stimuli, the one based on\\xa0predicting the stimulus from the concurrent brain recording is called brain decoding.The goal of this competition is to predict the category of a visual stimulus presented to\\xa0a\\xa0subject from the\\xa0concurrent brain activity. The brain activity is captured with an MEG device\\xa0which records\\xa0306\\xa0timeseries at 1KHz of the magnetic field associated with\\xa0the brain currents. The categories of the visual stimulus for this competition\\xa0are two: face and scrambled face. A stimulus and the concurrent\\xa0MEG recording is called trial and thousands\\xa0of randomized trials were recorded from multiple subjects. The trials of some of the subjects, i.e. the train set, are provided to create prediction models. The remaining trials, i.e. the test set, belong to different subjects and they will be used to score the prediction models. Because of the variability across subjects in brain anatomy and in the patterns of brain activity,\\xa0a certain degree of difference is expected between the data of different subjects\\xa0and thus between the train set and the test set.BibliographyFull details of the neuroscientific experiment in which the data were collected are described in:Front. Hum. Neurosci.\\xa0http://www.frontiersin.org/Journal/10.3389/fnhum.2011.00076/abstractA brief survey of the scientific literature on the problem of decoding across subjects, together with the description of the train set of this competition and a preliminary solution in terms of transfer learning, are described in:Pattern Recognition in Neuroimaging, 2014 International Workshop onieeexplore.ieee.orghttp://arxiv.org/abs/1404.4175ConferenceThis competition is associated with\\xa0the the 19th International Conference on Biomagnetism,\\xa0Biomag 2014.\\xa0The\\xa0Biomag conference will be held in Halifax, Canada, August 24-28, 2014.OrganizationThis competition is organized by\\xa0Emanuele Olivetti, Mostafa Kia and Paolo Avesani (NeuroInformatics Lab, Fondazione Bruno Kessler and Università di Trento, IT).AcknowledgementsThe awards of this competition are funded by\\xa0Elekta Oy,\\xa0MEG International Services Ltd (MISL),\\xa0Fondazione Bruno Kessler, and Besa. We would also like to thank Daniel Wakeman (Martinos Center, MGH, USA), Richard Henson (MRC/CBU, Cambridge, UK), Ole Jensen (Donders Institute, NL), Nathan Weisz (University of Trento, IT) and Alexandre Gramfort (Telecom ParisTech, CNRS, CEA / Neurospin) for their contributions in preparing this competition.\\xa0 \\xa0 \\xa0\\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0\\xa0'}, {'title': 'The Analytics Edge (15.071x)', 'url': 'https://www.kaggle.com/competitions/the-analytics-edge-mit-15-071x', 'briefDescription': 'Learn what predicts happiness by using informal polling questions.', 'coverImageUrl': None, 'tag': 'auc', 'description': \"(Please note: this competition is only open to students of\\xa0https://www.edx.org/course/mitx/mitx-15-071x-analytics-edge-1416)What predicts happiness? In this competition, you'll be using data from Show of Hands, an informal polling platform for use on mobile devices and the web, to see what aspects and characteristics of people's lives predict happiness.Show of Hands has been downloaded over 300,000 times across Apple and Android app stores, and users have cast more than 75 million votes. In this problem, we'll use data from thousands of users and one hundred different questions to see which responses predict happiness.AcknowledgementsThis competition is brought to you by 15.071x, edX, and Show of Hands.\"}, {'title': 'Acquire Valued Shoppers Challenge', 'url': 'https://www.kaggle.com/competitions/acquire-valued-shoppers-challenge', 'briefDescription': 'Predict which shoppers will become repeat buyers', 'coverImageUrl': None, 'tag': 'auc', 'description': 'Consumer brands often offer discounts to attract\\xa0new shoppers to buy their products. The most valuable customers are those who return after this\\xa0initial incented purchase. \\xa0With enough purchase history, it is possible\\xa0to predict\\xa0which shoppers, when presented an offer, will buy\\xa0a new item. However, identifying the shopper who will become a loyal\\xa0buyer -- prior to the initial purchase -- is a more challenging task.The Acquire Valued Shoppers\\xa0Challenge asks participants\\xa0to predict which shoppers are most likely to repeat purchase. To aid with algorithmic development, we have provided complete, basket-level, pre-offer shopping history for a large set of shoppers who were targeted for an acquisition campaign. The incentive offered to that shopper and their post-incentive behavior\\xa0is also provided.This challenge provides\\xa0almost\\xa0350 million\\xa0rows of\\xa0completely anonymised transactional data from over 300,000 shoppers. It is one of the largest problems run on Kaggle to date.'}, {'title': 'Risky Business', 'url': 'https://www.kaggle.com/competitions/risky-business', 'briefDescription': 'Predict the risk of customer credit default', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'Improve credit risk models by predicting the probability of default on a consumer credit product in the next 18 months.\\xa0More accurate credit risk evaluations allow issuers of credit to be able to responsibly extend and manage credit lines for their\\xa0The goal of this contest is to make the most accuraEnter Now!This competition is only open to Masters-level participants who meet the eligibility criteria. Visit the Enter the Competition page to view the eligibility criteria and request entrance.'}, {'title': 'The Random Number Grand Challenge', 'url': 'https://www.kaggle.com/competitions/random-number-grand-challenge', 'briefDescription': 'Decode a sequence of pseudorandom numbers', 'coverImageUrl': None, 'tag': 'mae', 'description': \"Quality pseudorandom number generation forms the bedrock on which all of computing is built. From cryptography to financial markets to particle physics, it is our trust in\\xa0random numbers that props up\\xa0the modern economy and allows technology to march forth, unabated.Machine learning is incredibly powerful at recognizing statistical patterns. For this\\xa0competition, we challenge you to\\xa0apply\\xa0your\\xa0machine learning skills to predict a\\xa0set of random numbers. To date, there are no known methods for predicting this set of numbers. Some experts have said\\xa0it is too random, that it can't be done within current limitations of computing power. We believe the creativity of the Kaggle community will triumph over the cynical\\xa0doubts\\xa0of the naysayers. If there is one thing the working data scientist can do, it is extract insights from a sea of randomness.Before asking questions in the forums, we recommend reading the\\xa0authoritative source\\xa0in\\xa0this field:\\xa0A Million Random Digits with 100,000 Normal Deviates, RAND\\xa0et. al.We also provide this helpful widget to cross validate your submissions:\"}, {'title': 'Sentiment Analysis on Movie Reviews', 'url': 'https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews', 'briefDescription': 'Classify the sentiment of sentences from the Rotten Tomatoes dataset', 'coverImageUrl': None, 'tag': 'text, multiclass classification, categorizationaccuracy', 'description': '\"There\\'s a thin line between likably old-fashioned and fuddy-duddy, and The Count of Monte Cristo ... never quite settles on either side.\"The Rotten Tomatoes movie review dataset is a corpus of movie reviews used for sentiment analysis, originally collected by Pang and Lee [1]. In their work on sentiment treebanks, Socher et al. [2] used Amazon\\'s Mechanical Turk to create fine-grained labels for all parsed phrases in the corpus. This competition presents a chance to benchmark your sentiment-analysis ideas on the Rotten Tomatoes dataset. You are asked to label phrases\\xa0on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive. Obstacles like sentence negation, sarcasm, terseness, language ambiguity, and many others make this task very challenging.Kaggle is hosting this competition for the machine learning community to use for fun and practice. This competition was inspired by the work of Socher et al [2].\\xa0We encourage participants to explore the accompanying (and dare we say, fantastic) website that accompanies the paper:http://nlp.stanford.edu/sentiment/There you will find have source code, a live demo, and even an online interface to help train the model.[1]\\xa0Pang and L. Lee. 2005. Seeing stars: Exploiting class\\xa0relationships for sentiment categorization with respect\\xa0to rating scales. In ACL, pages 115–124.[2]\\xa0Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank, Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Chris Manning, Andrew Ng and Chris Potts. Conference on Empirical Methods in Natural Language Processing (EMNLP 2013).'}, {'title': 'Walmart Recruiting - Store Sales Forecasting', 'url': 'https://www.kaggle.com/competitions/walmart-recruiting-store-sales-forecasting', 'briefDescription': 'Use historical markdown data to predict store sales', 'coverImageUrl': None, 'tag': 'time series analysis, wmae', 'description': 'One challenge of modeling retail data is the need to make decisions based on limited history. If Christmas comes but once a year, so does the chance to see how strategic decisions impacted the bottom line.In this recruiting competition, job-seekers are provided with historical sales data for 45 Walmart stores located in different regions. Each store contains many departments, and participants must project the sales for each department in each store. To add to the challenge, selected holiday markdown events are included in the dataset. These markdowns are known to affect sales, but it is challenging to predict which departments are affected and the extent of the impact.Want to work\\xa0in a great environment with some of the world\\'s largest data sets? This is a chance to display your modeling mettle to the Walmart hiring teams.This competition counts towards rankings & achievements. \\xa0If you wish to be considered for an interview at Walmart, check the box \"Allow host to contact me\" when you make your first entry.\\xa0You must compete as an individual in recruiting competitions. You may only use the provided data to make your predictions.'}, {'title': 'Allstate Purchase Prediction Challenge', 'url': 'https://www.kaggle.com/competitions/allstate-purchase-prediction-challenge', 'briefDescription': 'Predict a purchased policy based on transaction history', 'coverImageUrl': None, 'tag': 'categorizationaccuracy', 'description': \"As a customer shops an insurance policy, he/she will receive a number of quotes with different coverage options before purchasing a plan. This is represented in this challenge as a series of rows that include a customer ID, information about the customer, information about the quoted policy, and the cost. Your task is to predict the purchased coverage options using a limited subset of the total interaction history. If the eventual purchase can be predicted sooner in the shopping window, the quoting process is shortened and the issuer is less likely to lose the customer's business.Using a customer’s shopping history, can you predict what policy they will end up choosing?\"}, {'title': 'CONNECTOMICS', 'url': 'https://www.kaggle.com/competitions/connectomics', 'briefDescription': 'Reconstruct the wiring between neurons from fluorescence imaging of neural activity', 'coverImageUrl': None, 'tag': 'auc', 'description': \"Understanding the brain structure and some of its disease alterations is key to research on the treatment of epilepsy, Alzheimer's disease, and other neuropathologies, as well as understanding the general function of the brain and its learning capabilities. The brain contains nearly 100 billion neurons with an average 7000 synaptic connections. \\xa0Recovering the exact wiring of the brain (connectome) at this neural level is therefore a daunting task. Traditional neuroanatomic methods of axonal tracing cannot scale up to very large networks. Could there be alternative methods to recovering neural network structures from patterns of neural activity? [Learn more ...]Today's cutting edge optical imaging of neural activity (using fluorescent calcium indicators)\\xa0provides a tool to monitor the\\xa0activity of tens of thousands of neurons simultaneously.\\xa0Mathematical algorithms capable of discovering network structures are faced with the challenge of solving a new inverse problem: recover the neural network structure of a living system given the observation of a very large population of neurons. A promising way to experimentally proceed is to use neuronal cultures. Such cultures consist in a number of individual cells (dissected and dissociated from actual brain tissue) that are plated on a cover glass and maintained for several weeks in vitro. These living neuronal networks typically contain on the order of few thousand cells. One can then monitor their activity by fluorescence imaging, reconstruct their connectivity from activity data and, finally, compare the reconstructed circuitry with the real one. However, to fully understand the degree of accuracy of the reconstruction one needs first to procure superior reconstruction algorithms: this is where you can help by entering this competition!Monitoring changes in effective connectivity patterns of a network during behavior promises to advance our understanding of learning and intelligence.\\xa0This challenge will stimulate research on\\xa0network-structure learning from neurophysiological data, including causal discovery methods. [Learn more...]Brain of the zebrafish in action. Today's cutting edge neurophysiology multi-electrode recording tools are capable of \\xa0recording (and even stimulating) of the order of 100 neurons. Optical imaging of neural activity using fluorescent calcium indicator molecules (calcium imaging) increases the number of neurons recorded by three orders of magnitude. Recently, researchers have been able to record in vivo the activity of the brain of a zebrafish embryo in 80% of its 100,000 neurons.\\xa0This video comes from the work of Arens et al. Nature \\xa0485, \\xa0471–477 (May 2012).AcknowledgementsThis competition is brought to you by ChaLearn. See our credits page.\"}, {'title': 'PAKDD 2014 - ASUS Malfunctional Components Prediction', 'url': 'https://www.kaggle.com/competitions/pakdd-cup-2014', 'briefDescription': 'Predict malfunctional components of ASUS notebooks', 'coverImageUrl': None, 'tag': 'mae', 'description': 'The goal of PAKDD 2014 competition is to predict future malfunctional components of ASUS notebooks from historical data. This will help estimate how many products will require maintenance or repair services.ASUS has provided information on its laptop shipments as well as the laptops requiring maintenance or repair services. Participants will use this information to estimate how many of each module of a specific model will require maintenance or repair services.AcknowledgementsThe organizers of PAKDD would like to thank ASUS for sponsorship of this competition.'}, {'title': 'Large Scale Hierarchical Text Classification', 'url': 'https://www.kaggle.com/competitions/lshtc', 'briefDescription': 'Classify Wikipedia documents into one of 325,056 categories', 'coverImageUrl': None, 'tag': 'macrofscore', 'description': 'We are pleased to announce the 4th edition of the Large Scale Hierarchical Text Classification (LSHTC) Challenge. The LSHTC Challenge is a hierarchical text classification competition, using very large datasets.Hierarchies are becoming ever more popular for the organization of text documents, particularly on the Web. Web directories and Wikipedia are two examples of such hierarchies. Along with their widespread use comes the need for automated classification of new documents to the categories in the hierarchy. As the size of the hierarchy grows and the number of documents to be classified increases, a number of interesting machine learning problems arise. In particular, it is one of the rare situations where data sparsity remains an issue, despite the vastness of available data: as more documents become available, more classes are also added to the hierarchy, and there is a very high imbalance between the classes at different levels of the hierarchy. Additionally, the statistical dependence of the classes poses challenges and opportunities for new learning methods.The challenge is based on a large dataset created from Wikipedia. The dataset is multi-class, multi-label and hierarchical. The number of categories is roughly 325,000 and number of the documents is 2,400,000.This challenge builds upon a series of successful challenges on large-scale hierarchical text classification. More information can be found at\\xa0http://lshtc.iit.demokritos.gr/Very Large Scale Supervised Learning TrackThis track concerns multi-label classification based on the Wikipedia dataset. The hierarchy is a graph that can have cycles.\\xa0 The number of categories is roughly 325,000 and the number of documents is 2,400,000. A document can appear in multiple classes.OrganizersIoannis Partalas, LIG, Grenoble, FranceMassih-Reza Amini, LIG, Grenoble, FranceIon Androutsopoulos, AUEB, Athens, GreeceThierry Artières, LIP6, Paris, FranceNicolas Baskiotis, LIP6, Paris, FrancePatrick Gallinari, LIP6, Paris, FranceEric Gaussier, LIG, Grenoble, FranceAris Kosmopoulos, NCSR \"Demokritos\" & AUEB, Athens, GreeceGeorge Paliouras, NCSR \"Demokritos\", Athens, GreeceAcknowledgementsClass-Y ANR project, University of Grenoble, University of Pierre and Marie Curie, NCSR \"Demokritos\", and Athens University of Economics and Business. We would also like to thank the Kaggle team for their support.'}, {'title': 'Flight Quest 2: Flight Optimization, Final Phase', 'url': 'https://www.kaggle.com/competitions/flight2-final', 'briefDescription': 'Final Phase of Flight Quest 2', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/3793/logos/header.png', 'tag': 'custom metric', 'description': 'Flight Quest Phase 2 WinnersFinal Prizes1stJose Fonollosa2ndSergey Kozub3rdWillem Mestrom4thDmytro LystopadRead more about the winners »Milestone PrizeRoman A. Prokopenko\\xa0The submissions to the Final Phase leaderboard closed on Sunday 11:59 pm UTC February 23, 2014. \\xa0The teams on the leaderboard carried forward from the Main Phase of the Flight Quest 2 competition.'}, {'title': 'Loan Default Prediction - Imperial College London', 'url': 'https://www.kaggle.com/competitions/loan-default-prediction', 'briefDescription': 'Constructing an optimal portfolio of loans', 'coverImageUrl': None, 'tag': 'mae', 'description': 'This competition asks you to determine whether a loan will default, as well as the loss incurred if it does default. Unlike traditional finance-based approaches to this problem, where one distinguishes between good or bad counterparties in a binary way, we seek to anticipate and incorporate both the default and the severity of the losses that result. In doing so, we are building a bridge between traditional banking, where we are looking at reducing the consumption of economic capital, to an asset-management perspective, where we optimize on the risk to the financial investor.This competition is sponsored by researchers at Imperial College London.'}, {'title': 'March Machine Learning Mania', 'url': 'https://www.kaggle.com/competitions/march-machine-learning-mania-2014', 'briefDescription': 'Tip off college basketball by predicting the 2014 NCAA Tournament', 'coverImageUrl': None, 'tag': 'sports, basketball, logloss', 'description': 'Each year, millions of people fill out a bracket to predict the outcome of the popular men’s college basketball tournament that tips off in March. While the odds of creating a perfect bracket are astronomical, these odds are made better by the growing amount of data collected throughout the season, including player statistics, tournament seeds, geographical factors and social media. How well can machine learning and statistical techniques improve the forecast? Presented by Intel, this competition will test how well predictions based on data stack up against a (jump) shot in the dark.We have assembled the basic elements necessary to get started with tournament prediction. The provided data covers nearly two decades of historical games, but you’re also encouraged to use data from external sources. To help turn all of that information into useful insight, Intel is making its big data technologies more affordable, available, and easier to use for everything from helping develop new scientific discoveries and business models to gaining the upper hand on good-natured predictions of sporting events.In stage one of this two-stage competition, participants will build and test their models against the previous five tournaments. In the second stage, participants will predict the outcome of the 2014 tournament. You don’t need to participate in the first stage to enter the second, but the first stage exists to incentivize model building and provide a means to score predictions. The real competition is forecasting the 2014 results, for which you’ll predict winning percentages for the likelihood of each possible matchup, not just a traditional bracket.To sweeten the pot, Intel will present the team with the most accurate predictions a $15,000 cash prize. Get started today – predictions are due by Wednesday, March 19, 2014.Please visit the FAQs for more information.'}, {'title': 'Galaxy Zoo - The Galaxy Challenge', 'url': 'https://www.kaggle.com/competitions/galaxy-zoo-the-galaxy-challenge', 'briefDescription': 'Classify the morphologies of distant galaxies in our Universe', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"Understanding how and why we are here is one of the fundamental questions for the human race. Part of the answer to this question lies in the origins of galaxies, such as our own Milky Way. Yet questions remain about how the Milky Way (or any of the other ~100 billion galaxies in our Universe) was formed and has evolved. Galaxies come in all shapes, sizes and colors: from beautiful spirals to huge ellipticals. Understanding the distribution, location and types of galaxies as a function of shape, size, and color are critical pieces for solving this puzzle.The Whirlpool Galaxy (M51). Credit: NASA and European Space AgencyWith each passing day telescopes around and above the Earth capture more and more images of distant galaxies. As better and bigger telescopes continue to collect these images, the datasets begin to explode in size. In order to better understand how the different shapes (or morphologies) of galaxies relate to the physics that create them, such images need to be sorted and classified. Kaggle has teamed up with Galaxy Zoo\\xa0and Winton Capital to produce the Galaxy Challenge, where participants will help classify galaxies into categories.\\xa0Image Credit: ESA/Hubble & NASAGalaxies in this set have already been classified once through the help of hundreds of thousands of volunteers, who collectively classified the shapes of these images by eye in a successful\\xa0citizen science\\xa0crowdsourcing project.\\xa0However, this approach becomes less feasible as data sets grow to contain of hundreds of millions (or even billions) of galaxies. That's where you come in.This competition asks you to analyze the JPG images of galaxies to find automated metrics that reproduce the probability distributions derived from human classifications. For each galaxy, determine the probability that it belongs in a particular class. Can you write an algorithm that behaves as well as the crowd does?Contributors: D. Harvey, C. Lintott, T. Kitching, P. Marshall, K. Willett, Galaxy Zoo\\xa0AcknowledgmentsThe Contributors and the rest of the Galaxy Zoo and Kaggle teams would like to say a big thank you to Winton Capital for helping make this happen. Without their support, we would have not been able to make this competition go ahead.\"}, {'title': 'Flu Forecasting', 'url': 'https://www.kaggle.com/competitions/genentech-flu-forecasting', 'briefDescription': 'Predict when, where and how strong the flu will be', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/3757/logos/header.png?t=2020-12-21-22-33-52', 'tag': 'rmsle', 'description': 'Seasonal influenza, commonly referred to as “the flu”, affects 5-20% of the United States population ever year, causing over 200,000 people to be hospitalized from associated complications. Influenza is a contagious respiratory illness, which can range in severity from mild cases with cold-like symptoms to death.Flu epidemics are fast-moving and spread rapidly due to rapid viral reproduction and short generation times (time from when an infected person infects another), which makes them very difficult to control. Additionally, there are several different strains of the influenza virus and new viruses constantly evolving.\\xa0All together, this poses a significant challenge when it comes to predicting when, where\\xa0and at what level of severity the flu will strike during the flu season.The objective of this competition is to build an algorithm that helps predict where the occurrence, peak and severity of influenza in a given season.Enter Now!This competition is only open to Masters-level participants who meet the eligibility criteria. Visit the Enter the Competition page to view the eligibility criteria and request entrance.* Image courtesy of CDC'}, {'title': \"Packing Santa's Sleigh\", 'url': 'https://www.kaggle.com/competitions/packing-santas-sleigh', 'briefDescription': \"He's making a list, checking it twice; to fill up his sleigh, he needs your advice\", 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"It's that time of year again, when Santa and his helpers gear up for their big night. Last year's path recommendations were such a success that Santa is back for more. As the latest in a line of many data science converts, Santa is looking to you to help pack his sleigh. Problem DescriptionGiven a list of presents, pack them in Santa's sleigh as compactly as possible and in the best order possible.The sleigh and presents are discretized and described in units of the fundamental length unit \\\\\\\\(\\\\ell\\\\\\\\). The sleigh is 1000 x 1000 with infinite vertical extent as needed by your highest placed present. The cells of the sleigh go from 1 to 1000 for the length and width, and 1 to infinity in height.Presents come in random sizes and are represented by their extent in the x, y, and z dimensions.\\xa0Each present has\\xa0PresentId,Dimension1,Dimension2,Dimension31,2,5,32,243,207,73Present 1 is 2 x 5 x 3 \\\\\\\\(\\\\ell^3\\\\\\\\) and Present 2 is 243 x 207 x 73 \\\\\\\\(\\\\ell^3\\\\\\\\). Presents can be packed in any orientation provided they are parallel and perpendicular to the x-y-z axes, meaning they can be rotated in any direction by multiples of 90\\\\\\\\(^\\\\circ\\\\\\\\) but not, for example, by 60\\\\\\\\(^\\\\circ\\\\\\\\).\\xa0Please see the evaluation page to learn how your packing configurations will be scored and for the submission file schema.AcknowledgementsThis competition is brought to you by MathWorks, creators of MATLAB® and Simulink®. Learn more about MathWorks.\"}, {'title': 'Boston Data Festival Hackathon', 'url': 'https://www.kaggle.com/competitions/boston-data-festival-hackathon', 'briefDescription': 'Can you make a better prediction than a monkey with a dart?', 'coverImageUrl': None, 'tag': 'auc', 'description': 'Boston Data Festival is hosting a Hackathon on Sunday 11/10/13 from 10 am to 6 pm. The event will take place at Hack/Reduce (275 Third Street, Cambridge, MA).The goal of the Hackathon is to predict the directional accuracy of a stock prices. The following cash prices will be awarded!1st place: $5002nd place: $250Best submission using Matlab: $250Self-respect from doing better than a monkey throwing darts: Priceless.During the Hackathon every participant can use a free Matlab license.AcknowledgementsWe thank MathWorks for providing free licences for competitors during the competition.\\xa0'}, {'title': 'As the World Churns', 'url': 'https://www.kaggle.com/competitions/deloitte-churn-prediction', 'briefDescription': 'Predict which customers will leave an insurance company in the next 12 months.', 'coverImageUrl': None, 'tag': 'mcauc', 'description': 'Understanding customer loyalty is an important part of any business. The ability to predict ahead of time when a customer is likely to churn can\\xa0enable early intervention processes to be put in place, and ultimately a reduction in customer churn.\\xa0\\xa0This competition seeks a solution for predicting which current customers of an insurance company will leave in 12 months time, and when.This competition is now closed to new entrants.'}, {'title': 'CIFAR-10 - Object Recognition in Images', 'url': 'https://www.kaggle.com/competitions/cifar-10', 'briefDescription': 'Identify the subject of 60,000 labeled images', 'coverImageUrl': None, 'tag': 'categorizationaccuracy', 'description': \"CIFAR-10 \\xa0is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class. It was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.Kaggle is hosting a CIFAR-10 leaderboard for the machine learning community to use for fun and practice. You can see how your approach compares to the latest research methods on Rodrigo Benenson's classification results page.Please cite this technical report if you use this dataset:\\xa0Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.\"}, {'title': 'Multi-label Bird Species Classification - NIPS 2013', 'url': 'https://www.kaggle.com/competitions/multilabel-bird-species-classification-nips2013', 'briefDescription': 'Identify which of 87 classes of birds and amphibians are present into 1000 continuous wild sound recordings', 'coverImageUrl': None, 'tag': 'auc', 'description': 'The Neural Information Processing Scaled for Bioacoustics (NIPS4B)\\xa0bird song\\xa0competition asks participants to identify which of 87 sound classes of birds and their ecosystem are present in 1000 continuous wild recordings from different places in Provence, France. The data is provided by the BIOTOPE society, which maintains the largest collection of wild recordings of birds in Europe. This challenge is a more complex task than the previous\\xa0ICML4B challenge, in which 77 teams participated (see proceedings at sabiod.org).For more information about the Neural Information Processing Scaled for Bioacoustics workshop, please visit the official site.OrganizersPr. H. Glotin - Institut Universitaire de France, CNRS LSIS and USTV, glotin@univ-tln.frO. Dufour - CNRS LSIS, FR Dr. Y. Bas - BIOTOPE, FR'}, {'title': \"Conway's Reverse Game of Life\", 'url': 'https://www.kaggle.com/competitions/conway-s-reverse-game-of-life', 'briefDescription': 'Reverse the arrow of time in the Game of Life', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/3638/logos/header.png?t=2020-08-31-19-58-33', 'tag': 'mae', 'description': 'The Game of Life is a cellular automaton created by mathematician John Conway in 1970. The game consists of a board of cells that are either on or off. One creates an initial configuration of these on/off states and observes how it evolves. There are four simple rules to determine the next state of the game board, given the current state:Any live cell with fewer than two live neighbours dies, as if by underpopulation.Any live cell with two or three live neighbours lives on to the next generation.Any live cell with more than three live neighbours dies, as if by overpopulation.Any dead cell with exactly three live neighbours becomes a live cell, as if by reproduction.These simple rules result in many interesting behaviors and have been the focus of a large body of mathematics. \\xa0As Wikipedia tells it,Ever since its publication, Conway\\'s Game of Life has attracted much interest, because of the surprising ways in which the patterns can evolve. Life provides an example of emergence and self-organization. It is interesting for computer scientists, physicists, biologists, biochemists, economists, mathematicians, philosophers, generative scientists and others to observe the way that complex patterns can emerge from the implementation of very simple rules. The game can also serve as a didactic analogy, used to convey the somewhat counter-intuitive notion that \"design\" and \"organization\" can spontaneously emerge in the absence of a designer. For example, philosopher and cognitive scientist Daniel Dennett has used the analogue of Conway\\'s Life \"universe\" extensively to illustrate the possible evolution of complex philosophical constructs, such as consciousness and free will, from the relatively simple set of deterministic physical laws governing our own universe.The emergence of order from simple rules begs an interesting question--what happens if we set time backwards?This competition is an experiment to see if machine learning (or optimization, or any method) can predict the game of life in reverse. \\xa0Is the chaotic start of Life predictable from its orderly ends? \\xa0We have created many games, evolved them, and provided only the end boards. You are asked to predict the starting board that resulted in each end board. Although some people have examined this problem, it is unknown (at least, to us...) just how difficult this will be.'}, {'title': 'Personalized Web Search Challenge', 'url': 'https://www.kaggle.com/competitions/yandex-personalized-web-search-challenge', 'briefDescription': 'Re-rank web documents using personal preferences', 'coverImageUrl': None, 'tag': 'ndcg@{k}', 'description': 'The Personalized Web Search Challenge provides a unique opportunity to consolidate and scrutinize the work from industrial labs on personalizing web search using user-logged search behavior context. It provides a fully anonymized dataset shared by Yandex, which has anonymized user ids, queries, query terms, urls, url domains and clicks.This Challenge and the shared dataset will enable a whole new set of researchers to study the problem of personalizing web search experience. The Personalized Web Search Challenge is a part of series of contests organized by Yandex over many years. This year’s event is the eighth\\xa0since 2004. In previous years, participants tried to learn to rank documents,\\xa0predict traffic jams,\\xa0find similar images,\\xa0predict relevance of documents using search logs\\xa0and detect search engine switchings in search sessions.The Challenge is intended as a logical follow-up to the previous two\\xa0challenges. We ask participants to re-rank URLs of each SERP\\xa0returned by the search engine according to the personal preferences of the\\xa0users. In other words, participants need to personalize search using the\\xa0long-term (user history based) and short-term (session-based) user context. The\\xa0evaluation relies on a variant of a dwell-time based model of personal\\xa0relevance and is data-driven, as it is presently accepted in the\\xa0state-of the-art research on personalized search.The Challenge is a part of the Web Search Click Data workshop (WSCD 2014) and the reports of the best teams are welcome to be presented at this workshop, to be held at\\xa0WSDM 2014 conference, on 28th February in New York, USA. The workshop is organized by Pavel Serdyukov (Yandex),\\xa0Georges Dupret (Yahoo!) and Nick Craswell (Microsoft Research/Bing).\\xa0'}, {'title': 'See Click Predict Fix', 'url': 'https://www.kaggle.com/competitions/see-click-predict-fix', 'briefDescription': 'Predict which 311 issues are most important to citizens', 'coverImageUrl': None, 'tag': 'rmsle', 'description': 'This competition is the successor to the See Click Predict Fix Hackathon.\\xa0The purpose of both competitions is to quantify and predict how people will react to a specific 311 issue. What makes an issue urgent? What do citizens really care about? How much does location matter? Being able to predict the most pressing 311 topics will allow governments to focus their efforts on fixing the most important problems. The data set for the competitions contains several hundred thousand 311 issues from four cities.For those who are more interested in using the data for visualization or \"non-predictive\" data mining, we have added a $500 visualization prize. You may submit as many entries as you wish via the Visualization page. If you\\'re plotting issues on maps, displaying the text in some meaningful way, or making any other creative use of the data, save it and post it!About 311311 is a mechanism by which citizens can express their desire to solve a problem the city or government by submitting a description of what needs to be done, fixed, or changed. In effect, this provides a high degree of transparency between government and its constituents. Once an issue has been established, citizens can vote and make comments on the issue so that government officials have some degree of awareness about what is the most important issue to address.SponsorsThe meeting space has been provided by Microsoft. \\xa0Prize money is graciously offered by our sponsors:On the citizen side, SeeClickFix leverages crowdsourcing to help both maintain the flow of incoming requests but show the public how effective you can be. When anyone in the community can report or comment on any issue, the entire group has a better perspective on what\\'s happening--and how to fix it effectively.For governments, SeeClickFix acts as a completely-customizable CRM that plugs into your existing request management tools. From types of service requests to managing different watch areas, SeeClickFix helps better mA public policy entrepreneur and open innovation expert David advises numerous governments on open government and open data and works with leading non-profits and businesses on strategy, open innovation and community management. In addition to his work, David is an affiliate with the Berkman Centre for Internet and Society at Harvard where he is looking at issues surrounding the politics of data.You can find David\\'s writing on open innovation, public policy, public sector renewal and open source systems at his blog, or at TechPresident. In addition to his writing, David is frequently invited to speak on open government, policy making, negotiation and strategy to executives, policymakers, and students.You can read a background on how this challenge came to be here.'}, {'title': 'See Click Predict Fix - Hackathon', 'url': 'https://www.kaggle.com/competitions/the-seeclickfix-311-challenge', 'briefDescription': 'Predict which 311 issues are most important to citizens', 'coverImageUrl': None, 'tag': 'rmsle', 'description': '>>\\xa0View the San Francisco venue live\\xa0<<Competition ends:Save the date! You\\'re invited. We are organizing not one but two exciting competitions: a 24-hour hackathon followed by a deeper, two-month dive.\\xa0The purpose of both competitions is to quantify and predict how people will react to a specific 311 issue. What makes an issue urgent? What do citizens really care about? How much does location matter? Being able to predict the most pressing 311 topics will allow governments to focus their efforts on fixing the most important problems. The data set for both competitions contains several hundred thousand 311 issues from four cities.For those in the Bay Area: on the evening of September 27 to the evening of September 28, we will convene at Microsoft San Francisco (835 Market St Ste 700, San Francisco, CA), in the heart of the shopping district. \\xa0At that place and time, we will release the password to the competition data. \\xa0Please register on the meetup page if you plan to attend.\\xa0Come see, predict, and fix by working with actual city data on real city problems.Those outside the Bay Area can still participate in the Hackathon, and also in the ensuing longer competition.For those who are more interested in using the data for visualization or \"non-predictive\" data mining, we have added a $500 visualization prize to both the hackathon and the longer competition. \\xa0When the competition opens, you may submit as many entries as you wish via the Visualization page. \\xa0If you\\'re plotting issues on maps, displaying the text in some meaningful way, or making any other creative use of the data, save it and post it!Note: the data will be uploaded prior to the\\xa0hackathon\\xa0 \\xa0The data will be encrypted and the key released to participants at the start of the hackathon. Because this is a live event and delays are possible, the start time is approximate. Please be sure you have a program capable of handling encrypted .7z files.About 311311 is a mechanism by which citizens can express their desire to solve a problem the city or government by submitting a description of what needs to be done, fixed, or changed. In effect, this provides a high degree of transparency between government and its constituents. Once an issue has been established, citizens can vote and make comments on the issue so that government officials have some degree of awareness about what is the most important issue to address.SponsorsThe meeting space has been provided by Microsoft. \\xa0Prize money is graciously offered by our sponsors:On the citizen side, SeeClickFix leverages crowdsourcing to help both maintain the flow of incoming requests but show the public how effective you can be. When anyone in the community can report or comment on any issue, the entire group has a better perspective on what\\'s happening--and how to fix it effectively.For governments, SeeClickFix acts as a completely-customizable CRM that plugs into your existing request management tools. From types of service requests to managing different watch areas, SeeClickFix helps better mA public policy entrepreneur and open innovation expert David advises numerous governments on open government and open data and works with leading non-profits and businesses on strategy, open innovation and community management. In addition to his work, David is an affiliate with the Berkman Centre for Internet and Society at Harvard where he is looking at issues surrounding the politics of data.You can find David\\'s writing on open innovation, public policy, public sector renewal and open source systems at his blog, or at TechPresident. In addition to his writing, David is frequently invited to speak on open government, policy making, negotiation and strategy to executives, policymakers, and students.You can read a background on how this challenge came to be here.'}, {'title': 'Partly Sunny with a Chance of Hashtags', 'url': 'https://www.kaggle.com/competitions/crowdflower-weather-twitter', 'briefDescription': 'What can a #machine learn from tweets about the #weather?', 'coverImageUrl': None, 'tag': 'rmse', 'description': 'In this competition you are provided a set of tweets related to the weather. The challenge is to analyze the tweet and determine whether it has a positive, negative, or neutral sentiment, whether the weather occurred in the past, present, or future, and what sort of weather the tweet references. It\\'s a lot to mine from so few characters, but if the going gets tough you can always blame the weather...\"Please knock out the power giant storm that is passing thru....please.\" -Tweet #74096CrowdFlowerWe are excited to team up with CrowdFlower on the first of what we hope will be many fun machine learning projects. CrowdFlower is debuting a new open data library and we\\'re always looking for an excuse to have a competition. Why is this exciting? Sweet, sweet Labels.Data repositories sometimes have more in common with a landfill than a library. They\\'re home to tattered piles of spreadsheets in odd formats with nary a shred of documentation to tell the GDP of Chile from the migratory patterns of North American goldfinches. If creating value from this digital exhaust is a defining theme of the big data explosion, most repositories leave you choking on the diesel fumes of data disappointment. Such data is great if you are doing a report on the GDP of Chile, but not so useful if you are doing machine learning, or its red-headed step child, data science.Crowdflower\\'s data sets provide the thing that makes so many repositories fall short - data paired with labels. One can decide whether two English sentences are related, make judgments about yogurt chatter, or rank emotions on tweets about nuclear energy. It\\'s all about the (wo)manpower to label what these bytes actually mean.The Open Data LibraryCrowdFlower Open Data Library is a repository of real data set samples that developers, researchers and data scientists can download and use to test and improve algorithms. Our mission is to encourage users to explore the possibilities and power of crowdsourcing. Open Data is free, available to anyone, and ready-to-use with CrowdFlower’s Platform.New data sets are continuously added to CrowdFlower Open Data Library as users of the CrowdFlower Platform opt-in to share their data with the crowdsourcing community. Sample data sets currently available include tweets for sentiment and topic analysis, word combinations to test similarities, sentence combinations to test related topics, and more. Learn more at www.crowdflower.com.'}, {'title': 'Flight Quest 2: Flight Optimization, Main Phase', 'url': 'https://www.kaggle.com/competitions/flight2-main', 'briefDescription': 'Optimize flight routes based on current weather and traffic.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/3611/logos/header.png', 'tag': 'custom metric', 'description': 'These pages describe the Main phase of this competition, which is now closed. Click here to visit the final phase of Flight Quest 2.Think you can change the future of flight?Did you know airlines are constantly looking for ways to make flights more efficient? From gate conflicts to operational challenges to air traffic management, the dynamics of a flight can change quickly and lead to costly delays.There is good news. Advancements in real-time big data analysis are changing the course of flight as we know it. Imagine if the pilot could augment their decision-making process with “real time business intelligence” — information available in the cockpit that would allow them to make adjustments to their flight patterns.\\xa0Your challenge, should you decide to accept it:\\xa0Use the different data sets found on this page under Get the Data to develop a usable\\xa0and scalable algorithm that delivers a real-time flight profile to the pilot, helping them\\xa0make flights more efficient and reliably on time. For background on the competition structure, visit the Basic Structure page.Be sure to check the Forums regularly to stay on top of the latest competition news.Download data »  Make a submission » '}, {'title': 'Dogs vs. Cats', 'url': 'https://www.kaggle.com/competitions/dogs-vs-cats', 'briefDescription': 'Create an algorithm to distinguish dogs from cats', 'coverImageUrl': None, 'tag': 'categorizationaccuracy', 'description': \"In this competition, you'll write an algorithm to classify whether images contain either a dog or a cat. \\xa0This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.Deep Blue beat Kasparov at chess in 1997.Watson beat the brightest trivia minds at Jeopardy in 2011.Can you tell Fido from Mittens in 2013?The Asirra data setWeb services are often protected with a challenge that's supposed to be easy for people to solve, but difficult for computers. Such a challenge is often called a\\xa0CAPTCHA\\xa0(Completely Automated Public Turing test to tell Computers and Humans Apart) or HIP (Human Interactive Proof). HIPs are used for many purposes, such as to reduce email and blog spam and prevent brute-force attacks on web site passwords.Asirra (Animal Species Image Recognition for Restricting Access) is a HIP that works by asking users to identify photographs of cats and dogs. This task is difficult for computers, but studies\\xa0have shown that people can accomplish it quickly and accurately. Many even think it's fun! Here is an example of the Asirra interface:Asirra is unique because of its partnership with\\xa0Petfinder.com, the world's largest site devoted to finding homes for homeless pets. They've provided Microsoft Research with over\\xa0three million images\\xa0of cats and dogs, manually classified by people at thousands of animal shelters across the United States. Kaggle is fortunate to offer a subset of this data for fun and research.\\xa0Image recognition attacksWhile random guessing is the easiest form of attack, various forms of image recognition can allow an attacker to make guesses that are better than random. There is enormous diversity in the photo database (a wide variety of backgrounds, angles, poses, lighting, etc.), making accurate automatic classification difficult. In an informal poll conducted many years ago, computer vision experts posited that a classifier with better than 60% accuracy would be difficult without a major advance in the state of the art. For reference, a 60% classifier improves the guessing probability of a 12-image HIP from 1/4096 to 1/459.State of the artThe current literature suggests machine classifiers can score above 80% accuracy on this task [1]. Therfore, Asirra is no longer considered safe from attack. \\xa0We have created this contest to benchmark the latest computer vision and deep learning approaches to this problem. Can you crack the CAPTCHA? Can you improve the state of the art? Can you create lasting peace between cats and dogs?Okay, we'll settle for the former.\\xa0AcknowledgementsWe extend our thanks to Microsoft Research for providing the data for this competition.\"}, {'title': 'Personalize Expedia Hotel Searches - ICDM 2013', 'url': 'https://www.kaggle.com/competitions/expedia-personalized-sort', 'briefDescription': 'Learning to rank hotels to maximize purchases', 'coverImageUrl': None, 'tag': 'ndcg@{k}', 'description': 'Expedia is the world’s largest online travel agency (OTA) and powers search results for millions of travel shoppers every day. In this competitive market matching users to hotel inventory is very important since users easily jump from website to website. As such, having the best ranking of hotels (“sort”) for specific users with the best integration of price competitiveness gives an OTA the best chance of winning the sale.For this contest, Expedia has provided a dataset that includes shopping and purchase data as well as information on price competitiveness. The data are organized around a set of “search result impressions”, or the ordered list of hotels that the user sees after they search for a hotel on the Expedia website. In addition to impressions from the existing algorithm, the data contain impressions where the hotels were randomly sorted, to avoid the position bias of the existing algorithm. The user response is provided as a click on a hotel or/and a purchase of a hotel room.Appended to impressions are the following:1) Hotel characteristics2) Location attractiveness of hotels3) User’s aggregate purchase history4) Competitive OTA informationModels will be scored via performance on a hold-out set.'}, {'title': 'Facebook Recruiting III - Keyword Extraction', 'url': 'https://www.kaggle.com/competitions/facebook-recruiting-iii-keyword-extraction', 'briefDescription': 'Identify keywords and tags from millions of text questions', 'coverImageUrl': None, 'tag': 'meanfscore', 'description': 'Looking for a data science position at Facebook? \\xa0After two successful prior Kaggle competitions, Facebook continues their mission to identify the best data scientists and software engineers that Kaggle has to offer. In this third installment, they seek candidates who have experience text mining large amounts of data.This competition tests your text skills on a large dataset from the Stack Exchange sites. \\xa0The task is to predict the tags (a.k.a. keywords, topics, summaries), given only the question text and its title. The dataset contains content from disparate stack exchange sites, containing a mix of both technical and non-technical questions. Positions are available in Menlo Park, Seattle, New York City, and London; candidates must have, or be eligible to obtain, authorization to work in the US or UK.Please note: you must compete as an individual in recruiting competitions. You may only use the data provided to make your predictions. Crawling stack exchange sites to look up answers is not permitted.\\xa0Facebook will review the code of the top participants before deciding whether to offer an interview.\\xa0This competition counts towards rankings & achievements. \\xa0If you wish to be considered for an interview at Facebook, check the box \"Allow host to contact me\" when you make your first entry.AcknowledgementsWe thank Stack Exchange (and its users) for generously releasing the source dataset through its Creative Commons Data Dumps. All data is licensed under the cc-by-sa license.'}, {'title': 'StumbleUpon Evergreen Classification Challenge', 'url': 'https://www.kaggle.com/competitions/stumbleupon', 'briefDescription': 'Build a classifier to categorize webpages as evergreen or non-evergreen', 'coverImageUrl': None, 'tag': 'internet, tabular, text, auc', 'description': 'StumbleUpon is a user-curated web content discovery engine that recommends relevant, high quality pages and media to its users, based on their interests. While some pages we recommend, such as news articles or seasonal recipes, are only relevant for a short period of time, others maintain a timeless quality and can be recommended to users long after they are discovered. In other words, pages can either be classified as \"ephemeral\" or \"evergreen\". The ratings we get from our community give us strong signals that a page may no longer be relevant - but what if we could make this distinction ahead of time? A high quality prediction of \"ephemeral\" or \"evergreen\" would greatly improve a recommendation system like ours.Many people know evergreen content when they see it, but can an algorithm make the same determination without human intuition? Your mission is to build a classifier which will evaluate a large set of URLs and label them as either evergreen or ephemeral. Can you out-class(ify) StumbleUpon?\\xa0As an added incentive to the prize, a strong performance in this competition may lead to a career-launching internship at one of the best places to work in San Francisco.'}, {'title': 'The Big Data Combine Engineered by BattleFin', 'url': 'https://www.kaggle.com/competitions/battlefin-s-big-data-combine-forecasting-challenge', 'briefDescription': 'Predict short term movements in stock prices using news and sentiment data provided by RavenPack ', 'coverImageUrl': None, 'tag': 'mae', 'description': 'The Big Data Combine engineered by BattleFin are rapid fire, live tryouts for computer scientists with elite predictive analytic skills intent on monetizing their models.\\xa0The first stage of the competition is a predictive modeling competition that requires participants to develop a model that predicts stock price movements using sentiment data provided by RavenPack. Traders, analysts and investors are always looking for techniques to better predict price movements. \\xa0Knowing whether a security will increase or decrease allows traders to make better investment decisions and manage risk more effectively.\\xa0This competition is designed to identify people with the talent to create a predictive model using financial data. Competitors are given intraday trading data showing stock price movements at 5 minute intervals and asked to predict the change two hours in the future. The winners of the predictive modeling phase are invited to the \"live\" Big Data Combine tryouts in Miami, FL. Up to 12 finalists will be selected to compete in the live event in Miami. The lucky few will pitch their predictive model to expert judges and an engaged audience. They have only three minutes to present in non-technical terms three items: personal background, predictive model description, and how they would use there model to make money in finance. If their model and presentation impresses our judges, they will be eligible to work with BattleFin and Deltix to convert their predictive model into a trading strategy.Master of Ceremonies (\"MC\")Matt Iseman - Actor, Comedian, Host of American Ninja WarriorMr. Iseman has hosted the game shows Scream Play on E! and Casino Night on the GSN. He currently appears as a regular cast member on the home makeover show Clean House, and its companion outtakes show, Clean House Comes Clean, both on the Style Network. Additionally, he hosted season 2 and 3 of American Ninja Warrior on the channel G4. He also has worked episodically in television shows including The Drew Carey Show, NCIS, and General Hospital. He has appeared on the syndicated MAD TV, Comedy Central’s Premium Blend, Fox’s The Best Damn Sports Show Period, and Fox News Channel’s Red Eye w/ Greg Gutfeld. Mr. Iseman was also the host of Sports Soup, a spin-off of E!\\'s The Soup, on Versus. Style Network and Versus are owned by Comcast. Iseman began working with American Ninja Warrior (G4) in 2010. He uses his great athleticism and work as a comedian to add his style to the show with Johnny Moseley (American Professional Freestyle Skier), and Angela Sun (Sideline Correspondent).JudgesIlya Gorelik, CEO of Deltix Inc. CEO, Ilya Gorelik is responsible for setting the strategic direction of the company, as well as overseeing global product development, sales and marketing.Ilya has more than 15 years of experience managing large-scale software projects and teams. He was one of the key development leaders of PTC, where he worked from 1989 to 1998, attaining the position of Senior VP of Engineering and Chief Technology Officer. From 1998 until 2000, Ilya was Senior VP of Product Strategy and Development and Chief Scientist for FirePond. From 2000 until founding Deltix in 2005, Ilya worked as Advisory CTO for HighRoads and several other software technology companies. Ilya has a Ph.D. in ComputationalMechanics from Moscow Technical University, he received an MS in Mechanical Engineering from Minsk Technical University.Peter Hafez, Head Quantitative Research at RavenPackPeter is an award-winning expert in the field of applied news analytics and has consulted numerous leading trading and investment firms on how to take advantage of news analytics in financial markets. Peter has more than 10 years of experience in quantitative finance with companies such as Standard & Poor\\'s, Credit Suisse First Boston, and Saxo Bank. He is a recognized speaker at conferences on behavioral finance and algorithmic trading. Peter holds a Master\\'s degree in Quantitative Finance from City University\\'s Cass Business School along with an undergraduate degree in Economics from Copenhagen University.Nabyl Charania, Managing Director at Rokk3r LabsNabyl is a Co-Founder and Managing Director at Rokk3r Labs.\\xa0 Rokk3r Labs is Miami based Venture Capital firm with 35 employees.\\xa0 Rokk3r Labs fuses entrepreneurial and professional talent to help entrepreneurs create ideas, prototypes, products and generally invests in disruptive companies designed for the modern hyper-connected world. Prior,\\xa0he was a Founder and Managing Director at Decipher Labs Inc. He graduated from University of Waterloo in 2000.Zeid Barakat, Co-Founder at Flyberry Capital LLC\\xa0Zeid is a Co-Founder of Flyberry Capital a Boston based hedge fund that utilizes a Big Data strategy. Zeid works with ‘best-in class’ MIT & Harvard computer scientists and machine learning experts to develop proprietary trading strategies, focused on event-based arbitrage. In charge of dfining corporate growth strategy,business development, marketing, managing Board of Advisers, and fundraising. He is an Entrepreneur in high-tech companies, focused on novel approaches to biotechnology, healthcare and financial services. He earned MBA degree in General Management and Entrepreneurship from MIT in 2008.About BattleFinBattleFin is a tournament platform that crowdsources the world\\'s best investment talent. The firm uses rapid fire, real capital tournaments to democratically identify up and coming investment talent. BattleFin has recently been featured in Bloomberg Business Week in an article titles \"The Hedge Fund Hunger Games\". The firm is passionate about leveling the playing field in finance so that anyone with an internet connection can participate in its tournaments. The firm specializes in finding the hedge fund managers of tomorrow. To learn more about BattleFin visit BattleFin.com.About DeltixFounded in 2005 and with more than 50 staff, Deltix has established itself as a leader in the growing domain of software and services for quantitative research and systematic automated trading. The Deltix Product Suite is an end-to-end platform for all phases of the alpha discovery and trading life-cycle; including data collection and aggregation, model development, back-testing, optimization, simulation, and deployment to production trading.About RavenPackFinancial firms are overloaded with information and have turned to computers to read news and other media. What would take days for an investment professional to read and interpret takes computers only a few milliseconds. Now financial institutions can react much faster to the ever increasing amounts of news and information available for making investment decisions. Powered by a proprietary text analysis platform, RavenPack the tournament data sponsor, analyzes novel and relevant stories published by major news sources to look for key scheduled and unexpected geopolitical, macro-economic and corporate events, topics and opinions that indicate changes in market sentiment. Sampled news sources represent the most reliable and authoritative publishers of business and financial news.RavenPack continuously analyzes relevant information from Dow Jones Newswires, regional editions for the Wall Street Journal, and Barron’s to produce real time news sentiment scores and events from entities across multiple asset classes, including currencies, commodities, organizations, companies, sectors, and industries.'}, {'title': 'Flight Quest 2: Flight Optimization, Milestone Phase', 'url': 'https://www.kaggle.com/competitions/flight2-milestone', 'briefDescription': 'Optimize flight routes based on current weather and traffic.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/3521/logos/header.png', 'tag': 'custom metric', 'description': 'These pages describe the first Milestone phase of this competition, which is now closed. Click here to visit the current phase of Flight Quest 2.Think you can change the future of flight?Did you know airlines are constantly looking for ways to make flights more efficient? From gate conflicts to operational challenges to air traffic management, the dynamics of a flight can change quickly and lead to costly delays.There is good news. Advancements in real-time big data analysis are changing the course of flight as we know it. Imagine if the pilot could augment their decision-making process with “real time business intelligence” — information available in the cockpit that would allow them to make adjustments to their flight patterns.\\xa0Your challenge, should you decide to accept it:\\xa0Use the different data sets found on this page under Get the Data to develop a usable\\xa0and scalable algorithm that delivers a real-time flight profile to the pilot, helping them\\xa0make flights more efficient and reliably on time. For background on the competition structure, visit the Basic Structure page.Be sure to check the Forums regularly to stay on top of the latest competition news.Download data »  Make a submission » '}, {'title': 'MasterCard - Data Cleansing Competition', 'url': 'https://www.kaggle.com/competitions/mastercard-data-cleansing-competition-finals', 'briefDescription': 'Improve the quality of information within transaction data', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'This is a private, invitation-only competition. The relevant information is provided only to contestants. The competition is closed to new entrants.Qualification for future private competitions is based solely on objective leaderboard performance in competitions. '}, {'title': 'Accelerometer Biometric Competition', 'url': 'https://www.kaggle.com/competitions/accelerometer-biometric-competition', 'briefDescription': 'Recognize users of mobile devices from accelerometer data', 'coverImageUrl': None, 'tag': 'auc', 'description': 'Since everyone moves differently and accelerometers are fast becoming ubiquitous, this competition is designed to investigate the feasibility of using accelerometer data as a biometric for identifying users of mobile devices.Seal has collected accelerometer data from several hundred users over a period of several months during normal device usage. To collect the data, we published an app on Googles’s Android PlayStore that samples accelerometer data in the background and posts it to a central database for analysis.We have uploaded approximately 60 million unique samples of accelerometer data collected from 387 different devices. These are split into equal sets for training and test. Samples in the training set are labeled with the unique device from which the data was collected. The test set is demarcated into 90k sequences of consecutive samples from one device. \\xa0A file of test questions is provided in which you are asked to determine whether the accelerometer data came from the proposed device.'}, {'title': 'AMS 2013-2014 Solar Energy Prediction Contest', 'url': 'https://www.kaggle.com/competitions/ams-2014-solar-energy-prediction-contest', 'briefDescription': 'Forecast daily solar energy with an ensemble of weather models', 'coverImageUrl': None, 'tag': 'mae', 'description': 'Welcome to the American Meteorological Society 2013-2014 Solar Energy Prediction Contest! This contest is organized by the American Meteorological Society Committees on Artificial Intelligence Applications to Environmental Science, Probability and Statistics, and Earth and Energy. Prizes are sponsored by EarthRisk Technologies, Inc.MotivationRenewable energy sources, such as solar and wind, offer many environmental advantages over fossil fuels for electricity generation, but the energy produced by them fluctuates with changing weather conditions. Electric utility companies need accurate forecasts of energy production in order to have the right balance of renewable and fossil fuels available. Errors in the forecast could lead to large expenses for the utility from excess fuel consumption or emergency purchases of electricity from neighboring utilities. Power forecasts typically are derived from numerical weather prediction models, but statistical and machine learning techniques are increasingly being used in conjunction with the numerical models to produce more accurate forecasts.ObjectiveThe goal of this contest is to discover which statistical and machine learning techniques provide the best short term predictions of solar energy production. Contestants will predict the total daily incoming solar energy at 98\\xa0Oklahoma Mesonet\\xa0sites, which will serve as \"solar farms\" for the contest. Input numerical weather prediction data for the contest comes from the NOAA/ESRL Global Ensemble Forecast System (GEFS)\\xa0Reforecast Version 2. Data include all 11 ensemble members and the forecast timesteps 12, 15, 18, 21, and 24. Locations of the Mesonet sites relative to the GEFS data are shown in the above figure. Training data will come from 1994-2007. Public testing data will be from 2008-2009. Private testing data for a more recent period will be used for the final evaluation.AcknowledgementsDaily solar energy data were provided by the Oklahoma Mesonet with the assistance of Dr. Jeffrey Basara. The GEFS Reforecast Version 2 data were developed and provided by Dr. Thomas Hamill. The contest is being administered by David John Gagne and Dr. Amy McGovern of the University of Oklahoma.About Our SponsorEarthRisk Technologies creates a market advantage for its clients by uniquely quantifying weather data.\\xa0 Our company is a research pioneer that analyzes extreme weather risk at lead times longer than one week.\\xa0 Our techniques enhance competitive business decisions. TempRisk, the company’s first product suite, is a web-based platform that utilizes historical data, machine learning and predictive analytics to project risk for extreme winter cold and summer heat up to 40 days before it occurs. These patent-pending algorithms were developed in conjunction with Scripps Institution of Oceanography at the University of California San Diego.\\xa0 Energy producers and commodity investment firms currently employ TempRisk in their daily operations. Our customers require a uniquely objective quantitative methods for extreme event prediction.\\xa0 Our products are continuously developing thanks to ongoing support from customer-partners including large energy companies, investment firms, and reinsurance advisors. EarthRisk\\'s leadership team is excited to be deeply engaged with the American Meteorological Society.\\xa0 In addition to our engagement with the Committee on Artificial Intelligence Applications to Environmental Science, we\\'re also active on the AMS Energy Committee, the Board on Private Sector Meteorology, the Financial Weather/Climate Risk Management Committee, and the Weather Enterprise Economic Evaluation Team.\\xa0 We have a true passion for advancing meteorological methods through the intelligent application of technology and are proud to be part of the Solar Energy Prediction Contest!'}, {'title': 'Belkin Energy Disaggregation Competition', 'url': 'https://www.kaggle.com/competitions/belkin-energy-disaggregation-competition', 'briefDescription': 'Disaggregate household energy consumption into individual appliances', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'Imagine an energy feedback system that displays not only your total power consumption, but also continuously shows real-time usage, broken down by electrical appliance. Such a system could provide personalized and cost-effective energy saving recommendations. For example, it could report, \"Based on your usage patterns, you could save $215 per year by switching to a more efficient heating unit, which will pay for itself in 27 months.\" The challenge in this scenario is to sense end-uses of energy to provide feedback at the fine-grained, appliance level.There has been substantial prior research in this area [1,5,6,7,8], however most of this work has concentrated on the use of power consumption patterns and using changes in power draw as features to identify what appliance is being used and how much energy it is consuming. We recommend the reader refer to [2,3,9] for a detailed overview of machine learning features for energy disaggregation.A more recent approach to estimate appliance usage is to examine the Electromagnetic Interference (EMI) that most consumer electronic appliances produce as identifying signatures [4]. This EMI is measured using a special sensor built at the Ubicomp Lab at the University of Washington as part of Sidhant Gupta\\'s thesis work. The figure below shows an example of EMI captured from a home. The plot is in frequency domain and shows the signatures of various appliances.The presence or absence of such EMI signatures would ideally tell us when a particular appliance is in use. However, due to the large numbers of appliances in a home, the solution is not straightforward. Machine learning is required not only to make an inference about the appliance class given a particular signature, but probabilistic models are needed that take into account, for example, human appliance usage patterns (think using coffee machine and toaster in morning vs. lights in evening), weather patterns (very unlikely that AC came on during winters), and appliance electrical model. The signature of an appliance can also drift or vary over time due to operating conditions and the mode in which they are used (for instance, a washing machine has many modes). We encourage participants to review [4] to better understand the use of EMI for electrical appliance use detection and classification.Videos and SlidesHere are a few lab quality videos that may helo you grasp the big picture:Video of the signal: http://youtu.be/o-SqO8y8XUAVideo of the technology applied to energy monitoring:\\xa0http://www.youtube.com/watch?v=dcPI1Cp0VZISlides from conference talk for ElectriSense can be accessed here:\\xa0http://homes.cs.washington.edu/~sidhant/slides/ElectriSense_PDF.pdfReferences1. Berges, M., Goldman, E., Matthews, H.S., and Soibelman, L. Training Load Monitoring Algorithms on Highly Sub-Metered Home Electricity Consumption Data. Tsinghua Science & Technology 13, Supple, 0 (2008), 406–411.2. Carrie Armel, K., Gupta, A., Shrimali, G., and Albert, A. Is disaggregation the holy grail of energy efficiency? The case of electricity. Energy Policy 52, (2012), 213–234.3. Froehlich, J., Larson, E., Gupta, S., Cohn, G., Reynolds, M., and Patel, S. Disaggregated End-Use Energy Sensing for the Smart Grid. IEEE Pervasive Computing 10, 1 (2011), 28–39.4. Gupta, S., Reynolds, M., and Patel, S. ElectriSense: Single-Point Sensing Using EMI for Electrical Event Detection and Classification in the home. Ubicomp 2010, (2010).5. Hart, G. Nonintrusive appliance load monitoring. Proceedings of the IEEE, (1992).6. Laughman, C., Lee, K., and Cox, R. Power signature analysis. IEEE Power and Energy, april 2003 (2003).7. Leeb, S.B., Shaw, S.R., and Kirtley, J.L. Transient Event Detection in Spectral Envelope Estimates. IEEE Transactions on Power Delivery 10, 3 (1995), 1200–1210.8. Norford, L.K. and Leeb, S.B. Non-intrusive electrical load monitoring in commercial buildings based on steady-state and transient load-detection algorithms. Energy and Buildings 24, 1 (1996), 51–64.9. Zeifman, M., Ph, D., and Roth, K. Non-Intrusive Appliance Load Monitoring ( NIALM ): Review and Outlook * Fraunhofer\\u202f: A Leading Force in Applied R & D. Consumer Electronics, January (2011).\\xa0'}, {'title': 'Multi-modal Gesture Recognition', 'url': 'https://www.kaggle.com/competitions/multi-modal-gesture-recognition', 'briefDescription': 'Recognize gesture sequences in video and depth data from Kinect', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'The Multi-modal gesture recognition challenge, focused on gesture recognition from 2D and 3D video data using Kinect, is organized by ChaLearn in conjunction with ICMI 2013.Kinect is revolutionizing the field of gesture recognition given the set of input data modalities it provides, including RGB image, depth image (using an infrared sensor), and audio. Gesture recognition is genuinely important in many multi-modal interaction and computer vision applications, including image/video indexing, video surveillance, computer interfaces, and gaming. It also provides excellent benchmarks for algorithms. The recognition of continuous, natural signing is very challenging due to the multimodal nature of the visual cues (e.g., movements of fingers and lips, facial expressions, body pose), as well as technical limitations such as spatial and temporal resolution and unreliable depth cues.The Multi-modal Challenge workshop will be devoted to the presentation of most recent and challenging techniques from multi-modal gesture recognition. The committee encourages paper submissions in the following topics (but not limited to):Multi-modal descriptors for gesture recognitionFusion strategies for gesture recognitionMulti-modal learning for gesture recognitionData sets and evaluation protocols for multi-modal gesture recognitionApplications of multi-modal gesture recognitionThe results of the challenge will be discussed at the workshop. It features a quantitative evaluation of automatic gesture recognition from a multi-modal dataset recorded with Kinect (providing RGB images of face and body, depth images of face and body, skeleton information, joint orientation and audio sources), including about 15,000 Italian gestures from several users. The emphasis of this edition of the competition will be on multi-modal automatic learning of a vocabulary of 20 types of Italian gestures performed by several different users while explaining a history, with the aim of performing user independent continuous gesture recognition combined with audio information.\\xa0Additionally, the challenge includes a live competition of demos/systems of applications based on multi-modal gesture recognition techniques. Demos using data from different modalities and different kind of devices are welcome. The demos will be evaluated in terms of multi-modality, technical quality, and applicability.Best workshop papers and top three ranked participants of the quantitative evaluation will be invited to present their work at ICMI 2013 and their papers will be published in the ACM proceedings. Additionally, there will be travel grants (based on availability) and the possibility to be invited to present extended versions of their works to a special issue in a high impact factor journal. Moreover, all three top ranking participants in both, quantitative and qualitative challenges will be awarded with a ChaLearn winner certificate and an economic prize (based on availability). We will also announce a best paper and best student paper awards among the workshop contributions.'}, {'title': 'MLSP 2013 Bird Classification Challenge', 'url': 'https://www.kaggle.com/competitions/mlsp-2013-birds', 'briefDescription': 'Predict the set of bird species present in an audio recording, collected in field conditions.', 'coverImageUrl': None, 'tag': 'auc', 'description': 'It is important to gain a better understanding of bird behavior and population trends. Birds respond quickly to environmental change, and may also tell us about other organisms (e.g., insects they feed on), while being easier to detect. Traditional methods for collecting data about birds involve costly human effort. A promising alternative is acoustic monitoring. There are many advantages to recording audio of birds compared to human surveys, including increased temporal and spatial resolution and extent, applicability in remote sites, reduced observer bias, and potentially lower costs. However, it is an open problem for signal processing and machine learning to reliably identify bird sounds in real-world audio data collected in an acoustic monitoring scenario. Some of the major challenges include multiple simultaneously vocalizing birds, other sources of non-bird sound (e.g. buzzing insects), and background noise like wind, rain, and motor vehicles.The goal in this challenge is to predict the set of bird species that are present given a ten-second audio clip. This is a multi-label supervised classification problem. The training data consists of audio recordings paired with the set of species that are present.BackgroundThe audio dataset for this challenge was collected in the H. J. Andrews (HJA) Long-Term Experimental Research Forest, in the Cascade mountain range of Oregon. Since 2009, members of the OSU Bioacoustics group have collected over 10TB of audio data in HJA using Songmeter audio recording devices. A Songmeter has two omnidirectional microphones, and records audio in WAV format to flash memory. A Songmeter can be left in the field for several weeks at a time before either its batteries run out, or its memory is full.HJA has been the site of decades of experiments and data collection in ecology, geology and meteorology. This means, for example, that given an audio recording from a particular day and location in HJA, it is possible to look up the weather, vegetative composition, elevation, and much more. Such data enables unique discoveries through cross-examination, and long-term analysis.Previous experiments on supervised classification using multi-instance and/or multi-label formulations have used audio data collected with song meters in HJA. The dataset for this competition is similar to, but perhaps more difficult than that dataset used in these prior works; in earlier work care was taken to avoid recordings with rain and loud wind, or no birds at all, and all of the recordings came from a single day. In this competition, you will consider a new dataset which includes rain and wind, and represents a sample from two years of audio recording at 13 different locations.Conference AttendanceTo participate in the conference, participants should email the following information to catherine.huang {at} intel.com no later than August 19, 2013:\\xa0(1) the names of the team members (each person may belong to at most one team), (2) the name(s) of the host institutions of the researchers, (3) a 1-3 paragraph description of the approach used, (4) their submission score. \\xa0Those planning to attend the conference should additionally upload their source code to reproduce results. \\xa0model submission best practicesAcknowledgementsCollection and preparation of this dataset was partially funded by NSF grant DGE 0333257, NSF-CDI grant 0941748, NSF grant 1055113, NSF grant CCF-1254218, and the College of Engineering, Oregon State University. We would also like to thank Sarah Hadley, Jed Irvine, and others for their contributions in data collection and labeling.'}, {'title': 'Amazon.com - Employee Access Challenge', 'url': 'https://www.kaggle.com/competitions/amazon-employee-access-challenge', 'briefDescription': \"Predict an employee's access needs, given his/her job role\", 'coverImageUrl': None, 'tag': 'auc', 'description': \"When an employee at any company starts work, they first need to obtain the computer access necessary to fulfill their role. This access may allow an employee to read/manipulate resources through various applications or web portals. It is assumed that employees fulfilling the functions of a given role will access the same or similar resources. It is often the case that employees figure out the access they need as they encounter roadblocks during their daily work (e.g. not able to log into a reporting portal). A knowledgeable supervisor then takes time to manually grant the needed access in order to overcome access obstacles. As employees move throughout a company, this access discovery/recovery cycle wastes a nontrivial amount of time and money.There is a considerable amount of data regarding an employee’s role within an organization and the resources to which they have access. Given the data related to current employees and their provisioned access, models can be built that automatically determine access privileges as employees enter and leave roles within a company. These auto-access models seek to minimize the human involvement required to grant or revoke employee access.ObjectiveThe objective of this competition is to build a model, learned using historical data, that will determine an employee's access needs, such that manual access transactions (grants and revokes) are minimized as the employee's attributes change over time. The model will take an employee's role information and a resource code and will return whether or not access should be granted.PartnersThis competition is hosted in collaboration with the IEEE International Workshop on Machine Learning for Signal Processing (MLSP 2013) \"}, {'title': 'dunnhumby & hack/reduce Product Launch Challenge', 'url': 'https://www.kaggle.com/competitions/hack-reduce-dunnhumby-hackathon', 'briefDescription': \"The success or failure of a new product launch is often evident within the first few weeks of sales. Can you predict a product's destiny? \", 'coverImageUrl': None, 'tag': 'rmsle', 'description': 'Predict how successful a product will be after its launchhack/reduce\\xa0and  dunnhumby\\xa0announce the\\xa0Product launch challenge, as part of a one day hackathon. This competition asks you to predict how successful each of a number of product launches will be 26 weeks after the launch, based only on information up to the 13th week after the launch.The training set and question set each contain by week for each launch:The category of the product, such as Bread, Coffee or Video GamesThe number of stores selling the productThe number of units sold that weekThe number of distinct customers who have bought the product (cumulative)The number of distinct customers who have bought the product at least twice (cumulative)Cumulative units sold to a number of different customer groups: Convenience at home, Family\\xa0Focussed, Finest, Grab and Go, Shoppers On A Budget, Traditional Homes, Watching the Waistline,\\xa0Least Price Sensitive, Price Sensitive, Splurge and Save, and Very Price Sensitive. Competition begins: Saturday, May 11, 9am EDT (1:00pm UTC) Competition ends: Saturday, May 11, 7pm EDT (11:00pm UTC)This competition awards 25% the\\xa0ranking points\\xa0of a standard competition, but does not count towards tiers.\\xa0The top remote participant in the Kaggle competition will receive a \"Prize Winner\" achievement on their profile, in addition to the three local winners.'}, {'title': 'The ICML 2013 Whale Challenge - Right Whale Redux', 'url': 'https://www.kaggle.com/competitions/the-icml-2013-whale-challenge-right-whale-redux', 'briefDescription': 'Develop recognition solutions to detect and classify right whales for BIG data mining and exploration studies', 'coverImageUrl': None, 'tag': 'auc', 'description': 'This competition complements the previously held\\xa0Marinexplore Whale Detection Challenge, in which Cornell University provided data from a ship monitoring application termed \"Auto Buoy\", or AB Monitoring System. In the Marinexplore challenge we received solutions that exceeded 98% accuracy and will ultimately advance the process of automatically classifying North Atlantic Right Whales using the AB Monitoring Platform.Since the results from the previous challenge proved so successful, we decided to extend the goals and consider applications that involve running algorithms on archival data recorded using portable hydrophone assemblies, otherwise referred to as Marine Autonomous Recording Unit (or MARU’s). Since Cornell and its partners have been using the MARU for over a decade, a sizable collection of data has been accumulated. This data spans several ocean basins and covers a variety of marine mammal species.Solutions to this challenge will be ported to a High Performance Computing (HPC) platform, being developed in part through funding provided by the Office of Naval Research (ONR grant N000141210585, Dugan, Clark, LeCun and Van Parijs). Together, Cornell will combine algorithms, HPC technologies and its data archives to explore data using highly accurate measuring tools. We encourage participants who developed prior solutions (through the collaboration with Marinexplore) to test them on this data.Workshop on Machine Learning for Bioacoustics'}, {'title': 'The ICML 2013 Bird Challenge', 'url': 'https://www.kaggle.com/competitions/the-icml-2013-bird-challenge', 'briefDescription': 'Identify bird species from continuous audio recordings', 'coverImageUrl': None, 'tag': 'auc', 'description': \"We're aware the competition deadline is tight, but wanted to give Kagglers the chance to work on this interesting problem. The results will be presented at the Workshop on Machine Learning for Bioacoustics at ICML 2013.Acknowledgementshttp://sabiod.org\"}, {'title': 'Facial Keypoints Detection', 'url': 'https://www.kaggle.com/competitions/facial-keypoints-detection', 'briefDescription': 'Detect the location of keypoints on face images', 'coverImageUrl': None, 'tag': 'image, rmse', 'description': 'The objective of this task is to predict keypoint positions on face images. This can be used as a building block in several applications, such as:tracking faces in images and videoanalysing facial expressionsdetecting dysmorphic facial signs for medical diagnosisbiometrics / face recognitionDetecing facial keypoints is a very challenging problem. \\xa0Facial features vary greatly from one individual to another, and even for a single individual, there is a large amount of variation due to 3D pose, size, position, viewing angle, and illumination conditions. Computer vision research has come a long way in addressing these difficulties, but there remain many opportunities for improvement.This getting-started competition provides a benchmark data set and an  R tutorial to get you going on analysing face images.\\xa0Get started with R >>AcknowledgementsThe data set for this competition was graciously provided by  Dr. Yoshua Bengio of the University of Montreal.\\xa0James Petterson.'}, {'title': 'RecSys2013: Yelp Business Rating Prediction', 'url': 'https://www.kaggle.com/competitions/yelp-recsys-2013', 'briefDescription': 'RecSys Challenge 2013: Yelp business rating prediction', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"We are pleased to announce the 2013 Recommender Systems Challenge associated with ACM RecSys 2013. \\xa0Known as RecSysChallenge 2013, this is a LBS contest organized by Yelp. The theme of this year’s competition is personalized business recommendations for Yelp users. We provide a\\xa0detailed snapshot of Yelp data:\\xa0over 10,000 businesses, 8,000 check-in sites, 40,000 users, and 200,000 reviews from the Phoenix, AZ metropolitan area.ContestAt the heart of any recommender system is an algorithm to predict ratings. \\xa0Contestants are asked to predict the users’ future ratings of businesses. Participants will create a model to predict the rating a user would assign to a business. Models will be graded on accuracy using the root mean squared error metric. See the\\xa0Evaluation page\\xa0for more details.The competition starts on May 3, 2013 and ends on August 31, 2013. Submissions to the workshop must be submitted by September 8, 2013.A total of $500 in prize\\xa0money\\xa0will be presented to the winners.\\xa0Top ranking teams will also be recognized at the RecSys banquet.WorkshopAfter the competition closes, we will also hold a full-day\\xa0workshop, co-located with the\\xa0ACM RecSys 2013\\xa0conference, to discuss interesting approaches to the competition problem as well as lessons learned. We invite all contest participants to present their approach to building business recommendations. Contributions may focus on any individual steps such as feature extraction or model building; or describe an end-to-end system to predict business ratings. \\xa0Workshop participation is independent of the contest: researchers are welcome to participate in either (or, hopefully, both!).Looking for last year's challenge? \\xa0Check out  RecSys Challenge 2012.\"}, {'title': 'KDD Cup 2013 - Author Disambiguation Challenge (Track 2)', 'url': 'https://www.kaggle.com/competitions/kdd-cup-2013-author-disambiguation', 'briefDescription': 'Identify which authors correspond to the same person', 'coverImageUrl': None, 'tag': 'meanfscore', 'description': 'The ability to search literature and collect/aggregate metrics around publications is a central tool for modern research. Both academic and industry researchers across hundreds of scientific disciplines, from astronomy to zoology, increasingly rely on search to understand what has been published and by whom.Microsoft Academic Search is an open platform that provides a variety of metrics and experiences for the research community, in addition to literature search. It covers more than 50 million publications and over 19 million authors across a variety of domains, with updates added each week. One of the main challenges of providing this service is caused by author-name ambiguity.\\xa0This KDD Cup task challenges participants to determine which authors in a given data set are duplicates.'}, {'title': 'KDD Cup 2013 - Author-Paper Identification Challenge (Track 1)', 'url': 'https://www.kaggle.com/competitions/kdd-cup-2013-author-paper-identification-challenge', 'briefDescription': 'Determine whether an author has written a given paper', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'THIS COMPETITION IS COMPLETE. CONGRATULATIONS TO THE PRELIMINARY WINNERS!The ability to search literature and collect/aggregate metrics around publications is a central tool for modern research. Both academic and industry researchers across hundreds of scientific disciplines, from astronomy to zoology, increasingly rely on search to understand what has been published and by whom.Microsoft Academic Search is an open platform that provides a variety of metrics and experiences for the research community, in addition to literature search. It covers more than 50 million publications and over 19 million authors across a variety of domains, with updates added each week. One of the main challenges of providing this service is caused by author-name ambiguity. On one hand, there are many authors who publish under several variations of their own name. \\xa0On the other hand, different authors might share a similar or even the same name.As a result, the profile of an author with an ambiguous name tends to contain noise, resulting in papers that are incorrectly assigned to him or her. This KDD Cup task challenges participants to determine which papers in an author profile were truly written by a given author.'}, {'title': 'Influencers in Social Networks', 'url': 'https://www.kaggle.com/competitions/predict-who-is-more-influential-in-a-social-network', 'briefDescription': 'Predict which people are influential in a social network', 'coverImageUrl': None, 'tag': 'auc', 'description': \"Data Science London\\xa0and the\\xa0UK Windows Azure Users Group\\xa0in partnership with Microsoft and Peerindex,\\xa0announce the Influencers in Social Networks competition as\\xa0part of  The Big Data Hackathon. \\xa0The dataset, provided by Peerindex, comprises\\xa0a standard, pair-wise preference learning task. Each datapoint describes two individuals, A and B. For each person, 11 pThe binary label represents a human judgement about which one of the two individuals is more influential. A label '1' means A is more influential than B. 0 means B is more influential than A. The goal of the challenge is to train a machine learning model which, for pairs of individuals, predicts the human judgement on who is more influential with high accuracy.\\xa0Labels for the dataset have been collected by PeerIndex\\xa0using an application similar to the one described in this post.A python script computing a sample benchmark solution is available here:\\xa0Competition begins: Saturday, Apr 13, 1pm BST (12 noon UTC) This competition awards 25% the  ranking points of a standard competition, but does not count towards tiers.\\xa0\"}, {'title': 'Challenges in Representation Learning: The Black Box Learning Challenge', 'url': 'https://www.kaggle.com/competitions/challenges-in-representation-learning-the-black-box-learning-challenge', 'briefDescription': 'Competitors train a classifier on a dataset that is not human readable, without knowledge of what the data consists of.', 'coverImageUrl': None, 'tag': 'categorizationaccuracy', 'description': 'We are also providing a dataset of approx. 130,000 unsupervised examples that contestants can use to improve their models. The unsupervised data is a CSV file in the same format as the private test set (i.e. without the labels). The extra data comes from a distribution that is very similar to the training/test set distribution.We provide example code for this contest as part of the pylearn2 package at  https://github.com/lisa-lab/pylearn2For this contest, look at the pylearn2/scripts/icml_2013_wrepl/black_box directory.'}, {'title': 'Challenges in Representation Learning: Multi-modal Learning', 'url': 'https://www.kaggle.com/competitions/challenges-in-representation-learning-multi-modal-learning', 'briefDescription': 'The multi-modal learning challenge', 'coverImageUrl': None, 'tag': 'auc', 'description': \"In this contest, competitors will design systems to learn about two modalities of data: images and text. The provided training data is Louis von Ahn's Small ESP Game Dataset, containing images and word tags for these images. Competitors should train their system to associate images to sets of word tags. At test time, the system is presented with two possible sets of word tags for an image, and must determine which is the correct set of word tags.Because this task is very easy for humans to do, we will not provide the final test inputs until one week before the contest closes. Preliminary winners will need to release their winning code and demonstrate that they did not manually label the test set. We reserve the right to disqualify entries that may involve any manual labeling of the test set.\"}, {'title': 'Challenges in Representation Learning: Facial Expression Recognition Challenge', 'url': 'https://www.kaggle.com/competitions/challenges-in-representation-learning-facial-expression-recognition-challenge', 'briefDescription': 'Learn facial expressions from an image', 'coverImageUrl': None, 'tag': 'categorizationaccuracy', 'description': 'Example baseline submissions are available as part of the pylearn2 python package available at\\xa0https://github.com/lisa-lab/pylearn2The baseline submissions for this contest are in pylearn2/scripts/icml_2013_wrepl/emotionsBecause this task is very easy for humans to do, we will not provide the final test inputs until one week before the contest closes. Preliminary winners will need to release their winning code and demonstrate that they did not manually label the test set. We reserve the right to disqualify entries that may involve any manually labeling of the test set.Preliminary winners will need to release their winning code and demonstrate that they did not manually label the test set. We reserve the right to disqualify entries that may involve any manually labeling of the test set.'}, {'title': 'Cause-effect pairs', 'url': 'https://www.kaggle.com/competitions/cause-effect-pairs', 'briefDescription': 'Given samples from a pair of variables A, B, find whether A is a cause of B.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': '\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0The problem of attributing causes to effects is pervasive in science, medicine, economy and almost every aspects of our everyday life involving human reasoning and decision making. What affects your health? the economy? climate changes?\\xa0The gold standard to establish causal relationships is to perform randomized controlled experiments. However, experiments are costly while non-experimental \"observational\"\\xa0data collected routinely around the world are readily available. Unraveling potential cause-effect relationships from such observational data could save a lot of time and effort.Consider for instance a target variable B, like occurence of \"lung cancer\" in patients. The goal would be to find whether a factor A, like \"smoking\", might cause B.\\xa0The objective of the challenge is to rank pairs of variables {A, B} to prioritize experimental verifications of the conjecture that A causes B.As is known, \"correlation does not mean causation\". More generally, observing a statistical dependency between A and B does not imply that A causes B or that B causes A; \\xa0A and B could be consequences of a common cause. But, is it possible to determine from the joint observation of samples of two variables A and B that A should be a cause of B? There are  new algorithms that have appeared in the literature in the past few years that tackle this problem. This challenge is an opportunity to evaluate them and propose new techniques to improve on them.We provide hundreds of pairs of real variables with known causal relationships from domains as diverse as chemistry,\\xa0climatology,\\xa0ecology, economy, engineering, epidemiology,\\xa0genomics,\\xa0medicine, physics. and\\xa0sociology. Those are intermixed with controls (pairs of independent variables and pairs of variables that are dependent but not causally related) and semi-artificial cause-effect pairs (real variables mixed in various ways to produce a given outcome).This challenge is limited to pairs of variables deprived of their context. Thus constraint-based methods relying on conditional independence tests and/or graphical models are not applicable. The goal is to push the state-of-the art in complementary methods, which can eventually disambiguate Markov equivalence classes.\\xa0If you are skeptical that this is possible, try this quiz: Examine the plot below of values of variable B plotted as a function of values of variable A. Can you guess which one is a cause of the other? Hint: Some non-linear functions are non-invertible.July 1: A new data release was made to address a\\xa0normalization problem\\xa0and the deadline was extended. Scores on the public leaderboard prior to July 1 were decreased by 0.5. Please make new submissions with the new validation set. The competition is open to new teams.'}, {'title': 'Yelp Recruiting Competition', 'url': 'https://www.kaggle.com/competitions/yelp-recruiting', 'briefDescription': 'How many \"useful\" votes will a Yelp review receive? Show off your skills to land an interview for a position on a Yelp data mining team!', 'coverImageUrl': None, 'tag': 'rmsle', 'description': \"Here at Yelp, we really love the quality of our data. We're grateful that so many of our users take the time to write such great reviews. We track 3 community-powered metrics of review quality: Useful, Funny, Cool. Over time, a good review will accumulate lots of votes in these categories from the community. However, another extremely important quality feature is the freshness of a review. What if we didn't have to wait for the community to vote on the best reviews to know which ones are high quality?The goal of this competition is to estimate the number of Useful votes a review will receive. Yelp isn't only looking for the answer to this question; we're looking for an engineer that can solve this problem and push their code to production. The prize is a fast track through the recruiting process -- straight to an interview and the opportunity to show Yelp Engineers just what you've got.For more information about the exciting opportunities at Yelp, check out  http://www.yelp.com/careers! This competition counts towards rankings & achievements.\"}, {'title': 'ICDAR2013 - Handwriting Stroke Recovery from Offline Data', 'url': 'https://www.kaggle.com/competitions/icdar2013-stroke-recovery-from-offline-data', 'briefDescription': 'Predict the trajectory of a handwritten signature', 'coverImageUrl': None, 'tag': 'rmse', 'description': 'There are two ways of acquiring signatures (or handwritings). The first one being the offline acquisition in which images of the signatures are acquired using an image scanner. The second one being the online\\xa0acquisition in which x and y coordinates as well as the pressure are acquired with respect to time.Further details about online acquisition can be found here.The detection of the online trajectory (or stroke recovery) of offline handwritings has many applications including the forensic application where it can help investigators converting an offline signature into its online equivalent in order to perform the verification at the online mode. It can also be used in a similar way in handwriting recognition as online handwriting recognition reaches higher recognition rates than offline recognition.There are several studies regarding the detection of trajectories of handwritings. A survey of such methods is given in\\xa0[1].The aim of this competition is to attract the interest of document image analysis researchers as well as data scientists to this research area and to measure the performance of recent advances in this field.The dataset used in this study consists of 1081 signatures of 200 writers [2]. The signatures have been acquired using a Wacom Intuos4 Large digitizing tablet and a Wacom Inking pen. A blank paper has been placed on this tablet in order to acquire in a subsequent stage the offline signature using a scanner.Offline signatures consists of jpg images scanned using an appropriate HP scanner.Online signatures are provided in a single sequential csv file containing x and y coordinates for each time interval. Pressure is not considered in this competition.In order to ease the comparison, each signature is normalized such that its x and y values will be in (0,1).The online data is provided for the first 605 signatures. Participants are to predict the online signatures of the other 476 signatures.This competition is organized in the scope of the Twelfth\\xa0International Conference on Document Analysis and RecognitionICDAR2013\\xa0that will be held in Washington, DC.[1] Nguyen, Vu, and Michael Blumenstein. Techniques for static handwriting trajectory recovery: a survey. Proceedings of the 9th IAPR International Workshop on Document Analysis Systems. ACM, 2010.[2] S Al-Maadeed, W Ayouby, A Hassaine, A Al-Mejali, A Al-Yazeedi. Arabic Signature Verification Datasets. In: The International Arab Conference on Information Technology 2012.'}, {'title': 'Data Science London + Scikit-learn', 'url': 'https://www.kaggle.com/competitions/data-science-london-scikit-learn', 'briefDescription': 'Scikit-learn is an open-source machine learning library for Python. Give it a try here!', 'coverImageUrl': None, 'tag': 'categorizationaccuracy', 'description': 'hosting a meetup on Scikit-learnWe encourage participants to post code via the \"Tutorials\" link on the left. \\xa0Don\\'t worry about accuracy or whether your code is perfect. \\xa0The aim here is to explore sklearn by using it.\\xa0\\xa0Its implementation is high quality due to sMeetup InformationThursday, March 7, 2013,\\xa0“Learning in Python with scikit-learn\" by Andreas Mueller\"Parallel and large scale learning with scikit-learn\" by Olivier Griselnotebook interfaceHow to perform scalable text feature extraction with the Hashing Trickand hyper parameters tuningHow to optimize memory usage with memory mappingHow to approximate kernel Support Vector Machines for large scale datasetsA short introduction to Ensembles with model averaging and Random Forests\\xa0by day and a Python machine learning hacker by night. He is interested in\\xa0applications to Natural Language Processing, Computer Vision and\\xa0predictive modelling.'}, {'title': 'ICDAR2013 - Gender Prediction from Handwriting', 'url': 'https://www.kaggle.com/competitions/icdar2013-gender-prediction-from-handwriting', 'briefDescription': 'Predict if a handwritten document has been produced by a male or a female writer', 'coverImageUrl': None, 'tag': 'logloss', 'description': 'The prediction of gender from handwriting is a very interesting research field. It has many applications including the forensic application where it can help investigators focusing more on a certain category of suspects.There are a few studies regarding the automatic detection of the gender of a handwritten document\\xa0[1-3].The aim of this competition is to attract the interest of the document analysis community to this research area and to measure the performance of recent advances in this field.The dataset used in this study has been described in this paper [4].A total of 475 writers produced 4 handwritten documents:the first page contains an Arabic handwritten\\xa0text which varies from one writer to another.the second page\\xa0contains an Arabic handwritten\\xa0text which is the same for all the writers.the third page contains an English handwritten\\xa0text which varies from one writer to another.and the fourth\\xa0page\\xa0contains an English handwritten\\xa0text which is the same for all the writers.The training set consists of the first 282 writers for which the genders are provided.Participants are asked to predict the gender of the remaining 193 writers.For participants who are not familiar with digital image-processing, a set of features extracted from all the images will be provided. Those features are similiar to that of the previous 2011 and  2012 Arabic Writer Identification Contests. Those features are described in [5].This competition is organized in the scope of the Twelfth\\xa0International Conference on Document Analysis and Recognition ICDAR2013\\xa0that will be held in Washington, DC.Writer demographic identification using bagging and boosting[2] Liwicki, M., Schlapbach, A., Loretan, P., Bunke, H.,\\xa0Automatic detection of gender and handedness from online handwriting. In: Proc. 13th Conference of the International Graphonomics Society. pp. 179–183 (2007).[3] Liwicki, M., Schlapbach, A., Bunke, H.,\\xa0Automatic gender detection using on-line and off-line information. Pattern Analysis and Applications 14, 87–92 (2011).[4] Al-Ma’adeed, S., Ayouby, W., Hassaine, A., Aljaam, J.,\\xa0QUWI: An Arabic and English Handwriting Dataset for Offline Writer Identification. In: Frontiers in Handwriting Recognition, International Conference on. Bari, Italy (September 2012).[5] Hassaïne, A., Al-Maadeed, S. and Bouridane, A.,\\xa0A Set of Geometrical Features for Writer Identification. Neural Information Processing. Springer Berlin/Heidelberg, 2012.'}, {'title': 'Just the Basics - Strata 2013 After-party', 'url': 'https://www.kaggle.com/competitions/just-the-basics-the-after-party', 'briefDescription': 'Live from Santa Clara, CA', 'coverImageUrl': None, 'tag': 'auc', 'description': \"Missed the one hour Just the Basics tutorial competition? Didn't get to implement that method you had in mind? Too many coffee breaks has your brain inBeautiful Mind mode?This is the after-party competition. Same data. Same problem. More time! You have until the close of Strata to have fun with the problem.Competition Starts: approximately 12:30 PM PT (3:30 PM ET), 02/26/2013Competition Ends: 5:00 PM PT\\xa0(8:00 PM ET), 02/28/2013\"}, {'title': 'Just the Basics - Strata 2013', 'url': 'https://www.kaggle.com/competitions/just-the-basics-strata-2013', 'briefDescription': 'Live from Santa Clara, CA - Core Data Science Skills with Kaggle’s Top Competitors', 'coverImageUrl': None, 'tag': 'auc', 'description': \"Two of Kaggle's very own are presenting an introductory tutorial at Strata 2013. Targeted for those with basic programming experience, it will cover the end-to-end analysis of predictive data problems. The tutorial is comprised of four sections, the last of which is this, a hands-on Kaggle competition in which participants can experience firsthand the joys of creating a model and the sorrows of overfitting.Competition ends:9:00am\\xa0Tuesday, 02/26/2013 Location:\\xa0Ballroom AB  Competition Starts: Approximately 11:15 AM PT (2:15PM ET), 02/26/2013 Competition Ends: 12:30 PM PT (3:30 PM ET), 02/26/2013Open to the public!Yes, you can participate in this for-fun competition without attending the tutorial. \\xa0For fun?You heard correctly; there's no Kaggle points or money up for grabs here. Isn't getting to lunch early a big enough motivation?\\xa0Unlimited* submissions!Show our servers who's boss! *for small values of unlimitedWhere's the data?To prevent head starts, the data will be available at the start of the competition.About the presentersBen Hamner has worked with machine learning problems in a variety of different domains, including natural language processing, computer vision, web classification, and neuroscience. Prior to joining Kaggle, he applied machine learning to improve brain-computer interfaces as a Whitaker Fellow at the École Polytechnique Fédérale de Lausanne in Lausanne, Switzerland. He graduated with BSE in Biomedical Engineering, Electrical Engineering, and Math from Duke University.William Cukierski has a bachelor’s degree in physics from Cornell University and a Ph.D. in biomedical engineering from Rutgers University, where he studied applications of machine learning in cancer research.\"}, {'title': 'Job Salary Prediction', 'url': 'https://www.kaggle.com/competitions/job-salary-prediction', 'briefDescription': 'Predict the salary of any UK job ad based on its contents', 'coverImageUrl': None, 'tag': 'mae', 'description': 'Kaggle Startup Programplease applySuccessful models will incorporate some analysis of the impact of including different keywords or phrases, as well as making use of the structured data fields like location, hours or company. \\xa0Some of the structured data shown (such as category) is \\'inferred\\' by Adzuna\\'s own processes, based on where an ad came from or its contents, and may not be \"correct\" but is representative of the real data.You will be provided with a training data set on which to build your model, which will include all variables including salary. \\xa0A second data set will be used to provide feedback on the public leaderboard. \\xa0After approximately 6 weeks, Kaggle will release a final data set that does not include the salary field to participants, who will then be required to submit their salary predictions against each job for evaluation.'}, {'title': 'The Marinexplore and Cornell University Whale Detection Challenge', 'url': 'https://www.kaggle.com/competitions/whale-detection-challenge', 'briefDescription': 'Create an algorithm to detect North Atlantic right whale calls from audio recordings, prevent collisions with shipping traffic', 'coverImageUrl': None, 'tag': 'auc', 'description': \"Read the summary of the competition for a quick overview of the impact of the results.We depend on shipping industry's uninterrupted ability to transport goods across long distances. Navigation technologies combine accurate position and environmental data to calculate optimal transport routes. Accounting for and reducing the impact of commercial shipping on the ocean’s environment, while achieving commercial sustainability, is of increasing importance, especially as it relates to the influence of cumulative noise “footprints” on the great whales.Illustration of ships navigating safely around the habitat of whales.Right whales make a half-dozen types of sounds, but the characteristic up-call is the one identified by the auto-detection buoys.\\xa0Right whale up-callMarinexplore and Cornell researchers challenge YOU to beat the existing whale detection algorithm identifying the right whale calls. This will advance ship routing decisions in the region.[For details on the buoy network see a paper published by\\xa0Acoustical Society of America.]Read the summary\\xa0of the competition for a quick overview of the impact of the results.\"}, {'title': \"Predicting Parkinson's Disease Progression with Smartphone Data\", 'url': 'https://www.kaggle.com/competitions/predicting-parkinson-s-disease-progression-with-smartphone-data', 'briefDescription': 'Can we objectively measure the symptoms of Parkinson’s disease with a smartphone? We have the data to find out!', 'coverImageUrl': None, 'tag': 'rmse', 'description': 'There are many symptoms and features of Parkinson’s disease which can be objectively measured and monitored using simple technology devices we carry every day. Mobile phones are some of the most pervasive forms of monitoring devices, with many smartphones carrying basic sensors that can be used to give a window into a patient’s life. We have taken the initial steps with such a device, developing a basic collection application, and collecting data from a group of Parkinson’s patients and control subjects.Now the challenge is on you to determine the best way to use it!The challenge is to develop a way to help patients and clinicians using objective, passively collected data points. The goal is to use the provided data to distinguish PD patients from control subjects and/or to quantify PD symptoms in a way that could enable the measurement of disease progression.You are invited to submit an entry showing the way you would use the data to describe a solution that addresses the objectives of the contest, including next steps to be done if more data were available.\\xa0ENTRY DEADLINE: March 26, 2013, 11:59 PM ESTShare your participation and progress online: #PDdata '}, {'title': 'Blue Book for Bulldozers', 'url': 'https://www.kaggle.com/competitions/bluebook-for-bulldozers', 'briefDescription': 'Predict the auction sale price for a piece of heavy equipment to create a \"blue book\" for bulldozers.', 'coverImageUrl': None, 'tag': 'rmsle', 'description': 'The goal of the contest is to predict the sale price of a particular piece of heavy equiment at auction based on it\\'s usage, equipment type, and configuaration. \\xa0The data is sourced from auction result postings and includes information on usage and equipment configurations.Fast Iron is creating a \"blue book for bull dozers,\" for customers to value what their heavy equipment fleet is worth at auction.About Fast IronThis competition was launched under the  Kaggle Startup Program. If you\\'re a startup with a predictive modelling challenge, please apply!Photo credits:\\xa0Antonis Lamnatos'}, {'title': 'Event Recommendation Engine Challenge', 'url': 'https://www.kaggle.com/competitions/event-recommendation-engine-challenge', 'briefDescription': 'Predict what events our users will be interested in based on user actions, event metadata, and demographic information.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'We (the competition hosts) are excited to sponsor the Event Recommendation Engine Challenge, which asks you to predict what events our users will be interested in based on events they’ve responded to in the past, user demographic information, and what events they’ve seen and clicked on in our app. The insights you discover from this data, and the algorithms the winners create, will allow us to improve our event recommendation algorithm, a core part of our applications and a key element in improving user experience.This is the first competition launching under the Kaggle Startup Program!'}, {'title': 'Leaping Leaderboard Leapfrogs', 'url': 'https://www.kaggle.com/competitions/leapfrogging-leaderboards', 'briefDescription': 'Provide creative visualizations of the Kaggle leaderboard ', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"The leaderboard is a central fixture of the Kaggle experience. It provides context to the incredible work accomplished by the Kaggle data science community.\\xa0To a competitor, the leaderboard is a dynamic, living, action-filled battle. Tactics come to life.\\xa0Individuals leapfrog over each other. \\xa0Teams merge and blend submissions. \\xa0Some submit early and often, attempting to build up insurmountable leads. Others bide time, waiting to pounce minutes before the buzzer with their finest of forests. \\xa0We see the joys of regularization and the  agony of overfitting. \\xa0It's raw. It's beautiful. It's thousands of hours of collective human toil.It's boring.To an observer, the leaderboard is a spreadsheet. \\xa0They see funny team names, numbers with too many decimals, strange column titles, and none of the history behind the battle. We run a veritable nerd olympics, but instead of smashing the 100m world record, we're elbowing for a few decimal places of some esoteric quantity called a capped binomial deviance. It's faceless. It's cold. It fails to tell the story of the battle. And you know what that means?This means war.We're calling on you to bring the leaderboard to life. \\xa0Break out the  D3. Sacrifice an old PC to the javascript gods. Abandon all text, ye who enter here. \\xa0We're bootstrapping our own community to do what they do best, and that is doing things better.What kinds of submissions do we hope result from this competition?Maybe you know an API or two and can\\xa0create a motion chart? Maybe you know the hot, new HTML5 canvas tricks? Maybe you know of an R package that  styles plots like The Economist or XKCD? Maybe you know Edward Tufte and can call in a favor?Be creative. Scrape profile photos. Examine team formation. Examine relative scores. Watch for edge cases, cluttered text, and all the gotchas that crop up when you juggle a leaderboard of 10 vs. 1000 teams. \\xa0We're looking for entries that convey the storyline behind the leaderboard. \\xa0Style and substance counts, as does reproducibility (sorry to the Bob Rosses of the world who want to hand draw their submission). \\xa0Web-readiness is appreciated, but we know better than to put such constraints on the Kaggle community. \\xa0Use whatever brush you wish to paint this masterpiece.Credits:We'd like to acknowledge Chris Mulligan at Columbia University for providing the impetus that put this prospect in motion. You can see his blog post or even check out a git repository of the code he used to do it.Image:\"}, {'title': 'Traveling Santa Problem', 'url': 'https://www.kaggle.com/competitions/traveling-santa-problem', 'briefDescription': 'Solve ye olde traveling salesman problem to help Santa Claus deliver his presents', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"This competition will launch at midnight UTC on Saturday, December 15.Santa Claus was excited to learn about the Kaggle competition platform, and wanted to use it for a slightly different purpose. Rather than a predictive modeling problem, he has an optimization problem for you: a very, very important optimization problem.Santa needs help choosing the route he takes when delivering presents around the globe. Every year, Santa has to visit every boy and girl on his list. \\xa0It's a tough challenge, and Santa admits he scored a B- on his combinatorical optimization final. He's hoping you can develop algorithms that will solve his problem year after year.Santa asked that we give you one particular instance of his TSP (Traveling Santa Problem). However,\\xa0Santa's dilemma isn't quite the same as the Traveling Salesman Problem with which you may be familiar. Santa likes to see new terrain every year--don't ask, it's a reindeer thing--and doesn't want his route to be predictable.You're looking for shortest-distance paths through a set of chimneys, but instead of providing one path, Santa asks you to provide two\\xa0disjoint\\xa0paths. If one of your paths contains an edge from A to B, your other path must\\xa0not\\xa0contain an edge from A to B\\xa0or\\xa0from B to A (either order still counts as using that edge). Your score is the larger of the two distances. \\xa0Santa asks competition winners to publish and open source the algorithms they use (for his future use, of course).Rudolph was very adament about minimizing his workload. Trust us, you don't want to be on Rudolph's bad side.Important note about prizes:\\xa0We believe that Kaggle's public leaderboard is very important for both the fun of the competition and achieving great results, and we want to provide an incentive for everyone to submit to the public leaderboard all along the way (even though you can easily determine your submission's score all by yourself). So the competition will have\\xa0two sets of prizes,\\xa0one based on the scores at the end of the competition, and one based on the scores at the end of a randomly chosen day (UTC) between December 23 and January 17.\\xa0 The day will not be revealed (or even chosen) until after the competition ends. (The competition will end at the end of the day UTC on January 18.)\\xa0Attributions:Data generation and lots of help framing the problem (including coming up with this TSP variant):Robert Bosch of Oberlin College Math DepartmentSanta photo:\\xa0AurélienSSleigh photo:\\xa0Creative ToolsGlobe: William Cook\\xa0\\xa0\"}, {'title': 'Visualize the State of Public Education in Colorado', 'url': 'https://www.kaggle.com/competitions/visualize-the-state-of-education-in-colorado', 'briefDescription': 'Using 3 years of school grading data supplied by the Colorado Department of Education and R-Squared Research, visually uncover trends in the Colorado public school system.', 'coverImageUrl': None, 'tag': 'rmse', 'description': 'Colorado School Grades was created by a coalition of non-profit, community organizations that believe all children deserve access to a high-performing school. Our mission is to provide community members, parents, students, and educators with school performance information that is both accessible and easy-to-understand. Our hope is that this will help families and students make more informed decisions about the school they choose based in some part on academic performance information. We also aim to inspire and equip community members, parents, students, and educators with the information and resources they need to effectively engage in local school improvement efforts.\\xa0 We provide resources for community stakeholders to improve their chosen schools.Colorado School Grades\\xa0receives over 300,000 parents annually. Please use the site as a reference for any additional questions that you may have. And please be sure to include the Colorado School Grades link and logo in your visualization.Competition is organized and administered by Ryan Wilson at\\xa0FiveFifty. \\xa0\\xa0We believe that information is power and our work translates the state of Colorado’s school performance labels into easier-to-understand letter grades. We make these grades public on an intuitive, user-friendly platform atwww.ColoradoSchoolGrades.com. Now that we have three years of letter grades for the schools, we are interested in seeing what trends and insights visualisation experts can identify and explain in compelling data visualizations. Here is a list of some the questions we find intriguing:How have grades changed over time across the state (or perhaps more importantly how have they remained the same)?Where are the A schools primarily located? Our vision is that all kids have access to a high-performing school – how does the Colorado deliver against that promise of equity?\\xa0Are there correlations between A schools and student demographics (free/reduced lunch is a proxy for poverty or by race) – Do poor and minority kids have access to A schools?Academic growth is an indicator used in the grading system. It is described in more detail in the data description page and on the Colorado School Grades website, but is perhaps the greatest indicator of how much teaching and learning is actually occurring in the school. That said, where are the schools that have the best sub-grades for student growth? Are there particular schools that have high percentages of low income students AND high grades for student growth. Some may say those schools are doing more to close Colorado’s achievement gap between the wealthy and the poor than any other.What percentage of Colorado’s student’s are ready for college and career by school or by school district?Which districts have the most A schools, F schools, or improving schools? Which schools have improved their letter grades the most? How do these grades, graduation rates, and college/career readiness metrics compare to labor market and economic data / needs?What have we missed? Please use your creativity to identify interesting trends or insights that the data tells us.'}, {'title': 'Prescription Volume Prediction', 'url': 'https://www.kaggle.com/competitions/RxVolumePrediction', 'briefDescription': 'Predict future prescription volume', 'coverImageUrl': None, 'tag': 'mcap@k', 'description': 'This is a private, invitation-only competition. The relevant information is provided only to contestants.'}, {'title': 'GE Flight Quest', 'url': 'https://www.kaggle.com/competitions/flight', 'briefDescription': 'Think you can change the future of flight?', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/3209/logos/header.png', 'tag': 'custom metric', 'description': \"Flight Quest Phase 1 Winners1. Xavier Conort1. Hong Cao1. Clifton Phua1. Ghim-Eng Yap1. Kenny Chua            Team Gxav &* used a mixture of gradient boosting and random forest models to predict gate and runway arrival times. With average errors of 4.2 and 3.2 minutes for gate and runway arrivals, respectively, this translates to 40% and 45% improvements over the standard industry benchmark estimates. Key to their success was careful feature selection with their final models using only 58 and 84 features for gate and runway arrivals, respectively, from the total 258 features they painstakingly constructed and optimized.        2. Jonathan Peters2. Pawel Jankiewicz            Team As High As Honor used a two-step approach that combined the results of a generalized linear model that encoded intuition about important variables with refinements derived from a random forest model. The team capitalized on the success of the linear model to add the effects of multiple variables and cleanly resolve issues of missing data.        3. Gabor Takacs            Team Taki used a six layer model relying on successive ridge regressions and gradient boostingmachines to model both gate and runway arrival times. This approach used 56 features extracted from the raw data, with all but two coming from the test day data.        4. Sergey Kozub            Team Sun’s approach to predicting gate and runway arrival times relied on creating a derived data set with new variables encoding information about the aircraft, airport, airway, gate, hour, and flight path times. Important features used in this model include aircraft GPS position, ASDI flight plans the direction from which airplanes approached airport runways.        5. Jacques KvamJacques Kvam’s approach for predicting runway and gate arrival times used gradient boosting for a model using 10,000 trees and a whopping 1,102 features trained on 260,000 flights. Most significant among these included the distance between the final waypoint and the arrival airport. Many weather features were important as well including temporary vertical visibility and wind speed at the arrival airport.        Honorable Mention: Matt Berseth            Team __mtb__ used random forest and gradient boosted models to estimate runway and gate arrival times. The final solution included over 100 different individual models, each focused on a narrow set of features (i.e. wind/weather, flight plan, aircraft's current location, etc.). These individual models were blended together to generate the final estimates. The training data was created by randomly selecting eight cutoff times for each day in the training period. A separate cross validation data set was used to select hyper-parameters.        Think you can change the future of flight?Did you know airlines are constantly looking for ways to make flights more efficient? From gate conflicts to operational challenges to air traffic management, the dynamics of a flight can change quickly and lead to costly delays.There is good news. Advancements in real-time big data analysis are changing the course of flight as we know it. Imagine if the pilot could augment their decision-making process with “real time business intelligence,”—information available in the cockpit that would allow them to make adjustments to their flight patterns.\\xa0Your challenge, should you decide to accept it:\\xa0Use the different data sets found on this page under Get the Data to develop a usable\\xa0and scalable algorithm that delivers a real-time flight profile to the pilot, helping them\\xa0make flights more efficient and reliably on time.Tweet\"}, {'title': 'GE Hospital Quest', 'url': 'https://www.kaggle.com/competitions/hospital', 'briefDescription': 'Think it’s possible to make hospital visits hassle-free? GE does.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/3199/logos/header.png', 'tag': 'rmse', 'description': 'Hospital Quest Winners    1. Russ Graney     1. Mike Galbo     1. Janan RajeevikaranIntegrated with the discharge management process, this app automatically generates lists of available post-acute care providers. This minimizes administrative tasks for social workers and enables them to devote more time to patients.    2. Sabrina Casucci, Dapeng Cao, Theresa Guarrera, David Lavergne, Nicolette McGeorge, Judith Tiferes Wang, and Yuan Zhou (Buffalo, NY, USA)This app provides a mobile solution to the complex problems of discharge management. By supporting better communication throughout the discharge management process, it introduces patient and caregiver choice into the discharge discussion and supports timely communication between the hospital care team and community based care providers.    3. Dr Philip Xiu     3. Ivan Wong     3. Alex Fargus    3. Dr Alain VuylstekeThis app enables a more efficient approach to managing porter resources in a care facility, dispatching porter resources to the areas of greatest need.\\xa0    4. Jon GautschBy grouping primary care physicians by “permission levels” and patients with a “priority score,” this app is designed to streamline scheduling between primary care physicians and specialists. This allows specialists to schedule more referrals from physicians whose referrals lead to the most surgeries and ultimately, more profit for specialty offices.    5. Mark Kizelshteyn     5. Molly Lafferty This app facilitates the communication of discharge instructions in a visual, plain-language manner, helping patients to better follow with their post-discharge care plan.    6. Matt Scantland  This app streamlines the medication pre-authorization process by consolidating and automating requests from health plans and delivering the information to care providers.    7. Chris NunesThis tablet-based app delivers a robust set of tools to patients, allowing them to interface with the hospital to learn more about their care, understand ownership of their own health and records, participate in quality and error control, and provide feedback on their experience.    8. Kerry McLuckie     8. Colin N. Young     8. Catharine G. Clark    8. David ClarkThis app provides workflow checklists for standard healthcare procedures to improve operational flow, provide vital information for the patient and hospital staff, reduce mistakes and improve the patient experience.    LSU. Scott KeislerThis idea focused on increasing the use of geographic information and technologies to improve scheduling.Think it’s possible to make hospital visits hassle-free? GE does.Despite every good intention, far too often, frustration and confusion are common reactions to a hospital visit. Many factors must come together to avoid things like long wait times, poor communication, repetitive paperwork, procedure delays, damaged or lost equipment, delayed discharge, and more. It is estimated that there is $100 billion wasted annually in healthcare inefficiencies, distracting facilities from their primary focus ‐ patient care. Now more than ever, we have the ability to improve on the efficiencies within hospitals. Think you’ve got the cure?Your challenge: \\xa0Contribute to the design of the ultimate patient experience.While medicine should be left to the professionals, many aspects of hospital operations are ripe for rethinking. In this Quest, focus on operational (non-medical) solutions that can promote an improved health care system experience for patient and family.Tweet'}, {'title': 'Facebook II - Mapping the Internet', 'url': 'https://www.kaggle.com/competitions/facebook-ii', 'briefDescription': 'Round II of the Facebook Recruiting Competition. ', 'coverImageUrl': None, 'tag': 'auc', 'description': 'The Task: you will be given a path which, at one point in the training time period,\\xa0was\\xa0an optimal path from node A to B. The question is then to make a probalistic prediction, for each of the 5 test graphs, whether the given path is STILL an optimal path. \\xa0This is a much more difficult task than link prediction alone.\\xa0The global structure of the graph may affect many optimal routes, paths can have varying lengths (and thus varying\\xa0a priori\\xa0probabilities of being optimal), and there may be multiple optimal routes for a given source & destination.The Prize: Facebook is seeking data-savvy software engineers (Data Engineers) to build the next generation of systems that will transform the online experience of over a billion users. Appropriate candidates should have experience with multiple components across the big data stack (check out the Visualization track for another way to highlight your skills). \\xa0There are many teams that they could be a fit for depending on their backgrounds\\xa0.\\xa0\\xa0An example visualization of Internet topology (round-trip times) produced by Walrus\\xa0(courtesy of Young Hyun and inverted for display purposes)'}, {'title': 'Observing Dark Worlds', 'url': 'https://www.kaggle.com/competitions/DarkWorlds', 'briefDescription': 'Can you find the Dark Matter that dominates our Universe? Winton Capital offers you the chance to unlock the secrets of dark worlds.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"There is more to the Universe than meets the eye. Out in the cosmos exists a\\xa0form of matter that outnumbers the stuff we can see by almost 7 to 1, and we don't know what it is. What we do know is that it does not emit or absorb light, so we call it Dark Matter.Such a vast amount of aggregated matter does not go unnoticed. In fact we observe that this stuff aggregates and forms massive structures called\\xa0Dark Matter Halos.Although dark, it warps and bends spacetime such that any light from a background galaxy which passes close to theDark Matter will\\xa0have its path altered and changed.\\xa0This bending causes the galaxy to appear as an ellipse in the sky.\\xa0\\xa0Figure 1: Dark Matter bending the light from a background galaxy. In extreme cases the galaxy here is seen as the two arcs surrounding it. (Credit: NASA, ESA, and Johan Richard (Caltech, USA))Since there are many galaxies behind a Dark Matter halo, their shapes will correlate with its position.Figure 2: The effect of Dark Matter on the sky\\xa0\\xa0What’s The Problem?Detecting these\\xa0Dark Matter\\xa0halos is hard, but possible using this data. If we can accurately estimate the positions of these halos, we can then understand the function they play in the Universe. There are various methods to attack the problem (we have given you some examples), however we have not been able to reach the level of precision required to understand exactly where this\\xa0Dark Matter\\xa0is for allDark Matter halos.Figure 3: Dark Matter in Action. If you look closely at this real world example, you can see the warped and elliptical galaxies.\\xa0(Credit\\xa0NASA; ESA; L. Bradley (Johns Hopkins University); R. Bouwens (University of California, Santa Cruz); H. Ford (Johns Hopkins University); and G. Illingworth (University of California, Santa Cruz)Challenge Organisers:\\xa0David Harvey (Astrophysics PhD Student, Institute for Astronomy, University of Edinburgh), Dr. Tom Kitching (Royal Society Post Doctorial Fellow, Institute for Astronomy, University of Edinburgh)\"}, {'title': 'Detecting Insults in Social Commentary', 'url': 'https://www.kaggle.com/competitions/detecting-insults-in-social-commentary', 'briefDescription': 'Predict whether a comment posted during a public discussion is considered insulting to one of the participants.', 'coverImageUrl': None, 'tag': 'auc', 'description': 'Visualization Track now open >>\\xa0Do you think you can take on the crudest, meanest trolls on the internet? Okay then, game on!The challenge is to detect when a comment from a conversation would be considered insulting to another participant in the conversation. Samples could be drawn from conversation streams like news commenting sites, magazine comments, message boards, blogs, text messages, etc.The idea is to create a generalizable single-class classifier which could operate in a near real-time mode, scrubbing the filth of the internet away in one pass.Prizes you say?Besides the prize money, eternal fame and glory, monuments in your honor, and the admiration of friend and foe alike, you get a chance for an interview at Impermium for the Principal Data Engineer role.In addition, there will be a Visualization prospect attached to the contest. \\xa0Slice and dice the data to show us the most amazing, informative and thought-provoking infographics, diagrams or plots!\\xa0Submission open 1 week before the contest ends.\\xa0'}, {'title': 'Follow the Money: Investigative Reporting Prospect', 'url': 'https://www.kaggle.com/competitions/cir-prospect', 'briefDescription': 'Find hidden patterns, connections, and ultimately compelling stories in a treasure trove of data about US federal campaign contributions', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"The most expensive political campaign season in US history is well underway, with experts predicting that spending from both the Republican and Democratic camps willexceed $5.8 billion before races for president and Congress are decided in November.Needless to say, campaign finance is a big business. And where big money leads the way, big data is never too far behind.That's why the Center for Investigative Reporting, the nation's largest non-profit investigative reporting organization, is teaming up withInvestigative Reporters and Editors, Inc. -- the world's leading investigative and data journalism trade group -- to offer this Prospect challenge in the hopes of answering one simple question: What can some of the world's most brilliant data scientists teach us about finding hidden patterns, interesting connections and ultimately compelling stories in a treasure trove of data about federal campaign contributions?Data journalists have been examining federal campaign finance records for decades, finding patterns and trends that have forced resignations and reforms. But despite many noteworthy successes, journalists' imaginations are limited by our skills. We're not mathematicians and machine learning experts! We might learn from a source, for instance, that a particular congressman has begun receiving campaign contributions from a new and unusual donor. But a carefully tuned anomaly detection system might reveal those patterns before our sources would ever notice them.What kinds of ideas are we looking for with this Prospect challenge? We want to see how sophisticated clustering algorithms can help spot donors that coordinate their operations, giving to the same candidates at the same times. We want to see how classification or anomaly detection systems can find donations that are particularly interesting or unusual. We want to know how you would mix up campaign contribution data with other sources -- lobbying records, congressional votes, federal contracts -- to find patterns that journalists are missing.Novel approaches to analysis, ideas for useful tools, and data visualizations will all be considered.What we're looking for is new ideas and approaches. To give you a sense of what journalists have done so far, we've included severalexamples of some of the most interesting campaign finance reporting around, along with sometipsheets that explain how journalists approach campaign finance data and what to look for.\"}, {'title': 'Will I Stay or Will I Go?', 'url': 'https://www.kaggle.com/competitions/customer-retention', 'briefDescription': 'Predict which of our current customers will stay insured with us for an entire policy term.  ', 'coverImageUrl': None, 'tag': 'logloss', 'description': 'An important part of succeeding as an insurance company is having a good understanding of which of the company’s current customers will be with the company into the future.\\xa0 Every customer comes with a different risk profile and it is critical to plan appropriately for that future risk.\\xa0 The goal of this competition is to predict which current customers will still be with the company in 6 months, given many of the customer’s characteristics.\\xa0'}, {'title': 'Global Energy Forecasting Competition 2012 - Wind Forecasting', 'url': 'https://www.kaggle.com/competitions/GEF2012-wind-forecasting', 'briefDescription': 'A wind power forecasting problem: predicting hourly power generation up to 48 hours ahead at 7 wind farms', 'coverImageUrl': None, 'tag': 'rmse', 'description': 'This is the Wind Forecasting track of Global Energy Forecasting Competition 2012 (GEFCom2012).This competition will bring together state-of-the-art techniques for energy forecasting, serve as the bridge to connect academic research and industry practice, promote analytics in power engineering education, and prepare the industry to overcome forecasting challenges in the smart grid world.The total prize pool for the wind forecasting track is $7,500.\\xa0GEFCom is not a paper contest. Instead, this is a competition that requires participants to develop models and submit forecasts based on a given data set. Accuracy of the forecasts will be one of the evaluation criteria.\\xa0In addition to accuracy, the participants are also required to submit a report describing the methodology, findings and models. Selected entries will be invited to IEEE PES General Meeting 2013 in Vancouver, Canada to present their methodologies and\\xa0results. The team that finishes at the top of the leaderboard will win a cash prize. However overall winners of the competition will be determined by the GEFCom Award Committee after the presentations based on\\xa0forecasting accuracy, clarity of documentation, rigors of the approach, interpretability of the models and practicality to the industry.\\xa0A few winning entries will be invited to submit the report in scientific paper format to prestigious scholarly journals, such as International Journal of Forecasting and IEEE Transactions on Smart Grid.The topic for the wind forecasting track is focused on mimicking the operation 48-hour ahead prediction of hourly power generation at 7 wind farms, based on historical measurements and additional wind forecast information (48-hour ahead predictions of wind speed and direction at the sites). The data is available for period ranging from the 1st hour of 2009/7/1 to the 12th hour of 2012/6/28.The period between 2009/7/1 and 2010/12/31 is a model identification and training period, while the remainder of the dataset, that is, from 2011/1/1 to 2012/6/28, is there for the evaluation. The training period is there to be used for designing and estimating models permiting to predicting wind power generation at lead times from 1 to 48 hours ahead, based on past power observations and/or available meteorological wind forecasts for that period. Over the evaluation part, it is aimed at mimicking real operational conditions. For that, a number of 48-hour periods with missing power observations where defined. All these power observations are to be predicted. These periods are defined as following. The first period with missing observations is that from 2011/1/1 at 01:00 until 2011/1/3 at 00:00. The second period with missing observations is that from 2011/1/4 at 13:00 until 2011/1/6 at 12:00. Note that to be consistent, only the meteorological forecasts for that period that would actually be available in practice are given. These two periods then repeats every 7 days until the end of the dataset. Inbetween periods with missing data, power observations are available for updating the models.\\xa0'}, {'title': 'Global Energy Forecasting Competition 2012 - Load Forecasting', 'url': 'https://www.kaggle.com/competitions/global-energy-forecasting-competition-2012-load-forecasting', 'briefDescription': 'A hierarchical load forecasting problem: backcasting and forecasting hourly loads (in kW) for a US utility with 20 zones.', 'coverImageUrl': None, 'tag': 'wrmse', 'description': \"The prize pool for the load forecasting track is $7,500.\\xa0GEFCom is not a paper contest. Instead, this is a competition that requires participants to develop models and submit forecasts based on a given data set. Accuracy of the forecasts will be one evaluation criteria.\\xa0In addition to accuracy, the participants are also required to submit a report describing the methodology, findings and models. Selected entries will be invited to IEEE PES General Meeting 2013 at Vancouver, Canada to present their methodologies and\\xa0results. The team that finishes top of the leaderboard will win a cash prize. However an overall winner of the competition will be determined by the GEFCom Award Committee after the presentations based on\\xa0forecasting accuracy, clarity of documentation, rigors of the approach, interpretability of the models and practicality to the industry.\\xa0A few winning entries will be invited to submit the report in scientific paper format to prestigious scholarly journals, such as International Journal of Forecasting and IEEE Transactions on Smart Grid.The topic for the load forecasting track is a hierarchical load forecasting problem: backcasting and forecasting hourly loads (in kW) for a US utility with 20 zones. The participants are required to backcast and forecast at both zonal level (20 series) and system (sum of the 20 zonal level series) level, totally 21 series.Data (loads of 20 zones and temperature of 11 stations) history ranges from the 1st hour of\\xa02004/1/1 to the 6th hour of 2008/6/30.Given actual temperature history, the 8 weeks below in the load history are set to be missing and are required to be backcasted. It's OK to use the entire history to backcast these 8 weeks.2005/3/6 - 2005/3/12;2005/6/20 - 2005/6/26;2005/9/10 - 2005/9/16;2005/12/25 - 2005/12/31;2006/2/13 - 2006/2/19;2006/5/25 - 2006/5/31;2006/8/2 - 2006/8/8;2006/11/22 - 2006/11/28;In addition, the particpants need to forecast hourly loads from 2008/7/1 to 2008/7/7. No actual temperatures are given for this week.\\xa0\"}, {'title': 'U.S. Census Return Rate Challenge', 'url': 'https://www.kaggle.com/competitions/us-census-challenge', 'briefDescription': 'Predict census mail return rates.', 'coverImageUrl': None, 'tag': 'nwmae', 'description': 'Note: The prediction phase of this competition has ended. Please join the visualization competition\\xa0which ends on Nov. 11, 2012.--This challenge is to develop a statistical model to predict census mail return rates at the Census block group level of geography. The Census Bureau will use this model for planning purposes for the decennial census and for demographic sample surveys. The model-based estimates of predicted mail return will be publicly released in a later version of the Census \"planning database\" containing updated demographic data.Participants are encouraged to develop and evaluate different statistical approaches to proposing the best predictive model for geographic units. The intent is to improve our current predictive analytics.Please note also that as described in the rules, only US citizens and residents are eligible for prizes.'}, {'title': 'Predict Closed Questions on Stack Overflow', 'url': 'https://www.kaggle.com/competitions/predict-closed-questions-on-stack-overflow', 'briefDescription': 'Predict which new questions asked on Stack Overflow will be closed', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'This competition is now complete. Congratulations to thewinners!Millions of programmers use Stack Overflow to get high quality answers to their programming questions every day. \\xa0We take quality very seriously, and have evolved an effective culture of moderation to safe-guard it.With more than six thousand new questions asked on\\xa0Stack Overflow\\xa0every weekday we\\'re looking to add more sophisticated software solutions to our moderation toolbox.Closing QuestionsCurrently about 6% of all new questions end up \"closed\". \\xa0Questions can be closed asoff topic, not constructive, not a real question, or too localized. \\xa0More in depth descriptions of each reason can be found in the\\xa0Stack Overflow FAQ. \\xa0Theexact duplicate close reason has been excluded from this contest, since it depends on previous questions.Your goal is to build a classifier that predicts whether or not a question will be closed given the question as submitted, along with the reason that the question was closed. \\xa0Additional data about the user at question creation time is also available.'}, {'title': \"Harvard Business Review 'Vision Statement' Prospect\", 'url': 'https://www.kaggle.com/competitions/harvard-business-review-vision-statement-prospect', 'briefDescription': 'Your Analysis and/or Visualization featured in the Harvard Business Review', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"View the Winning Entry in the HBR >>Data-mine the progress of almost a century's worth of the most influential management concepts and ideas.\\xa0 The Harvard Business Review is asking you to turn your data-vision on the archival history of the HBR. The goal of this prospect to to generate analysis and visualizations from the metadata and abstracts of every article they have published over the last 90 years. Winning entries will be featured in the Vision Statement feature of the upcoming 90th anniversary issue.What makes a great entry?\\xa0 Check out the past 'Vision Statement' features scattered throughout the contest page, and available for download.\\xa0 The HBR wants you to find the story behind the data. Don't just build a latent topic model... show how the important topics have trended over the last 90 years.\\xa0 Once you quantify the impact of an article, can you pick out the most seminal case-studies of the 20th century?. You don't have to be a professional graphic designer, but you should keep in mind how your work will make its point to a professional, but possibly non-technical, audience.\\xa0 This is a contest for every analyst who has struggled to explain the value of data to his or her boss.\\xa0\\xa0 Well, now is your chance to show what you can do to your boss's boss's boss.\"}, {'title': 'Data Mining Hackathon on (20 mb) Best Buy mobile web site - ACM SF Bay Area Chapter', 'url': 'https://www.kaggle.com/competitions/acm-sf-chapter-hackathon-small', 'briefDescription': 'Getting Started - Predict which Xbox game a visitor will be most interested in based on their search query.  (20 MB)', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'Two years of mobile behavior, 67 million clicks, 27 million searches, 8 million users, 1 million productsThere will also be a Visualization Contest that can be entered from either track.For more details on the event, go to:http://www.sfbayacm.org/DM-Hackathon-2012-10Data Provided by:\\xa0Cloud Compute Sponsors: \\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0'}, {'title': 'Data Mining Hackathon on BIG DATA (7GB) Best Buy mobile web site', 'url': 'https://www.kaggle.com/competitions/acm-sf-chapter-hackathon-big', 'briefDescription': 'Predict which BestBuy product a mobile web visitor will be most interested in based on their search query or behavior over 2 years (7 GB).', 'coverImageUrl': None, 'tag': 'custom metric', 'description': '3 months of real-world mobile behavior, 1.8 million clicks, 1.2 million users.There will also be a Visualization Contest that can be entered from either track.For more details on the event, go to:http://www.sfbayacm.org/DM-Hackathon-2012-10\\xa0 (links to presentations were added 8/19/2012)Data Provided by:\\xa0Cloud Compute Sponsors: \\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0'}, {'title': 'Merck Molecular Activity Challenge', 'url': 'https://www.kaggle.com/competitions/MerckActivity', 'briefDescription': 'Help develop safe and effective medicines by predicting molecular activity.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"Help enable the development of safe, effective medicines.When developing new medicines\\xa0it is important to identify molecules that are highly active toward their intended targets but not toward other targets that might cause side effects. The objective of this competition is to identify the best statistical techniques for predicting biological activities of different molecules, both on- and off-target,\\xa0given numerical descriptors generated from their chemical structuresThe challenge is based on 15 molecular activity data sets, each for a biologically relevant target. Each row corresponds to a molecule and contains descriptors derived from that molecule's chemical structure.In addition to the prediction competition, Merck is also hosting a visualization\\xa0challenge\\xa0with a $2,000 prize for the most insightful and elegant graphical representations of the data.Prizes total\\xa0$40,000.\"}, {'title': 'Job Recommendation Challenge', 'url': 'https://www.kaggle.com/competitions/job-recommendation', 'briefDescription': 'Predict which jobs users will apply to', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'This competition has completed. Congratulations to the winners along with all the other participants!CareerBuilder.com is proud to sponsor the Job Recommendation Engine Challenge, which asks you to predict what jobs its users will apply to based on their previous applications, demographic information, and work history. The insights you discover from this data, and the algorithms the winners create, will allow CareerBuilder to improve its job recommendation algorithm, a core part of its website and a key element in improving user experience.\\xa0 \\xa0  There will also be a data visualization prospect towards the end of this contest.'}, {'title': 'Digit Recognizer', 'url': 'https://www.kaggle.com/competitions/digit-recognizer', 'briefDescription': 'Learn computer vision fundamentals with the famous MNIST data', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/3004/logos/header.png?t=2018-11-14-20-12-43', 'tag': 'tabular, image, multiclass classification, categorizationaccuracy', 'description': 'Start here if...You have some experience with R or Python and machine learning basics, but you’re new to computer vision. This competition is the perfect introduction to techniques like neural networks using a classic dataset including pre-extracted features.Competition DescriptionMNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.Practice SkillsComputer vision fundamentals including simple neural networksClassification methods such as SVM and K-nearest neighborsAcknowledgements\\xa0More details about the dataset, including algorithms that have been tried on it and their levels of success, can be found at http://yann.lecun.com/exdb/mnist/index.html. The dataset is made available under a Creative Commons Attribution-Share Alike 3.0 license.'}, {'title': 'EMI Music Data Science Hackathon - July 21st - 24 hours', 'url': 'https://www.kaggle.com/competitions/MusicHackathon', 'briefDescription': 'Can you predict if a listener will love a new song?', 'coverImageUrl': None, 'tag': 'rmse', 'description': '  (Data will be made available 24 hours prior to the start of the contest)For more info http://musicdatascience.com/hashtag #musicdata #ds_ldn #DSGhack \\xa0Proudly brought to you by\\xa0'}, {'title': 'Raising Money to Fund an Organizational Mission', 'url': 'https://www.kaggle.com/competitions/Raising-Money-to-Fund-an-Organizational-Mission', 'briefDescription': 'Help worthy organizations more efficiently target and recruit loyal donors to support their causes. ', 'coverImageUrl': None, 'tag': 'averageamongtopp', 'description': 'Many organizations prospect for loyal supporters and donors by sending direct mail appeals. This is an effective way to build a large base, but can be very expensive and have a low efficiency. Eliminating likely non-donors is the key to running an efficient Prospecting program and ultimately to pursuing the mission of the organization. Help us help these organizations to target the best prospective donors and fund organizational goals!\\xa0Please note: This competition has rules that we have not used previously restricting what kinds of models are acceptable. Please see the rules page for more information.'}, {'title': 'Practice Fusion Diabetes Classification', 'url': 'https://www.kaggle.com/competitions/pf2012-diabetes', 'briefDescription': 'Identify patients diagnosed with Type 2 Diabetes', 'coverImageUrl': None, 'tag': 'logloss', 'description': \"In the first phase of this prediction challenge  Practice Fusion invited anyone with an interest in using electronic medical record data to improve public health to submit and vote on ideas for prediction problems based on a new dataset of 10,000 de-identified medical records. The votes are in and Shea Parkes' top voted submission has won.Practice Fusion is now sponsoring the second and final phase of the challenge inspired by the winning problem: Identify patients diagnosed with Type 2 Diabetes Mellitus.Over 25 million people, or nearly 8.3% of the entire United States population, have diabetes. Diabetes is also associated with a wide range of complications from heart disease and stroke to blindness and kidney disease. Predicting who has diabetes will lead to a better understanding of these complications and the common comorbidities that diabetics suffer.The Challenge: Given a de-identified data set of patient electronic health records, build a model to determine who has a diabetes diagnosis, as defined by ICD9 codes 250, 250.0, 250.*0 or 250.*2 (e.g., 250, 250.0, 250.00, 250.10, 250.52, etc).\"}, {'title': 'CPROD1: Consumer PRODucts contest #1', 'url': 'https://www.kaggle.com/competitions/cprod1', 'briefDescription': 'Identify product mentions within a largely user-generated web-based corpus and disambiguate the mentions against a large product catalog.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"A significant proportion of web usage relates to discussions, research, and purchase of consumer products. Currently, hundreds of thousands of blogs, forums, product review sites, and e-commerce merchants currently exist, in part, to service consumer's need to access product related information and demand to share experiences with products.The goal of this competition is to determine the state-of-the-art methods to automatically recognize product mentions in such textual content and to also disambiguate which product(s) in product catalogs are being referenced.\\xa0Specifically, the task is to automatically identify all mentions of consumer products in a largely user generated collection of web-content, and to correctly identify the product(s) that each product mention refers to from a large catalog of products.\\xa0The datasets provided includes hundreds of thousands of text items, a product catalog with over fifteen million products, and hundreds of manually annotated product mentions to support data-driven approaches.The prize pool for the contest is $10,000 and is divided as follows: $6,000 for first, $3,000 for second and $1,000 for third place submissions.Note that the contest is colocated with the ICDM-2012 conference. There will be a workshop on the contest results on December 10th.\"}, {'title': 'The Hewlett Foundation: Short Answer Scoring', 'url': 'https://www.kaggle.com/competitions/asap-sas', 'briefDescription': 'Develop a scoring algorithm for student-written short-answer responses.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"This competition has completed, congratulations to the preliminary winners and the other participants!The William and Flora Hewlett Foundation (Hewlett Foundation) is sponsoring the Automated Student Assessment Prize (ASAP) in hopes of discovering new tools to support schools and teachers. The competition aspires to solve the problem of the high cost and the slow turnaround of hand scoring thousands of written responses in standardized tests.\\xa0 As a result many schools exclude written responses in favor of multiple-choice questions, which are less able to assess students’ critical reasoning and writing skills.\\xa0 ASAP has been designed to help determine whether computerized systems are capable of grading written content accurately for schools and teachers to adopt those solutions.\\xa0 ASAP aspires to inform key decision makers, who are already considering adopting these systems, by delivering a fair, impartial and open series of trials to test current capabilities and to drive greater awareness when outcomes warrant further consideration.Critical reasoning is one of a suite of skills that experts believe students must be taught to succeed in the new century. The Hewlett Foundation makes grants to educators and nonprofit organizations in support of these skills, which it calls “deeper learning.” They include the mastery of core academic content, critical reasoning and problem solving, working collaboratively, communicating effectively, and learning how to learn independently. With ASAP, Hewlett is appealing to data scientists to help solve an important problem in the field of educational testing.\\xa0Hewlett is sponsoring the following prizes as part of Phase Two:$50,000:\\xa0 1 place $25,000:\\xa0 2 place $15,000:\\xa0 3 place $\\xa0 7,500:\\xa0\\xa04 place $\\xa0 2,500:\\xa0 5 placeIn May of this year, $100,000 in prizes was rewarded for ASAP, Phase One, and we have launched ASAP, Phase Two, with the same intentions.\\xa0 During Phase One, we focused on systems to support the grading of student written essays.\\xa0This time, we’re offering a similar competition, only focused on short answer responses.\\xa0 We welcome you to learn more about our previous phase at www.kaggle.com/c/asap-aesDuring Phase Two, you are provided access to graded short answer responses and their corresponding prompts, so that you can build, train and test your scoring engines against a wide field of competitors.\\xa0Your success depends upon how closely you can align your scores to those of human expert graders.\\xa0 While we believe that a pool of $100,000 in potential financial incentives are important, we also intend to secure and distribute your solutions to the public, in hopes of elevating the field of automated assessment through your contributions.\\xa0 We want you to induce a breakthrough that is both personally satisfying and game-changing for improving public education.We have already learned that automated assessment systems can yield fast, effective and affordable solutions that would allow states to introduce new testing tools capable of assessing deeper measures of learning.\\xa0 We believe that you can help us pave the way towards better student assessment.\\xa0ASAP is designed to achieve the following goals:Challenge developers of student assessment systems to demonstrate their current capabilities.Reveal the efficacy and cost of alternative scoring systems to support teachers.Promote the capabilities of effective scoring systems to state departments of education and other key decision makers, when those advantages have been proven to support student and teacher interests.The Phase Two graded content is selected according to specific characteristics.\\xa0 On average, each answer is approximately 50 words in length.\\xa0 Some are more dependent upon source materials than others, and the answers cover a broad range of disciplines (from English Language Arts to Science). \\xa0The range of answer types is provided so that we can better understand the strengths of your solution.\\xa0 It is our intent to showcase quality and reliability, based on how well you can align with expert human graders for each response.You will be provided with training data for each prompt.\\xa0 Most training sets will consist of about 1,800 responses that have been randomly selected from a sample of approximately 3,000.\\xa0 The number of training data may vary.\\xa0 The data will contain ASCII formatted text for each response followed by two hand scores.\\xa0 The first score is the final score and the one that you are trying to predict. The second score was used to determine reliability of the first score. The second score did not in any way influence the first (final) score. You are provided with both scores, so that you may evaluate the reliability of the hand scoring.\\xa0 Further instruction and clarification regarding the data is available on the DATA tab.Following a period of 2.5 months to train your scoring engine, you will be provided with test data that will contain approximately 6,000 new responses (600 per data set), randomly selected for blind evaluation.\\xa0 However, you will notice that the score columns will be blank.\\xa0 You will be asked to supply, based on your engine's predictions for each response, your score for each response and to submit your new scored data set on this site.As part of the ZIP file that you will submit with your predictive scores, you will be asked to submit a technical METHODS PAPER.\\xa0We would like to understand your specific approach to developing your scorig engine, along with any known limitations.\\xa0Basically, you will have the opportunity to present your scoring engine to the world, so that others may build upon it.\\xa0 Your technical METHODS PAPER will not be used to determine any prize rewards, but it is a required component of your final submission.Also, please note that it is our intention to continue staging other follow-on ASAP phases in the months ahead.\\xa0 We have started with graded essays (Phase 1), and we are now focusing on short answers (Phase 2); we are developing plans for a third phase, and we’re planning to launch a phase to demonstrate efficacy of systems capable of offering formative feedback as part of classroom applications:Phase 1:\\xa0 Demonstration for long-form constructed response (essays);\\xa0Phase 2:\\xa0 Demonstration for short-form constructed response (short answers);Phase 3:\\xa0\\xa0Demonstration for symbolic mathematical/logic reasoning (charts/graphs).In every instance, we seek to drive innovation for new solutions to student assessment, to support teachers in evaluating critical reasoning skills.\\xa0 We hope that you will enjoy this process.\\xa0 May the best model win!\"}, {'title': 'GigaOM WordPress Challenge: Splunk Innovation Prospect', 'url': 'https://www.kaggle.com/competitions/predict-wordpress-likes', 'briefDescription': 'Predict which blog posts someone will like.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'Splunk Innovation Prize now OPEN »\\xa0Announced at the GigaOM Structure Conference, powered by Splunk, and using data from WordPress.com, this competition is about predicting which people will \"like\" which blog posts from across 90k active blogs on WordPress.com.\\xa0 WordPress.com hosts about half of the 74 million WordPress sites in the world (over 16% of all domains on the web). The winning solutions may be used by WordPress.com in a recommendation engine, but winning solutions must be open-sourced, so they could be used by anyone to solve a similar problem using similar data in a similar domain.Competition winners will be announced in September at GigaOM Mobilize.About Splunk: Splunk\\xa0Inc. provides the engine for machine data™. Splunk software enables organizations to monitor, search, analyze, visualize and act on massive streams of real-time and historical machine data.\\xa0Splunk has donated access to a Splunk server containing the entire WordPress dataset for you to explore, visualize and experiment. When you accept the rules for the competition, you will automatically be sent a personal login to the Splunk server.There is also a 5K companion competition to the predictive modeling challenge. TheSplunk Innovation Prize will be awarded for the most innovative use of Splunk for data science (using the competition dataset).Never used Splunk before?\\xa0 Here are some tutorials to get you started.Getting started videos Search Reference guide (explains the search language) About Gigaom: GigaOM is one of the most credible and insightful voices at the intersection of business and technology, with an online audience of more than 5.5 million monthly unique visitors, industry-leading events, and a pioneering research service and digital community, GigaOM Pro, which provides expert analysis on emerging technology markets.\\xa0\\xa0'}, {'title': 'EMC Israel Data Science Challenge', 'url': 'https://www.kaggle.com/competitions/emc-data-science', 'briefDescription': 'Match source code files to the open source code project', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'The EMC source code classification challenge requires you to classify source code files according to the projects they belong to.Given a set of source code files collected from various open source projects, how well can unseen source code files from the same set of open source projects can be classified?Possible real-world applications:Protecting intellectual property Data Loss Protection (DLP) Automatic categorization of source code repositories '}, {'title': 'Practice Fusion Analyze This! 2012 - Open Challenge', 'url': 'https://www.kaggle.com/competitions/pf2012-at', 'briefDescription': 'Start digging into electronic health records and submit your creative, insightful, and visually striking analyses.', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"Get the data » Practice Fusion is America's fastest growing Electronic Health Record (EHR) community, with more than 170,000 medical professional users treating 34 million patients in all 50 states. Practice Fusion’s EHR-driven research dataset is used to detect disease outbreaks, identify dangerous drug interactions and compare the effectiveness of competing treatments.In partnership with Kaggle, Practice Fusion is releasing 10,000 de-identified, HIPAA-compliant medical records to spur innovation into new uses of clinical data to improve public health and patient care. This dataset is one of the largest and richest sources of medical record data ever released and includes information on diagnoses, lab results, medications, allergies, immunizations, vital signs, and health behavior.Practice Fusion’s past data challenges have spawned a range of creative visualizations, applications, analyses, and even a few start-ups. In this year’s Analyze This!, Practice Fusion and Kaggle call on an ever-growing community of developers, designers, and data scientists interested in solving our nation’s most stubborn healthcare problems by tackling our two data challenges: the Prediction Challenge and the Open Challenge.Open ChallengeGet the dataset and show us what you can find!Combine the Analyze This! dataset with one or more datasets from  www.data.gov. Use the mash-up however you like: map chronic disease across the country, create a personal health app, or a tool for running clinical trials. Share your results and analyses online!Submissions for the Open Challenge will be accepted from the launch of Analyze This! to Monday, September 10. \"}, {'title': 'Practice Fusion Analyze This! 2012 - Prediction Challenge', 'url': 'https://www.kaggle.com/competitions/pf2012', 'briefDescription': 'Start digging into electronic health records and submit your ideas for the most promising, impactful or interesting predictive modeling competitions', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"Get the data » Practice Fusion is America's fastest growing Electronic Health Record (EHR) community, with more than 170,000 medical professional users treating 34 million patients in all 50 states. Practice Fusion’s EHR-driven research dataset is used to detect disease outbreaks, identify dangerous drug interactions and compare the effectiveness of competing treatments.In partnership with Kaggle, Practice Fusion is releasing 10,000 de-identified, HIPAA-compliant medical records to spur innovation into new uses of clinical data to improve public health and patient care. This dataset is one of the largest and richest sources of medical record data ever released and includes information on diagnoses, lab results, medications, allergies, immunizations, vital signs, and health behavior.Practice Fusion’s past data challenges have spawned a range of creative visualizations, applications, analyses, and even a few start-ups. In this year’s Analyze This!, Practice Fusion and Kaggle call on an ever-growing community of developers, designers, and data scientists interested in solving our nation’s most stubborn healthcare problems by tackling our two data challenges: the Prediction Challenge and the Open Challenge.Prediction ChallengeThe first phase of the Prediction Challenge is  Kaggle Prospect in which you submit ideas for the best prediction problem! The Kaggle community is invited to vote on the most interesting and promising ideas. A panel of judges will select a winner from the top-voted 10 ideas for the second phase, a predictive modeling competition based on the winning idea.Kaggle Prospect submissions and voting will be available from the launch of Analyze This! to June 30. The predictive modeling phase of the Prediction Challenge will start no later than July 9, and end on Monday, September 10.The predictive modeling competition is now underway and can be found here.Open ChallengeGet the dataset and show us what you can find!Combine the Analyze This! dataset with one or more datasets from  www.data.gov. Use the mash-up however you like: map chronic disease across the country, create a personal health app, or a tool for running clinical trials. Share your results and analyses online!Submissions for the Open Challenge will be accepted from the launch of Analyze This! to Monday, September 10. \"}, {'title': 'Facebook Recruiting Competition', 'url': 'https://www.kaggle.com/competitions/FacebookRecruiting', 'briefDescription': 'Show them your talent, not just your resume.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': '\\xa0Please note: You must compete as an  in recruiting competitions.\\xa0 You may only use the data provided to make your predictions.\\xa0 Facebook will review the code of the top participants before deciding whether to offer an interview.'}, {'title': 'Psychopathy Prediction Based on Twitter Usage', 'url': 'https://www.kaggle.com/competitions/twitter-psychopathy-prediction', 'briefDescription': 'Identify people who have a high degree of Psychopathy based on Twitter usage.', 'coverImageUrl': None, 'tag': 'mcap', 'description': \"The\\xa0 aim of the competition is to determine to what degree it's possible to predict people with a sufficiently high degree of Psychopathy based on Twitter usage and Linguistic Inquiry.The organizers provide all interested participants an anonymised dataset of users self assessed psychopathy scores together with 337 variables derived from functions of Twitter information, useage and lingusitc analysis. Psychopathy scores are based on a checklist developed by Professor Del Paulhus at the University of British Columbia.The model should aim to identify people scoring high in Psychopathy, for the purpose of this competition, defined as 2 SD's above a mean of 1.98. This accounts for roughly 3% of the entire sample and therefore the challenge with this dataset is developing a model to work with a highly imbalanced dataset.The best performing model(s) will be formally cited in a future paper/papers. The authors of the winning model may also be invited to attend future conferences to discuss their model.\\xa0The intention of this research is to seperate fact from fiction and examine just what can be predicted by social media use and how this information might be used, both for good and bad. As an organization, the Online Privacy Foundation works to raise awareness of online privacy issues and empower people to make informed choices about what they do online. We hope you'll support our mission and take part in this competition.\\xa0\\xa0\"}, {'title': 'Personality Prediction Based on Twitter Stream', 'url': 'https://www.kaggle.com/competitions/twitter-personality-prediction', 'briefDescription': 'Identify the best performing model(s) to predict personality traits based on Twitter usage', 'coverImageUrl': None, 'tag': 'mcap', 'description': \"The aim of this competition is to determine the best models to predict the personality traits of Machiavellianism, Narcissism, Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism based on Twitter usage and linguistic inquiry.The organizers provide all interested participants an anonymised dataset of users self assessed personality scores (based checklists developed by Prof Del Paulhus at the University of British Columbia and Prof Sam Gosling and the University of Texas) together with 337 variables derived from functions of Twitter information and lingusitc analysis.The best performing model(s) will be formally cited in a future paper and any presentations.\\xa0The intention of this research is to seperate fact from fiction and examine just what can be predicted by social media use and how this information might be used, both for good and bad. As an organization, the Online Privacy Foundation works to raise awareness of online privacy issues and empower people to make informed choices about what they do online. We hope you'll support our mission and take part in this competition.\\xa0\\xa0(\"}, {'title': 'CHALEARN Gesture Challenge 2', 'url': 'https://www.kaggle.com/competitions/GestureChallenge2', 'briefDescription': 'Develop a Gesture Recognizer for Microsoft Kinect (TM)', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'This is Round 2 - Check out the results of the first round!NEW: data annotations and examples of algorithms (in Matlab).This competition is identitical to the first round of the CHALEARN gesture challenge, the only difference is that is will be judged on new fresh final evaluation data. Keep informed of new data releases and new events, sign up to thegesturechallenge group.Similarly, there will be a development phase\\xa0(May 7, 2012 to September 6, 2012) and afinal evaluation phase (September 7, 2012 to September 10. 2012):\\xa0Development phase:\\xa0Create a learning system capable of learning from a single training example a gesture classification problem. Practice with\\xa0development data (a large database of 50,000 labeled gestures is available) and submit predictions on-line on validation data to get immediate feed-back on the leaderboard. Recommended: towards the end of the development phase, submit your code for verification purpose. See theevaluation section.Final evaluation phase: Make predictions on the\\xa0new final evaluation data revealed at the end of the development phase. The participants will have 4 days to train their systems and upload their predictions.\\xa0SponsorsThis challenge is organized by\\xa0CHALEARN\\xa0and is sponsored in part byMicrosoft (Kinect for Xbox 360). Other sponsors includeTexas Instrument.\\xa0'}, {'title': 'Online Product Sales', 'url': 'https://www.kaggle.com/competitions/online-sales', 'briefDescription': 'Predict the online sales of a consumer product based on a data set of product features.', 'coverImageUrl': None, 'tag': 'rmsle', 'description': 'The objective of the competition is to help us build as good a model as possible to predict monthly online sales of a product. Imagine the products are online \\xa0self-help programs following an initial advertising campaign.We have shared the data in the comma separated values (CSV) format. \\xa0Each row in this data set represents a different consumer product.The first 12 columns (Outcome_M1 through Outcome_M12) contains the monthly online sales for the first 12 months after the product launches. \\xa0Date_1 is the day number the major advertising campaign began and the product launched. \\xa0Date_2 is the day number the product was announced and a pre-release advertising campaign began.Other columns in the data set are features of the product and the advertising campaign. \\xa0Quan_x are quantitative variables and Cat_x are categorical variables. Binary categorical variables are measured as (1) if the product had the feature and (0) if it did not.'}, {'title': 'EMC Data Science Global Hackathon (Air Quality Prediction)', 'url': 'https://www.kaggle.com/competitions/dsg-hackathon', 'briefDescription': 'Build a local early warning systems to accurately predict dangerous levels of air pollutants on an hourly basis.', 'coverImageUrl': None, 'tag': 'mae', 'description': 'Hosted by Data Science London and Data Science Global as part of aBig Data Week event, and organised by Kaggle, the first ever global data science hackathon will take place at the same time in several cities around the world spanning a 24-hour period. During this time the data scientists will compete with each other for cash prizes using a large dataset provided by the Cook County, Illinois, local government.The challenge for the hackathon is to build with better more accurate predictive models of metropolitan air pollution. The EPA’s Air Quality Index is used daily by people suffering from asthma and other respiratory diseases to avoid dangerous levels of outdoor air pollutants, which can trigger attacks. According to the World Health Organisation there are now estimated to be 235 million people suffering from asthma. Globally, it is now the most common chronic disease among children, with incidence in the US doubling since 1980.\\xa0 The model we build could be used as the basis for an early warning system that is capable of accurately predicting dangerous levels of air pollutants on an hourly basis.Data Science Global is a non-profit organization dedicated to bringing together the world’s communities of data scientists, artists, technologists and visionaries.\\xa0 For our inaugural event, we are hosting a global data science hackathon. \\xa0 It will be taking place simultaneously in cities around the world: London, New York, Boston, Chicago, San Francisco, Melbourne, Canberra, Sydney and Turku, Finland, as well as remote participants competing directly through Kaggle.\\xa0 You can join in the live webcast from the participating venues at datascienceglobal.org'}, {'title': 'Million Song Dataset Challenge', 'url': 'https://www.kaggle.com/competitions/msdchallenge', 'briefDescription': 'Predict which songs a user will listen to.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"The Million Song Dataset Challenge aims at being the best possible offline evaluation of a music recommendation system.\\xa0 Any type of algorithm can be used: collaborative filtering, content-based methods, web crawling, even human oracles!* By relying on theMillion Song Dataset, the data for the competition is completely open: almost everything is known and possibly available.What is the task in a few words? You have: 1) the full listening history for 1M users, 2) half of the listening history for 110K users (10K validation set, 100K test set), and you must predict the missing half. How much easier can it get?The most straightforward approach to this task is pure collaborative filtering, but remember that there is a wealth of information available to you through theMillion Song Dataset. Go ahead, explore! \\xa0If you have questions, we recommend that you consult theMSD Mailing List.Ready to start recommending? \\xa0Read through our Getting Started tutorial. You can also look at this open-source solution offered by a contestant.For a more technical introduction to the MSD Challenge, see our AdMIRe paper. (Please use this following citation when referring to the contest in an academic setting.)* This contest is for computer models, but if you manage to get recommendations from humans for 110K listeners, we'd like to know how!\\xa0The Million Song Dataset Challenge is a joint effort between the Computer Audition Lab\\xa0at UC San Diego\\xa0and\\xa0LabROSA atColumbia University. The user data for the challenge, like much of the data in the Million Song Dataset, was generously donated byThe Echo Nest, with additional data contributed bySecondHandSongs, musiXmatch, and Last.fm.\\xa0Follow-up evaluations will be conducted by\\xa0IMIRSEL at theGraduate School of Library Information Science at UIUC\\xa0as part of the Music Information Retrieval Evaluation eXchange (MIREX).\\xa0\\xa0\\xa0\\xa0\"}, {'title': 'Eye Movements Verification and Identification Competition', 'url': 'https://www.kaggle.com/competitions/emvic', 'briefDescription': 'Determine how people may be identified based on their eye movement characteristic.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"The aim of the contest is to determine how people may be identified based on their eye movement characteristic. The organizers provide all interested participants dataset\\xa0of eye movements' recordings in CSV format. After downloading the training dataset, participants may analyze it to prepare their own classification models and try to classify sapmles in test dataset.This in an official competition for\\xa0BTAS 2012\\xa0(The Fifth IEEE International Conference on Biometrics: Theory, Applications and Systems, September 23-27, Washington DC, USA) and all results will be published during that conference (and of course on this web page as well).. All data needed is ready to download! You only need to have some experience in data classification and... take your chance.\"}, {'title': 'Predicting a Biological Response', 'url': 'https://www.kaggle.com/competitions/bioresponse', 'briefDescription': 'Predict a biological response of molecules from their chemical properties', 'coverImageUrl': None, 'tag': 'logloss', 'description': 'The objective of the competition is to help us build as good a model as possible so that we can, as optimally as this data allows, relate molecular information, to an actual biological response.We have shared the data in the comma separated values (CSV) format. Each row in this data set represents a molecule. The first column contains experimental data describing an actual biological response; the molecule was seen to elicit this response (1), or not (0). The remaining columns represent molecular descriptors (d1 through d1776), these are calculated properties that can capture some of the characteristics of the molecule - for example size, shape, or elemental constitution. The descriptor matrix has been normalized.'}, {'title': 'ICFHR 2012 - Arabic Writer Identification', 'url': 'https://www.kaggle.com/competitions/awic2012', 'briefDescription': 'Identify which writer wrote which documents.', 'coverImageUrl': None, 'tag': 'categorizationaccuracy', 'description': \"Writer identification is a very active research field. It is of a primordial importance in forensic document examination when it helps experts in delibirating on the authenticity of a certain document.This is a follow-up contest of the last year' Arabic Writer Identification Contest.As we mentioned in the last edition,\\xa0we have significantly augmented the number of writers (we have more than 200 writers in this new database).we will not be providing any side-information (eg. number of documents per writer), as this is not necessarly known in a real forensic casework.we will only provide binary images, as color and gray-level images might transform this into a pen identification task.This competition is organized in conjunction with the International Conference of Frontiers in Handwriting RecognitionICFHR2012 which will be held in Bari, Italy in September\\xa018-20.\"}, {'title': 'KDD Cup 2012, Track 2', 'url': 'https://www.kaggle.com/competitions/kddcup2012-track2', 'briefDescription': 'Predict the click-through rate of ads given the query and user information.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/2749/logos/header.png', 'tag': 'custom metric', 'description': \"TASK 2 DESCRIPTION Search advertising has been one of the major revenue sources of the Internet industry for years. A key technology behind search advertising is to predict the click-through rate (pCTR) of ads, as the economic model behind search advertising requires pCTR values to rank ads and to price clicks. In this task, given the training instances derived from session logs of the Tencent proprietary search engine, soso.com, participants are expected to accurately predict the pCTR of ads in the testing instances.TRAINING DATA FILE\\xa0\\xa0\\xa0 The training data file is a text file, where each line is a training instance derived from search session log messages. To understand the training data, let us begin with a description of search sessions.\\xa0 \\xa0A search session refers to an interaction between a user and the search engine. It contains the following ingredients: the user, the query issued by the user, some ads returned by the search engine and thus impressed (displayed) to the user, and zero or more ads that were clicked by the user. For clarity, we introduce a terminology here. The number of ads impressed in a session is known as the ’depth’. The order of an ad in the impression list is known as the ‘position’ of that ad. An Ad, when impressed, would be displayed as a short text known as ’title’, followed by a slightly longer text known as the ’description’, and a URL (usually shortened to save screen space) known as ’display URL’.\\xa0 \\xa0We divide each session into multiple instances, where each instance describes an impressed ad under a certain setting\\xa0 (i.e., with certain depth and position values). \\xa0We aggregate instances with the same user id, ad id, query, and setting in order to reduce the dataset size. Therefore, schematically, each instance contains at least the following information:UserID\\xa0AdID\\xa0Query\\xa0Depth\\xa0Position\\xa0Impression\\xa0the number of search sessions in which the ad (AdID) was impressed by the user (UserID) who issued the query (Query).Click\\xa0the number of times, among the above impressions, the user (UserID) clicked the ad (AdID).\\xa0 \\xa0Moreover, the training, validation and testing data contain more information than the above list, because each ad and each user have some additional properties. We include some of these properties into the training, validation \\xa0and the testing instances, and put other properties in separate data files that can be indexed using ids in the instances. For more information about these data files, please refer to the section ADDITIONAL DATA FILES.\\xa0Finally, after including additional features, each training instance is a line consisting of fields delimited by the TAB character:\\xa01. Click: as described in the above list.\\xa02. Impression: as described in the above list.\\xa03. DisplayURL: a property of the ad.\\xa0The URL is shown together with the title and description of an ad. It is usually the shortened landing page URL of the ad, but not always. In the data file, \\xa0this URL is hashed for anonymity.\\xa04. AdID: as described in the above list.\\xa05. AdvertiserID: a property of the ad.\\xa0Some advertisers consistently optimize their ads, so the title and description of their ads are more attractive than those of others’ ads.\\xa06. Depth: a property of the session, as described above.\\xa0\\xa0\\xa07. Position: a property of an ad in a session, as described above.\\xa08. QueryID:\\xa0 id of the query.\\xa0This id is a zero‐based integer value. It is the key of the data file 'queryid_tokensid.txt'.9. KeywordID: a property of ads.\\xa0This is the key of \\xa0'purchasedkeyword_tokensid.txt'.\\xa010. TitleID: a property of ads.\\xa0This is the key of 'titleid_tokensid.txt'.\\xa011. DescriptionID: a property of ads.\\xa0\\xa0This is the key of 'descriptionid_tokensid.txt'.\\xa012. UserID\\xa0This is the key of 'userid_profile.txt'.\\xa0 When we cannot identify the user, this field has a special value of 0.\\xa0ADDITIONAL DATA FILESThere are five additional data files, as mentioned in the above section:\\xa01. queryid_tokensid.txt\\xa02. purchasedkeywordid_tokensid.txt\\xa03. titleid_tokensid.txt\\xa04. descriptionid_tokensid.txt\\xa05. userid_profile.txt\\xa0Each line of the first four files maps an id to a list of tokens, corresponding to the query, keyword, ad title, and ad description, respectively. In each line, a TAB character separates the id and the token set.\\xa0 A token can basically be a word in a natural language. For anonymity, each token is represented by its hash value. \\xa0Tokens are delimited by the character ‘|’.\\xa0Each line of ‘userid_profile.txt’ is composed of UserID, Gender, and Age, delimited by the TAB character. Note that not every UserID in the training and the testing set will be present in ‘userid_profile.txt’. Each field is described below:\\xa01. Gender:\\xa0'1' \\xa0for male, '2' for female, \\xa0and '0' \\xa0for unknown.\\xa02. Age:\\xa0'1' \\xa0for (0, 12], \\xa0'2' for (12, 18], '3' for (18, 24], '4' \\xa0for \\xa0(24, 30], '5' for (30, \\xa040], and '6' for greater than 40.\\xa0TESTING DATASETThe testing dataset shares the same format as the training dataset, except for the counts of ad impressions and ad clicks that are needed for computing the empirical CTR. A subset of the testing dataset is used to consistently rank submitted/updated results on the leaderboard. The testing dataset is used for picking the final winners.The log for forming the training dataset corresponds to earlier time than that of the testing dataset.EVALUATIONTeams are expected to submit their result file in text format, in which each line corresponds to a line in the downloaded file with the same order, and there is only one field in each line: the predicted CTR. In the result file, the lines corresponding to the lines from validation dataset will be used to score for the ranking on the leaderboard during the competition except the last day (June 1, 2012), and the lines corresponding to the lines from testing dataset will be used for the ranking on the leaderboard on the day of June 1, 2012, and for picking the final winners.The performance of the prediction will be scored in terms of the AUC (for more details about AUC, please see ‘ROC graphs:\\xa0Notes\\xa0and practical considerations for researchers‘ by Tom Fawcett). For a detailed definition of the metric, please refer to the tab ‘Evalaution’.PRIZESTeams with the best performance scores will be the winners. The prizes for the 1, 2 and 3 winners for task 2 are US Dollars $5000, $2000, and $1000, respectively.\\xa0\"}, {'title': 'KDD Cup 2012, Track 1', 'url': 'https://www.kaggle.com/competitions/kddcup2012-track1', 'briefDescription': 'Predict which users (or information sources) one user might follow in Tencent Weibo.', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/2748/logos/header.png', 'tag': 'map@3', 'description': '\\xa0BACKGROUNDOnline social networking services have become tremendously popular in recent years, with popular social networking sites like Facebook, Twitter, and Tencent Weibo adding thousands of enthusiastic new users each day to their existing billions of actively engaged users. Since its launch in April 2010, Tencent Weibo, one of the largest micro-blogging websites in China, has become a major platform for building friendship and sharing interests online. Currently, there are more than 200 million registered users on Tencent Weibo, generating over 40 million messages each day. This scale benefits the Tencent Weibo users but it can also flood users with huge volumes of information and hence puts them at risk of information overload. Reducing the risk of information overload is a priority for improving the user experience and it also presents opportunities for novel data mining solutions. Thus, capturing users’ interests and accordingly serving them with potentially interesting items (e.g. news, games, advertisements, products), is a fundamental and crucial feature social networking websites like Tencent Weibo.\\xa0TASK 1 DESCRIPTION\\xa0The prediction task involves predicting whether or not a user will follow an item that has been recommended to the user. Items can be persons, organizations, or groups and will be defined more thoroughly below.\\xa0DATASETSFirst, we define some notations as follows:“Item”: An item is a specific user in Tencent Weibo, which can be a person, an organization, or a group, that was selected and recommended to other users. Typically, celebrities, famous organizations, or some well-known groups were selected to form the ‘items set’ for recommendation. The size of this is about 6K items in the dataset.\\xa0Items are organized in categories; each category belongs to another category, and all together they form a hierarchy. For example, an item, a vip user Dr. Kaifu LEE,vip user: http://t.qq.com/kaifulee (wikipedia:http://en.wikipedia.org/wiki/Kai-Fu_Lee)represented asscience-and-technology.internet.mobile We can see that categories in different levels are separated by a dot ‘.’, and the category information about an item can help enhance your model prediction. For example, if a user Peter follows kaifulee, he may be interested in the other items of the category that kaifulee belongs to, and might also be interested in the items of the parent category of kaifulee’s category.“Tweet”: a “tweet” is the action of a user posting a message to the microblog system, or the posted message itself. So when one user is “tweeting“, his/her followers will see the “tweet”.“Retweet”: a user can repost a tweet and append some comments (or do nothing), to share it with more people (my followers).“Comment”: a user can add some comments to a tweet. The contents of the comments \\xa0will not be automatically pushed to his/her followers as ‘tweeting’ or ‘retweeting’,but will appear at the ‘comment history’ of the commented tweet.“Followee/follower”: If User B is followed by User A, B is a followee to A, and A is a follower to B.We describe the datasets as follows:The dataset represents a sampled snapshot of Tencent Weibo users’ preferences for various items –– the recommendation of items to users and the history of users’ ‘following’ history. It is of a larger scale compared to other publicly available datasets ever released. Also it provides richer information in multiple domains such as user profiles, social graph, item category, which may hopefully evoke deeply thoughtful ideas and methodology.The users in the dataset, numbered in millions, are provided with rich information (demographics, profile keywords, follow history, etc.) for generating a good prediction model. To protect the privacy of the users, the IDs of both the users and the recommended items are anonymized as random numbers such that no identification is revealed. Furthermore, their information, when in Chinese, will be encoded as random strings or numbers, thus no contestant who understands Chinese would get advantages. Timestamps for recommendation are given for performing session analysis.Two datasets in 7 text files, downloadable:a) Training dataset : some fields are in the file rec_log_train.txt\\xa0b)\\xa0Testing dataset: some fields are in the filerec_log_test.txtFormat of the above 2 files:(UserId)\\\\t(ItemId)\\\\t(Result)\\\\t(Unix-timestamp)Result: values are 1 or -1, where 1 represents the user UserId accepts the recommendation of item ItemId and follows it (i.e., adds it to his/her social network), and -1 represents the user rejects the recommended item.We provide the true values of the ‘Result’ field in rec_log_train.txt, whereas in \\xa0rec_log_test.txt, the true values of the ‘Result’ field are withheld (for simplicity, in the file they are always 0). Another difference from rec_log_test.txt to rec_log_train.txt is that repeated recommended (UserId,ItemId) pairs were removed.c)\\xa0\\xa0\\xa0\\xa0\\xa0 More fields of the training and the testing datasets about the user and the item are in the following 5 files:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 i.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0User profile data: user_profile.txtEach line contains the following information of a user: the year of birth, the gender, the number of tweets and the tag-Ids. It is important to note that information about the users to be recommended is also in this file.Format:(UserId)\\\\t(Year-of-birth)\\\\t(Gender)\\\\t(Number-of-tweet)\\\\t(Tag-Ids)Year of birth is selected by user when he/she registered.Gender has an integer value of 0, 1, or 2, which represents “unknown”, “male”, or “female”, respectively.Number-of-tweet is an integer that represents the amount of tweets the user has posted.Tags are selected by users to represent their interests. If a user likes mountain climbing and swimming, he/she may select \"mountain climbing\" or \"swimming\" to be his/her tag. There are some users who select nothing. The original tags in natural languages are not used here, each unique tag is encoded as an unique integer.Tag-Ids are in the form “tag-id1;tag-id2;...;tag-idN”. If a user doesn’t have tags, Tag-Ids will be \"0\".\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 ii.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Item data:item.txtEach line contains the following information of an item: its category and keywords.Format:(ItemId)\\\\t(Item-Category)\\\\t(Item-Keyword)Item-Category is a string “a.b.c.d”, where the categories in the hierarchy are delimited by the character “.”, ordered in top-down fashion (i.e., category ‘a’ is a parent category of ‘b’, and category ‘b’ is a parent category of ‘c’, and so on.Item-Keyword contains the keywords extracted from the corresponding Weibo profile of the person, organization, or group. The format is a string “id1;id2;…;idN”, where each unique keyword is encoded as an unique integer such that no real term is revealed.\\xa0\\xa0\\xa0\\xa0\\xa0 iii.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 User action data:user_action.txtThe file user_action.txt contains the statistics about the ‘at’ (@) actions between the users in a certain number of recent days.Format:(UserId)\\\\t(Action-Destination-UserId)\\\\t(Number-of-at-action)\\\\t(Number-of-retweet )\\\\t(Number-of-comment)If user A wants to notify another user about his/her tweet/retweet/comment, he/she would use an ‘at’ (@) action to notify the other user, such as ‘@tiger’ (here the user to be notified is ‘tiger’)..For example, user A has retweeted user B 5 times, has “at” B 3 times, and has commented user B 6 times, then there is one line “A\\xa0\\xa0 B\\xa0\\xa0\\xa0\\xa0 3\\xa0\\xa0\\xa0\\xa0 5\\xa0\\xa0\\xa0\\xa0 6” in user_action.txt.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 iv.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 User sns data:user_sns.txtThe file user_sns.txt contains each user’s follow history (i.e., the history of following another user). Note that the following relationship can be reciprocal.Format:(Follower-userid)\\\\t(Followee-userid)\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 v.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 User key word data:user_key_word.txtThe file user_key_word.txt contains the keywords extracted from the tweet/retweet/comment by each user.Format:(UserId)\\\\t(Keywords)Keywords is in the form “kw1:weight1;kw2:weight2;…kw3:weight3”.Keywords are extracted from the tweet/retweet/comment of a user, and can be used as features to better represent the user in your prediction model. The greater the weight, the more interested the user is with regards to the keyword.Every keyword is encoded as a unique integer, and the keywords of the users are from the same vocabulary as the Item-Keyword.\\xa0EVALUATION\\xa0Teams’ scores and ranks on the leaderboard are based on a metric calculated from the predicted results in submitted result file and the held out ground truth of a validation dataset whose instances were a fixed set sampled from the testing dataset in the beginning and, until the last day of the competition (June 1, 2012) by then the scores and associated ranks on leaderboard are based on the predicted results and that of the rest of the testing dataset. This entails that the top-3 ranked teams at the time when the competition ends are the winners. The log for forming the training dataset corresponds to earlier time than that of the testing dataset.The evaluation metric is average precision. For a detailed definition of the metric, please refer to the tab ‘Evaluation’.\\xa0PRIZES\\xa0The prizes for the 1, 2 and 3 winners for task 1 are US Dollars $5000, $2000, and $1000, respectively.\\xa0'}, {'title': 'The Hewlett Foundation: Automated Essay Scoring', 'url': 'https://www.kaggle.com/competitions/asap-aes', 'briefDescription': 'Develop an automated scoring algorithm for student-written essays.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"The William and Flora Hewlett Foundation (Hewlett) is sponsoring the Automated Student Assessment Prize (ASAP).\\xa0 Hewlett is appealing to data scientists and machine learning specialists to help solve an important social problem.\\xa0 We need fast, effective and affordable solutions for automated grading of student-written essays.Hewlett is sponsoring the following prizes:$60,000:\\xa0 1 place$30,000:\\xa0 2 place$10,000:\\xa0 3 placeYou are provided access to hand scored essays, so that you can build, train and test scoring engines against a wide field of competitors.\\xa0 Your success depends upon how closely you can deliver scores to those of human expert graders.\\xa0 While we believe that these financial incentives are important, we also intend to introduce top performers both to leading vendors in the industry and/or an established base of interested buyers.\\xa0 Hewlett is opening the field of automated student assessment to you.\\xa0 We want to induce a breakthrough that is both personally satisfying and game-changing for improving public education.Today, state departments of education are developing new forms of testing and grading methods, to assess the new common core standards.\\xa0 In this environment the need for more sophisticated and affordable options is vital.\\xa0 For example, we know that essays are an important expression of academic achievement, but they are expensive and time consuming for states to grade them by hand.\\xa0 So, we are frequently limited to multiple-choice standardized tests.\\xa0 We believe that automated scoring systems can yield fast, effective and affordable solutions that would allow states to introduce essays and other sophisticated testing tools.\\xa0 We believe that you can help us pave the way towards a breakthrough.\\xa0 ASAP is designed to achieve the following goals:Challenge developers of automated student assessment systems to demonstrate their current capabilities.Compare the efficacy and cost of automated scoring to that of human graders.Reveal product capabilities to state departments of education and other key decision makers interested in adopting them.The graded essays are selected according to specific data characteristics.\\xa0 On average, each essay is approximately 150 to 550 words in length. \\xa0Some are more dependent upon source materials than others.\\xa0 This range of essay type is provided so that we can better understand the strengths of your solution.\\xa0 It is our intent to showcase quality and reliability, based on how well you can match expert human graders for each essay.You will be provided with training data for each essay prompt.\\xa0 The number of training essays does vary.\\xa0 For example, the lowest amount of training data is 1,190 essays, randomly selected from a total of 1,982.\\xa0 The data will contain ASCII formatted text for each essay followed by one or more human scores, and (where necessary) a final resolved human score.\\xa0 Where it is relevant, you are provided with more than one human score, so that you may evaluate the reliability of the human scorers, but - keep in mind - that you will be predicting to the resolved score.\\xa0 Also, please note that most essays are scored using a holistic scoring rubric.\\xa0 However, one data set uses a trait scoring rubric.\\xa0 The variability is intended to test the limits of your scoring engine’s capabilities.Following a period of 3 months to build and/or train your engine, you will be provided with test data that will contain new essays, randomly selected for blind evaluation.\\xa0 However, you will notice that the rater and resolved score columns will be blank.\\xa0 You will be asked to supply, based on your engine's predictions for each essay, your score in the resolved score column and then submit your new data set on this site.As part of the file that you will submit with your predictive scores, you will be asked to submit additional information.\\xa0 We would like to understand both the time and capital that you’ve spent developing your engine, the profile of your team (or you as an individual if you are working alone) and the projected cost to implement your solution on a larger scale, along with any known limitations.\\xa0 Basically, you will have the opportunity to present your case for who you are, why your model is commercially viable and to what extent you can use your model to satisfy the interests of potential buyers.\\xa0 This other information will not be used to determine any prize rewards, and it is optional.\\xa0 But, if you provide it, it will be used to evaluate whether or not your model should be presented to state departments of education and others who stand to benefit from your work.Also, please note that it is our intention to stage other follow-on ASAP phases in the months ahead.\\xa0 We are starting with graded essays and will follow with new data:Phase 1: Demonstration for long-form constructed response (essays);Phase 2: Demonstration for short-form constructed response (short answers);Phase 3: Demonstration for symbolic mathematical/logic reasoning (charts/graphs).In every instance, we seek to drive innovation for new solutions to automated student assessment.\\xa0 We hope that you will enjoy this process.\\xa0 May the best model win!\"}, {'title': 'Benchmark Bond Trade Price Challenge', 'url': 'https://www.kaggle.com/competitions/benchmark-bond-trade-price-challenge', 'briefDescription': 'Develop models to accurately predict the trade price of a bond.', 'coverImageUrl': None, 'tag': 'wmae', 'description': 'The Benchmark Bond Trade Price Challenge is a competition to predict the next\\xa0price\\xa0that a\\xa0US corporate bond might trade at. Contestants are given information on the bond including current coupon, time to maturity and a reference price computed byBenchmark Solutions. \\xa0Details of the previous 10 trades are also provided.\\xa0\\xa0'}, {'title': 'Getting Started', 'url': 'https://www.kaggle.com/competitions/getting-started', 'briefDescription': 'Create a forum for New Users', 'coverImageUrl': None, 'tag': 'rmse', 'description': 'Insert your description here'}, {'title': 'CHALEARN Gesture Challenge', 'url': 'https://www.kaggle.com/competitions/GestureChallenge', 'briefDescription': 'Develop a Gesture Recognizer for Microsoft Kinect (TM)', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'One-shot-learning Gesture RecognitionHumans are capable of recognizing patterns like hand gestures after seeing just ONE example. Can machines do that too?This challenge is one of four CHALEARN Gesture Challenge events\\xa0\\xa0This challenge round is over, round 2 has started follow that link to enter.MotivationsYou will never need a remote controller anymore, you will never need a light switch. Lying in bed in the dark, you will point to the ceiling to turn on the light, you will wave your hand to increase the temperature, you will make a T with your hands to turn on the TV set. You and your loved ones will feel safer at home, in parking lots, in airports: nobody will be watching, but computers will detect distressed people and suspicious activities. Computers will teach you how to effectively use gestures to enhance speech, to communicate with people who do not speak your language, to speak with deaf people, and you will easily learn many other sign languages to comminicate under water, to referee sports, etc. All that thanks to gesture recognition!\\xa0Kinect (TM)This is a challenge on gesture and sign language recognition using a Kinect camera.  by providing an affordable 3D camera, which records both an RGB image and a depth image (using an infrared sensor). The challenge focuses on hand gestures. Applications include man-machine communication, translating sign languages for the deaf, video surveillance, and computer gaming. Check out some examples.\\xa0One-shot-learningEvery application needs a specialized gesture vocabulary. If we want gesture recognition to become part of everyday life, we need gesture recognition machines, which easily get tailored to new gesture vocabularies. This is why the focus of the challenge is on “one-shot-learning” of gestures, which means learning to recognize new categories of gestures from a single video clip of each gesture.\\xa0The gestures will be drawn from a small vocabulary of gestures, generally related to a particular task, for instance, hand signals used by divers, finger codes to represent numerals, signals used by referees, or marchalling signals to guide vehicles or aircrafts.\\xa0Protocol sketchThis competition consists of two main components: a development phase\\xa0(December 7, 2011 to April 6, 2012) and a final evaluation phase (April 7, 2012 to April 10. 2012):\\xa0During the development phase of the competition, the participants build a learning system capable of learning from a single training example a gesture classification problem. To that end, they get development data consisting of several batches of gestures, each split into a training set (of one example for each gesture) and a test set of short sequences of one to 5 gestures. Each batch contains gestures from a different small vocabulary of 8 to 15 gestures, for instance diving signals, signs of American Sign Language representing small animals, Italian gestures, etc. The test data labels are provided for such development data so the participants can self-evaluate their systems. To evaluate their progress and compare themselves with others, they can use provided validation data, for which one training example is provided for each gesture token in each batch, but the test data labels are withheld. The prediction results on validation test data can be submitted on-line to get immediate feed-back. A real-time leaderboard shows participants their current standing based on their validation set predictions.During the final evaluation phase of the competition, the participants get to perform similar tasks as those of the validation data on new final evaluation data revealed at the end of the development phase. The participants have a few days to train their systems and upload their predictions. Prior to the end of the development phase, Kaggle will make available a software vault so the participants can upload executable code for their best learning system, which they will then use to train their models and make predictions on the final evaluation test data. This will allow the competition organizers to check their results and ensure the fairness of the competition. Note that participation is NOT conditiioned on submitting code or disclosing methods. See the rules for details. If any of the top ranking participants opted not to submit their learning system for verification, he/she will have to demonstrate the performance of his/her system in person on another verification set. \\xa0Any statistically significant deviation between the performance on the final evaluation set and the verification set may result in disqualification.\\xa0SponsorsThis challenge is organized by\\xa0CHALEARN\\xa0and is sponsored in part by Microsoft (Kinect for Xbox 360). Other sponsors include  Texas Instrument.\\xa0'}, {'title': 'What Do You Know?', 'url': 'https://www.kaggle.com/competitions/WhatDoYouKnow', 'briefDescription': 'Improve the state of the art in student evaluation by predicting whether a student will answer the next test question correctly.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"When studying for a test, you want to know how well you're going to do.\\xa0 More specifically, you want to know what areas you need to study more.\\xa0 In order to help students answer this question, we are attempting to predict their probability of answering questions correctly.\\xa0 The data in this competition comes from students studying for three tests: the GMAT, SAT, and ACT.You are attempting to predict, for each question attempted in the test set, whether the student will answer the question correctly.\\xa0 To succeed, you will need to improve on the state-of-the-art in student evaluation.\\xa0 While the questions included labels indicating their specified test area, there may be structure which helps better organize the areas of knowledge involved in each question.\\xa0 In the short term, this will help students figure out what areas they are weak in; but ultimately, this will help create tests to better measure what a student actually knows.The prize pool is $5,000 ($3,000 for first, $1,500 for second and $500 for third), with entries judged usingCapped Binomial Deviance.\"}, {'title': 'Algorithmic Trading Challenge', 'url': 'https://www.kaggle.com/competitions/AlgorithmicTradingChallenge', 'briefDescription': 'Develop new models to accurately predict the market response to large trades.', 'coverImageUrl': None, 'tag': 'rmse', 'description': 'The Algorithmic Trading Challenge is a forecasting competition which aims to encourage the development of new models to predict the stock market\\'s short-term response following large trades.\\xa0Contestants are asked to derive empirical models to predict the behaviour of bid and ask prices following such \"liquidity shocks\".Modelling market resiliency will improve trading strategy evaluation methods by increasing the realism of backtesting simulations,\\xa0which currently assume zero market resiliency.'}, {'title': 'Photo Quality Prediction', 'url': 'https://www.kaggle.com/competitions/PhotoQualityPrediction', 'briefDescription': \"Given anonymized information on thousands of photo albums, predict whether a human evaluator would mark them as 'good'.\", 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"BackgroundWe have a large collection of user-generated photos. We want to automatically pick out particularly enjoyable or impressive ones to highlight, especially travel-related, using only the meta-data associated with the images such as caption text, image dimensions and approximate location in the world. We know from our preliminary experiments and intuition that certain words and places are correlated with good photos, and others are indicators of less enjoyable pictures, but we would like to develop an algorithm to tie together these multiple signals.ObjectiveGiven anonymized information on thousands of photo albums, predict whether a human evaluator would mark them as 'good'.\"}, {'title': \"Don't Get Kicked!\", 'url': 'https://www.kaggle.com/competitions/DontGetKicked', 'briefDescription': 'Predict if a car purchased at auction is a lemon', 'coverImageUrl': None, 'tag': 'gini', 'description': 'One of the biggest challenges of an auto dealership purchasing a used car at an auto auction is the risk of that the vehicle might have serious issues that prevent it from being sold to customers. The auto community calls these unfortunate purchases \"kicks\".Kicked cars often result when there are tampered odometers, mechanical issues the dealer is not able to address, issues with getting the vehicle title from the seller, or some other unforeseen problem. Kick cars can be very costly to dealers after transportation cost, throw-away repair work, and market losses in reselling the vehicle.Modelers who can figure out which cars have a higher risk of being kick can provide real value to dealerships trying to provide the best inventory selection possible to their customers.The challenge of this competition is to predict if the car purchased at the Auction is a Kick (bad buy).'}, {'title': 'Semi-Supervised Feature Learning', 'url': 'https://www.kaggle.com/competitions/SemiSupervisedFeatureLearning', 'briefDescription': 'Find methods which work best on large-scale, high-dimensional learning tasks', 'coverImageUrl': None, 'tag': 'auc', 'description': 'There\\'s recently been a lot of work done in unsupervised feature learning for classification, with great advances made by approaches such as deep belief nets, graphical models, and transfer learning. Meanwhile, there are a ton of older methods that also work well, including matrix factorization, random projections, and clustering methods. The purpose of this competition is to find out which of these methods work the best, on relatively large-scale high dimensional learning tasks.The Short VersionIn this task, you\\'ll do the following:Learn a feature representation of at most 100 features, using a small amount of labeled data and a large amount of unlabeled data. \\xa0The orginial data is very sparse.Transform training and test data using your learned feature representation. Train a standard linear classifier on the transformed training data. Measure the AUC of the classifier on transformed test data. We have public data to be used for the leaderboard evaluations, and a separate private data set used for final evaluation through a special submission process. \\xa0We have scripts to simplify the training and evaluation; how you do the feature transformation is up to you.\\xa0The Long VersionThe task that we\\'re evaluating on is a binary-class classification problem, drawn from web classification. \\xa0(The data has been cleaned heavily and anonymized.) \\xa0The data itself is sparse, high dimensional data with about a million features. \\xa0A few features have non-zero values in many or even all examples; most features have non-zero values in very few examples.Your task is to transform the data from a high dimensional space to a lower dimensional space of at most 100 features. \\xa0The goal is to make this new feature space so rich and informative that it allows a new classifier to be trained with the best possible predictive performance. \\xa0Any method of producing a condensed representation is fair game: deep learning graphical models, transfer learning, supervised learning, semi-supervised learning, matrix factorization, random projection, clustering, feature selection, or anything else you can invent.In addition to a small amount of labeled data, you will also be given a large amount of unlabeled data. \\xa0Both the labeled and the unlabeled data can be used to learn good ways to transform the feature space.The final evaluation will be done by using your method to transform training and test sets whose labels are not known. \\xa0These transformed data sets will be sent to tne organizers, who will apply the hidden labels and use these new data sets to train and test a standard supervised classifier. \\xa0The data set that produces the best classification performance on test data (using AUC as the evaluation measure) will be declared the winner. \\xa0We also provide versions of our evaluation scripts to be used on public versions of our private evaluation data sets, and these results can be used to update the leaderboard. \\xa0Please see the \"Evaluation\" page for full details.Although there is a modest cash prize, the main goal of this competition is to encourage research and share ideas. \\xa0The results of this competition will be included in a paper submitted to the2011 NIPS workshop on deep learning and unsupervised feature learning. \\xa0Contestants will be acknowledged by name in this paper for noteworthy performance, including results that do especially well or which are especially interesting.'}, {'title': 'Give Me Some Credit', 'url': 'https://www.kaggle.com/competitions/GiveMeSomeCredit', 'briefDescription': 'Improve on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years.  ', 'coverImageUrl': None, 'tag': 'auc', 'description': 'Banks play a crucial role in market economies. They decide who can get finance and on what terms and can make or break investment decisions. For markets and society to function, individuals and companies need access to credit.\\xa0Credit scoring algorithms, which make a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted. This competition requires participants to improve on the state of the art in credit scoring, by predicting the probability that somebody will experience financial distress in the next two years.The goal of this competition is to build a model that borrowers can use to help make the best financial decisions.Historical data are provided on 250,000 borrowers and the prize pool is $5,000 ($3,000 for first, $1,500 for second and $500 for third).'}, {'title': \"dunnhumby's Shopper Challenge\", 'url': 'https://www.kaggle.com/competitions/dunnhumbychallenge', 'briefDescription': 'Going grocery shopping, we all have to do it, some even enjoy it, but can you predict it? dunnhumby is looking to build a model to better predict when supermarket shoppers will next visit the store and how much they will spend. ', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"Going grocery shopping, we all have to do it, some even enjoy it, but can you predict it?Dunnhumby is looking to build a model to better predict when supermarket shoppers will next visit the store and how much they will spend.The modelling data set consists of details of every visit made by 100,000 customers over a year from April 2010 to March 31st 2011.Each visit is stamped with the date and the customer’s spend in that visit.We also have details of their next visit after March 31st.Your challenge is to predict the visit_date and visit_spend of this next visit for each customer_id in the modelling test set. For more details on how you're scored, click here\"}, {'title': 'Allstate Claim Prediction Challenge', 'url': 'https://www.kaggle.com/competitions/ClaimPredictionChallenge', 'briefDescription': 'A key part of insurance is charging each customer the appropriate price for the risk they represent.', 'coverImageUrl': None, 'tag': 'normalizedgini', 'description': 'Risk varies widely from customer to customer, and a deep understanding of different risk factors helps predict the likelihood and cost of insurance claims. The goal of this competition is to better predict Bodily Injury Liability Insurance claim payments based on the characteristics of the insured customer’s vehicle.Many factors contribute to the frequency and severity of car accidents including how, where and under what conditions people drive, as well as what they are driving.\\xa0Bodily Injury Liability Insurance covers other people’s bodily injury or death for which the insured is responsible.\\xa0 \\xa0The goal of this competition is to predict Bodily Injury Liability Insurance claim payments based on the characteristics of the insured’s vehicle. \\xa0\\xa0'}, {'title': \"Wikipedia's Participation Challenge\", 'url': 'https://www.kaggle.com/competitions/wikichallenge', 'briefDescription': 'This competition challenges data-mining experts to build a predictive model that predicts the number of edits an editor will make five months from the end date of the training dataset. ', 'coverImageUrl': None, 'tag': 'rmsle', 'description': 'This competition challenges data-mining experts to build a predictive model that predicts the number of edits an editor will make in the five months after the end date of the training dataset. The dataset is randomly sampled from the English Wikipedia dataset from the period January 2001 - August 2010.The objective of this competition is to quantitively understand what factors determine editing behavior. We hope to be able to answer questions, using these predictive models, why people stop editing or increase their pace of editing.Contestants are expected to build a predictive model that can be reused by the Wikimedia Foundation to forecast long term trends in the number of edits that we can expect.'}, {'title': 'Mapping Dark Matter', 'url': 'https://www.kaggle.com/competitions/mdm', 'briefDescription': 'Measure the small distortion in galaxy images caused by dark matter', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"\\xa0\\xa0The universe isn't behaving. Or at least, that's the view of many of the world's leading scientists: the universe behaves as if there is far more matter than we can observe. And that's important, because it means either that vital scientific theories are wrong, or that there are whole new types of stuff that we haven't yet discovered.Mapping Dark Matter is a image analysis competition whose aim is to encourage the development of new algorithms that can be applied to challenge of measuring the tiny distortions in galaxy images caused by dark matter.The aim is to measure the shapes of\\xa0galaxies to reconstruct the gravitational lensing signal in the presence ofnoise and a known Point Spread Function. The signal is a very small change in the galaxies’ellipticity, an exactly circular galaxy image would be changed into an; however real galaxies are not circular.The challenge is to measure the ellipticity of 100,000 simulated galaxies.The data consists of :Galaxy images, that are very noisy images of elliptical objects with a simple brightness profile. The galaxy images are convolved or smoothed with a kernel that would act to turn a single point into a blurry image. Part of the challenge is to attempt to remove or account for that blurring effect.\\xa0\\xa0\\xa0To help account for the blurring effect each galaxy image has a star image where we provide a pixelised version of the kernel that with which the galaxy image was convolved.Participants are provided with 100,000 galaxy and star pairs. A participant should provide an estimate for the ellipticity for each galaxy.\\xa0\\xa0\\xa0\\xa0* NASA Support : Jet Propulsion Laboratory, operated by the California Institute of Technology, under contract with the National Aeronautics and Space Administration (NASA).\\xa0* RAS Support : Through funding for the PI (Kitching)\"}, {'title': 'Heritage Health Prize', 'url': 'https://www.kaggle.com/competitions/hhp', 'briefDescription': 'Identify patients who will be admitted to a hospital within the next year using historical claims data. (Enter by 06:59:59 UTC Oct 4 2012) ', 'coverImageUrl': 'https://storage.googleapis.com/kaggle-competitions/kaggle/2496/logos/header.png', 'tag': 'rmsle', 'description': 'Please note: This competition is over! The leaderboard now displays the final results.This means that the only people can download the data or make submissions are people who accepted the competition rules prior to 06:59:59 UTC on October 4, 2012. Individuals who had accepted to rules but not yet formed a team at that date may join a team or create their own team (consisting of them only). No teams may merge at this point.------------------More than 71 million individuals in the United States are admitted to hospitals each year, according to the latest survey from the American Hospital Association. Studies have concluded that in 2006 well over $30 billion was spent on unnecessary hospital admissions. Is there a better way? Can we identify earlier those most at risk and ensure they get the treatment they need? The Heritage Provider Network (HPN) believes that the answer is \"yes”.To achieve its goal of developing a breakthrough algorithm that uses available patient data to predict and prevent unnecessary hospitalizations, HPN is sponsoring the Heritage Health Prize Competition (the “Competition”). HPN believes that incentivized competition is the best way to achieve the radical breakthroughs necessary to begin fixing America’s health care system.The winning team will create an algorithm that predicts how many days a patient will spend in a hospital in the next year. Once known, health care providers can develop new care plans and strategies to reach patients before emergencies occur, thereby reducing the number of unnecessary hospitalizations. This will result in increasing the health of patients while decreasing the cost of care. In short, a winning solution will change health care delivery as we know it – from an emphasis on caring for the individual after they get sick to a true health care system.The Competition runs for two years and offers a US $3 million Grand Prize, as well as six Milestone Prizes totaling $230,000, which are awarded in varying amounts at three designated intervals during the Competition.'}, {'title': \"Don't Overfit!\", 'url': 'https://www.kaggle.com/competitions/overfitting', 'briefDescription': 'With nearly as many variables as training cases, what are the best techniques to avoid disaster? ', 'coverImageUrl': None, 'tag': 'auc', 'description': 'One of the main objectives of predictive modelling is to build a model that will give accurate predictions on unseen data.A necessary step in the building of models is to ensure that they have not overfit the training data, which leads to sub optimal predictions on new data.The purpose of this challenge is to stimulate research and highlight existing algorithms, techniques or strategies that can be used to guard against overfitting.In order to achieve this we have created a simulated data set with 200 variables and 20,000 cases. An ‘equation’ based on this data was created in order to generate a Target to be predicted. Given the all 20,000 cases, the problem is very easy to solve – but you only get given the Target value of 250 cases – the task is to build a model that gives the best predictions on the remaining 19,750 cases.This competition is of particular relevance to medical data analysis, where often the number of cases is severely restricted.'}, {'title': 'ICDAR 2011 - Arabic Writer Identification', 'url': 'https://www.kaggle.com/competitions/WIC2011', 'briefDescription': 'This competition require participants to develop an algorithm to identify who wrote which documents. The winner will be honored at a special session of the ICDAR 2011 conference. ', 'coverImageUrl': None, 'tag': 'mae', 'description': 'Writer identification is important for forensic analysis, helping experts to deliberate on the authenticity of documents. This competition aims to further the science of writer identification. It requires participants develop algorithms that can identify handwriting. This is a difficult problem because a writer never reproduces exactly the same characters.\\xa0Writer identification generally requires two steps. The first is an image-processing step, where features are extracted from the images. The second step is a classification step, where the document is assigned to the “closest” document in the dataset according to the “difference” between their features.In this contest, a previously unpublished data has been made available, containing the writings of more than 50 writers. Participants are asked to provide a similarity score, showing how probable it is that two documents are written by the same person.\\xa0For participants who are not familiar with image-processing, a set of geometrical features extracted have been provided.This contest is organized in conjunction with the International Conference on Document Analysis and Recognition (ICDAR2011).\\xa0The winner of this contest will win $1,000 and will be acknowledged in a special session at the ICDAR2011, which will be held in Beijng in September 18-21. The prize money is paid on condition that the winning entrant shares their methodology.\\xa0'}, {'title': 'Deloitte/FIDE Chess Rating Challenge', 'url': 'https://www.kaggle.com/competitions/ChessRatings2', 'briefDescription': 'This contest, sponsored by professional services firm Deloitte, will find the most accurate system to predict chess outcomes, and FIDE will also bring a top finisher to Athens to present their system', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'The datasets for this contest include real historical data provided by the world chess federation (FIDE).\\xa0 Contest participants will train their rating systems using a training dataset of over 1.84 million game results for more than 54,000 chess players across a recent eleven year period.\\xa0 Participants then use their method to predict the outcome of a further 100,000 games played among those same players during the following three months.\\xa0 Contest entries will be scored automatically by the website, based on the accuracy of their predictions.\\xa0 Two entries per day can be submitted by each team, and prizes will be determined according to each team\\'s best-scoring single submission.The contest\\'s sponsor, Deloitte Australia, has provided the $10,000 prize to be awarded to the team that submits the most accurate predictions.\\xa0 Deloitte is a preeminent provider of analytics globally and helps companies capture, manage and analyze their data as part of their overall business strategy.Chessbase has donated chess software with signatures by famous players for the three teams finishing in 2nd/3rd/4th place.In addition, FIDE representatives will award a special \"FIDE prize\" to what they consider to be the most promising approach, out of the ten most accurate entries that meet a restrictive definition of a \"practical chess rating system\".\\xa0 This restrictive definition is specified within the rules of the contest.\\xa0 For the winner, FIDE will provide air fare for a round trip flight to Athens, Greece, and full board for three nights in Athens, and payment toward other expenses, for one person to present and discuss their system during a special FIDE meeting of chess rating experts in Athens.'}, {'title': 'Stay Alert! The Ford Challenge', 'url': 'https://www.kaggle.com/competitions/stayalert', 'briefDescription': 'Driving while not alert can be deadly. The objective is to design a classifier that will detect whether the driver is alert or not alert, employing data that are acquired while driving.', 'coverImageUrl': None, 'tag': 'auc', 'description': \"Driving while distracted, fatigued or drowsy may lead to accidents. Activities that divert the driver's attention from the road ahead, such as engaging in a conversation with other passengers in the car, making or receiving phone calls, sending or receiving text messages, eating while driving or events outside the car may cause driver distraction. Fatigue and drowsiness can result from driving long hours or from lack of sleep.The objective of this challenge is to design a detector/classifier that will detect whether the driver is alert or not alert, employing any combination of vehicular, environmental and driver physiological data that are acquired while driving.The winner receives free registration to the 2011 International Joint Conference on Neural Networks (San Jose, California July 31 - August 5, 2011), which is valued at $950. The winner will also be invited to present their solution at the conference.\"}, {'title': 'Predict Grant Applications', 'url': 'https://www.kaggle.com/competitions/unimelb', 'briefDescription': 'This task requires participants to predict the outcome of grant applications for the University of Melbourne. ', 'coverImageUrl': None, 'tag': 'auc', 'description': 'Around the world, the pool of funds available for research grants is steadily shrinking (in a relative sense). In Australia, success rates have fallen to 20-25 per cent, meaning that most academics are spending valuable time making applications that end up being rejected. With this problem in mind, the University of Melbourne is hosting a competition to predict the success of grant applications. The winning model will be used by the university to predict which grant applications are likely to be successful, so that less time is wasted on applications that are unlikely to succeed. The university hopes the competition will also shed some light on what factors are important in determining whether an application will succeed. The university has provided a dataset containing 249 features, including variables that represent the size of the grant, the general area of study and de-identified\\xa0information on the investigators who are applying for the grant. Participants train their models on 8,707 grant applications made between 2004 and 2008. They then make predictions on a further 2,176 applications made in 2009 and the first half of 2010.The winner of this competition will receive US$5,000. To be eligible for the prize, the winning method must be implementable by the University of Melbourne. \\xa0'}, {'title': 'RTA Freeway Travel Time Prediction', 'url': 'https://www.kaggle.com/competitions/RTA', 'briefDescription': \"This competition requires participants to predict travel time on Sydney's M4 freeway from past travel time observations.\", 'coverImageUrl': None, 'tag': 'rmse', 'description': \"Forecasting travel times helps improve road safety and efficiency. Accurate predictions help commuters make informed decisions about when to travel and on what routes. This helps to lower intensity on problem arterials by encouraging motorists to use underutilised parts of the grid, and where possible, by having them select alternative times and modes of travel.\\xa0 This competition requires participants to predict travel time on Sydney's M4 freeway from past travel time observations. In addition to better informing network managers and Australian motorists, insights from the competition will improve the general efficiency of the road transport system in Sydney and increase functionality on the government's live traffic website.\\xa0 Participants in this competition are required to forecast the travel time on the M4 freeway for 15 mins, 30 mins, 45 mins, one hour, 90mins, two hours, six hours, 12 hours, 18 hours and 24 hours ahead. The NSW Roads and Traffic Authority has made 2 years' worth of historical data on road use between 2008 and 2010\\xa0 available for this competition.\\xa0 $10,000 is being offered for the winning model.The competition is being hosted by Australia's NSW Roads and Traffic Authority and is being sponsored by the NSW Department of Premier and Cabinet.\"}, {'title': 'IJCNN Social Network Challenge ', 'url': 'https://www.kaggle.com/competitions/socialNetwork', 'briefDescription': 'This competition requires participants to predict edges in an online social network. The winner will receive free registration and the opportunity to present their solution at IJCNN 2011.', 'coverImageUrl': None, 'tag': 'auc', 'description': 'Internet, telco, bank and other commercial databases are filled with information on the connections between millions of individuals who share, influence and learn from each other. It is fast becoming apparent that these relationships hold significant commercial value. So much so that Gartner, a market-research firm, ranks network analysis software at number two in its list of strategic business operations meriting significant investment this year.\\xa0 Social network analysis views relationships in terms of nodes (people) and edges (links or connections - the relationship between the people). This competition requires participants to predict edges in an online social network. The algorithms developed could be used to power friend suggestions for an online social network. Good friend suggestion algorithms are extremely valuable because they encourage connections (and the strength of an online social network increases dramatically as the number of edges increase).\\xa0 For this competition, participants are given 7,237,983 contacts/edges from an online social network. Using this data, participants must predict whether the connections among a further 8,960 edges are true or false. The winner receives free registration to the 2011 International Joint Conference on Neural Networks (San Jose, California July 31 - August 5, 2011). The winner will also be invited to present their solution at the conference.'}, {'title': 'R Package Recommendation Engine', 'url': 'https://www.kaggle.com/competitions/R', 'briefDescription': 'The aim of this competition is to develop a recommendation engine for R libraries (or packages). (R is opensource statistics software.)', 'coverImageUrl': None, 'tag': 'auc', 'description': \"Beyond learning the basic syntax and idioms of a programming language, fluent programming requires the mastery of a large number of libraries that extend the functionality of the core language. For newcomers to a programming language, this poses a major challenge, as they must decide which libraries to invest their time into learning to use well. Given the sheer number of different libraries that are available for most popular programming languages and the considerable difficulty of determining their quality by simply inspecting their basic descriptions, this task can be a daunting one.We'd like you to build a library recommendation engine for R programmers, who usually refer to libraries as packages. We think that you can help neophyte R programmers by letting them know which packages are most likely to be installed by the average R user and what measurable properties of the packages themselves are able to predict this information. To train your algorithm, we're providing a data set that contains approximately 99,640 rows of data describing installation information for 1865 packages for 52 users of R. For each package, we've provided a variety of predictors derived from the rich metadata that is available for every R package. Your task is to model the behavior of the sample users for this training set of 1865 packages well enough that your predictions will generalize to a test data set, containing 33,125 rows. Using nothing more than simple data hacking, we think that you can radically improve upon the baseline model we're providing, which is a standard logistic regression that predicts the probability of a given package P being installed by a user U based on predictors derived from the package's metadata. But we are also providing you with a secondary data set that contains the unprocessed metadata, because we'd like to encourage you to dig deeper into the problem and use statistical analysis to find out what it is about a package that predicts whether it will be installed by the average user of a programming language. And, of course, particularly intrepid hackers can incorporate still more external information as the metadata we're using can be reproduced by spidering CRAN, the R package repository, directly and analyzing the raw source code for every existing R package.With that said, you are free to use whatever tools you wish, whether you prefer sophisticated modeling techniques or hacking metadata with regular expressions. We'll judge all contestants by their ability to predict whether a user U has package P installed. Whichever team achieves the highest AUC after four months on our test data set will win three UseR! books of their choosing.In order to be declared the winner of this contest, you must publicly release your final analysis code on GitHub as a fork of our example code. In addition, you will be required to document every step you've taken along the way. We're running this task to improve the lives of R programmers everywhere, so we'd like to make sure that any insights you discover are revealed to the entire world.This contest is being organized by the writers for Dataists, a new blog for data hackers.Update, 18 October: Towards the end of the competition, teams will have the opportunity to nominate five entries. It is the best of these five entries that counts toward a team's final position. A team's last five entries will be chosen by default if they don't nominate any entries.\"}, {'title': 'Tourism Forecasting Part Two', 'url': 'https://www.kaggle.com/competitions/tourism2', 'briefDescription': 'Part two requires competitors to predict 793 tourism-related time series. The winner of this competition will be invited to contribute a discussion paper to the International Journal of Forecasting.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'Tourism is one of the most rapidly growing global industries and tourism forecasting is becoming an increasingly important activity in planning and managing the industry. The time series in this competition have already been studied in detail in a paper by Athanasopoulos, Hyndman, Song and Wu (2010) (to be published in the International Journal of Forecasting). For parttwo of this contest, entrants must submit forecasts of the next 24 monthly and 8 quarterly\\xa0 observations for 793 time series. Forecasts will be evaluated against the actual future observations for each series.Results for part two will be evaluated on the basis of the average MASE across all series. The overall result will be calculated as the average MASE across all time series (from part one and part two of this competition).The overall winner will collect $AUD500 and will be invited to contribute a discussion paper to the International Journal of Forecasting describing their methodology and giving their results, provided either the monthly results are better than 1.38, the quarterly results are better than 1.43 or the yearly results are better than 2.28. These thresholds are the best performing methods in the analysis of these data described in Athanasopoulos et al (2010).\\xa0 In other words, the winner has to beat the best results in this paper for at least one of the three sets of series (note that 21 teams outdid the yearly threshold in part one of this competition). It will also be necessary that the winner be able to describe their method clearly, in sufficient detail to enable replication and in a form suitable for the International Journal of Forecasting. The paper would appear in the April 2011 issue of the IJF.Update 22 October: a correction was made to the data file. Please ensure that you build your models using tourism_data2_revision2.csv.'}, {'title': 'Tourism Forecasting Part One', 'url': 'https://www.kaggle.com/competitions/tourism1', 'briefDescription': 'Part one requires competitors to predict 518 tourism-related time series. The winner of this competition will be invited to contribute a discussion paper to the International Journal of Forecasting.', 'coverImageUrl': None, 'tag': 'custom metric', 'description': 'Tourism is one of the most rapidly growing global industries and tourism forecasting is becoming an increasingly important activity in planning and managing the industry. The time series in this competition have already been studied in detail in a paper by Athanasopoulos, Hyndman, Song and Wu (2010) (to be published in the International Journal of Forecasting). For part one of this contest, entrants must submit forecasts of the next four yearly observations. Forecasts will be tested against the actual future observations for each series.Results for part one will be evaluated on the basis of the average MASE across all series.Note, this is just part one of the competition. Part two will require entrants to forecast monthly and quarterly time series. The overall result will be calculated as the average MASE across all time series and across all frequencies. The overall winner will collect $AUD500 and will be invited to contribute a discussion paper to the International Journal of Forecasting describing their methodology and giving their results, provided either the monthly results are better than 1.38, the quarterly results are better than 1.43 or the yearly results are better than 2.28. These thresholds are the best performing methods in the analysis of these data described in Athanasopoulos et al (2010).\\xa0 In other words, the winner has to beat the best results in this paper for at least one of the three sets of series. It will also be necessary that the winner be able to describe their method clearly, in sufficient detail to enable replication and in a form suitable for the International Journal of Forecasting. The paper would appear in the April 2011 issue of the IJF.Update: The team Theta Benchmark (see the leaderboard), uses the best method from Athanasopoulos, Hyndman, Song and Wu (2010). '}, {'title': 'Chess ratings - Elo versus the Rest of the World', 'url': 'https://www.kaggle.com/competitions/chess', 'briefDescription': 'This competition aims to discover whether other approaches can predict the outcome of chess games more accurately than the workhorse Elo rating system.', 'coverImageUrl': None, 'tag': 'rmse', 'description': \"The Elo rating system was invented half a century ago by Hungarian-born physicist and chess master Arpad Elo. It is the most famous technique for rating chess players and is used throughout the chess world. It has been applied to many other contests as well, including other board games, sports, and video games.\\xa0 However, it has never really been demonstrated that the Elo approach to calculating chess ratings is superior.\\xa0 Elo's formula was derived theoretically, in an era without large amounts of historical data or significant computing power.\\xa0 With the benefit of powerful computers and large game databases, we can easily investigate approaches that might do better than Elo at predicting chess results.There are several alternatives to the Elo approach. Professor Mark Glickman developed the Glicko and Glicko-2 systems, which extend the Elo system by introducing additional parameters to represent the reliability and volatility of player ratings.\\xa0 Ken Thompson uses a linearly weighted average of a player's last 100 results to calculate a weighted performance rating.\\xa0 Jeff Sonas (who put together this competition) developed Chessmetrics ratings to maximize predictive power. More details are available on the hints page. We want to see if somebody out there can do even better.\\xa0 Competitors train their rating systems using a training dataset of over 65,000 recent results for 8,631 top players. Participants then use their method to predict the outcome of a further 7,809 games.Along with  the opportunity to help shape the future of chess ratings, the top ten entries  win the following prizes (assuming they share their methodology). 1. Fritz DVD autographed by world champions Viswanathan Anand, Garry Kasparov, Anatoly Karpov and Viktor Korchnoi (see image)2. ChessBase 10 Starter Package3. Big Database 20104. Kasparov: How to play the Queen's Gambit5. Anand - My Career (Vol 1 and 2)6. Kramnik - My Path to the Top7-10. $50 Amazon.com voucher Prizes 1-6 have been donated by Chessbase.Update: The team Elo Benchmark (see the leaderboard), uses the Elo rating system. Update 2: Thanks to Chessbase, we've got some new prizes up for grabs. Update 18 October: Some of the rules of this competition have not been explcitly stated, notably that:1. participants are restricted to two entries per day;2. the public leaderboard is calculated based on 20 per cent of the test dataset. The final standings are calculated based on the remaining 80 per cent of the test dataset; and3. the final standings are calculated based on participants' best (rather than last) entry. The best entry is the entry that scores highest on the 80 per cent of the test dataset that is used to calculate the final standings (which may different from the best entry on the public leaderboard).\"}, {'title': 'INFORMS Data Mining Contest 2010', 'url': 'https://www.kaggle.com/competitions/informs2010', 'briefDescription': 'The goal of this contest is to predict short term movements in stock prices. The winners of this contest will be honoured of the INFORMS Annual Meeting in Austin-Texas (November 7-10).', 'coverImageUrl': None, 'tag': 'auc', 'description': \"    The INFORMS Data Mining Section (in conjunction with Sinapse) is pleased to announce    its third annual data mining contest. This contest requires participants to develop    a model that predicts stock price movements at five minute intervals.    Competitors will be provided with intraday trading data showing stock price movements    at five minute intervals, sectoral data, economic data, experts' predictions and    indices. (We don’t reveal the underlying stock to prevent competitors from looking    up the answers.)    Being able to better predict short-term stock price movements would be a boon for    high-frequency traders, so the methods developed in this contest could have a big    impact on the finance industry.    We have provided a training database to allow participants to build their predictive    models. Participants will submit their predictions for the test database (which    doesn't include the variable being predicted). The public leaderboard will be calculated    based on 10 per cent of the test dataset.    See methods/techniques used by the top three competitors         here.    The winners of this contest will be honoured at a session of the INFORMS Annual    Meeting in Austin-Texas (November 7-10).\"}, {'title': 'World Cup 2010 - Confidence Challenge', 'url': 'https://www.kaggle.com/competitions/worldcupconf', 'briefDescription': 'The Confidence Challenge requires competitors to assign a level of confidence to their World Cup predictions. ', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"We are also running a World Cup 2010 - Take on the Quants Challenge. The Confidence Challenge requires competitors to predict how far each country will progress through the World Cup and then assign a level of confidence to each prediction. A competitor's score is weighted by their level of confidence. There are more details on the submission instructions page and the evaluation page. The competition closes just before the first game kicks off on June 11th. What is your incentive to enter?The winner of this challenge wins $USD100 to bet on the winner of the FIFA Golden Ball award. \"}, {'title': 'World Cup 2010 - Take on the Quants', 'url': 'https://www.kaggle.com/competitions/worldcup2010', 'briefDescription': 'Quants at Goldman Sachs and JP Morgan have modeled the likely outcomes of the 2010 World Cup. Can you do better?', 'coverImageUrl': None, 'tag': 'custom metric', 'description': \"Can you outdo the quants?As a break from projecting the strength of subprime mortgages, credit default swaps and other abstruse financial instruments, quantitative analysts at Goldman Sachs, JP Morgan, UBS and Danske Bank have modeled the 2010 soccer FIFA World Cup. We have set up a forecasting competition, allowing competitors to go head-to-head with these corporate giants. The challenge is to correctly predict how far each country will progress in the tournament. There is a small dataset and some links to variables of interest on the data page. There are links to the investment banks' predictions and other World Cup modeling efforts on the hints page.We are running two challenges side-by-side - a Take on the Quants Challenge and a Confidence Challenge. The Take on the Quants Challenge simply requires competitors to pick how far teams will progress in the tournament. Competitors' entries will be ranked against the predictions made by the investment banks. The Confidence Challenge requires competitors to assign a level of confidence to each prediction - a competitor's score is weighted by their level of confidence. Competitors enter both challenges with a single submission. There are more details on the submission instructions page and the evaluation page. The competition closes just before the first game kicks off on June 11th. What is your incentive to enter?The winner of each challenge wins $USD100 to bet on the winner of the FIFA Golden Ball award. However, far more enticing is the opportunity take on some of the best brains at the world's most venerable investment banks. \"}, {'title': 'Predict HIV Progression', 'url': 'https://www.kaggle.com/competitions/hivprogression', 'briefDescription': \"This contest requires competitors to predict the likelihood that an HIV patient's infection will become less severe, given a small dataset and limited clinical information. \", 'coverImageUrl': None, 'tag': 'mce', 'description': \"According to the World Health Organization, HIV has caused 25 millions deaths worldwide since it was first recognized in 1981. In recent years, the infection has been managed with a collection of therapies. However, the virus will likely evolve around these drugs, making it crucially important that we get a better understanding of the virus itself.\\xa0An important step in understanding the virus, is to get a handle on its genetic blueprint. This competition aims to do this by having contestants find markers in the HIV sequence which predict a change in the severity of the infection (as measured by viral load and CD4 counts).Models can be trained using the records of 1,000 patients. To predict an improvement in a patient's viral load, competitors will be provided with data on the nucleotide sequences of their Reverse Transcriptase (RT) their Protease (PR) and their viral load and CD4 count at the beginning of therapy. There is a brief discussion of the science of these variables in the Background section, but no knowledge of biology is necessary to succeed in this competition. Competitors' predictions will be tested on a dataset containing 692 patients. \\xa0 \\xa0 \\xa0 \\xa0\\xa0There is $USD500 up for grabs, and the winner(s) will also have the opportunity to co-author a paper with the competition host. The winner must supply their methodology before any prize money is awarded.\\xa0\"}, {'title': 'Forecast Eurovision Voting ', 'url': 'https://www.kaggle.com/competitions/Eurovision2010', 'briefDescription': \"This competition requires contestants to forecast the voting for this year's Eurovision Song Contest in Norway on May 25th, 27th and 29th. \", 'coverImageUrl': None, 'tag': 'ae', 'description': 'The intrigue of Eurovision - the modeller\\'s delightSince its inauguration in 1956, the Eurovision Song Contest has transfixed millions of viewers worldwide with its bubblegum pop, quirks, ballads and flops.\\xa0 During its tenure as one of the world\\'s longest-running television programs, it has attracted its fair share of controversy, with claims that the voting outcomes don\\'t simply reflect performance quality but are influenced by factors such as regional politics, expatriate populations, alliances, and artists\\' sexual appeal.\\xa0 Patterns have appeared over time which support this hypothesis. Contestants will attempt to exploit these patterns in order to predict the voting for the 2010 Eurovision Song Contest. Down to the detailsWe will provide you with publicly-available data on variables we have deemed potentially important, such as historical voting patterns, betting odds, song details and artist details.\\xa0 You are welcome to supplement this with any data you believe will improve the accuracy of your model.As the voting method for the Contest has changed over time, we will supply \\'Finals\\' data from 1998 when the current \"televoting\" format was implemented, and \\'semi-finals\\' data from 2004 when semi-finals were introduced.\\xa0 We will detail Eurovision\\'s voting procedures and their minor changes/exceptions pertinent to the provided data in the \\'Data\\' page of this competition. Your entry will involve submitting a matrix of the individual votes of each voting country for the competitor countries. What is your incentive to enter?There will be a cash prize of USD1000 for the contestant who produces the most accurate predictions. And just as the Contest has launched the high-flying careers of its own performers - notably ABBA and Céline Dion - creating a strong model for this competition will land you a top ranking as a modeler on the Kaggle website.'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "from retrying import retry\n",
    "import random\n",
    "import time\n",
    "import emoji\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": ua.random,   \n",
    "    \"cookie\": \"ka_sessionid=007c0ea4fa6fa02ca9285e4a6ab4f08d; _ga=GA1.2.845049904.1668501166; __Host-KAGGLEID=CfDJ8M8bzImQuQVBugV8xw6Jv2vz4D6IJmy5bZh_Ch9KTzXmos9PJYvn-9bI2gqmIGHETjK6rtoQIZpKEvHIKEQVh2pis-Q8RfmDe8GBBFToY7M6gX-MeU0DOeuD; CSRF-TOKEN=CfDJ8Gm7kp8NARJBjtS2astAKvSLOjDUOhO9z4XDb4Cs9Gt-fy7xDzbswtX5Y6kW8oWViWeP7FKF5V1fsGgfMC7Y1tWQMgK-463lzixwzHf15g; GCLB=CMaXzdfs0Z6gfA; _gid=GA1.2.660380570.1669293594; XSRF-TOKEN=CfDJ8Gm7kp8NARJBjtS2astAKvRLudml_uJExERBlejV-5z-k3tc_OnNSCtTAqMaScV9hLrT-SgDHFAlPZpEIj3CpEz5zxR81FFsm-8Ksgh8Luesgt0CLytPG_5XXaqz5JVlzQuClGMZoB3iomwgwqdmFJ0; CLIENT-TOKEN=eyJhbGciOiJub25lIiwidHlwIjoiSldUIn0.eyJpc3MiOiJrYWdnbGUiLCJhdWQiOiJjbGllbnQiLCJzdWIiOiJ5aW5ncWlhbmMiLCJuYnQiOiIyMDIyLTExLTI0VDEyOjQxOjAzLjUwODI3MDlaIiwiaWF0IjoiMjAyMi0xMS0yNFQxMjo0MTowMy41MDgyNzA5WiIsImp0aSI6IjA2YjRkZmY4LTViZDAtNDE3NS1hNWM3LWY3MmRhNzNkMTYyMSIsImV4cCI6IjIwMjItMTItMjRUMTI6NDE6MDMuNTA4MjcwOVoiLCJ1aWQiOjk5MDcwOTAsImRpc3BsYXlOYW1lIjoiWWluZ3FpYW5DIiwiZW1haWwiOiJ5aW5ncWlhbmNoZW4uY25AZ21haWwuY29tIiwidGllciI6Ik5vdmljZSIsInZlcmlmaWVkIjpmYWxzZSwicHJvZmlsZVVybCI6Ii95aW5ncWlhbmMiLCJ0aHVtYm5haWxVcmwiOiJodHRwczovL3N0b3JhZ2UuZ29vZ2xlYXBpcy5jb20va2FnZ2xlLWF2YXRhcnMvdGh1bWJuYWlscy9kZWZhdWx0LXRodW1iLnBuZyIsImZmIjpbIktlcm5lbHNEcmFmdFVwbG9hZEJsb2IiLCJLZXJuZWxzRmlyZWJhc2VQcm94eSIsIktlcm5lbHNHQ1NVcGxvYWRQcm94eSIsIktlcm5lbHNGaXJlYmFzZUxvbmdQb2xsaW5nIiwiS2VybmVsc1N0YWNrT3ZlcmZsb3dTZWFyY2giLCJDb21tdW5pdHlLbUltYWdlVXBsb2FkZXIiLCJUUFVDb21taXRTY2hlZHVsaW5nIiwiQWxsb3dGb3J1bUF0dGFjaG1lbnRzIiwiS2VybmVsc1NhdmVDZWxsT3V0cHV0IiwiS01MZWFybkRldGFpbCIsIkZyb250ZW5kQ29uc29sZUVycm9yUmVwb3J0aW5nIiwiUGhvbmVWZXJpZnlGb3JDb21tZW50cyIsIlBob25lVmVyaWZ5Rm9yTmV3VG9waWMiLCJMaWhwTmV4dFN0ZXBzIiwiTGlocE5leHRTdGVwc01ldHJpY3MiLCJLbUNvbXBzU3VibWlzc2lvblBhZ2UiLCJMZWFybkd1aWRlcyIsIkRhdGFzZXRzTWV0YWRhdGFUb0RhdGFUYWIiLCJEYXRhc2V0c1ZhbGlkYXRlVXBsb2FkZWRaaXBGaWxlcyIsIktlcm5lbEVkaXRvckhhbmRsZU1vdW50T25jZSJdLCJmZmQiOnsiS2VybmVsRWRpdG9yQXV0b3NhdmVUaHJvdHRsZU1zIjoiMzAwMDAiLCJGcm9udGVuZEVycm9yUmVwb3J0aW5nU2FtcGxlUmF0ZSI6IjAuMDEiLCJFbWVyZ2VuY3lBbGVydEJhbm5lciI6InsgfSIsIkNsaWVudFJwY1JhdGVMaW1pdCI6IjQwIiwiRmVhdHVyZWRDb21tdW5pdHlDb21wZXRpdGlvbnMiOiIzNTMyNSwzNzE3NCwzMzU3OSwzNzg5OCwzNzM1NCwzNzk1OSIsIkFkZEZlYXR1cmVGbGFnc1RvUGFnZUxvYWRUYWciOiJkYXRhc2V0c01hdGVyaWFsRGV0YWlsIn0sInBpZCI6ImthZ2dsZS0xNjE2MDciLCJzdmMiOiJ3ZWItZmUiLCJzZGFrIjoiQUl6YVN5QTRlTnFVZFJSc2tKc0NaV1Z6LXFMNjU1WGE1SkVNcmVFIiwiYmxkIjoiYWNiOWIxZTBkNjkxMGRkNzJjZDgyN2VhMGM4NzllZGYzYmJhOWY5ZSJ9.; _gat_gtag_UA_12629138_1=1\",\n",
    "    \"x-xsrf-token\": \"CfDJ8Gm7kp8NARJBjtS2astAKvRLudml_uJExERBlejV-5z-k3tc_OnNSCtTAqMaScV9hLrT-SgDHFAlPZpEIj3CpEz5zxR81FFsm-8Ksgh8Luesgt0CLytPG_5XXaqz5JVlzQuClGMZoB3iomwgwqdmFJ0\"\n",
    "}\n",
    "\n",
    "result = []\n",
    "\n",
    "@retry(stop_max_attempt_number=10, wait_random_min=1000, wait_random_max=2000)\n",
    "def get_info(resp):\n",
    "    base_url = 'https://www.kaggle.com/competitions/'\n",
    "    for i in resp['competitions']:\n",
    "        try:\n",
    "            comp = {}\n",
    "            url = base_url + i['competitionName']\n",
    "            html = requests.get(url, headers=headers).text\n",
    "\n",
    "            comp['title'] = i['title']\n",
    "            comp['url'] = url\n",
    "            comp['briefDescription'] = i['briefDescription']\n",
    "            \n",
    "            try:\n",
    "                comp['coverImageUrl'] = i['coverImageUrl']\n",
    "            except:\n",
    "                comp['coverImageUrl'] = None\n",
    "                \n",
    "            try:\n",
    "                tag_info = re.findall('\"tags\":(.*?)]', html, re.S)[0]\n",
    "                tag = re.findall('\"name\":\"(.*?)\",', tag_info, re.S)\n",
    "                tag = ', '.join(tag)\n",
    "            except:\n",
    "                tag = None\n",
    "            comp['tag'] = tag\n",
    "          \n",
    "            des_info = re.findall('\"pages\":(.*)</script>', html, re.S)[0]\n",
    "            des = re.findall('\"content\":\"(.*)\",.*?\"name\":\"[dD]escription\"', des_info, re.S)[0]\n",
    "            while des.find('\"content\":') != -1:\n",
    "                index = des.find('\"content\"')\n",
    "                des = re.findall('\"content\":\"(.*)', des[index:], re.S)[0]\n",
    "            if des.find('\",\"') != -1:\n",
    "                des = des[:des.find('\",\"')]\n",
    "            des = des.encode().decode(\"unicode_escape\")\n",
    "            des =  BeautifulSoup(des,'lxml').text.replace('\\n', '')\n",
    "            comp['description'] = des\n",
    "            \n",
    "            print('正在爬取{}'.format(i['competitionName']))\n",
    "            result.append(comp)\n",
    "        except:\n",
    "            print(url)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t = random.random()\n",
    "    url = \"https://www.kaggle.com/api/i/competitions.CompetitionService/ListCompetitions\"\n",
    "    data = '{\"selector\":{\"competitionIds\":[],\"listOption\":\"LIST_OPTION_DEFAULT\",\"sortOption\":\"SORT_OPTION_NEWEST\",\"hostSegmentIdFilter\":0,\"searchQuery\":\"\",\"prestigeFilter\":\"PRESTIGE_FILTER_UNSPECIFIED\",\"participationFilter\":\"PARTICIPATION_FILTER_UNSPECIFIED\",\"tagIds\":[],\"requireSimulations\":false},\"pageToken\":\"\",\"pageSize\":20,\"readMask\":\"competitions,totalResults\"}'\n",
    "    resp = requests.post(url, data, headers = headers).json()\n",
    "    get_info(resp)\n",
    "    time.sleep(t)\n",
    "    for i in range(1, 28):\n",
    "        data = '{\"selector\":{\"competitionIds\":[],\"listOption\":\"LIST_OPTION_DEFAULT\",\"sortOption\":\"SORT_OPTION_NEWEST\",\"hostSegmentIdFilter\":0,\"searchQuery\":\"\",\"prestigeFilter\":\"PRESTIGE_FILTER_UNSPECIFIED\",\"participationFilter\":\"PARTICIPATION_FILTER_UNSPECIFIED\",\"tagIds\":[],\"requireSimulations\":false},'+'\"pageToken\":\"{}\",'.format(i*20)+'\"pageSize\":20,\"readMask\":\"competitions,totalResults\"}'''\n",
    "        resp = requests.post(url, data, headers = headers).json()\n",
    "        get_info(resp)\n",
    "        time.sleep(t)\n",
    "    print(result)\n",
    "    pd.DataFrame(result).to_csv('kaggle_competition.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42163dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>briefDescription</th>\n",
       "      <th>coverImageUrl</th>\n",
       "      <th>tag</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTTO – Multi-Objective Recommender System</td>\n",
       "      <td>https://www.kaggle.com/competitions/otto-recom...</td>\n",
       "      <td>Build a recommender system based on real-world...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-competit...</td>\n",
       "      <td>retail and shopping, recommender systems, weig...</td>\n",
       "      <td>## Goal of the CompetitionThe goal of this com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tabular Playground Series - Nov 2022</td>\n",
       "      <td>https://www.kaggle.com/competitions/tabular-pl...</td>\n",
       "      <td>Practice your ML skills on this approachable d...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-competit...</td>\n",
       "      <td>tabular, ensembling, logloss</td>\n",
       "      <td>You may have heard that blending predictions f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scrabble Player Rating</td>\n",
       "      <td>https://www.kaggle.com/competitions/scrabble-p...</td>\n",
       "      <td>Predict players' ratings based on Woogles.io g...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-competit...</td>\n",
       "      <td>tabular, rmse</td>\n",
       "      <td>Are you a Kaggle Scrabble Grandmaster? In the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFL Big Data Bowl 2023</td>\n",
       "      <td>https://www.kaggle.com/competitions/nfl-big-da...</td>\n",
       "      <td>Help evaluate linemen on pass plays</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-competit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>##Goal of the CompetitionThe National Football...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022 Kaggle Machine Learning &amp; Data Science Su...</td>\n",
       "      <td>https://www.kaggle.com/competitions/kaggle-sur...</td>\n",
       "      <td>The most comprehensive dataset available on th...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-competit...</td>\n",
       "      <td>data analytics, online communities, survey ana...</td>\n",
       "      <td>**Welcome to Kaggle's annual Machine Learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>INFORMS Data Mining Contest 2010</td>\n",
       "      <td>https://www.kaggle.com/competitions/informs2010</td>\n",
       "      <td>The goal of this contest is to predict short t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auc</td>\n",
       "      <td>The INFORMS Data Mining Section (in conjun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>World Cup 2010 - Confidence Challenge</td>\n",
       "      <td>https://www.kaggle.com/competitions/worldcupconf</td>\n",
       "      <td>The Confidence Challenge requires competitors ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>custom metric</td>\n",
       "      <td>We are also running a World Cup 2010 - Take on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>World Cup 2010 - Take on the Quants</td>\n",
       "      <td>https://www.kaggle.com/competitions/worldcup2010</td>\n",
       "      <td>Quants at Goldman Sachs and JP Morgan have mod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>custom metric</td>\n",
       "      <td>Can you outdo the quants?As a break from proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Predict HIV Progression</td>\n",
       "      <td>https://www.kaggle.com/competitions/hivprogres...</td>\n",
       "      <td>This contest requires competitors to predict t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mce</td>\n",
       "      <td>According to the World Health Organization, HI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Forecast Eurovision Voting</td>\n",
       "      <td>https://www.kaggle.com/competitions/Eurovision...</td>\n",
       "      <td>This competition requires contestants to forec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ae</td>\n",
       "      <td>The intrigue of Eurovision - the modeller's de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0            OTTO – Multi-Objective Recommender System   \n",
       "1                 Tabular Playground Series - Nov 2022   \n",
       "2                               Scrabble Player Rating   \n",
       "3                               NFL Big Data Bowl 2023   \n",
       "4    2022 Kaggle Machine Learning & Data Science Su...   \n",
       "..                                                 ...   \n",
       "543                   INFORMS Data Mining Contest 2010   \n",
       "544              World Cup 2010 - Confidence Challenge   \n",
       "545                World Cup 2010 - Take on the Quants   \n",
       "546                            Predict HIV Progression   \n",
       "547                        Forecast Eurovision Voting    \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://www.kaggle.com/competitions/otto-recom...   \n",
       "1    https://www.kaggle.com/competitions/tabular-pl...   \n",
       "2    https://www.kaggle.com/competitions/scrabble-p...   \n",
       "3    https://www.kaggle.com/competitions/nfl-big-da...   \n",
       "4    https://www.kaggle.com/competitions/kaggle-sur...   \n",
       "..                                                 ...   \n",
       "543    https://www.kaggle.com/competitions/informs2010   \n",
       "544   https://www.kaggle.com/competitions/worldcupconf   \n",
       "545   https://www.kaggle.com/competitions/worldcup2010   \n",
       "546  https://www.kaggle.com/competitions/hivprogres...   \n",
       "547  https://www.kaggle.com/competitions/Eurovision...   \n",
       "\n",
       "                                      briefDescription  \\\n",
       "0    Build a recommender system based on real-world...   \n",
       "1    Practice your ML skills on this approachable d...   \n",
       "2    Predict players' ratings based on Woogles.io g...   \n",
       "3                  Help evaluate linemen on pass plays   \n",
       "4    The most comprehensive dataset available on th...   \n",
       "..                                                 ...   \n",
       "543  The goal of this contest is to predict short t...   \n",
       "544  The Confidence Challenge requires competitors ...   \n",
       "545  Quants at Goldman Sachs and JP Morgan have mod...   \n",
       "546  This contest requires competitors to predict t...   \n",
       "547  This competition requires contestants to forec...   \n",
       "\n",
       "                                         coverImageUrl  \\\n",
       "0    https://storage.googleapis.com/kaggle-competit...   \n",
       "1    https://storage.googleapis.com/kaggle-competit...   \n",
       "2    https://storage.googleapis.com/kaggle-competit...   \n",
       "3    https://storage.googleapis.com/kaggle-competit...   \n",
       "4    https://storage.googleapis.com/kaggle-competit...   \n",
       "..                                                 ...   \n",
       "543                                                NaN   \n",
       "544                                                NaN   \n",
       "545                                                NaN   \n",
       "546                                                NaN   \n",
       "547                                                NaN   \n",
       "\n",
       "                                                   tag  \\\n",
       "0    retail and shopping, recommender systems, weig...   \n",
       "1                         tabular, ensembling, logloss   \n",
       "2                                        tabular, rmse   \n",
       "3                                                  NaN   \n",
       "4    data analytics, online communities, survey ana...   \n",
       "..                                                 ...   \n",
       "543                                                auc   \n",
       "544                                      custom metric   \n",
       "545                                      custom metric   \n",
       "546                                                mce   \n",
       "547                                                 ae   \n",
       "\n",
       "                                           description  \n",
       "0    ## Goal of the CompetitionThe goal of this com...  \n",
       "1    You may have heard that blending predictions f...  \n",
       "2    Are you a Kaggle Scrabble Grandmaster? In the ...  \n",
       "3    ##Goal of the CompetitionThe National Football...  \n",
       "4    **Welcome to Kaggle's annual Machine Learning ...  \n",
       "..                                                 ...  \n",
       "543      The INFORMS Data Mining Section (in conjun...  \n",
       "544  We are also running a World Cup 2010 - Take on...  \n",
       "545  Can you outdo the quants?As a break from proje...  \n",
       "546  According to the World Health Organization, HI...  \n",
       "547  The intrigue of Eurovision - the modeller's de...  \n",
       "\n",
       "[548 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('kaggle_competition.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
